{
  "nodes": [
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.173Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "2023-08-06",
      "content": "Recently had the surprise charge of $70 of Dataroom domains updating. Decided I'm going to turn it into an editor ala Obsidian, but using my syncing tools I have developed. \n\nIt will handle file sizes big enough for AI images -- maybe 2mb max. \n\nIt will allow zipping and uploading of files, \n\n[[Context Switcher]] - numbers 0 - 9. Number 0 opens [[Sync, Save and Export]] [[Notebooks]] ,[[Manual]],[[Settings]]  page. \n \n9 opens the 3d visualization of that notebook\n\n[[Notebooks]] -- users can have multiple notebooks. Each notebook has a unique id. User selects id via link. Reload when user switches notebook.\n\n[[Router]] everything generates a link. so when user switches context they \n\n1 -9 free spaces\nEach one has 3 contexts users can switch\nEach context on each page has a unique id that stores: loaded file and state.\n\n\n[[3d view]], showing that page and links 2 steps \neditor view\n\n[[Editor]] [[Rendered View]]\n\n \n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.173Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Settings",
      "content":"blerge"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.181Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "3d Force Graph",
      "content": "```html\n<!DOCTYPE html>\n<html>\n<head>\n\t<meta charset=\"utf-8\">\n\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  <script src=\"//unpkg.com/3d-force-graph\"></script>\n\n\t<title>DATAROOM.NETWORK</title>\n</head>\n<body>\n  <div id=\"3d-graph\"></div>\n\n\t<button style=\"position:fixed;left:1em; top:1em; z-index:1000\" id=\"save_json_file\">save</button>\n\t<button style=\"position:fixed;left:1em; top:4em; z-index:1000\" id=\"new_node\">add node</button>\n\n<script type=\"module\">\n\n\n\nconst elem = document.getElementById(\"3d-graph\");\n\nconst Graph = ForceGraph3D()(elem)\n    .enableNodeDrag(true)\n    .nodeLabel('id')\n    .jsonUrl('/files/index.json')\n\n    .onNodeDragEnd(node => {\n    \tconsole.log(node)\n      node.fx = node.x;\n      node.fy = node.y;\n      node.fz = node.z;\n    })\n\n\tnew_node.onclick = () => {\n\t  const { nodes, links } = Graph.graphData();\n\t  const id = nodes.length;\n\t  Graph.graphData({\n\t    nodes: [...nodes, { id }],\n\t    links: [...links, { source: id, target: Math.round(Math.random() * (id-1)) }]\n\t  })\n\n\t}\n\n\n\nfunction addNode(node){\n\tconst { nodes } = Graph.graphData()\n\tconst id = nodes.length\n\tGraph.graphData({\n\t\tnodes: [...nodes, {id}],\n\t})\n}\n\nfunction addLink(link){\n\n}\n\nfunction removeNode(node) {\n  let { nodes, links } = Graph.graphData();\n  links = links.filter(l => l.source !== node && l.target !== node); // Remove links attached to node\n  nodes.splice(node.id, 1); // Remove node\n  nodes.forEach((n, idx) => { n.id = idx; }); // Reset node ids to array index\n  Graph.graphData({ nodes, links });\n}\n\n\nsave_json_file.onclick = function(){\n\n\tlet new_json = Graph.graphData()\n\tnew_json.links = new_json.links.map(link =>{\n\t\treturn {id:link.id, source:link.source.id, target:link.target.id}\n\t})\n\n\tconsole.log(new_json.links)\n\tconst options = {\n    method: 'POST',\n    body: JSON.stringify(new_json),\n    headers: {\n        'Content-Type': 'application/json'\n\t\t}\n\t}\n\n\tfetch('/save-graph/index.json', options)\n\t    .then(res => res.json())\n\t    .then(res => console.log(res));\n}\n\n\n\n\n\n</script>\n\n<script type=\"module\">\n\n\n\n</script>\n</body>\n</html>\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.182Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "3d view",
      "content": "3D View: \n\nCentral notebook context, \nall hashtags \nSetting to render depth of page -- searches each file\n\nuses [[Construct Graph]]  web folder\n\nEmbeddings should have their own 3d rendered shapes. Perhaps AI generated at first? \n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.183Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "A Controversial Tutorial about Javascript, HTML and CSS",
      "content": "There is a lot of misinformation about JavaScript, also known as EcmaScript or ES6 or JS. Here is my contribution to it. \n\nI have been slinging web since before there was such a thing as CSS or JS. Since the 90's, JS CSS and HTML has grown into a beautiful, powerful framework that runs on billions of devices. It has absorbed concepts and ideas from COBOL to LISP. \n\nIt is still relatively esoteric, alas. It is my hope that I may demystify a few things and suggest a few ways we in the JS world can do things differently. You shouldn't see me as the be all end all of Web Development, but you shouldn't see those other guys like that, either. In the end, programming is about \n\nA large drawback to our current information eco-system is that people don't understand vanilla JS, HTML and CSS at this moment. \n\n[[Cobol and HTML]]\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.183Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "AI Devices",
      "content": "Setup, documented. \n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.184Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "AI",
      "content": "\n2024-02-01\n\nhttps://www.axios.com/2024/02/01/allen-institute-for-ai-fully-open-source-large-language-model-olmo-7b\n\nhttps://allenai.org/olmo\n\n# Allen Institute for AI releases fully open-source large language model\n\n\n![logo for the new open language model from AI2: OLMo 7B](https://images.axios.com/dJk1RpMkqzVeLr1qqdwEvsEJa54=/0x0:2752x1548/1920x1080/2024/02/01/1706748125569.png?w=1920)\n\nImage: Allen Institute for AI\n\nThe Allen Institute for AI (AI2) released a fully open-source large language model designed to help researchers better understand what's taking place under the hood.\n\n**Why it matters:** The move comes as [some have argued](https://www.axios.com/2023/12/05/open-source-ai-fights-back) open-source alternatives are needed to avoid concentration of power, while [others worry](https://www.axios.com/2023/12/13/open-source-ai-white-house-ntia) that such models could be harder to regulate.\n\n**Details**: OLMo 7B, as the [model](https://allenai.org/olmo) is known, was created with support from AMD, Databricks, and researchers at Harvard and the University of Washington.\n\n- AI2 (created by Microsoft co-founder Paul Allen) is going further than most companies offering open source models, releasing not only the model and its weights, but also its full training data and pre-training code.\n- OLMo 7B will be available for direct download on [Hugging Face](https://huggingface.co/allenai) and via GitHub.\n- OLMo stands for \"open language model.\"\n\n**Between the lines:** Releasing so much data, along with the models themselves, allows researchers to better understand how such systems work, the Allen Institute says.\n\n- For example, one can see whether a model has truly learned a new set of skills or just memorized answers to a particular test.\n- More open models, which include training and evaluation systems, could also eliminate redundancies that drive up environmental impacts of AI, the Allen Institute says, noting that a typical training run for a large language model is equivalent to full-year emissions from nine U.S. homes.\n\n**What they're saying:** AI2 CEO Ali Farhadi says having a truly open, state-of-the-art large language model will \"fundamentally change how researchers and developers learn about and build AI.\"\n\n- \"Access to truly open models has never been more critical for the development of AI,\" Farhadi said in a statement to Axios.\n\n- While commercialization isn't inherently bad, Farhadi said the limited transparency offered by [many large language models](https://www.axios.com/2023/06/26/ais-next-battle-open-closed-chatgpt) made it hard to assess performance as well as issues related to toxicity and bias.\n- Executives from Meta and AMD praised the Allen Institute's effort. \"Open foundation models have been critical in driving a burst of innovation and development around generative AI,\" Meta chief AI scientist Yann LeCun said in a statement.\n- Meta has been a vocal advocate for open-source AI and has [released its Llama 2 model for commercial use](https://www.axios.com/2023/07/18/meta-llama-2-release-commercial-use). \"The vibrant community that comes from open source is the fastest and most effective way to build the future of AI,\" LeCun said.\n\n---\n\n\nhttps://evalplus.github.io/leaderboard.html\n\nhttps://deepseekcoder.github.io/\n\nhttps://blog.research.google/2024/01/mobilediffusion-rapid-text-to-image.html\n\nhttps://mitenmit.github.io/gpt/\n\n--- \n\nhttps://itnext.io/you-can-build-a-neural-network-in-javascript-even-if-you-dont-really-understand-neural-networks-e63e12713a3\n\n---\n\nhttps://franpapers.com/en/machine-learning-ai-en/2017-neural-network-implementation-in-javascript-by-an-example/\n\n\n\nPosted on [15 October 201728 November 2017](https://franpapers.com/en/machine-learning-ai-en/2017-neural-network-implementation-in-javascript-by-an-example/) by François Andrieux\n\nRead in:\n\n-   [Français](https://franpapers.com/fr/machine-learning-ai-fr/2017-implementation-dun-reseau-de-neurones-en-javascript-a-travers-un-exemple/)\n-   [English](https://franpapers.com/en/machine-learning-ai-en/2017-neural-network-implementation-in-javascript-by-an-example/)\n\nNeural networks are an exciting subject that I wanted to experiment after that I took up on [genetic algorithms](https://franpapers.com/en/2017-genetic-algorithm-used-for-linear-regression-over-acceleration/). Here is related my journey to implement a neural network in JavaScript, through a **visual example** to better understand the notion of automatic learning. You can find the [complete code](https://github.com/Spriteware/machinelearning/blob/master/mouse_experiment.js) of this example and its [neural net implementation](https://github.com/Spriteware/neural-network) on Github, as well as the [full demo](https://jsfiddle.net/franpapers/9hnwLpm5/) on JSFiddle. The article is divided into three parts:\n\n1.  Governing principle: a circle that learns to follow the mouse\n2.  How to a make a model which performs well\n3.  JavaScript implementation\n\nIf you are new in the machine learning field, here is some video resources that I would recommend for learning about neural networks:\n\n-   [Lecture 12a: Neural Nets by MIT](https://www.youtube.com/watch?v=uXt8qF2Zzfo) (math approach)\n-   [Neural Networks (part 1) by macheads101](https://www.youtube.com/watch?v=P02xWy63Q6U) (friendly approach)\n-   [Neural Networks: Perceptron (part 1) by Daniel Shiffman ](https://youtu.be/ntKn5TPHHAk) (friendly Javascript approach)\n\n## A circle that learns to follow the mouse\n\nThe example is not an example of classification, but rather of **linear regression** . I drew a circle in an HTML5 canvas and I now wish that this circle learns to follow the movements of the mouse until completely copying its position. I would like to send as input of my artificial intelligence the position of the mouse and recover the output of the position of my circle:\n\n![Illustration de l'apprentissage dans notre exemple fil rouge](media/Illustration_de_l'apprentissage_dans_notre_exemple_fil_rouge.png)\n\nIllustration of our example and desired result\n\nIn other words, the [neural network](https://en.wikipedia.org/wiki/Artificial_neural_network) (or NN) must learn to output its own input_._ Mathematically, we try in some way to approximate `f([x, y]) = [x', y']` or ‘identity function’. In the literature, this kind of neural network is a special [auto-encoder](https://en.wikipedia.org/wiki/Autoencoder) (but our goal is not to reduce dimension).\n\nThe advantage of this example is that we are sure that the whole problem can be solved with input neurons and two output neurons. However, at least one intermediate layer (_hidden layer_ ) otherwise it has no interest. The game’s goal is to set up the [backpropagation](https://en.wikipedia.org/wiki/Backpropagation) and really understand step by step how a neural net modifies it weights to get to its purpose.\n\n### Neural network training steps\n\n1.  The mouse changes its position\n2.  **Feedforwarding**: the NN calculates the new position of the circle\n3.  **Backpropagation**: the NN adjusts its weights to reduce the difference between the position of the circle and the position of the mouse\n4.  Restart\n\nIn the idea, the position of the circle should tend towards the position of the mouse. The experimentation allow to **visualize** the learning process since that when the NN **converges towards its solution**, the circle **converges** **visually** **towards the location** of the mouse. Here’s the result in video:\n\nIn this video, I discuss about the neural net training in 2 parts: a first **live-training** (the user has to move the mouse so that the neural network learns instantaneously) and the second with a **pre-training** based on a dataset. _In fact, the live training onto the video is way slower that the actual model. I invite you to try the experimentation further down in the page to see the difference in performance ([or directly on JSFiddle](https://jsfiddle.net/franpapers/9hnwLpm5/))._ _It was while I was writing the importance of normalization (implementation part of this article) that I suddenly noticed that performance improvements were possible.  \n_\n\nLet’s take a look a the neural net of the first part:\n\n![](media/neural-network-part1-hd-1024x309.png)\n\nVisualization of the weights of the trained neural network\n\nWhat’s interesting is to visualize how the network has finally “distributed” its two entries to the intermediate layer, which it will “reassemble” these two inputs to send them out. One can almost trace a path by looking at the most important weights:\n\n![](media/neural-network-part1-explained-1024x309.png)\n\nBy identifying the main weights of the neural network, two paths are spotted\n\nBy checking we realize that `0.4 * 0.9165 * 1.1456 ~= 0.41` while `-0.3 * 0.8663 * 1.2139 ~= -0.31`. What is interesting to see is how the NN modify itself to focus on one weight instead of two, and how it disregards biases (value between -1 and 1 added to the calculation of each neuron). The result of these weights combination do not give exactly 0.4 or -0.3 because they also correct the parasites generated by others, insignificant weights.\n\n![](media/sieve-explanation-201x300.png)\n\nThe stack of sieve analogy\n\nOn the other hand, with more neurons and more layers (eg 2 • 6 • 6 • 6 • 2), it’s much harder to identify a given path, since the two x and y information are much more scattered between the neurons and layers.\n\nIf we had to make an analogy, then I would say that in our case the NN is a formidable stack of sieves to which one passes grains of sand: well differentiated blue and green before the first sieve, the two types of grains mix in the intermediate layers but finish again separated by their color at the exit of the last layer.\n\nYou can even experiment yourself the video example using the JSFiddle below :\n\nNote that it is possible to vary the network’s hyperparameters and change its structure.\n\n## Make a model which perform well\n\nLet us now turn our attention to the development of our neural network. It’s possible to improve its learning and to act on the speed of convergence of the circle towards the mouse by adjusting the hyperparameters :\n\n-   The **learning rate,** which is an important factor in [gradient](https://en.wikipedia.org/wiki/Gradient) calculations, at the heart of backpropagation;\n-   The **activation function** which “filters” the output value of a neuron;\n-   The number of _hidden layers_ , and the amount of neurons on each _layer_\n\nThese parameters are making it possible to improve the performance of the model, but the most determining factor is still the choice of input data and what’s desired at the output.\n\n#### THE IMPORTANCE OF normalization\n\nIn our case there isn’t really too much to think about the nature of the input data and output data: we chose to have in input the mouse’s coordinates and in output the circle’s ones because it’s directly what we have available (input) and what we want (output).\n\nOn the other hand, we can’t send the mouse’s coordinates _directly_ without first normalizing them. Knowing that the output error ([_mean squared error_](https://en.wikipedia.org/wiki/Mean_squared_error)) is calculated such that `mse = 1/2 * (target - output)²` , with `target` our wanted value,  `(target - output)²` has to be bounded between 0 and 1 inclusive no matter `output` in order to prevent the error from increasing exponentially. For this, and knowing that our reference is centered, we divide the values ​​of abscissa by the half width of the canvas and the values ​​of ordinates by half its height.\n\n![](media/normalization-300x103.png)\n\nI invite you to test to normalize with 2 times the norm on each axis: your values ​​will therefore be in the interval [-0.5, 0.5] and the neural net will learn much less quickly because of smaller variations and therefore less “quantified” by the quadratic error.\n\nWithout normalization, incoherent error calculations are quickly obtained during backpropagation: errors explode, weights also and quickly the network is saturated. Although in the example the activation function is linear, in many cases (`tanh` , `sigmoid` , etc …) there’s no difference between 2 large values superior to 1. For example, at coordinates (300, 200) <=> (0.257, 0.171) normalized we have:\n\n-   `tanh(300) = 1` while `tanh(0.257) = 0.251`\n-   `tanh(200) = 1` while `tanh(0.171) = 0.169`\n\nHence the importance of normalizing its input values, but also favoring output values ​​between -1 and 1 to avoid the propagation of a too big error.\n\n#### Learning rate influence\n\nOverall, I often experimentally vary the learning rate on a logarithmic scale: _0.5_ , _0.05_ , _0.005_ , etc.\n\nIt’s completely possible to visualize the impact of a learning rate too low on learning (much slower): the circle struggles to follow the mouse and the live-training can really take a long time. By using pre-training, the difference is however hardly noticeable.\n\nSimilarly, a learning rate too large prevents the network of neurons from going to the end of its learning because of too big gradients in the backpropagation. This happens especially when there are a lot of intermediaries between input and output (ie. when there are many hidden layers and neurons).\n\n#### choose the activation function\n\nI have to say that I have not set up many different activation functions on the intermediate layers (**sigmoid, tanh and ReLU**) and my tests have shown that to solve this problem, the neural network works terribly better with a simple linear function. Tanh showed results, however not very interesting because of a much longer learning time than the linear. Sigmoid and ReLU showed no results.\n\nAnd this makes sense: sigmoid works badly because we work in the interval [-1, 1] while the sigmoid arrival set is [0, 1[. Similarly, ReLU does not take into account our negative values. These activation functions probably work better on classification problems but limit too much the values ​​on a linear regression problem.\n\n#### influence of the quantity of neurons\n\nThe above ‘sieve analogy’ is even more impressive (almost magical) when increasing the number of layers and neurons. Concretely, because of the simplicity of our example there’s no interest in increasing the number of intermediate layers apart from adding computational complexity and slowness.\n\nNevertheless, it is always impressive to see how the network can still find a solution even with a slightly deeper topology such as 2 • 6 • 6 • 6 • 6 • 6 • 6 • 6 • 2. In this case, it’s no longer possible to train live as in the video, unless you have a lot of time… **Don’t forget to activate backpropagation :  \n**\n\n## JavaScript Implementation\n\nThis whole example has been the governing principle to carry out my own implementation of a neural network in Javascript. The choice of Javascript is simply to have something working in the browser and the ability to create an interactive visualization.\n\nFinally, this is the starting point of a reusable implementation -or mini library- for other projects, of which you can find the integral [code on Github](https://github.com/Spriteware/neural-network).\n\n### Why not use an existing library?\n\nI have tested [ConvNetJS](http://cs.stanford.edu/people/karpathy/convnetjs/) written by [Andrej Karpathy](https://twitter.com/karpathy), but impossible to make it work initially due to my lack of knowledge. I needed to put my hands in the sludge myself to actually know how to handle a neural network library. I haven’t tried to use the library or another since, it would be interesting to compare results and performance with my implementation. But I also learned that every library (no matter what language / platform) makes its own algorithm implementation choices and that will ensure significant differences depending on the choices, making it difficult to compare.\n\nI wanted this implementation to be simple and focused around the basic idea of the main algorithms (_feedforwarding_ , _backpropagation_ , etc …) so that another beginner can, by reading the code, quickly understand. On the other hand, setting up a web worker to do the pre-training was necessary to avoid blocking the main thread in the browser for the pre-training, and thus have a better experience.\n\n### DaTa structure\n\nNeurons and network are in the form of prototyped objects:\n\nfunction Neuron(id, layer, biais) {\n\n    this.id = id;\n    this.layer = layer;\n    this.biais = biais || 0;\n    this.dropped = false;\n\n    this.output = undefined;\n    this.error = undefined;\n\n    this.activation = undefined;\n    this.derivative = undefined;\n};\n\n////////////////////////////////////////////\n\nfunction Network(params) {\n\n    // Required variables: lr, layers\n    this.lr = undefined; // Learning rate\n    this.layers = undefined;\n    this.hiddenLayerFunction = undefined; // activation function for hidden layer\n\n    this.neurons    = undefined;\n    this.weights    = undefined; \n    \n    \n    // ... load params\n}\n\nWeight and neurons are stored in 2 one-dimensional arrays for speed and flexibility reasons: I don’t find that multi-dimensional arrays are always the easiest to handle and operations on a one-dimensional array are generally more optimized by JS engines.\n\n### Random Selection\n\nWeights and bias are initialized between -1 and 1. According to my tests, picking up weights doesn’t have too much influence on performance, because in majority all converge towards their good value rather quickly (depending on the learning rate).\n\nfunction randomBiais() {\n    return Math.random() * 2 - 1;\n}\n\nfunction randomWeight() {\n    return Math.random() * 2 - 1;\n}\n\nOn the other hand, it’s necessary to take into account biases as weights in backpropagation and to adjust their value so that the network comes to a solution (since the function to be approximated is identity and doesn’t require constants in the equations). Thus, it’s possible for this example to disable biais (`randomBiais = () => 0;`).\n\n### Feedforward AND backpropagation\n\nFeed-forwarding is simple. The only implemented “optimization” is to avoid recovering for each neuron the array of neurons of the previous layer. This array is kept until current layer changes (lines 14/15 below). I first handle inputs neurons as special cases, then feed-forward through all the global neurons array (hence the interest of having a one-dimensional array) from the second layer:\n\n// Input layer filling\nfor (index = 0; index < this.layers[0]; index++)\n    this.neurons[index].output = inputs[index];\n\n// Fetching neurons from second layer (even if curr_layer equals 0, it'll be changed directly)\nfor (index = this.layers[0]; index < this.nbNeurons; index++)\n{\n    neuron = this.neurons[index];\n\n    if (neuron.dropped)\n        continue;\n\n    // Update if necessary all previous layer neurons. It's a cache\n    if (prev_neurons === undefined || neuron.layer !== curr_layer)\n        prev_neurons = this.getNeuronsInLayer(curr_layer++);\n\n    // Computing w1*x1 + ... + wn*xn\n    for (sum = 0, n = 0, l = prev_neurons.length; n < l; n++) {\n        if (!prev_neurons[n].dropped)\n            sum += this.getWeight(prev_neurons[n], neuron) * prev_neurons[n].output;\n    }\n\n    // Updating output    \n    neuron.output = neuron.activation(sum + neuron.biais); \n}\n\nThe backpropagation implementation is more dense. Again, I prefer to first handle particular neurons (the output ones) to calculate the error, then to iterate on each neuron to recalculate each weight:\n\n// Output layer error computing: err = (expected-obtained)\nfor (n = 0, l = outputs_neurons.length; n < l; n++)\n{\n    neuron = outputs_neurons[n];\n    grad = neuron.derivative(neuron.output);\n    err = targets[n] - neuron.output;\n    neuron.error = grad * err;\n    output_error += Math.abs(neuron.error);\n\n    // Update biais \n    neuron.biais = neuron.biais + this.lr * neuron.error;        \n}\n\nthis.outputError = output_error;\n\n// Fetching neurons from last layer\nfor (index = this.layersSum[curr_layer-1] - 1; index >= 0; index--)\n{\n    neuron = this.neurons[index];\n\n    // Dropping neuron is a technique to add dynamic into training\n    if (neuron.dropped)\n        continue;\n\n    // Update if necessary all next layer neurons. It's a cache\n    if (next_neurons === undefined || neuron.layer !== curr_layer)\n        next_neurons = this.getNeuronsInLayer(curr_layer--);\n\n    // Computing w1*e1 + ... + wn*en\n    for (sum = 0, n = 0, l = next_neurons.length; n < l; n++) {\n        if (!next_neurons[n].dropped)\n            sum += this.getWeight(neuron, next_neurons[n]) * next_neurons[n].error;\n    }\n\n    // Updating error    \n    neuron.error = sum * neuron.derivative(neuron.output); \n    this.globalError += Math.abs(neuron.error); \n\n    // Update biais\n    neuron.biais = neuron.biais + this.lr * neuron.error;\n\n    // Updating weights w = w + lr * en * output\n    for (n = 0, l = next_neurons.length; n < l; n++)\n    {\n        if (next_neurons[n].dropped)\n            continue;\n        weight_index = this.getWeightIndex(neuron, next_neurons[n]); \n\n        // Update current weight\n        weight = this.weightsTm1[weight_index] + this.lr * next_neurons[n].error * neuron.output;\n\n        // Update maxWeight (for visualisation)\n        max_weight = max_weight < Math.abs(weight) ? Math.abs(weight) : max_weight;\n\n        // Finally update weights\n        this.weights[weight_index] = weight;\n    }\n}\n\nYou can find the full implementation on [Github](https://github.com/Spriteware/neural-network/blob/master/neural-network.js) at `Network.prototype.feed()` and `Network.prototype.backpropagate()`\n\n### Training\n\nAs mentionned above, I used [WebWorkers](https://developer.mozilla.org/fr/docs/Utilisation_des_web_workers#API_Web_Workers) API to perform neural network training in a separate thread, with the goa to avoid blocking the page during processing. Since the memory isn’t shared and I don’t use a [`SharedWorker`](https://developer.mozilla.org/fr/docs/Web/API/SharedWorker), the entire neural network and training dataset has to be copied:\n\n1.  **Copying** parameters and training dataset to the worker\n2.  **Recreating** the neural network in the worker\n3.  **Training** on the dataset\n4.  **Copying back** parameters if modification, weights and bias\n5.  Main neural network **update** with new parameters, weight and bias.\n\n////////////////////// Main thread:\n\n// Start web worker with training data through epochs\nworker.postMessage({\n    params: this.exportParams(),\n    weights: this.exportWeights(),\n    biais: this.exportBiais(),\n    training_data: training_data,\n    epochs: epochs\n});\n\n////////////////////// Worker:\n\n// Create copy of our current Network\nvar brain = new Network(e.data.params);\nbrain.weights = e.data.weights;\n\n// ...\n\n// Feedforward NN\nfor (curr_epoch = 0; curr_epoch < epochs; curr_epoch++)\n{\n    for (sum = 0, i = 0; i < training_size; i++)\n    {\n        brain.feed(training_data[i].inputs);\n        brain.backpropagate(training_data[i].targets);\n\n        sum += brain.outputError;\n    }\n    \n    global_sum += sum;\n    mean = sum / training_size; \n    global_mean = global_sum / ((curr_epoch+1) * training_size); \n\n    // Send updates back to real thread\n    self.postMessage({\n        type: WORKER_TRAINING_PENDING,\n        curr_epoch: curr_epoch,\n        global_mean: global_mean,\n    });\n}\n\n/////////////////////// Main thread:\n\n// Training is over: we update our weights and biais\nif (e.data.type === WORKER_TRAINING_OVER)\n{\n    that.importWeights( e.data.weights );\n    that.importBiais( e.data.biais );\n\n    // Feeding and bping in order to have updated values (as error) into neurons or others\n    that.feed( training_data[0].inputs );\n    that.backpropagate( training_data[0].targets );\n}\n\nYou can find the full implementation on [Github](https://github.com/Spriteware/neural-network/blob/master/neural-network.js) at `Network.prototype.train()` and `Network.prototype.workerHandler()`\n\n## Next Step\n\nAs said at the beginning of the article, neural networks are for me a logical continuation of genetic algorithms and it would be interesting to determine the optimal neural network hyperparameters of by applying a genetic algorithm on it.\n\nThe next step is to modify this implementation to model a [recurrent neural network](https://en.wikipedia.org/wiki/Recurrent_neural_network), with an example to support it. _Stay tuned!  \n_\n"
    },
    {
      "aliases": [
        "RSS",
        "XLST"
      ],
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.186Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "AaronRSS",
      "content": "\nPassworded proxy -- request requires password, set in ENV and in browser\n\n\nhttps://darekkay.com/blog/rss-styling/?utm_source=ownyourweb&utm_medium=email&utm_campaign=issue-09\n\n#xlst\n\n---\n\n# Style your RSS feed\n\nPublished on 20 Jun 2023 in [rss](https://darekkay.com/tags/rss/) [blog](https://darekkay.com/tags/blog/)\n\nLast updated on 21 Jan 2024\n\n[RSS](https://en.wikipedia.org/wiki/RSS) is not dead. It is not _mainstream_, but it's still a thriving protocol, especially among tech users. However, many people do not know what RSS feeds are or how to use them. Most browsers render RSS as raw XML files, which doesn't help users understand what it's all about:\n\n![XML example as rendered in Chrome](https://darekkay.com/blog/rss-styling/rss-unstyled.webp)\n\nIn this post, I'll explain how to style RSS feeds and educate readers at the same time.\n\n## [XSL(T) to the rescue](https://darekkay.com/blog/rss-styling/?utm_source=ownyourweb&utm_medium=email&utm_campaign=issue-09#xslt-to-the-rescue)\n\nThis is how the [RSS feed for this blog](https://darekkay.com/atom.xml) looks like:\n\n![A styled RSS feed preview. It contains an alert box with a short description about RSS feeds and a list of blog post titles and dates.](https://darekkay.com/blog/rss-styling/rss-styled.webp)\n\nTo style a raw XML file in a browser, you have to provide styling information. You can do that by [attaching](https://www.w3.org/TR/2010/REC-xml-stylesheet-20101028/) an `xml-stylesheet` processing instruction within the RSS feed:\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<?xml-stylesheet href=\"/rss.xsl\" type=\"text/xsl\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\"\n      xmlns:media=\"http://search.yahoo.com/mrss/\">\n  ...\n</feed>\n```\n\nThe `href` attribute specifies a URL to a valid [XSL](https://www.w3.org/Style/XSL/WhatIsXSL.html) file. You can check out [mine](https://darekkay.com/assets/xsl/rss-style.xsl) for inspiration. Here's the gist:\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<xsl:stylesheet version=\"3.0\"\n                xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"\n                xmlns:atom=\"http://www.w3.org/2005/Atom\">\n  <xsl:output method=\"html\" version=\"1.0\" encoding=\"UTF-8\" indent=\"yes\"/>\n  <xsl:template match=\"/\">\n  <html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n    <head>\n      <title>\n        RSS Feed | <xsl:value-of select=\"/atom:feed/atom:title\"/>\n      </title>\n      <link rel=\"stylesheet\" href=\"/assets/styles.css\"/>\n    </head>\n    <body>\n      <p>\n        This is an RSS feed. Visit\n        <a href=\"https://aboutfeeds.com\">About Feeds</a>\n        to learn more and get started. It’s free.\n      </p>\n      <h1>Recent blog posts</h1>\n      <xsl:for-each select=\"/atom:feed/atom:entry\">\n        <a>\n          <xsl:attribute name=\"href\">\n            <xsl:value-of select=\"atom:link/@href\"/>\n          </xsl:attribute>\n          <xsl:value-of select=\"atom:title\"/>\n        </a>\n        <xsl:value-of select=\"atom:summary\"/>\n        Last updated:\n        <xsl:value-of select=\"substring(atom:updated, 0, 11)\" />\n      </xsl:for-each>\n    </body>\n    </html>\n  </xsl:template>\n</xsl:stylesheet>\n```\n\nThis code is inspired by [pretty-feed-v3](https://github.com/genmon/aboutfeeds/blob/main/tools/pretty-feed-v3.xsl), but I've adopted it for the Atom specification.\n\nThe XSL file transforms the XML feed into a valid HTML document that any browser can render. You can use any information included in the XML file and put it into a new markup structure. You can even include content that is not part of the XML feed. A perfect use case is to include a note about what RSS feeds are and how to use them (as shown in the example above).\n\nYou can define inline CSS styles with a regular `<style>` element, but it's also possible to import external CSS files. I've imported my blog's main CSS stylesheet, so I didn't have to write any new code to make the RSS feed match my blog's design.\n\nIt's also possible to use [XSLT functions](https://www.w3.org/TR/xpath-functions-30/) to alter values. Here's how I truncate the timestamp to display only the date:\n\n```xml\n<!-- Full timestamp -->\n<xsl:value-of select=\"atom:updated\" />\n\n<!-- Date only -->\n<xsl:value-of select=\"substring(atom:updated, 0, 11)\" />\n```\n\nThe [browser support](https://caniuse.com/?search=xslt) for XSL transformations is great; unsupported browsers will fall back to the default behavior (progressive enhancement).\n\n## [Examples](https://darekkay.com/blog/rss-styling/?utm_source=ownyourweb&utm_medium=email&utm_campaign=issue-09#examples)\n\nHere are some styled RSS feeds you can check for inspiration:\n\n- [This blog](https://darekkay.com/atom.xml)\n- [My photography website](https://photos.darekkay.com/atom.xml)\n- [BBC News](https://feeds.bbci.co.uk/news/world/europe/rss.xml)\n- [Hsiaoming Yang](https://lepture.com/feed.xml)\n- [Dave Rupert](https://daverupert.com/atom.xml)\n- [Oli Warner](https://thepcspy.com/feeds/full.xml)\n- [Chris Morgan](https://chrismorgan.info/feed.xml)\n\nThe XSL files are public, so you can check how those pages have been implemented.\n\n## [Sitemap](https://darekkay.com/blog/rss-styling/?utm_source=ownyourweb&utm_medium=email&utm_campaign=issue-09#sitemap)\n\nYou can apply XSL files to _any_ XML file. Another use case for styled XML files is a [website sitemap](https://www.sitemaps.org/). Although sitemaps are meant to be consumed by machines (e.g. crawlers), you can style them with little effort. See [my sitemap](https://darekkay.com/sitemap.xml) and the [respective XSL file](https://darekkay.com/assets/xsl/sitemap-style.xsl) as an example. Here's the gist:\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<xsl:stylesheet version=\"3.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"\n                xmlns:sitemap=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n  <xsl:output method=\"html\" version=\"1.0\" encoding=\"UTF-8\" indent=\"yes\"/>\n  <xsl:template match=\"/\">\n    <html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n      <body>\n        <h1>Sitemap</h1>\n        <xsl:for-each select=\"/sitemap:urlset/sitemap:url\">\n          <a>\n            <xsl:attribute name=\"href\">\n              <xsl:value-of select=\"sitemap:loc\"/>\n            </xsl:attribute>\n            <xsl:value-of select=\"sitemap:loc\"/>\n          </a>\n          Last updated:\n          <xsl:value-of select=\"substring(sitemap:lastmod, 0, 11)\" />\n        </xsl:for-each>\n      </body>\n    </html>\n  </xsl:template>\n</xsl:stylesheet>\n```\n\n## [Caveat](https://darekkay.com/blog/rss-styling/?utm_source=ownyourweb&utm_medium=email&utm_campaign=issue-09#caveat)\n\nWhat happens if a user wants to save a styled XML file? Interestingly, the answer depends on the browser. Chrome and Safari will save the original _XML_ file, but Firefox will store the styled _HTML_ page instead. Most RSS readers expect a feed URL, so this behavior doesn't make a difference. However, I would be careful with XML files that are meant to be downloaded, like OPML files. Kudos to Robb Knight for the [observation](https://social.lol/@robb/111793259765506845).\n\n## [Conclusion](https://darekkay.com/blog/rss-styling/?utm_source=ownyourweb&utm_medium=email&utm_campaign=issue-09#conclusion)\n\nI love RSS, and — according to [my stats](https://darekkay.com/blog/rss-subscriber-count/) — many of my readers love it, too. With all the social media walled gardens, I hope for RSS to become more popular. By providing a custom XSL file, you can make your RSS feed look nice _and_ include some information about what RSS actually is.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.186Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Amazon S3",
      "content": "\nCertainly! Below is an example of a Node.js script that utilizes the AWS SDK to upload, list, and delete files from an Amazon S3 bucket.\n\n```javascript\nconst AWS = require('aws-sdk');\nconst fs = require('fs');\n\n// Set up AWS credentials and region\nAWS.config.update({\n  accessKeyId: 'YOUR_ACCESS_KEY',\n  secretAccessKey: 'YOUR_SECRET_KEY',\n  region: 'YOUR_REGION' // e.g., 'us-east-1'\n});\n\n// Create an S3 instance\nconst s3 = new AWS.S3();\n\n// Upload a file to the S3 bucket\nfunction uploadFile(bucketName, fileName) {\n  const fileContent = fs.readFileSync(fileName);\n\n  const params = {\n    Bucket: bucketName,\n    Key: fileName,\n    Body: fileContent\n  };\n\n  s3.upload(params, function(err, data) {\n    if (err) {\n      console.error('Error uploading file:', err);\n    } else {\n      console.log('File uploaded successfully:', data.Location);\n    }\n  });\n}\n\n// List all files in the S3 bucket\nfunction listFiles(bucketName) {\n  const params = {\n    Bucket: bucketName\n  };\n\n  s3.listObjects(params, function(err, data) {\n    if (err) {\n      console.error('Error listing files:', err);\n    } else {\n      console.log('Files in the bucket:');\n      data.Contents.forEach(function(file) {\n        console.log(file.Key);\n      });\n    }\n  });\n}\n\n// Delete a file from the S3 bucket\nfunction deleteFile(bucketName, fileName) {\n  const params = {\n    Bucket: bucketName,\n    Key: fileName\n  };\n\n  s3.deleteObject(params, function(err, data) {\n    if (err) {\n      console.error('Error deleting file:', err);\n    } else {\n      console.log('File deleted successfully');\n    }\n  });\n}\n\n// Usage example\nconst bucketName = 'YOUR_BUCKET_NAME';\nconst fileName = 'path/to/file.ext';\n\nuploadFile(bucketName, fileName);\nlistFiles(bucketName);\ndeleteFile(bucketName, fileName);\n```\n\nPlease make sure to replace the placeholders `'YOUR_ACCESS_KEY'`, `'YOUR_SECRET_KEY'`, `'YOUR_REGION'`, and `'YOUR_BUCKET_NAME'` with your actual AWS credentials and bucket details. Additionally, `'path/to/file.ext'` should be replaced with the path to the file you want to upload or delete.\n\nThis script uses the `aws-sdk` package to interact with Amazon S3. You can install it by running `npm install aws-sdk`.\n\nConcept: Simple, secure upload with a AWS identity Key\n\n\nUpload to amazon s3 from browser:\n\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/HTTPPOSTExamples.html\n\n\nhttps://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/s3-example-photo-album.html\n\n\n```js\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.187Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Apple IIE",
      "content": "Price point:\n$1,395\n$4,100\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.188Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Arduino",
      "content": "Project:\n\nhttps://www.local-guru.net/blog/2018/9/14/Arduino-based-Midi-Trigger-box-for-analog-synths\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.188Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Async Generator",
      "content": "```js\nasync function* readFiles(files){\n  for (const file of files){\n    yield await readFile(file)\n  }\n}\n```\n\n```javascript\n let div_array = [...document.querySelectorAll('div')]\n\n while(div_array.length > 0){\n  const div = div_array.pop()\n  console.log(div)\n }\n```\n\n```javascript\nlet div_array = [...document.querySelectorAll('div')]\n\nasync function blah_generator(){\n while(div_array.length > 0){\n  const div = div_array.pop()\n  const res = await fetch('blah').then(res => res.json())\n  // do something to this specific div\n  // this function will wait for this specific\n  // item to be finished before moving onto the next\n }\n}\n\nblah_generator()\n```\n[[WebWorkers]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.189Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Audio in Linux",
      "content": "Start loopback:\n\n```bash\n#!/bin/bash\n\npactl load-module module-loopback\n```\n\n```bash\n#!/bin/bash\n\npactl unload-module module-loopback\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.189Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Basic Markdown Build Framework",
      "content": "For taking a collection of Markdown files and turning them into a static website.\n\nThis one is taken from Me and Michelangelo Mersi de Carravaggio. A generalized one \n\n```js\nconst fs = require('fs');\nconst matter = require('gray-matter');\nconst parser = require('@deskeen/markdown')\n\n\n// directory path\nconst dir = `${__dirname}/assets/paintings/`;\n\nlet PAINTINGS = ''\n\n// list all files in the directory\nfs.readdir(dir, async (err, files) => {\n  if (err) {\n      throw err;\n  }\n\n  files.forEach(async file => {\n    const yaml = matter.read(`${dir}/${file}`);\n    const data = yaml.data\n\n    const html_code = parser.parse(yaml.content).innerHTML;\n\n\n    PAINTINGS += `\n      <map-location\n        latitude=${data.coordinates[1]}\n        longitude=${data.coordinates[0]}\n        zoom=18\n        bearing=15\n        pitch=30\n        id=${data.id}\n\n      >\n        <map-marker>\n          <wikipedia-image src=${data.wikipedia}></wikipedia-image>\n        </map-marker>\n        <h1>${data.title}</h1>\n        <h2>${data.year}</h2>\n        <article class=\"content\">\n          ${html_code}\n        </article>\n\n        <wikipedia-entry src=${data.wikipedia}></wikipedia-entry>\n\n      </map-location>\n    `\n  })\n\n  fs.writeFile('paintings.html', PAINTINGS, function(err){\n    if(err){\n      console.log(err)\n    }\n  })\n\n});\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.189Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Bowie Oracle",
      "content": "```js\n\n// Get the <audio> element\nconst audioElement = document.getElementById(\"yourAudioElementId\");\n\n// Ensure the audio has loaded before manipulating it\naudioElement.addEventListener(\"loadedmetadata\", function () {\n  // Get the duration of the audio\n  const audioDuration = audioElement.duration;\n\n  // Generate a random time within the audio duration\n  const randomTime = Math.random() * (audioDuration - 1.4);\n\n  // Set the audio's currentTime to the random time\n  audioElement.currentTime = randomTime;\n\n  // Play 1.4 seconds of audio\n  audioElement.play();\n\n  // Stop playback after 1.4 seconds\n  setTimeout(() => {\n    audioElement.pause();\n  }, 1400);\n});\n\n// Start loading the audio\naudioElement.load();\n\n// Get the <audio> element\nconst audioElement = document.getElementById(\"yourAudioElementId\");\n\n// Add an event listener to track the loading progress\naudioElement.addEventListener(\"progress\", function() {\n  const loadedPercentage = (audioElement.buffered.end(0) / audioElement.duration) * 100;\n  console.log(`Loaded: ${loadedPercentage}%`);\n});\n\n// Start loading the audio\naudioElement.load();\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.190Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Brain.js",
      "content": "Brain.js generates [[Neural Network]]s\n\n\n\n# Generate text\n```javascript\nconst brain = require('brain.js');\n\nconst trainingData = [\n  'Jane saw Doug.',\n  'Doug saw Jane.',\n  'Spot saw Doug and Jane looking at each other.',\n  'It was love at first sight, and Spot had a frontrow seat. It was a very special moment for all.',\n];\n\nconst lstm = new brain.recurrent.LSTM();\nconst result = lstm.train(trainingData, {\n  iterations: 1500,\n  log: (details) => console.log(details),\n  errorThresh: 0.011,\n});\nconsole.log('Training result: ', result);\n\nconst run1 = lstm.run('Jane');\nconst run2 = lstm.run('Doug');\nconst run3 = lstm.run('Spot');\nconst run4 = lstm.run('It');\n\nconsole.log('run 1: Jane' + run1);\nconsole.log('run 2: Doug' + run2);\nconsole.log('run 3: Spot' + run3);\nconsole.log('run 4: It' + run4);\n\n```\n\n# String Classification\n```javascript\nconst brain = require('brain.js');\n\n// create configuration for training\nconst config = {\n  iterations: 1500,\n  log: true,\n  logPeriod: 50,\n  layers: [10],\n};\n\n// create data which will be used for training\nconst data = [\n  { input: 'Argon', output: 'a' },\n  { input: 'Argentina', output: 'a' },\n  { input: 'Aron', output: 'a' },\n  { input: 'August', output: 'a' },\n  { input: 'Australia', output: 'a' },\n  { input: 'America', output: 'a' },\n  { input: 'Allison', output: 'a' },\n  { input: 'Alex', output: 'a' },\n  { input: 'Arthur', output: 'a' },\n  { input: 'Also', output: 'a' },\n\n  { input: 'Barcelona', output: 'b' },\n  { input: 'Baseball', output: 'b' },\n  { input: 'Bayern', output: 'b' },\n  { input: 'Batch', output: 'b' },\n  { input: 'Brasillia', output: 'b' },\n  { input: 'Brass', output: 'b' },\n  { input: 'Bateman', output: 'b' },\n  { input: 'Bose', output: 'b' },\n  { input: 'Biscuit', output: 'b' },\n  { input: 'Bhutan', output: 'b' },\n\n  { input: 'China', output: 'c' },\n  { input: 'Chile', output: 'c' },\n  { input: 'Cheat', output: 'c' },\n  { input: 'Caught', output: 'c' },\n  { input: 'Colombia', output: 'c' },\n  { input: 'Colorado', output: 'c' },\n  { input: 'Cult', output: 'c' },\n  { input: 'Cristiano', output: 'c' },\n  { input: 'Choke', output: 'c' },\n  { input: 'Cut', output: 'c' },\n];\n\n// the thing we would test\nconst test = 'Code';\n\nconst network = new brain.recurrent.LSTM();\nnetwork.train(data, config);\nconst output = network.run(test);\nconsole.log(`It starts with: ${output}`); // It starts with: c\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.191Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Build System",
      "content": "# Build System\n\n1652120464 #2022-05-09\n\nFound out that [[Obsidian]] can just do [[Mermaid.js]] diagrams. So, one new requirement for build system is it compiles Mermaid templates. \n\n---\n\n1650902732 #2022-04-25\n```nomnoml\n[Markdown Files]->[Dist]\n[TypeScript]->[Build]\n[SCSS]->[Build]\n[Build]->[Dist]\n[Component Library]->[Build]\n\n[CSS]->[Dist]\n[Image Files]->[Dist]\n[JSX]->[Build]\n[Tests]->[Dist]\n```\n\n---\n\n\n1649367411 #2022-04-07\n\nExperiments w/ build systems. \n\n\nThe first build system I'd like to try is snowpack. \n\n---\n\nBuild Script: \n- fetchs our latest component library\n- builds that\n- can handle typescript\n- can build react as well as plain HTML Elements and use them together\n- compiles markdown files to unsafe HTML\n\n\nhttps://nextjs.org/\nhttps://www.docz.site/docs/getting-started\nhttps://github.com/doczjs/docz/tree/main/core/gatsby-theme-docz\n\nhttps://parceljs.org/\n\n\n|       Build System           |      Website                                                                                      |\n|:-----------------------------|:--------------------------------------------------------------------------------------------------|\n| [[Gatsby.js]]                | https://www.gatsbyjs.com/                                                                         |\n|  [[lasso.js]]                |  https://github.com/lasso-js/lasso                                                                |\n|   [[parcel.js]]              |   https://parceljs.org/                                                                           |\n|   [[11ty]]                   |   https://www.11ty.dev/                                                                           |\n|       [[webpack]]            |      https://webpack.js.org/                                                                      |\n|       [[yarn]]<br>           |      <div>https://yarn.build/</div><div><br></div><div>https://classic.yarnpkg.com/en/</div>      |\n|       [[babel.js]]           |      https://babeljs.io/                                                                          |\n|      [[rollup.js]]           |      https://www.rollupjs.org/guide/en/                                                           |\n|      [[snowpack.js]]         |      https://www.snowpack.dev/                                                                    |\n|      [[esbuild]]             |      https://esbuild.github.io/                                                                   |\n|      [[broccoli]]            |      https://github.com/broccolijs/broccoli                                                       |\n|      [[browserify]]          |      https://browserify.org/                                                                      |\n|      [[brunch.io]]           |      <div><br></div><div>https://brunch.io/</div>                                                 |\n|      [[grunt]]               |      https://gruntjs.com/                                                                         |\n|      [[gulp]]                |      https://gulpjs.com/                                                                          |\n|      [[system.js]]           |      https://github.com/systemjs/systemjs                                                         |\n|    [[bazel build]]           |    https://bazel.build/                                                                           |\n|    [[buck]]                  |    https://github.com/facebook/buck<div><br></div>                                                |\n|    [[pants]]                 |    https://v1.pantsbuild.org/                                                                     |\n\nhttps://webpack.js.org/guides/\n\n\n> Build automation is the process of automating the creation of a software build and the associated processes including: compiling computer source code into binary code, packaging binary code, and running automated tests.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Build%20automation)\n\n\n> In software engineering, continuous integration (CI) is the practice of merging all developers' working copies to a shared mainline several times a day. Grady Booch first proposed the term CI in his 1991 method, although he did not advocate integrating several times a day. Extreme programming (XP) adopted the concept of CI and did advocate integrating more than once per day – perhaps as many as tens of times per day.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Continuous%20integration)\n\n> **Webpack** is an open-source JavaScript module bundler. It is made primarily for JavaScript, but it can transform front-end assets such as HTML, CSS, and images if the corresponding loaders are included. Webpack takes modules with dependencies and generates static assets representing those modules.Webpack takes the dependencies and generates a dependency graph allowing web developers to use a modular approach for their web application development purposes. It can be used from the command line or can be configured using a configuration file which is named webpack.config.js. This file defines rules, plugins, etc., for a project. (webpack is highly extensible via rules which allow developers to write custom tasks that they want to perform when bundling files together.) \n>\n> Node.js is required for using webpack.\n>\n> Webpack provides code on demand using the moniker code splitting. The Technical Committee 39 for ECMAScript is working on standardization of a function that loads additional code: \"proposal-dynamic-import\".\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Webpack)\n\n\n---\n\nNotes on our build system as of April 18, 2022\n\n[[nomnoml]]\n\n\n1650305467 #2022-04-18\n\n\n\nThe makefile currently looks like this: \n\n```bash\n\nCUSTOMER_NAME='client'\n\nbuild_dir:\n\trm -rf build/*\n\tmkdir -p build/${CUSTOMER_NAME}/\n\tmkdir -p build/${CUSTOMER_NAME}/assets\n\njs:\n\tmkdir build/${CUSTOMER_NAME}/scripts/\n\tcp scripts/*.js build/${CUSTOMER_NAME}/scripts/\n\tcp build.js build/${CUSTOMER_NAME}/\n\nimg:\n\tmkdir -p build/${CUSTOMER_NAME}/assets/img/;\n\t#cp assets/img/*.jpg build/assets/img/\n\tcp assets/img/*.gif build/${CUSTOMER_NAME}/assets/img/\n\tcp assets/img/*.png build/${CUSTOMER_NAME}/assets/img/\n\tcp assets/img/*.svg build/${CUSTOMER_NAME}/assets/img/\nstyle:\n\tmkdir -p build/${CUSTOMER_NAME}/assets/styles;\n\tcp assets/styles/*.css build/${CUSTOMER_NAME}/assets/styles/;\n\tcp assets/styles/*.otf build/${CUSTOMER_NAME}/assets/styles/;\n\tcp assets/styles/*.ttf build/${CUSTOMER_NAME}/assets/styles/;\n\tcp assets/styles/*.woff2 build/${CUSTOMER_NAME}/assets/styles/;\n\tcp assets/styles/*.woff build/${CUSTOMER_NAME}/assets/styles/;\n\nassets: js img style\n\nhtml:\n\tmkdir -p build/${CUSTOMER_NAME}/docs/;\n\tcp docs/*.html build/${CUSTOMER_NAME}/docs/\n\tcp docs/*.md build/${CUSTOMER_NAME}/docs/\n\tmkdir -p build/${CUSTOMER_NAME}/partials/;\n\tcp partials/*.html build/${CUSTOMER_NAME}/partials/\n\tcp *.html build/${CUSTOMER_NAME}/\n\ntemplate:\n\tpython3 bin/template_customer_json.py build/\n\nbuild: build_dir assets html template\n\ndata_dictionary:\n\tnpm run-script build\n\n```\n\n```nomnoml\n[Customer]-> [Customer Name]\n[build_dir] <- [build] \n[build] <- [Customer Name]\n```\n\n\n\n\n\n\n\n\nbuilds with template_customer_json.py:\n\n```python\nimport copy\nimport json\nfrom pathlib import Path\n\ndef main(input_path):\n    customer_json = json.load(open('./customer.json', 'r'))\n    customer_name = customer_json['customer']\n    customer_name_lower = customer_json['customer'].lower()\n    gpg_key = customer_json['gpgKey']\n\n    path = Path(input_path or '.')\n    \n    html_files = path.glob('**/*.html')\n    md_files = path.glob('**/*.md')\n    \n    for file_path in list(html_files) + list(md_files):\n        file_path_str = file_path.resolve()\n        with open(file_path_str, 'r') as file_obj:\n            file_str = file_obj.read()\n    \n        old_file_str = copy.deepcopy(file_str)\n    \n        file_str = file_str.replace('{customer}', customer_name)\n        file_str = file_str.replace('{sftpUsername}', customer_name_lower)\n        file_str = file_str.replace('{gpgKey}', gpg_key)\n    \n        if file_str != old_file_str:\n            print(f\"{file_path_str} written\")\n            with open(file_path_str, 'w') as file_obj:\n                file_obj.write(file_str)\n\nif __name__ == '__main__':\n    import sys\n    main(sys.argv[1])\n\n\n```\n\nThe reload script looks like: \n```bash\n#!/bin/bash\n\ncd /code && \\\n    make build && \\\n    while inotifywait -r -e modify /code; do\n        echo \"running build...\" && \\\n        make build\n    done\n\n```\n\n---\n\nProposal: GPG key component, loads customer.json from local directory. \n\nThat way we aren't building the GPG module?\n\n---\n\nWhat the build system should do\n\n- Grab all markdown files\n-  Fetch latest data dictionary from Google\n- Grab all HTML files in directory\n- Grab all assets\n- Build files into documents\n- Run Tests\n- Generate PDF's \n\n\nhttps://www.npmjs.com/package/@snowpack/plugin-build-script\n\nhttps://www.npmjs.com/package/snowpack-plugin-inliner\n\nhttps://www.npmjs.com/package/@snowpack/plugin-webpack\n\n---\n1650318084 #2022-04-18\n\ngit@github.com:FairPlay-AI/frontend-boilerplate.git\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.192Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "C",
      "content": "https://github.com/petersalomonsen/wasm-git\n\n[[WebASM]] [[WebAsm]]\n\nIdea: use wasm-git \n\nhttps://webassembly.org/getting-started/developers-guide/\n\nhttps://github.com/bytecodealliance/wasmtime/blob/main/docs/WASI-tutorial.md\n\nIdea for start of C learning: \nA web component that looks something like: \n\n```html\n\n<c-code id=\"c_code_div\">\nsprintf('Hello World')\n</c-code>\n\n\n```\n\nThat takes C code and compiles it in browser. \n\nYou should be able to message the webworker with: \n\n```js\n\nc_code_div.setAttribute('attribute', 'value')\n\n```\n\nThis would then send a message to the webworker with the compiled webASM code.  \n\nhttps://replit.com/languages/c\n\n1646931536-2022-03-10\n\n[[C]] thoughts: https://dev.to/tyfkda/running-a-c-compiler-in-a-browser-4g9h\nRelatively recent article on getting a c compiler to run in browser. \n\nGNN and ANN in C:\nhttps://codeplea.com/genann\n\nThis and [[Business Physics]]\n\nC code compiled into a bespoke physics engine written in C that others can modify.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.192Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "CSS Rotation Snippet",
      "content": "```CSS\n  \n.rotate {\n  animation: rotation 50s linear infinite;\n\n}\n\n@keyframes rotation {\n  from {\n    transform: rotate(0deg);\n  }\n  to {\n    transform: rotate(359deg);\n  }\n}\n\n\n@keyframes y-rotate {\n  from {\n    transform: translate(-50%, -50%) rotateY(0);\n  }\n\n  to {\n    transform: translate(-50%, -50%) rotateY(360deg);\n  }\n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.193Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "CSS",
      "content": "# CSS\n\n\n> Cascading Style Sheets (**CSS**) is a style sheet language used for describing the presentation of a document written in a markup language such as HTML. CSS is a cornerstone technology of the World Wide Web, alongside HTML and JavaScript.CSS is designed to enable the separation of presentation and content, including layout, colors, and fonts. This separation can improve content accessibility; provide more flexibility and control in the specification of presentation characteristics; enable multiple web pages to share formatting by specifying the relevant CSS in a separate .css file, which reduces complexity and repetition in the structural content; and enable the .css file to be cached to improve the page load speed between the pages that share the file and its formatting.\n>\n> Separation of formatting and content also makes it feasible to present the same markup page in different styles for different rendering methods, such as on-screen, in print, by voice (via speech-based browser or screen reader), and on Braille-based tactile devices. CSS also has rules for alternate formatting if the content is accessed on a mobile device.The name cascading comes from the specified priority scheme to determine which style rule applies if more than one rule matches a particular element. This cascading priority scheme is predictable.\n>\n> The CSS specifications are maintained by the World Wide Web Consortium (W3C). Internet media type (MIME type) text/css is registered for use with CSS by RFC 2318 (March 1998). The W3C operates a free CSS validation service for CSS documents.In addition to HTML, other markup languages support the use of CSS including XHTML, plain XML, SVG, and XUL.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/CSS)\n\n\n---\n\n[[CSS Rotation Snippet]]\n\n```css\n/*\n\n  *** begin ascii art ***\n  \n            CCCCCCCCCCCCC   SSSSSSSSSSSSSSS    SSSSSSSSSSSSSSS\n         CCC::::::::::::C SS:::::::::::::::S SS:::::::::::::::S\n       CC:::::::::::::::CS:::::SSSSSS::::::SS:::::SSSSSS::::::S\n      C:::::CCCCCCCC::::CS:::::S     SSSSSSSS:::::S     SSSSSSS\n     C:::::C       CCCCCCS:::::S            S:::::S\n    C:::::C              S:::::S            S:::::S\n    C:::::C               S::::SSSS          S::::SSSS\n    C:::::C                SS::::::SSSSS      SS::::::SSSSS\n    C:::::C                  SSS::::::::SS      SSS::::::::SS\n    C:::::C                     SSSSSS::::S        SSSSSS::::S\n    C:::::C                          S:::::S            S:::::S\n     C:::::C       CCCCCC            S:::::S            S:::::S\n      C:::::CCCCCCCC::::CSSSSSSS     S:::::SSSSSSSS     S:::::S\n       CC:::::::::::::::CS::::::SSSSSS:::::SS::::::SSSSSS:::::S\n         CCC::::::::::::CS:::::::::::::::SS S:::::::::::::::SS\n            CCCCCCCCCCCCC SSSSSSSSSSSSSSS    SSSSSSSSSSSSSSS\n                            The CSS file\n                            \n  *** end ascii art ***\n  \n  A lot of people get into months long javascript framework\n  boondoggles for reasons they could have solved in 5 minutes \n  fiddling with the humble CSS file.\n  \n  The penultimate best CSS framework is the one where every design \n  meeting you, the HTML/CSS Engineer (paid more than any of the \n  Javascript Jocks) are rolling your eyes at the cravat wearing \n  designer and sarcastically holding up a sticky note that says: \n  \"What about the standards, bro?\"\n  \n  But the absolute best HTML/CSS Framework is the one where the\n  designers are writing the CSS and HTML. Drop photoshop, drop \n  whatever flavor of the week closed-source Mac only garbage you've \n  been sending me that is just bad SVG and write some HTML and CSS. \n  \n  Design is about application of material facts (and yes, \n  HTML/CSS is a material fact on screen in browser), so start \n  applying the materials.\n  \n  A lot of people think CSS folk aren't Engineers, or that \n  Designers can't become good engineers, but I know better. A lot \n  of you designers and CSS pushers are already better engineers \n  than the Javascript Jocks around you.\n  \n  I know. I see you. Here's where you wow them.\n  \n  LNSY\n\n*/\n\n```\n\n```CSS\n/*\n  *** begin ascii art ***\n  \n   _    _____    ____  _______    ____  __    ___________\n  | |  / /   |  / __ \\/  _/   |  / __ )/ /   / ____/ ___/\n  | | / / /| | / /_/ // // /| | / __  / /   / __/  \\__ \\\n  | |/ / ___ |/ _, _// // ___ |/ /_/ / /___/ /___ ___/ /\n  |___/_/  |_/_/ |_/___/_/  |_/_____/_____/_____//____/\n  \n  *** end ascii art ***\n  \n  Most aesthethic options should live here for adjustment\n*/\n:root {\n  /* Colors */\n  --bg-color: #0b1520;\n  --overlay-bg-color: #0b1520ee;\n  --fg-color: #ffffff;\n  --link-color: #ff00ff;\n}\n\n```\n\n```CSS\n\n.rotate {\n  animation: rotation 50s linear infinite;\n}\n\n@keyframes rotation {\n  from {\n    transform: rotate(0deg);\n  }\n  to {\n    transform: rotate(359deg);\n  }\n}\n\n@keyframes y-rotate {\n\n  from {\n    transform: translate(-50%, -50%) rotateY(0);\n  }\n  \n  to {\n    transform: translate(-50%, -50%) rotateY(360deg);\n  }\n}\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.193Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Camera Canvas Component",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.193Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Cancel on Mouse Move",
      "content": "```js\n\ndocument.body.addEventListener('mousemove', function(e){\n\trun_cancel_event()\n})\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.194Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Check Battery Status Linux Command Line",
      "content": "```bash\nupower -i $(upower -e | grep 'BAT') | grep -E \"state|to\\ full|percentage\"\nupower -i /org/freedesktop/UPower/devices/battery_BAT0\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.194Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Clicik Status",
      "content": "\n```js\nAFRAME.registerComponent(\"click-status\", {\n  init: function () {\n    // Listen for click events\n    this.el.addEventListener(\"click\", this.onClick.bind(this));\n\n    // Listen for touch events\n    this.el.addEventListener(\"touchstart\", this.onClick.bind(this));\n\n    // Listen for VR controller events\n    this.el.addEventListener(\"triggerdown\", this.onClick.bind(this));\n  },\n\n  onClick: function (event) {\n    // Update the status message\n    document.querySelector(\"#status\").setAttribute('selected-planet',this.el.id);\n  },\n});\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.194Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Click to Copy HTML Element",
      "content": "```javascript \n/*\n  \n     ________    ____________ __\n    / ____/ /   /  _/ ____/ //_/\n   / /   / /    / // /   / ,<\n  / /___/ /____/ // /___/ /| |\n  \\____/_____/___/\\____/_/ |_|\n\n    __________\n   /_  __/ __ \\\n    / / / / / /\n   / / / /_/ /\n  /_/  \\____/\n\n     __________  ______  __\n    / ____/ __ \\/ __ \\ \\/ /\n   / /   / / / / /_/ /\\  /\n  / /___/ /_/ / ____/ / /\n  \\____/\\____/_/     /_/\n\n  CLICK TO COPY\n\n  An HTML Element that allows users to click\n  and copy its contents\n\n*/\n\nconst style_content = `\n\n    click-to-copy {\n      position:relative;\n      transition: filter 0.10s ease-in;\n    }\n    \n    click-to-copy::before {\n      content: \"Click To Copy\";\n      position:absolute;\n      right:0px;\n      height: 14pt;\n      bottom:-26pt;\n      background-color:black;\n      color:white;\n      z-index:1000;\n      padding: 6pt 12pt;\n    }\n\n    click-to-copy:active {\n      filter: brightness(75%);\n    }\n\n`\n\nclass ClickToCopy extends HTMLElement {\n  connectedCallback(){\n    const style = document.createElement('style')\n    style.innerText = style_content;\n    document.body.appendChild(style);\n    this.style.cursor = \"pointer\";\n    const innerText = this.innerText\n    this.addEventListener('click', () => {\n        navigator.clipboard.writeText(innerText);\n    });\n  }\n\n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n    switch(name){\n      default:\n    }\n  }\n\n}\n\ncustomElements.define('click-to-copy', ClickToCopy)\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.195Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Command Line arguments in node.js",
      "content": "to make a script executable in Node.js:\n\n```js\n#!/usr/bin/env node\n```\n\nthen\n\n```bash\nchmod +x {script_name}.js\n```\n[[Node.js]] as a command line tool notes\n\n```js\nconsole.log(process.argv);\n```\n\n```bash\n$ node argv.js one two three four five\n[ 'node',\n  '/home/avian/argvdemo/argv.js',\n  'one',\n  'two',\n  'three',\n  'four',\n  'five' ]\n```\n\n\n> Where everyday CLI arguments are concerned, you'll want to skip the first two. Now try this in `argv.js`:\n\n```js\nconst myArgs = process.argv.slice(2);\nconsole.log('myArgs: ', myArgs);\n```\n\n\n## Links\nhttps://nodejs.dev/learn/run-nodejs-scripts-from-the-command-line\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.197Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Computational Weaving",
      "content": "https://www.sciencenews.org/article/core-memory-weavers-navajo-apollo-raytheon-computer-nasa\n\n# Core memory weavers and Navajo women made the Apollo missions possible\n\n![A Navajo woman sitting at a microscope](https://www.sciencenews.org/wp-content/uploads/2022/02/sn100_computing_spotlight-weaver_feat-1030x580.jpg)\n\nIntegrated circuits for the Apollo Guidance Computer came from Fairchild Semiconductor, which opened a factory in Shiprock, N.M., in 1965. The factory employed mostly Navajo women. (This woman was featured, unnamed, in a Shiprock brochure.)\n\nCOURTESY OF THE COMPUTER HISTORY MUSEUM\n\n### Share this:\n\n-   [Email](mailto:?subject=Core%20memory%20weavers%20and%20Navajo%20women%20made%20the%20Apollo%20missions%20possible&body=I%20saw%20this%20on%20Science%20News%3A%20https%3A%2F%2Fwww.sciencenews.org%2Farticle%2Fcore-memory-weavers-navajo-apollo-raytheon-computer-nasa%3Futm_source%3Dinternal%26utm_medium%3Demail%26utm_campaign%3Demail_share \"Share via email\")\n-   [Facebook](https://www.sciencenews.org/article/core-memory-weavers-navajo-apollo-raytheon-computer-nasa?share=facebook&nb=1 \"Click to share on Facebook\")\n-   [Twitter](https://www.sciencenews.org/article/core-memory-weavers-navajo-apollo-raytheon-computer-nasa?share=twitter&nb=1 \"Click to share on Twitter\")\n-   [Pinterest](https://www.sciencenews.org/article/core-memory-weavers-navajo-apollo-raytheon-computer-nasa?share=pinterest&nb=1 \"Click to share on Pinterest\")\n-   [Pocket](https://www.sciencenews.org/article/core-memory-weavers-navajo-apollo-raytheon-computer-nasa?share=pocket&nb=1 \"Click to share on Pocket\")\n-   [Reddit](https://www.sciencenews.org/article/core-memory-weavers-navajo-apollo-raytheon-computer-nasa?share=reddit&nb=1 \"Click to share on Reddit\")\n-   [Print](https://www.sciencenews.org/article/core-memory-weavers-navajo-apollo-raytheon-computer-nasa#print \"Click to print\")\n\nBy [Joy Lisi Rankin](https://www.sciencenews.org/author/joy-lisi-rankin)\n\nFEBRUARY 18, 2022 AT 10:51 AM\n\nThe historic Apollo moon missions are often associated with high-visibility test flights, dazzling launches and spectacular feats of engineering. But intricate, challenging handiwork — comparable to weaving — was just as essential to putting men on the moon. Beyond Neil Armstrong, Buzz Aldrin and a handful of other names that we remember were hundreds of thousands of men and women who contributed to Apollo over a decade. Among them: the Navajo women who assembled state-of-the-art integrated circuits for the Apollo Guidance Computer and the women employees of Raytheon who wove the computer’s core memory.\n\nIn 1962, when President John F. Kennedy [declared](https://millercenter.org/the-presidency/educational-resources/fly-me-to-the-moon) that putting Americans on the moon should be the top priority for NASA, computers were large mainframes; they occupied entire rooms. And so one of the most daunting yet crucial challenges was developing a highly stable, reliable and portable computer to control and navigate the spacecraft.\n\n![Science News 100](https://www.sciencenews.org/wp-content/uploads/2021/01/centennial-logo-800x84.png)\n\nTo celebrate our 100th anniversary, we’re highlighting some of the biggest advances in science over the last century. To see more from the series, visit [Century of Science](https://www.sciencenews.org/century).\n\n[READ MORE](https://www.sciencenews.org/century)\n\nNASA chose to use cutting-edge integrated circuits in the Apollo Guidance Computer. These commercial circuits had been introduced only recently. Also known as microchips, they were revolutionizing electronics and computing, contributing to the gradual miniaturization of computers from mainframes to today’s smartphones. NASA sourced the circuits from the original Silicon Valley start-up, Fairchild Semiconductor. Fairchild was also leading the way in the practice known as outsourcing; the company opened a factory in Hong Kong in the early 1960s, which by 1966 employed 5,000 people, compared with Fairchild’s 3,000 California employees.\n\nAt the same time, Fairchild sought low-cost labor within the United States. Lured by tax incentives and the promise of a labor force with almost no other employment options, Fairchild opened a plant in Shiprock, N.M., within the Navajo reservation, in 1965. The Fairchild factory operated until 1975 and employed more than 1,000 individuals at its peak, most of them Navajo women manufacturing integrated circuits.\n\nIt was challenging work. Electrical components had to be placed on tiny chips made of a semiconductor such as silicon and connected by wires in precise locations, creating complex and varying patterns of lines and geometric shapes. The [Navajo women’s work](https://lnakamur.files.wordpress.com/2011/01/indigenous-circuits-nakamura-aq.pdf) “was performed using a microscope and required painstaking attention to detail, excellent eyesight, high standards of quality and intense focus,” writes digital media scholar Lisa Nakamura.\n\n![A Fairchild 9040 integrated circuit juxtaposed with a geometrically patterned rug](https://www.sciencenews.org/wp-content/uploads/2022/02/sn100_computing_spotlight-weaver_fairchild9040.jpg)\n\nA brochure commemorating the dedication of Fairchild Semiconductor’s plant in Shiprock, N.M., included this Fairchild 9040 integrated circuit.COURTESY OF THE COMPUTER HISTORY MUSEUM\n\nIn a [brochure commemorating the dedication of the Shiprock plant](https://archive.computerhistory.org/resources/access/text/2017/01/102770254-05-01-acc.pdf), Fairchild directly compared the assembly of integrated circuits with what the company portrayed as the traditional, feminine, Indigenous craft of rug-weaving. The Shiprock brochure juxtaposed a photo of a microchip with one of a geometric-patterned rug, and another of a woman weaving such a rug. That portrayal, Nakamura argues, reinforced racial and gender stereotypes. The work was dismissed as “women’s work,” depriving the Navajo women of appropriate recognition and commensurate compensation.  Journalists and Fairchild employees also “depict[ed] electronics manufacture as a high-tech version of blanket weaving performed by willing and skillful Indigenous women,” Nakamura notes, yet “the women who performed this labor did so for the same reason that women have performed factory labor for centuries — to survive.”\n\nFar from the Shiprock desert, outside of Boston, women employees at Raytheon assembled the Apollo Guidance Computer’s core memory with a process that in this case directly mimicked weaving. Again, the moon missions demanded a stable and compact way of storing Apollo’s computing instructions. Core memory used metal wires threaded through tiny doughnut-shaped ferrite rings, or “cores,” to represent 1s and 0s. All of this core memory was [woven by hand](https://scholarworks.umass.edu/cpo/vol7/iss2/4/), with women sitting on opposite sides of a panel passing a wire-threaded needle back and forth to create a particular pattern. (In some cases, a woman worked alone, passing the needle through the panel to herself.)\n\n![an old, black-and-white photo of a woman threading metal wire through small holes in a machine](https://www.sciencenews.org/wp-content/uploads/2022/02/sn100_computing_spotlight-weaver_raytheon-woman.jpg)\n\nWomen employees of Raytheon assembled core memory for the Apollo Guidance Computer by threading metal wires through rings. (This unnamed woman was described as a “space age needleworker” in a Raytheon press kit.)COURTESY OF THE COLLECTION OF DAVID MEERMAN SCOTT, RAYTHEON PUBLIC RELATIONS\n\nApollo engineers referred to this process of building memory as the “LOL,” or “Little Old Ladies,” method. Yet this work was so mission critical that it was tested and inspected multiple times. Mary Lou Rogers, who worked on Apollo, [recalled](http://news.bbc.co.uk/2/hi/technology/8148730.stm), “[Each component] had to be looked at by three of four people before it was stamped off. We had a group of inspectors come in for the federal government to check our work all the time.”\n\nThe core memory was also known as rope memory, and those who supervised its development were “rope mothers.” We know a great deal about one rope mother — Margaret Hamilton. She has been recognized with the [Presidential Medal of Freedom](https://obamawhitehouse.archives.gov/blog/2016/11/22/celebrating-presidential-medal-freedom-winners-science-and-tech-garwin-hopper-and), among other awards, and is now remembered as the woman who oversaw most of the Apollo software. But her efforts were unrecognized by many at the time. Hamilton [recalled](https://www.theguardian.com/technology/2019/jul/13/margaret-hamilton-computer-scientist-interview-software-apollo-missions-1969-moon-landing-nasa-women), “At the beginning, nobody thought software was that big a deal. But then they began to realize how much they were relying on it…. Astronauts‘ lives were at stake. Our software needed to be ultrareliable and it needed to be able to detect an error and recover from it at any time during the mission. And it all had to fit on the hardware.” Yet, little is known about the thousands of others who performed this mission-critical work of weaving integrated circuits and core memory.\n\n![A black-and-white photo of Margaret Hamilton standing and smiling next to a very tall stack of books](https://www.sciencenews.org/wp-content/uploads/2022/02/sn100_computing_spotlight-weaver_hamilton.jpg)\n\nMargaret Hamilton is known for overseeing the development of the Apollo software.DRAPER LABORATORY, RESTORED BY ADAM CUERDEN/WIKIMEDIA COMMONS\n\nAt the time, Fairchild’s representation of the Navajo women’s work as a feminine craft differentiated it from the high-status and masculine work of engineering. As Nakamura has [written](https://lnakamur.files.wordpress.com/2011/01/indigenous-circuits-nakamura-aq.pdf), the work “came to be understood as affective labor, or a ‘labor of love.’” Similarly, the work performed at Raytheon was described by Eldon Hall, who led the Apollo Guidance Computer’s hardware design, as “[tender loving care](https://scholarworks.umass.edu/cpo/vol7/iss2/4/).” Journalists and even a Raytheon manager presented this work as requiring no thinking and no skill.\n\nRecently, the communications scholar Samantha Shorey, engineer Daniela Rosner, technologist Brock Craft and quilt artist Helen Remick firmly overturned the notion that weaving core memory was a “no-brainer” with their [Making Core Memory](https://faculty.washington.edu/dkrosner/files/CHI-2018-Core-Memory.pdf) project. In nine workshops, they invited participants to weave core memory “patches” using metal matrices, beads and conductive threads, showcasing the deep focus and meticulous attention to detail required. The patches were then assembled in an electronic quilt that played aloud accounts from 1960s Apollo engineers and Raytheon managers. The Making Core Memory collaboration challenged the dichotomy of masculine, high-status, well-paid science and engineering cognitive labor versus feminine, low-status, low-paid, manual labor.\n\n## Subscribe to Science News\n\nGet great science journalism, from the most trusted source, delivered to your doorstep.\n\n[SUBSCRIBE](https://www.sciencenews.org/subscription?conversion=subscribe)\n\nA 1975 NASA report that summarized the Apollo missions spoke glowingly of the Apollo computing systems — but mentioned none of the Navajo or Raytheon women. “[The performance of the computer was flawless](https://history.nasa.gov/apsr/Apollopt3-1.pdf),” the report declared. “Perhaps the most significant accomplishment during Apollo pertaining to guidance, navigation, and control was the demonstration of the versatility and adaptability of the computer software.”\n\nThat computer, and that software, relied on the skilled, technical, embodied expertise and labor of thousands of women, including women of color. They were indubitably women of science, and their untold stories call us to reconsider _who_ does science, and what counts as scientific expertise.\n\n---\n\nhttps://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html\n\n### Software woven into wire: Core rope and the Apollo Guidance Computer\n\nOnboard the Apollo spacecraft, the revolutionary [Apollo Guidance Computer](https://en.wikipedia.org/wiki/Apollo_Guidance_Computer) helped navigate to the Moon and land on its surface. One of the first computers to use integrated circuits, the Apollo Guidance Computer was lightweight enough and small enough (70 pounds and under a cubic foot) to fly in space. An unusual feature that contributed to its small size was [core rope memory](https://en.wikipedia.org/wiki/Core_rope_memory), a technique of physically weaving software into high-density storage. In this blog post, I take a close look at core rope and the circuitry that made it work.[1](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:earlyrope)\n\n[![Detail of core rope memory wiring from an early (Block I) Apollo Guidance Computer. Photo from Raytheon.](http://static.righto.com/images/agc-rope/Plate_19-w350.jpg \"Detail of core rope memory wiring from an early (Block I) Apollo Guidance Computer. Photo from Raytheon.\")](http://static.righto.com/images/agc-rope/Plate_19.jpg)\n\nDetail of core rope memory wiring from an early (Block I) Apollo Guidance Computer. [Photo](https://authors.library.caltech.edu/5456/1/hrst.mit.edu/hrs/apollo/public/visual3.htm) from Raytheon.\n\nThe Apollo Guidance Computer (AGC) had very little memory by modern standards: 2048 words of RAM in erasable core memory and 36,864 words of ROM in core rope memory. In the 1960s, most computers (including the AGC) used magnetic core memory for RAM storage, but core ropes were unusual and operated differently. Erasable core memory and core rope both used magnetic cores, small magnetizable rings. But while erasable core memory used one core for each bit, core rope stored an incredible 192 bits per core, achieving much higher density.[2](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:density) The trick was to put many wires through each core (as shown above), hardwiring the data: a 1 bit was stored by threading a wire through a core, while the wire bypassed the core for a 0 bit. Thus, once a core rope was carefully manufactured, using a half-mile of wire, data was permanently stored in the core rope.\n\n[![The Apollo Guidance Computer. The empty space on the left held the core rope modules. The connectors on the right linked the AGC to the rest of the spacecraft.](http://static.righto.com/images/agc-rope/agc-w600.jpg \"The Apollo Guidance Computer. The empty space on the left held the core rope modules. The connectors on the right linked the AGC to the rest of the spacecraft.\")](http://static.righto.com/images/agc-rope/agc.jpg)\n\nThe Apollo Guidance Computer. The empty space on the left held the core rope modules. The connectors on the right linked the AGC to the rest of the spacecraft.\n\nWe[3](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:owner) are restoring the Apollo Guidance Computer shown above. The core rope modules (which we don't have)[4](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:rope) would be installed in the empty space on the left. On the right of the AGC, you can see the two connectors that connected the AGC to other parts of the spacecraft, including the DSKY (Display/Keyboard). By removing the bolts holding the two trays together, we could disassemble the AGC. Pulling the two halves apart takes a surprising amount of force because of the three connectors in the middle that join the two trays. The tray on the left is the \"A\" tray, which holds the logic and interface modules. The tray on the right is the \"B\" tray, which holds the memory circuitry, oscillator, and alarm. The six core rope modules go under the metal cover in the upper right. Note that the core ropes took up roughly a quarter of the computer's volume.\n\n[![The AGC is implemented with dozens of modules in two trays. The trays are connected through the three connectors in the middle.](http://static.righto.com/images/agc-rope/agc-opened-w700.jpg \"The AGC is implemented with dozens of modules in two trays. The trays are connected through the three connectors in the middle.\")](http://static.righto.com/images/agc-rope/agc-opened.jpg)\n\nThe AGC is implemented with dozens of modules in two trays. The trays are connected through the three connectors in the middle.\n\n## How core rope works\n\nAt a high level, core rope is simple: sense wires go through cores to indicate 1's, or bypass cores to indicate 0's. By selecting a particular core, the sense wires through that core were activated to provide the desired data bits.\n\nMagnetic cores have a few properties that made core memory work.[7](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:erasabledifferences) By passing a strong current along a wire through the core, the core becomes magnetized, either clockwise or counterclockwise depending on the direction of the current. Normally the cores were all magnetized in one direction, called the \"reset\" state, and when a core was magnetized the opposite direction, this is called the \"set\" state. When a core flips from one state to another, the changing magnetic field induces a small voltage in any sense wires through the core. A sense amplifier detects this signal and produces a binary output.\n\nThe key advantage of core rope is that many sense wires pass through a single core, so you can store multiple bits per core and achieve higher-density storage. (In the case of the AGC, each core has 192 sense wires passing through (or around) it[5](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:wires), so each core stored 12 words of data.) This is in contrast to regular read/write core memory, where each core held one bit.\n\nCore rope used an unusual technique to select a particular core to flip and read. Instead of directly selecting the desired core, inhibit lines blocked the flipping of every core _except_ the desired one. In the diagram below, the current on the set line (green) would potentially flip all the cores. However, various inhibit lines (red) have a current in the opposite direction. This cancels out the set current in all the cores except #2, so only core #2 flips.\n\n[![This diagram illustrates how core rope memory worked. Simplified diagram from MIT's Role in Project Apollo vol III, Fig. 3-12](http://static.righto.com/images/agc-rope/rope-simplified-diagram-w600.png \"This diagram illustrates how core rope memory worked. Simplified diagram from MIT's Role in Project Apollo vol III, Fig. 3-12\")](http://static.righto.com/images/agc-rope/rope-simplified-diagram.png)\n\nThis diagram illustrates how core rope memory worked. Simplified diagram from [MIT's Role in Project Apollo vol III](http://ibiblio.org/apollo/hrst/archive/1029.pdf), Fig. 3-12\n\nIn the diagram above, only the sense lines (blue) passing through core #2 pick up an induced voltage. Thus, the weaving pattern of the sense lines controls what data is read from core #2. To summarize, the inhibit lines control which core is selected, and the sense wires woven through that core control what data value is read.\n\nThe inhibit lines are driven from the address lines and arranged so that all inhibit lines will be inactive for just the desired core. For any other address, at least one inhibit line will be activated, preventing the core from flipping and being read. [6](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:complications)\n\n## The AGC's core ropes\n\nThe Apollo Guidance Computer contained six core rope modules, each storing 6 kilowords of program information. The AGC was a 15-bit machine: each word consisted of 15 data bits and a parity bit. (While a word that isn't a power of two may seem bizarre now, computers in the 1960s were designed with whatever word size fit the problem.[8](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:wordsize)) Each module contained 512 cores, each storing 12 words of data. That is, each module had 192 (12×16) sense wires going either through or around each core. Each group of 16 sense wires for a word was called a \"strand\", so there were 12 strands.\n\n[![AGC with rope modules. A rope module is partially inserted into one of the 6 slots in the AGC. Photo © Draper Labs via Caltech.](http://static.righto.com/images/agc-rope/agc_with_ropes-w400.jpg \"AGC with rope modules. A rope module is partially inserted into one of the 6 slots in the AGC. Photo © Draper Labs via Caltech.\")](http://static.righto.com/images/agc-rope/agc_with_ropes.jpg)\n\nAGC with rope modules. A rope module is partially inserted into one of the 6 slots in the AGC. Photo © Draper Labs via [Caltech](https://authors.library.caltech.edu/5456/1/hrst.mit.edu/hrs/apollo/public/visual3.htm).\n\nThe photo above shows how the core rope modules slid into the Apollo Guidance Computer; the pins on the end of each module meshed with connectors in the AGC. The core rope module below (and its companion) held an early Lunar Module program called Retread 50. We took our AGC to the Computer History Museum to read the data from these modules and we put the results [online](https://virtualagc.github.io/virtualagc/Restoration.html#Computer_History_Museum:_RETREAD_50).\n\n[![This core rope module held the Retread 50 software for the Apollo Guidance Computer. This module is from the Computer History Museum.](http://static.righto.com/images/agc-rope/fixed-memory-module-b2-w300.jpg \"This core rope module held the Retread 50 software for the Apollo Guidance Computer. This module is from the Computer History Museum.\")](http://static.righto.com/images/agc-rope/fixed-memory-module-b2.jpg)\n\nThis core rope module held the Retread 50 software for the Apollo Guidance Computer. This module is from the Computer History Museum.\n\nThe 512 cores in each module were arranged physically as two layers of 256 cores (but electrically as four planes of 128 cores).[9](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:block1) A set and reset line went through all the cores in a plane, allowing a particular plane in the module to be selected.[6](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:complications) The photo below shows the interior of a core rope module. One layer of 256 cores is visible, with the tiny wires threaded through them. (The second layer of 256 cores is underneath.) Note that the cores only take up about half the module space. Surrounding the cores are hundreds of resistors and diodes that were used to select the desired word.[10](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:select): These components were mounted with [cordwood construction](https://en.wikipedia.org/wiki/Printed_circuit_board#Cordwood_construction), with the components installed vertically through holes in the module.\n\n[![Inside a core rope. The 32×8 cores visible form a layer of 256 cores; a second layer is underneath. Photo from CHM/Raytheon CN-4-421-C.](http://static.righto.com/images/agc-rope/core-rope-internal-w500.jpg \"Inside a core rope. The 32×8 cores visible form a layer of 256 cores; a second layer is underneath. Photo from CHM/Raytheon CN-4-421-C.\")](http://static.righto.com/images/agc-rope/core-rope-internal.jpg)\n\nInside a core rope. The 32×8 cores visible form a layer of 256 cores; a second layer is underneath. Photo from CHM/Raytheon CN-4-421-C.\n\nThe photo below shows one of the Retread 50 modules from the Computer History Museum with the cover removed. The cores were encased (potted) in protective epoxy to protect them during flight, so the cores are not visible.\n\n[![A core rope module with the cover removed.  This module is at the Computer History Museum.](http://static.righto.com/images/agc-rope/module-chm-w500.jpg \"A core rope module with the cover removed.  This module is at the Computer History Museum.\")](http://static.righto.com/images/agc-rope/module-chm.jpg)\n\nA core rope module with the cover removed. This module is at the Computer History Museum.\n\n## Manufacturing the core rope\n\nWiring of the core rope was a tedious process that took about 8 weeks and cost $15,000 per module. As a result, the computer code needed to be frozen months in advance and last-minute patches to the code were not possible.[11](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:leap) The core ropes (and the AGC) were manufactured by Raytheon in Waltham, Massachusetts. Many of the women building the ropes were hired from the local textile industry for their sewing skills; other skilled women came from the [Waltham Watch Company](https://en.wikipedia.org/wiki/Waltham_Watch_Company#Waltham_Watch_and_the_race_to_the_moon), a company that also helped with the high-precision gyroscopes used on the Apollo missions.[12](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:gendered)\n\nMuch of the core rope wiring (address inhibit wires, set, reset, etc.) was the same for all core rope modules. Two women passed a needle back and forth through the cores to create this wiring. The needle was hollow and contained the necessary length of wire. The clip above (from [Computers for Apollo](https://youtu.be/ndvmFlg1WmE?t=1292) via [xpascal](http://www.angelfire.com/moon2/xpascal/MoonHoax/ProgressReport/ProgressReport.HTM)) shows this process.\n\n[![\"Space age needleworker 'weaves' core rope memory for guidance computers used in Apollo missions.\nMemory modules will permanently store mission profile data on which critical maneuvers in space are based.\nCore rope memories are fabricated by passing needle-like, hollow rod containing a length of fine wire through cores in the module frame.\nModule frame is moved automatically by computer-controlled machinery to position proper cores for weaving operation. Apollo guidance computer and associated display keyboard are produced at Raytheon Company plant in Waltham, Massachusetts.\"\nCaption and photo are from a Raytheon document, courtesy of \nTransistor Museum.](http://static.righto.com/images/agc-rope/rope-threader-w300.jpg \"\"Space age needleworker 'weaves' core rope memory for guidance computers used in Apollo missions.\nMemory modules will permanently store mission profile data on which critical maneuvers in space are based.\nCore rope memories are fabricated by passing needle-like, hollow rod containing a length of fine wire through cores in the module frame.\nModule frame is moved automatically by computer-controlled machinery to position proper cores for weaving operation. Apollo guidance computer and associated display keyboard are produced at Raytheon Company plant in Waltham, Massachusetts.\"\nCaption and photo are from a Raytheon document, courtesy of \nTransistor Museum.\")](http://static.righto.com/images/agc-rope/rope-threader.jpg)\n\n\"Space age needleworker 'weaves' core rope memory for guidance computers used in Apollo missions. Memory modules will permanently store mission profile data on which critical maneuvers in space are based. Core rope memories are fabricated by passing needle-like, hollow rod containing a length of fine wire through cores in the module frame. Module frame is moved automatically by computer-controlled machinery to position proper cores for weaving operation. Apollo guidance computer and associated display keyboard are produced at Raytheon Company plant in Waltham, Massachusetts.\" Caption and photo are from a Raytheon document, courtesy of [Transistor Museum](http://semiconductormuseum.com/Museum_Index.htm).\n\nTo store the desired binary data, the core rope's sense lines were threaded through or around cores in the proper sequence. Originally, this wiring was done entirely manually, which was slow and error-prone. Raytheon improved the process by combining automated positioning with manual threading. First, the program's [assembly code](https://virtualagc.github.io/virtualagc/listings/Retread50/LIST-PROCESSING_INTERPRETER.agc.html) was fed into an assembler called [YUL](https://virtualagc.github.io/virtualagc/yaYUL.html#What_is_YUL) that produced a Mylar punched tape. An automated system (above, below) read this tape and step-by-step moved the proper core into position. A woman manually threaded the sense line through an aperture into the indicated core. The aperture then jogged down to pull the wire around a nylon pin, moving the wire out of the way for the next sense wire to be threaded. Once all the cores were threaded, the nylon pins were removed and the final core rope module was tested by an automated system, again controlled by punched tape.\n\n[![A woman wiring sense lines in a core rope. She is threading the wire through a white circular aperture that indicates the core to wire. Source: Raytheon CN-4-20C / Smithsonian Institution WEB15435-2016.](http://static.righto.com/images/agc-rope/weaving-core-w400.jpg \"A woman wiring sense lines in a core rope. She is threading the wire through a white circular aperture that indicates the core to wire. Source: Raytheon CN-4-20C / Smithsonian Institution WEB15435-2016.\")](http://static.righto.com/images/agc-rope/weaving-core.jpg)\n\nA woman wiring sense lines in a core rope. She is threading the wire through a white circular aperture that indicates the core to wire. Source: Raytheon CN-4-20C / [Smithsonian Institution](https://airandspace.si.edu/multimedia-gallery/13006hjpg?id=13006) WEB15435-2016.\n\n## Core rope circuitry\n\nCore rope required a lot of digital and analog circuitry to drive and read the ropes. This section briefly describes this circuitry and shows the modules that implemented it. The bottom four modules in the picture below (Sense Amplifier, Strand Select, and two Rope Drivers) implemented the analog circuitry. Logic modules (in the \"A\" tray shown earlier) decoded the address into rope, module, and strand select signals. We carefully tested the analog and digital modules individually before powering up the AGC.\n\n[![Tray B of the Apollo Guidance Computer. The erasable memory module is the large black module. Most of the other modules on the left are support for the erasable (RAM) and fixed (core rope) memory. The core rope modules would slide into the right hand side under the metal cover.](http://static.righto.com/images/agc-rope/trayb-w500.jpg \"Tray B of the Apollo Guidance Computer. The erasable memory module is the large black module. Most of the other modules on the left are support for the erasable (RAM) and fixed (core rope) memory. The core rope modules would slide into the right hand side under the metal cover.\")](http://static.righto.com/images/agc-rope/trayb.jpg)\n\nTray B of the Apollo Guidance Computer. The erasable memory module is the large black module. Most of the other modules on the left are support for the erasable (RAM) and fixed (core rope) memory. The core rope modules would slide into the right hand side under the metal cover.\n\n### Sense Amplifier Modules\n\nWhen a core flipped (either in fixed memory or erasable memory), the changing magnetic field induced a weak signal in a sense line, one sense line for each bit in the word. This signal needed to be amplified and converted to a logic signal; this was the job of the sense amplifiers. The sense amplifiers were implemented using a custom sense amplifier IC. (The AGC used only two different types of integrated circuits, the sense amplifier and a dual NOR gate.) The AGC had two identical sense amplifier modules; one (in slot B13) was used by the erasable core memory, while the other (B14) was used by the fixed core rope memory.\n\nThe photo below shows a sense amp module. Eight sense amplifiers are visible and eight other sense amplifiers are on the other side of the module. The sense amplifiers required carefully-tuned voltage levels for bias and thresholds so the modules included voltage regulation circuitry (center and right in photo). On top of the module (front in the photo), you can see the horizontal lines of the nickel ribbon that connected the circuits; it is somewhat similar to a printed circuit board.\n\n[![Sense amplifier module with the top removed. Note the nickel ribbon interconnect at the top of the module.](http://static.righto.com/images/agc-rope/sense-amp-w850.jpg \"Sense amplifier module with the top removed. Note the nickel ribbon interconnect at the top of the module.\")](http://static.righto.com/images/agc-rope/sense-amp.jpg)\n\nSense amplifier module with the top removed. Note the nickel ribbon interconnect at the top of the module.\n\nThe closeup photo below shows the module's [cordwood construction](https://en.wikipedia.org/wiki/Printed_circuit_board#Cordwood_construction). In this high-density construction technique, components were inserted into holes in the module. Resistors and capacitors passed through from one side of the module to the other, with one lead on either side. On each side of the module, components were connected by point-to-point wiring. This wiring was welded, not soldered. White insulating sleeves were placed over the wires to prevent short circuits.\n\n[![Closeup of the sense amplifier module for the AGC. The sense amplifier integrated circuits are at the top and the reddish pulse transformers are below. The pins are at the bottom and the wires at the top go to the nickel ribbon, which is like a printed circuit board.](http://static.righto.com/images/agc-rope/sense-amp-closeup2-w350.jpg \"Closeup of the sense amplifier module for the AGC. The sense amplifier integrated circuits are at the top and the reddish pulse transformers are below. The pins are at the bottom and the wires at the top go to the nickel ribbon, which is like a printed circuit board.\")](http://static.righto.com/images/agc-rope/sense-amp-closeup2.jpg)\n\nCloseup of the sense amplifier module for the AGC. The sense amplifier integrated circuits are at the top and the reddish pulse transformers are below. The pins are at the bottom and the wires at the top go to the nickel ribbon, which is like a printed circuit board.\n\nNear the top of the photo are two amplifier integrated circuits in metal cans. Below are two reddish pulse transformers. An output driver transistor is between the pulse transformers.[13](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:fixed) Only the ends of resistors are visible, due to the cordwood construction. At the top of the module are connections to the nickel ribbon interconnect. Modules that were flown on spacecraft were potted in plastic so the components were protected against vibration. Since our AGC was used on the ground, most modules were unpotted and the components are visible.\n\n### Address decoding\n\nAddress decoding for the core rope required a fair amount of logic for two reasons. The first problem was the AGC's instructions used 12-bit addresses, which could only address 4 kilowords of storage. Since the AGC had 36 kilowords of fixed memory and 2 kilowords of erasable memory, it used a [complex system](https://www.ibiblio.org/apollo/assembly_language_manual.html#Memory_Map) of bank registers and mapping logic to convert a 12-bit address into the correct physical memory location. The second problem was that each core rope module held 6 kilowords, which is not a power of two. Thus, moderately complex decoding circuitry was required to generate module and strand select signals from the address.\n\n[![The core rope addressing, control, and timing logic is spread across several logic modules. Most of the address decoding was implemented in logic module A15. Other core rope logic is in modules A6, A8, and A14. Photo courtesy of Mike Stewart.](http://static.righto.com/images/agc-rope/a14-w850.jpg \"The core rope addressing, control, and timing logic is spread across several logic modules. Most of the address decoding was implemented in logic module A15. Other core rope logic is in modules A6, A8, and A14. Photo courtesy of Mike Stewart.\")](http://static.righto.com/images/agc-rope/a14.jpg)\n\nThe core rope addressing, control, and timing logic is spread across several logic modules. Most of the address decoding was implemented in logic module A15. Other core rope logic is in modules A6, A8, and A14. Photo courtesy of Mike Stewart.\n\nThe AGC's logic circuitry (including the processor) was implemented with NOR gates. Each integrated circuit implemented two NOR gates using RTL (resistor-transistor logic), an early logic family. These ICs were costly; they cost $20-$30 each (around $150 in current dollars). There wasn't much inside each IC, just six transistors and eight resistors. Even so, the ICs provided a density improvement over the planned core-transistor logic, making the AGC practical. The decision to use ICs in the AGC was made in 1962, amazingly just four years after the IC was invented. The AGC was the [largest consumer of ICs](https://www.computerhistory.org/siliconengine/aerospace-systems-are-first-the-applications-for-ics-in-computers/) from 1962 to 1965 and ended up being a major driver of the integrated circuit industry.\n\n[![Each IC contained two NOR gates implemented with resistor-transistor logic. From SCD 2005011.](http://static.righto.com/images/agc-rope/nor-schematic-w500.png \"Each IC contained two NOR gates implemented with resistor-transistor logic. From SCD 2005011.\")](http://static.righto.com/images/agc-rope/nor-schematic.png)\n\nEach IC contained two NOR gates implemented with resistor-transistor logic. From [SCD 2005011](http://klabs.org/history/ech/agc_schematics/logic/5011-1.jpg).\n\n### Strand select\n\n[![The strand select module in position B15. Photo from Mike Stewart.](http://static.righto.com/images/agc-rope/strand-select-b15-w800.jpg \"The strand select module in position B15. Photo from Mike Stewart.\")](http://static.righto.com/images/agc-rope/strand-select-b15.jpg)\n\nThe strand select module in position B15. Photo from Mike Stewart.\n\nThe address decoding logic described above produced signals indicating the desired strand and module. These logic-level signals needed to be converted to 14-volt pulses to drive the core rope modules. This task was performed by the strand select module, which consisted of transistor driver circuits using NPN and PNP transistors. The resistors in these circuits were individually selected to produce exactly the desired currents.\n\n[![A closeup of the strand select module, showing its cordwood construction.](http://static.righto.com/images/agc-rope/strand-select-closeup-w500.jpg \"A closeup of the strand select module, showing its cordwood construction.\")](http://static.righto.com/images/agc-rope/strand-select-closeup.jpg)\n\nA closeup of the strand select module, showing its cordwood construction.\n\n### Rope driver\n\nThe rope driver modules generated the high-current pulses (up to 450mA) necessary to flip the cores. Like the strand select module, the rope driver modules used NPN and PNP transistor driver circuits with carefully-selected resistors to ensure the desired current. They also used inductors to control the pulse shape, necessary to keep switching noise from overwhelming the small signals generated by the cores. The modules generated 16 inhibit signals (7 address bits and parity, along with complements) as well as two core set signals and four core reset signals.\n\n[![The rope driver modules in B16 and B17 provided high-current pulses to the rope module. Photo from Mike Stewart.](http://static.righto.com/images/agc-rope/rope-driver-big-w800.jpg \"The rope driver modules in B16 and B17 provided high-current pulses to the rope module. Photo from Mike Stewart.\")](http://static.righto.com/images/agc-rope/rope-driver-big.jpg)\n\nThe rope driver modules in B16 and B17 provided high-current pulses to the rope module. Photo from Mike Stewart.\n\n## The core rope simulator\n\nUnfortunately, the core ropes were missing from the Apollo Guidance Computer we are restoring. Instead, this AGC has core rope simulator boxes in place of the ropes. The purpose of these simulator boxes was to feed code into an AGC for development and ground testing without requiring a new core rope to be manufactured every time. The simulator allowed an external computer to supply data words in place of the core rope, allowing the AGC to run arbitrary programs.\n\n[![The core rope simulators are installed in the left side of the AGC in place of the real core ropes. Two round connectors on the left allowed the simulators to be connected to an external computer that provided the data.](http://static.righto.com/images/agc-rope/agc-rope-sim-w500.jpg \"The core rope simulators are installed in the left side of the AGC in place of the real core ropes. Two round connectors on the left allowed the simulators to be connected to an external computer that provided the data.\")](http://static.righto.com/images/agc-rope/agc-rope-sim.jpg)\n\nThe core rope simulators are installed in the left side of the AGC in place of the real core ropes. Two round connectors on the left allowed the simulators to be connected to an external computer that provided the data.\n\nThe simulator consists of two boxes that plugged into the AGC's core rope slots. These boxes are visible in the upper-left side of the AGC above, with round military-style connectors for connection to the external computer. One box exported address information each time the AGC performed a core rope read, while the other box fed 16 data bits into the AGC, \"tricking\" the AGC into thinking it had read from core rope. I built an interface from the core rope simulator boxes to a Beaglebone and will write more about that project later.\n\n## Conclusion\n\nCore memory was the most common storage technology for computers in the 1960s. However, the Apollo Guidance Computer also used core ropes for read-only storage, an uncommon storage technique that achieved high density but required considerable labor. Core ropes made it possible to fit complex software into the compact physical space of the AGC. While 36K of code seems ludicrously small by modern standards, it held enough code to navigate and land on the Moon. And now, decades later, we can recover this code from core rope modules and learn more about it.\n\nMarc has a [series of AGC videos](https://www.youtube.com/watch?v=2KSahAoOLdU); the video below discusses the core rope simulators. I announce my latest blog posts on Twitter, so follow me [@kenshirriff](https://twitter.com/kenshirriff) for future articles. I also have an [RSS feed](https://www.righto.com/feeds/posts/default). See the footnotes for more information sources[15](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fn:links). Thanks to Mike Stewart for supplying images and extensive information.\n\n## Notes and references\n\n1.  [Prototype core rope memories](https://en.wikipedia.org/wiki/Core_rope_memory#/media/File:Apollo_guidiance_computer_ferrit_core_memory.jpg) had a single bundle of wire that looked similar to a rope. The final core rope memories didn't look as rope-like, but kept the name. [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:earlyrope \"Jump back to footnote 1 in the text\")\n    \n2.  The core rope memory achieved a density of 1500 bits per cubic inch, including the driving hardware and packaging. This was about 5 times the density of erasable core memory. See [MIT's Role in Project Apollo vol III](http://ibiblio.org/apollo/hrst/archive/1029.pdf) pages 91 and 274.\n    \n    The cores in core rope were not regular ferrite cores, but [permalloy](https://en.wikipedia.org/wiki/Permalloy) ribbon wound around a non-magnetic steel bobbin. If you're used to ferrite cores, winding a metallic ribbon around a bobbin may seem like a strange way to make a core, but that was how the earliest cores were built, until ferrite cores started to be used in the early 1950s. The ferromagnetic materials used in wound-ribbon cores were developed by Germany in World War II and used by the German navy in magnetic amplifiers. After the war, American personnel brought back the material along with a rolling mill, and started US manufacturing under the name Deltamax. In other words, core memory had its origin in Nazi technology captured by the US. See [Memories that shaped an industry](https://amzn.to/2HhfAnY), pages 39-40, 52, 87, 90.\n    \n    The cores used in the core rope were rather large, .249\" in diameter, about 5 times the diameter of the cores used in the erasable core memory. (In comparison, some IBM 360 mainframes of the same era used tiny cores that were .021\" in diameter.) When a rope core flipped, it yielded a fairly large voltage pulse of 215-430 mV. Properties of the cores were defined in NASA specification control drawing [SCD-1006320](http://www.ibiblio.org/apollo/SCDs/scd_1006320-.pdf). [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:density \"Jump back to footnote 2 in the text\")\n    \n3.  The AGC restoration team consists of Mike Stewart (creator of [FPGA AGC](https://github.com/virtualagc/agc_simulation)), [Carl Claunch](https://rescue1130.blogspot.com/2018/11/restoring-apollo-guidance-computer-part.html), Marc Verdiell ([CuriousMarc](https://www.youtube.com/channel/UC3bosUr3WlKYm4sBaLs-Adw) on YouTube) and myself. The AGC that we're restoring belongs to a private owner who picked it up at a scrap yard in the 1970s after NASA scrapped it. For simplicity, I refer to the AGC we're restoring as \"our AGC\".\n    \n    The Apollo flights had one AGC in the command module (the capsule that returned to Earth) and one AGC in the lunar module. In 1968, before the Moon missions, NASA [tested a lunar module](https://www.nasa.gov/feature/50-years-ago-thermo-vacuum-testing-certifies-critical-lunar-hardware) with astronauts aboard in a giant vacuum chamber in Houston to ensure that everything worked in space-like conditions. We believe our AGC was installed in that lunar module (LTA-8). Since this AGC was never flown, most of the modules were not potted with epoxy. [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:owner \"Jump back to footnote 3 in the text\")\n    \n4.  Yes, we know about [Francois](https://youtu.be/WquhaobDqLU) and the rope modules he read; those are ropes for the earlier Block I Apollo Guidance Computer and are not compatible with our Block II AGC. Also, many people have asked if we talked to [Fran](https://www.youtube.com/watch?v=UjcfepTdvZI) about the DSKY. Yes, we have. [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:rope \"Jump back to footnote 4 in the text\")\n    \n5.  Mike Stewart pointed out that a core wouldn't have all 192 sense wires passing through it. Because the system used odd parity, at most 15 of the 16 bits can be high. Thus, at most 180 sense wires would pass through a core. [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:wires \"Jump back to footnote 5 in the text\")\n    \n6.  The Apollo Guidance Computer had one additional pair of inhibit lines for address parity so all non-matching cores will have at least two inhibit lines activated. (If a core was one line away from being activated, the parity would also be different, yielding two active inhibit lines.) The purpose of this was to ensure that every non-selected core received two inhibit signals and was solidly inhibited. Otherwise, a core with just one inhibit line high might receive a bit of net set current, changing its magnetism slightly and introducing noise.\n    \n    Note that 7 address lines select one of 128 cores. Each module consists of four (logical) planes of 128 cores, yielding 512 cores. To select one of the four planes, four different reset lines are used, to reset just the core in the desired plane. Thus, only that plane is read. Two set lines are used, one to set cores in planes A and B, and one for planes C and D. To avoid setting cores in two planes, the reset line in the undesired plane was activated at the same time as the set line, blocking the set in that plane. The obvious approaches would be to use four set lines (one per plane), or one set line (and use reset to block the others). I don't know why they used two set lines.\n    \n    Each module also had a \"clear\" line that passed through all the cores. This was similar to reset, but was needed due to a complexity of the AGC's opcode decoding. To fit more opcodes into a 15-bit instruction, the AGC used \"[quartercode](https://www.ibiblio.org/apollo/assembly_language_manual.html#Instruction_Representation)\" instructions. The idea was that some instructions didn't make sense on a fixed memory address, such as increment. The AGC would perform an entirely different instruction in that case, allowing a larger instruction set. The problem was that by the time instruction decoding had decided that the instruction didn't apply to the specified address, the read of fixed memory had already started, and the core was set. The \"clear\" line allowed this core to be reset so it wouldn't interfere with the desired read. I don't know why the existing reset lines couldn't be used for this purpose. ([Summary](https://archive.org/details/acelectroniclmma00acel_0/page/n275) and [details](https://www.ibiblio.org/apollo/Documents/dd_memo_376.pdf).) The schematic is [here](https://archive.org/details/acelectroniclmma00acel_0/page/n293). [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:complications \"Jump back to footnote 6 in the text\")\n    \n7.  If you are familiar with regular core memory (i.e. erasable RAM core memory), there are many similarities, but also many important differences. First, erasable core memory was arranged in a grid, and a particular core was selected by energizing an X line and a Y line in the grid. Second, erasable core memory stored a single bit per core, with the direction of magnetization indicating a 0 or 1. Core rope, on the other hand, stored many bits per core, with a 0 or 1 depending on if a sense wire goes through the core or not. The cores in core rope were much larger, since about 200 wires went through each core, while erasable core memory typically had 3 wires through each core. Finally, erasable core memory used the inhibit line for writing a 0, while core rope used inhibit lines for addressing. [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:erasabledifferences \"Jump back to footnote 7 in the text\")\n    \n8.  For more information on why the Apollo Guidance Computer used 15-bit words, see [MIT's Role in Project Apollo vol III](http://ibiblio.org/apollo/hrst/archive/1029.pdf) page 32. The short answer is they required about 27-32 bits accuracy for navigation computations, and about 15 bits for control variables. Using a 15-bit word for small values and double-precision values for navigation provided sufficient accuracy. A 14-bit word was too small. A 17- or 18- bit word would simplify some things but increase costs. [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:wordsize \"Jump back to footnote 8 in the text\")\n    \n9.  Core rope memory in the earlier Block I Apollo Guidance Computer was configured slightly differently. The memory was folded into 4 layers of 128 cores instead of 2 layers of 256 cores. As a result, the Block I rope modules had a different shape: roughly square in cross-section, unlike the flat Block II modules. In early Block I modules, each core had 128 sense wires (8 words) threaded through it, yielding 4K words per module. With 6 modules, an early Block I AGC had 24K words of rope storage. In later Block I AGCs, the rope modules provided more storage: 192 sense wires (12 words) per core, yielding 6K words per module. Thus, 24K of rope storage required just 4 modules. For the Block II computers used for the Moon missions, 6 modules × 512 cores per module × 192 bits per core ÷ 16 bits per word = 36864 (36K) words in total. [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:block1 \"Jump back to footnote 9 in the text\")\n    \n10.  Selection of a particular module and strand was done through a resistor/diode biasing network using hundreds of resistors and diodes in each module. The diagram below shows how this network operated. The selected strand line was pulled high, while the selected module line was pulled low. This resulted in current (red) through the selected strand and through the sense amplifier transformer. The remaining diodes were reverse-biased, so no current flowed. A voltage pulse on the sense wire through the selected core perturbed the current flow, resulting in a voltage imbalance across the sense amplifier transformer. This signal was detected by the sense amplifier, resulting in a 1 bit. (This circuit is rather confusing; you might expect the circuit to be a loop through the sense wire and the sense amplifier transformer, but instead, the currents are flowing towards the 0-volt module line in the middle. Study the directional arrows carefully to see how the current flows. The current from a flipped core is essentially superimposed on this current flow.)\n    \n    [![A particular strand and module were selected by a resistor/diode network. The non-selected diodes were reverse-biased, blocking those signals from the sense amplifiers.  Based on MIT's Role in Project Apollo vol III, Fig. 3-13](http://static.righto.com/images/agc-rope/module-select-labeled-w500.jpg \"A particular strand and module were selected by a resistor/diode network. The non-selected diodes were reverse-biased, blocking those signals from the sense amplifiers.  Based on MIT's Role in Project Apollo vol III, Fig. 3-13\")](http://static.righto.com/images/agc-rope/module-select-labeled.jpg)\n    \n    A particular strand and module were selected by a resistor/diode network. The non-selected diodes were reverse-biased, blocking those signals from the sense amplifiers. Based on [MIT's Role in Project Apollo vol III](http://ibiblio.org/apollo/hrst/archive/1029.pdf), Fig. 3-13\n    \n    The resistor and diodes in the left green box were repeated once for each strand (i.e. 192 times in each module), while the resistor and diodes in the right box were repeated once for each sense line (i.e. 16 times in each module). [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:select \"Jump back to footnote 10 in the text\")\n    \n11.  The need to freeze the software design weeks in advance was viewed as a feature: \"The inability to change the program without rebuilding one or more modules provides an effective management tool for the control of software changes. It also provides another incentive to make the software error free.\" See [MIT's Role in Project Apollo vol III](http://ibiblio.org/apollo/hrst/archive/1029.pdf) page 274. Much of the information in this section on core rope manufacturing is from [One Giant Leap](https://amzn.to/2NlGLmC). The 1965 video [Computers For Apollo](https://youtu.be/ndvmFlg1WmE?t=1244) shows AGC manufacturing process (including core ropes) in detail. [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:leap \"Jump back to footnote 11 in the text\")\n    \n12.  There are interesting gender issues behind the manufacture of core rope and core memory that I'll only mention briefly. The core rope has been referred to as LOL memory, referencing the \"Little Old Ladies\" who assembled it, but this name erases the women of color who also assembled core ropes. (I'm also not convinced that the LOL name was used at the time.) The software for a particular flight was managed by \"[rope mother](https://wehackthemoon.com/people/dan-lickly-computer-engineering)\" who was generally male (although the famous Margaret Hamilton was rope mother on LUMINARY). Also see [Making Core Memory: Design Inquiry into Gendered Legacies of Engineering and Craftwork](https://faculty.washington.edu/dkrosner/files/CHI-2018-Core-Memory.pdf).\n    \n    [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:gendered \"Jump back to footnote 12 in the text\")[![Women weaving a core rope. Raytheon photo, via BBC.](http://static.righto.com/images/agc-rope/raytheon-weaving-w400.jpg \"Women weaving a core rope. Raytheon photo, via BBC.\")](http://static.righto.com/images/agc-rope/raytheon-weaving.jpg)\n    \n    Women weaving a core rope. Raytheon photo, via [BBC](http://news.bbc.co.uk/2/hi/technology/8148730.stm).\n    \n13.  The sense amplifier output circuitry is a bit confusing because the erasable core memory (RAM) and fixed rope core memory (ROM) sense amp outputs were wired together to connect to the CPU. The RAM had one sense amp module with 16 amplifiers in slot B13, and the ROM had its own identical sense amp module in slot B14. However, each module only had 8 output transistors. The two modules were wired together so 8 output bits are driven by transistors in the RAM's sense amp module and 8 output bits are driven by transistors in the ROM's sense amp module. (The motivation behind this was to use identical sense amp modules for RAM and ROM, but only needing 16 output transistors in total. Thus, the transistors are split up 8 to a module.) [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:fixed \"Jump back to footnote 13 in the text\")\n    \n14.  I'll give a bit more detail on the sense amps here. The key challenge with the sense amps is that the signal from flipping a core is small and there are multiple sources of noise that the sense line can pick up. By using a differential signal (i.e. looking at the difference between the two inputs), noise that is picked up by both ends of the sense line (common-mode noise) can be rejected. The differential transformer improved the common-mode noise rejection by a factor of 30. (See page 9-16 of the [Design Review](http://www.ibiblio.org/apollo/Documents/agc_blk2_design_review.pdf).) The other factor is that the sense line goes through some cores in the same direction as the select lines, and through some cores the opposite direction. This helps cancel out noise from the select lines. However, the consequence is that the pulse on the select line may be positive or may be negative. Thus, the sense amp needed to handle pulses of either polarity; the threshold stage converted the bipolar signal to a binary output.\n    \n    [![Schematic of the circuitry inside a sense amplifier IC.](http://static.righto.com/images/agc-rope/sense-amp-labeled-w500.jpg \"Schematic of the circuitry inside a sense amplifier IC.\")](http://static.righto.com/images/agc-rope/sense-amp-labeled.jpg)\n    \n    Schematic of the circuitry inside a sense amplifier IC.\n    \n    The sense amplifier (above) was a custom integrated circuit designed by Sperry Rand in 1962. This chip pushed the state of the art for analog ICs and it may be the first integrated circuit amplifier. The sense amp chips initially cost $200 each, equivalent to $1700 now. [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:senseamp \"Jump back to footnote 14 in the text\")\n    \n15.  For more information on the AGC, the [Virtual AGC site](https://virtualagc.github.io/virtualagc/index.html) has tons of information on the AGC, in particular the [ElectroMechanical](https://virtualagc.github.io/virtualagc/ElectroMechanical.html) page has lots of schematics and drawings. There's a [video of Eldon Hall](http://www.ibiblio.org/apollo/klabs/video/hall.wmv), designer of the AGC, disassembling our AGC in 2004. Eldon Hall's book [Journey to the Moon](https://amzn.to/2J6nYav) describes development of the Apollo Guidance Computer in detail, and was very helpful for this blog post. If you want to try a simulated AGC in your browser, see [moonjs](http://svtsim.com/moonjs/agc.html).\n    \n    The Apollo manuals provide detailed information on the memory system. The manual has a [block diagram](https://archive.org/stream/acelectroniclmma00acel_0#page/n242/mode/1up) of the AGC's memory system. Engineering drawings of the AGC's core rope are [here](https://archive.org/stream/AgcApertureCardsBatch1Images#page/n228/mode/1up). Fixed memory is described in the AC Electronic LM Manual volume 2 starting at [4-594](https://archive.org/details/acelectroniclmma00acel_0/page/n275) and a core rope wiring diagram is [here](https://archive.org/stream/agc_handbook_jp2#page/n112/mode/2up). Sense amplifiers: [description](https://archive.org/details/acelectroniclmma00acel_0/page/n296), [schematics](https://archive.org/details/acelectroniclmma00acel_0/page/n298). Strand and module select circuits: [description](https://archive.org/details/acelectroniclmma00acel_0/page/n296), [schematic](https://archive.org/details/acelectroniclmma00acel_0/page/n284), [schematic](https://archive.org/details/acelectroniclmma00acel_0/page/n298). Set circuit: [description](https://archive.org/details/acelectroniclmma00acel_0/page/n275), [description](https://archive.org/details/acelectroniclmma00acel_0/page/n278), [schematic](https://archive.org/details/acelectroniclmma00acel_0/page/n282), [schematic](https://archive.org/details/acelectroniclmma00acel_0/page/n291). Reset circuit: [description](https://archive.org/details/acelectroniclmma00acel_0/page/n275), [description](https://archive.org/details/acelectroniclmma00acel_0/page/n278), [schematic](https://archive.org/details/acelectroniclmma00acel_0/page/n289). Inhibit circuit: [description](https://archive.org/details/acelectroniclmma00acel_0/page/n279), [schematic](https://archive.org/details/acelectroniclmma00acel_0/page/n287). Address decoder: [description](https://archive.org/details/acelectroniclmma00acel_0/page/n93), [schematic](https://archive.org/details/acelectroniclmma00acel_0/page/n98). [↩](https://www.righto.com/2019/07/software-woven-into-wire-core-rope-and.html#fnref:links \"Jump back to footnote 15 in the text\")\n\n\n\n---\n\nhttp://timui.blogspot.com/p/core-rope-memory.html\n\n### Core Rope Memory\n\nThis is [Core Rope Memory](https://en.wikipedia.org/wiki/Core_rope_memory), a type of [read-only memory](https://simple.wikipedia.org/wiki/Read-only_memory) that was used in the Apollo space program. It was often called LOL (Little Old Lady) memory, because it was painstakingly [woven by hand](https://www.youtube.com/watch?v=P12r8DKHsak) by seamstresses.  \n  \n\n[![](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Apollo_guidiance_computer_ferrit_core_memory.jpg/220px-Apollo_guidiance_computer_ferrit_core_memory.jpg)](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Apollo_guidiance_computer_ferrit_core_memory.jpg/220px-Apollo_guidiance_computer_ferrit_core_memory.jpg)\n\nCore rope memory test sample from the Apollo Program. (photo from Wikipedia)\n\n  \nThe core concept (ba dum dum) of this type of memory is that the wires (green in the photo above) weave in and out of the cores (red beads above); each wire is a binary word (in my jewellery, a character) and each bit is encoded by the wire going through (1) or around (0) the bead.  \n  \nThis photo made me want to have a piece of this memory to wear. It's beautiful, and I love the idea of jewellery that encodes a message. I began with beads and embroidery thread, but as I worked on the design I started to want jewellery that not only encoded a message, but could be read electronically.  \n  \nThe first step in that process was to make a working demonstration of a small piece of Core Rope Memory. There are a few short videos showing the working demo in [this post](http://www.timui.org/2015/07/omg.html), and you can see some of the steps along the way in posts labeled [core-rope-memory](http://www.timui.org/search/label/core-rope-memory). I presented the demo at [Dublin Maker 2015](http://www.dublinmaker.ie/).  \n  \nI had a stall at [Octocon](http://2015.octocon.com/) 2015 where I sold the bead-based jewellery (amongst other things). I'm still taking orders (email contact[at]timui[dot]org), but my main focus for the project is now miniaturizing the demo so that I can make wearable jewellery that can be read electronically.  \n  \nHere are a couple of photos of prototypes:  \n  \n  \n\n[![](https://2.bp.blogspot.com/-B5gUNiblAZM/VSFpba5n39I/AAAAAAAAZOM/Yhh1NcXG86Q/s1600/DSCF0376.JPG)](http://2.bp.blogspot.com/-B5gUNiblAZM/VSFpba5n39I/AAAAAAAAZOM/Yhh1NcXG86Q/s1600/DSCF0376.JPG)\n\n  \n\n[![](https://3.bp.blogspot.com/-oOsmCGfdLP0/VT6Z7N3ewsI/AAAAAAAAZP0/MHmsEnh5FLw/s1600/DSCF0400.JPG)](http://3.bp.blogspot.com/-oOsmCGfdLP0/VT6Z7N3ewsI/AAAAAAAAZP0/MHmsEnh5FLw/s1600/DSCF0400.JPG)\n\n  \n\n[![](https://2.bp.blogspot.com/-fNaUoae05Xc/VT6f_PbNmAI/AAAAAAAAZQE/CLJ9b0_o3lI/s1600/DSCF0406.JPG)](http://2.bp.blogspot.com/-fNaUoae05Xc/VT6f_PbNmAI/AAAAAAAAZQE/CLJ9b0_o3lI/s1600/DSCF0406.JPG)\n\n  \nAnd some of the orders from Octocon weekend  \n  \n\n[![](https://1.bp.blogspot.com/-QPnF9VCPAH0/Vh61uJo7rcI/AAAAAAAAZxM/xicKD0JfuPg/s320/paul-mara.JPG)](http://1.bp.blogspot.com/-QPnF9VCPAH0/Vh61uJo7rcI/AAAAAAAAZxM/xicKD0JfuPg/s1600/paul-mara.JPG)\n\n  \n\n[![](https://3.bp.blogspot.com/-a6jQVx_PbT0/Vhq_umqdF-I/AAAAAAAAZwg/Y7VvFRcRYA0/s320/DSCF0643%2B-%2BEdited.jpg)](http://3.bp.blogspot.com/-a6jQVx_PbT0/Vhq_umqdF-I/AAAAAAAAZwg/Y7VvFRcRYA0/s1600/DSCF0643%2B-%2BEdited.jpg)\n\n  \n  \n\n[![](https://2.bp.blogspot.com/-uXOtB81JoVc/Vh62dWsN8jI/AAAAAAAAZxU/qHTlOWpVe90/s320/bagged-bracelet.jpg)](http://2.bp.blogspot.com/-uXOtB81JoVc/Vh62dWsN8jI/AAAAAAAAZxU/qHTlOWpVe90/s1600/bagged-bracelet.jpg)\n\n  \n  \nI've just ordered some [toroidal balloons](https://mathsgear.co.uk/collections/all-products/products/torus-balloons) from [https://mathsgear.co.uk/](https://mathsgear.co.uk/) and I can't wait to use them in my display for Dublin Maker 2016!\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.197Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Construct Graph",
      "content": "Webworker, steps through all files in a notebook and generates a graph, returning all hash tags, as a graph.\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.197Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Context Switcher",
      "content": "```html\n\n<context-switcher>\n\t<notebook-page id=\"\"></notebook-page>\n</context-switcher>\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.198Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Convert JSON to CSV",
      "content": "```js\nfunction convertJSONtoCSV(json) {\n  const delimiter = ','; // Change this to a different delimiter if needed\n  let csv = '';\n\n  // Extracting the headers\n  const headers = Object.keys(json[0]);\n  csv += headers.join(delimiter) + '\\n';\n\n  // Extracting the values\n  json.forEach((item) => {\n    const row = headers.map((header) => {\n      let value = item[header];\n\n      // If the value contains a delimiter, surround it with double quotes\n      if (value && value.includes(delimiter)) {\n        value = `\"${value}\"`;\n      }\n\n      return value;\n    });\n\n    csv += row.join(delimiter) + '\\n';\n  });\n\n  return csv;\n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.198Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Copy to Clipboard",
      "content": "```js\nfunction copyToClipboard(text) {\n  const type = 'text/plain';\n  const blob = new Blob([text], {type});\n  const data = [new ClipboardItem({[type]: blob})];\n  navigator.clipboard.write(data).then(function() {\n    console.log('Copied to clipboard!');\n  }, function() {\n    console.log('Failed to copy to clipboard.');\n  });\n}\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.198Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Create New Form from Object",
      "content": "\nhttps://github.com/ProjectPhysX/FluidX3D\n\n---\n\n\n```javascript\nfunction createForm(json) {\n  // Create a new form element.\n  const form = document.createElement(\"form\");\n\n  // Iterate over the JSON object.\n  for (const [key, value] of Object.entries(json)) {\n    // Determine the appropriate input type for the value.\n    switch (typeof value) {\n      case \"string\":\n        inputType = \"text\";\n        break;\n      case \"number\":\n        inputType = \"number\";\n        break;\n      case \"boolean\":\n        inputType = \"checkbox\";\n        break;\n      default:\n        inputType = \"text\";\n        break;\n    }\n\n    // Create a new input element.\n    const input = document.createElement(\"input\");\n\n    // Set the input element's name and value.\n    input.name = key;\n    input.value = value;\n    input.type = inputType;\n\n    // Add the input element to the form.\n    form.appendChild(input);\n  }\n\n  // Return the form element.\n  return form;\n}\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.199Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Create New Notebook",
      "content": "notebook name,\nnotebook id\nnotebook description\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.199Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Crypto",
      "content": "```javascript\nasync function sha256(source) {\n    const sourceBytes = new TextEncoder().encode(source);\n    const digest = await crypto.subtle.digest(\"SHA-256\", sourceBytes);\n    const resultBytes = [...new Uint8Array(digest)];\n    return resultBytes.map(x => x.toString(16).padStart(2, '0')).join(\"\");\n}\n```\n\nCreate a hash for text\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.199Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Custom HTML Element",
      "content": "```js\n/*\n\nThis is an implementation of the HTML Custom Element API: https://developer.mozilla.org/en-US/docs/Web/API/Window/customElements\n\n\" Living code explains itself, somewhat, but the real value is in having a haunted town full of horror stories.\"\n  --𝙙𝙙𝙖𝙮\n\nOnly other programmers believe that below this comment lies several John Grisham novels worth of code.\n\nA demo:\n\nhttps://codepen.io/lindseymysse/pen/ExWZEEr\n\n*/\n\n\nclass CustomElement extends HTMLElement {\n\n  /* \n    the connectedCallback function runs when the component is connected to the dom. \n    the *this* keyword refers to the HTML component itself, and you\n    can treat it as any DOM object \n  */\n  \n  connectedCallback(){\n    // get the attribute called title, if it is null assign a new one\n    this.title = this.getAttribute('title')\n    if(this.title === null){\n      this.title = 'CUSTOM ELEMENT'\n    } \n\t\n\t// This gets all attributes into an object called attrs\n    this.attrs = this.getAttributeNames().reduce((acc, name) => {\n      return {...acc, [name]: this.getAttribute(name)};\n    }, {});\n\t\n\n    this.innerHTML = `<h1>${this.title}</h1>`\n  }\n  \n  static get observedAttributes() {\n    // an array of attribute names you want to watch for this component\n    return ['title'];\n  }\n  /*\n    what to do when an attribute has changed \n    name is the attribute name that has changed\n    old_value is the old name of the attribute\n    new_value is the new name of the attribute\n\n    To update this element access it like any other HTML element and use setAttribute() to make changes.\n    an example:\n    document.querySelector('custom-element').setAttribute('title', 'Hello World')\n  */\n  attributeChangedCallback(name, old_value, new_value){\n    if(name  === 'title'){\n      this.title = new_value\n      this.innerHTML = `<h1>${this.title}</h1>`\n    }\n  }\n  \n  /*  \n  \n    This runs when the element is removed from the dom.\n    \n    Be warned: if you delete its parent div it will not run but still be removed. \n    \n    If you want to have complex remove functions, it is better to write your own\n    custom remove function and step through and remove child elements individually. \n    \n    Something like [...this.children].forEach(child => child.remove()) should work.\n  \n  */\n\n  disconnectedCallback() {\n    console.log('Custom element removed from page.')\n  }\n}\n\n/*\n  this component can be placed in the document using the notation\n  <custom-element title=\"element name here\"></custom-element>\n  to change the name of the element in the dom, change the \n  value in the quotation marks. \n*/\n\ncustomElements.define('custom-element', CustomElement)\n\n// LNSY\n\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.202Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "D3 Charts Boilerplate",
      "content": "```HTML\n<!DOCTYPE html>\n<html>\n<head>\n\n  <!-- Meta Tags -->\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n\n  <!-- FAVICON -->\n\n  <link rel=\"icon\" href=\"https://demo_app.ai/icons/icon-48x48.png?v=8fcbd421b862991f41eaffab442dfe91\">\n\n  <!--\n\n      GLOBAL STYLES\n\n  -->\n\n  <link href=\"https://fonts.googleapis.com/css?family=Overpass:300,600&display=swap\" rel=\"stylesheet\">\n\n  <!-- CSS RESET -->\n  <style>\n    /* Box sizing rules */\n    *,*::before,*::after {\n      box-sizing: border-box;\n    }\n\n    /* Remove default padding */\n    ul[class],\n    ol[class] {\n      padding: 0;\n    }\n\n    /* Remove default margin */\n    body,\n    h1,\n    h2,\n    h3,\n    h4,\n    p,\n    ul[class],\n    ol[class],\n    li,\n    figure,\n    figcaption,\n    blockquote,\n    dl,\n    dd {\n      margin: 0;\n    }\n\n    /* Set core body defaults */\n    body {\n      min-height: 100vh;\n      scroll-behavior: smooth;\n      text-rendering: optimizeSpeed;\n      line-height: 1.5;\n    }\n\n    /* Remove list styles on ul, ol elements with a class attribute */\n    ul[class],\n    ol[class] {\n      list-style: none;\n    }\n\n    /* A elements that don't have a class get default styles */\n    a:not([class]) {\n      text-decoration-skip-ink: auto;\n    }\n\n    /* Make images easier to work with */\n    img {\n      max-width: 100%;\n      display: block;\n    }\n\n    /* Natural flow and rhythm in articles by default */\n    article > * + * {\n      margin-top: 1em;\n    }\n\n    /* Inherit fonts for inputs and buttons */\n    input,\n    button,\n    textarea,\n    select {\n      font: inherit;\n    }\n\n    /* Remove all animations and transitions for people that prefer not to see them */\n    @media (prefers-reduced-motion: reduce) {\n      * {\n        animation-duration: 0.01ms !important;\n        animation-iteration-count: 1 !important;\n        transition-duration: 0.01ms !important;\n        scroll-behavior: auto !important;\n      }\n    }\n\n  </style>\n\n  <style type=\"text/css\">\n\n\n    :root {\n      --demo_app-blue: #0f2048;\n      --demo_app-white: rgba(255,255,255,0.6);\n      --demo_app-seagreen: rgba(6,244,204, 0.8);\n      --demo_app-cerulean: rgba(23,189,210);\n      --demo_app-highlight-blue: rgba(57,78,221, 0.8);\n      --demo_app-infrared: rgba(255,72,29);\n      --demo_app-light-grey: rgba(228, 2324, 242, 0.8);\n      --demo_app-acid-green: #c8ff3a;\n      --demo_app-bright-pink: #ff359b;\n      --demo_app-light-orange: #ffb647;\n      --demo_app-deep-pink: #ff5c74;\n      --demo_app-orange: #ff7100;\n      --standard-font-family:  'Overpass', sans-serif;\n\n      --CI-color: #aaaaaa;\n      --demo_app-dark-grey: rgba(0,0,0,.5);\n      --demo_app-spend-green: rgba(0,120,0,1);\n\n    }\n\n    body {\n      font-family: var(--standard-font-family);\n      font-size: 14px;\n      margin: 0;\n      padding: 0;\n      margin-left: 20em;\n    }\n\n    header p {\n      width: 40em;\n      line-height: 18px;\n      font-weight: 200;\n    }\n\n    h1, h2, h3 ,h4 {\n      font-weight: 200;\n    }\n\n    .label {\n      font-weight: 600;\n    }\n\n    .value {\n      font-weight: 200;\n    }\n\n    .viz-container {\n      width: 100%;\n      margin-top: 20px;\n\n     }\n\n    .section-header {\n      margin-top: 5em;\n      padding: 1em 0 1em 140px;\n      background-color: var(--demo_app-dark-grey);\n      color: white;\n      clear: both;\n    }\n\n    section {\n      float: left;\n    }\n\n    .axis-label {\n      font-size: 12pt;\n      font-family: 'Overpass', sans-serif;\n      font-weight: 200;\n    }\n\n    .dot {\n      width: 1em;\n      height: 1em;\n      border-radius: 50%;\n      margin-right: 0.5em;\n      float: left;\n    }\n\n    .point {\n      background-color: var(--demo_app-dark-grey);\n    }\n\n    .spend {\n      background-color: rgba(0,150,0,0.6);\n    }\n\n    .spend:hover {\n      background-color: rgba(0,80,0,1);\n    }\n\n    .square {\n      width: 1em;\n      height: 2.75em;\n      margin-top: 0.25em;\n      margin-right: 0.5em;\n      float: left;\n    }\n\n    .confidence-interval {\n      background-color: rgba(0,0,0,0.1);\n    }\n\n\n\n    .key p {\n      margin-bottom: 1em;\n    }\n\n\n    .key-description {\n      padding-left: 1.75em;\n      line-height: 1.0em;\n      font-size: 9pt;\n\n    }\n\n    aside {\n      width: 160px;\n      position: absolute;\n      left: 0px;\n      top: 170px;\n      padding: 1em;\n      border: 1px solid lightgrey;\n      background-color: white;\n    }\n\n\n    .sidebar {\n      background-color: var(--demo_app-cerulean);\n      width: 200px;\n      height: 100%;\n      position: fixed;\n      left: 0;\n      margin: 0;\n      padding: 40px 20px;\n      color: white;\n      z-index: 100;\n      text-align: right;\n    }\n\n    .sidebar .links {\n      position: absolute;\n      bottom: 4em;\n      left: 2.5em;\n      width: 10em;\n    }\n\n    .sidebar a {\n      color: white;\n    }\n\n\n    .chart-container {\n      width: calc(100vw - 200px);\n      margin-left: -80px;\n      margin-top: -28px;\n      display: block;\n      position: relative;\n      padding: 0;\n    }\n\n    .tooltip {\n      opacity: 0;\n      pointer-events: none;\n      text-align: right;\n      background-color: var(--demo_app-dark-grey);\n      color: white;\n      padding: 1em;\n      font-size: 9pt;\n    }\n\n    ul {\n      list-style: none;\n      padding:0;\n      margin: 0;\n    }\n\n\n\n  </style>\n\n  <!--\n\n    Utility Libraries\n\n    These libraries and javascript functions are available everywhere throughout the app.\n\n  -->\n  <script src=\"https://code.jquery.com/jquery-3.3.1.js\"></script>\n  <script src=\"https://d3js.org/d3.v5.min.js\"></script>\n\n  <!--\n\n\n\n              _ood>H&H&Z?#M#b-\\.\n          .\\HMMMMMR?`\\M6b.\"`' ''``v.\n       .. .MMMMMMMMMMHMMM#&.      ``~o.\n     .   ,HMMMMMMMMMMMM*\"'-`          &b.\n    .   .MMMMMMMMMMMMH'               `\"&\\\n   -     RMMMMM#H##R'                   4Mb\n  -      |7MMM'    ?::                 `|MMb\n /         HMM__#|`\"\\>?v..              `MMML\n.           `\"'#Hd|       `              9MMM:\n-                |\\,\\?HH#bbL             `9MMb\n:                   !MMMMMMMH#b,          `\"\"T\n.              .   ,MMMMMMMMMMMbo.           |\n:                  4MMMMMMMMMMMMMMMHo        |\n:                   ?MMMMMMMMMMMMMMM?        :\n-.                   `#MMMMMMMMMMMM:        .-\n :                     |MMMMMMMMMM?         .\n  -                    JMMMMMMMT'          :\n  `.                   MMMMMMH'           -\n    -.                |MMM#*`            -\n      .               HMH'            . '\n        -.            #H:.          .-\n          ` .           .\\       .-\n              '-..-+oodHL_,--/-`\n\n\n    Global Variables and Functions\n\n    Sets up the global variables and functions that will be used through the app.\n\n  -->\n  <script>\n\n    /*\n\n       __             __   ___  __\n      |__)  /\\  |\\ | / _` |__  /__`\n      |  \\ /~~\\ | \\| \\__> |___ .__/\n\n                  __   __          __\n       |\\/|  /\\  |__) / _` | |\\ | /__`\n       |  | /~~\\ |  \\ \\__> | | \\| .__/\n\n                 __\n       /\\  |\\ | |  \\\n      /~~\\ | \\| |__/\n\n       __        __   __          __\n      |__)  /\\  |  \\ |  \\ | |\\ | / _`\n      |    /~~\\ |__/ |__/ | | \\| \\__>\n\n\n      Adjust padding for application here.\n\n    */\n\n    const margin_size = 40\n\n    const margin = {\n      top: 20,\n      right: 20,\n      bottom: 200,\n      left: 140\n    }\n\n    const height =  window.innerHeight * 0.8 > 480 ? window.innerHeight * 0.8 : 480\n    const width = window.innerWidth - 300\n\n\n    const tooltip_width = 200\n    const tooltip_height = 200\n\n    const point_radius = Math.sqrt(height + width) * 0.2\n    const point_diameter = point_radius * 2\n    const point_radius_hovered = point_radius * 1.4\n\n    const Y_RANGE = [height - (margin.bottom + margin.top + point_diameter), margin.top + point_diameter ]\n    const X_RANGE = [margin.left, width - margin.left ]\n\n\n    // AXIS Translations\n    const bottom_axis_transform = `translate(0,${height - margin.top - margin.bottom})`\n    const bottom_axis_domain_transform = `translate(0, ${(height - margin.top - margin.bottom) * -1})`\n    const bottom_axis_tick_size = height - margin.bottom - margin.top\n    const bottom_axis_text_transform = `rotate(-65) translate(-20, 0)`\n    const left_axis_transform  = `translate(${margin.left - point_diameter},0)`\n    const right_axis_transform  = `translate(${width - margin.right - margin.left - point_diameter},0)`\n\n\n    // Cursor Sizes and Transforms\n    const horizontal_cursor_y1 = margin.top - point_diameter\n    const horizontal_cursor_y2 = height - margin.bottom - margin.top\n\n    const vertical_cursor_x1 = margin.left\n    const vertical_cursor_x2 = width - margin.left - margin.right\n    const vertical_cursor_transform = `translate(${point_diameter}, 0)`\n    const horizontal_cursor_transform = `translate(0, 0)`\n    const confidence_interval_transform = `translate(${point_radius * 2}, 0)`\n    const lift_points_transform = `translate(${point_radius * 2 }, 0)`\n\n    const SPEND_X_OFFSET = 40\n    const spend_point_transform = `translate(${point_radius * 2}, 0)`\n\n    const cost_per_point_transform = `translate(${point_diameter}, 0)`\n\n    const line_chart_cursor_y1 = margin.top - point_diameter\n    const line_chart_cursor_y2 = height - margin.bottom - margin.top\n\n\n    /*\n\n       dP\"\"b8  dP\"Yb  88      dP\"Yb  88\"\"Yb .dP\"Y8\n      dP   `\" dP   Yb 88     dP   Yb 88__dP `Ybo.\"\n      Yb      Yb   dP 88  .o Yb   dP 88\"Yb  o.`Y8b\n       YboodP  YbodP  88ood8  YbodP  88  Yb 8bodP'\n\n      Define the colors across the page here\n\n    */\n\n    const demo_app_blue = 'rgba(15,32,56, 0.8)'\n    const demo_app_white =  'rgba(255,255,255,0.6)'\n    const demo_app_seagreen = 'rgba(6,244,204, 0.8)'\n    const demo_app_cerulean =  'rgba(23,189,210)'\n    const demo_app_highlight_blue = 'rgba(57,78,221, 0.8)'\n    const demo_app_infrared = 'rgba(255,72,29)'\n    const demo_app_light_grey = 'rgba(228, 2324, 242, 0.8)'\n    const demo_app_acid_green = '#c8ff3a'\n    const demo_app_bright_pink = '#ff359b'\n    const demo_app_light_orange =  '#ffb647'\n    const demo_app_deep_pink = '#ff5c74'\n    const demo_app_orange = '#ff7100'\n\n\n    const point_color = 'rgba(0,0,0,0.5)'\n    const point_color_hovered = 'rgba(0,0,0,0.6)'\n    const confidence_interval_color = 'rgba(0,0,0,0.1)'\n    const spend_data_point_color = 'rgba(0,150,0,0.6)'\n    const spend_data_point_color_hovered = 'rgba(0,80,0,1)'\n    const axis_domain_color = `rgba(0,0,0,0.3)`\n    const chart_cursor_color = 'grey'\n    const cursor_stroke_pattern = \"3, 3\"\n\n    const line_chart_stroke = ['rgba(255,0,10,0.5)','rgba(10,0,0,0.5)', 'rgba(0,0,255,0.5)']\n\n\n\n\n\n    /*\n\n      .__ .__ .___.___..___..   ,\n      [__)[__)[__   |    |   \\./\n      |   |  \\[___  |    |    |\n\n      .___.__..__ .  ..__..___..___.._..  ..__\n      [__ |  |[__)|\\/|[__]  |    |   | |\\ |[ __\n      |   |__||  \\|  ||  |  |    |  _|_| \\|[_./\n\n      PRETTY FORMATTING\n\n      These items modify the javascript number object to provide formatting\n\n      I would recommend using these functions at the last possible step -- so right before you render the item.\n\n    */\n\n    Number.prototype.pretty_float = function(){\n      let _val = this\n      if(isNaN(_val)) return '0.00'\n      let val_text = _val.toFixed(2)\n      if(_val > 0){\n        return `<span class=\"green-text\">${val_text}</span>`\n      } else {\n        return `<span class=\"red-text\">${val_text}</span>`\n      }\n\n    }\n\n    Number.prototype.pretty_currency = function(){\n      let _val = this\n      if(isNaN(_val)) return '$0'\n      if(_val > 999999){\n        let val_text = _val / 1000000\n        return `$${ new Intl.NumberFormat('en-IN', { maximumSignificantDigits: 3 }).format(val_text)}m`\n      } else if(_val > 1000){\n        let val_text = _val / 1000\n        return `$${ new Intl.NumberFormat('en-IN', {maximumSignificantDigits: 2 }).format(val_text)}k`\n      } else if (_val < 0) {\n        let val_text = Math.abs(_val)\n        return `-$${new Intl.NumberFormat('en-IN', {maximumSignificantDigits: 2 }).format(val_text)}`\n      } else {\n        let val_text = _val\n        return `$${ new Intl.NumberFormat('en-IN', {maximumSignificantDigits: 2 }).format(val_text)}`\n      }\n    }\n\n    Number.prototype.pretty_spend_change = function(){\n      let _val = this\n      if(isNaN(_val)) return '$0'\n      if(_val > 1000){\n        let val_text = Math.round(_val / 1000)\n        return `<span class=\"positive-currency\">$${ new Intl.NumberFormat().format(val_text)}k</span>`\n      } else if (_val < 0) {\n        let val_text = Math.round(Math.abs(_val))\n        if (val_text > 1000){\n          val_text = Math.round(val_text / 1000)\n          return `<span class=\"negative-currency\">-$${new Intl.NumberFormat().format(val_text)}k</span>`\n        }\n        return `<span class=\"negative-currency\">-$${new Intl.NumberFormat().format(val_text)}</span>`\n      } else {\n        let val_text = Math.round(_val)\n        return `<span class=\"positive-currency\">$${ new Intl.NumberFormat().format(val_text)}</span>`\n      }\n    }\n\n    Number.prototype.pretty_integer = function(){\n      let _val = this\n      let val_text = Math.floor(_val)\n      if(val_text < 0) val_text = 0\n      return `${ new Intl.NumberFormat().format(val_text)}`\n    }\n\n    Number.prototype.pretty_percentage = function(){\n      let _val = this\n      let val_text = Math.round(_val * 100)\n      return `${val_text}%`\n    }\n\n    Date.prototype.pretty_date = function(){\n      let _val = this\n      let day = _val.getDate()\n      let month = _val.getMonth() + 1\n      let year = _val.getFullYear()\n      return `${day}-${month}-${year}`\n    }\n\n    const MONTH_ARRAY = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\n\n    // Takes an object with one item, returns a template for key / label\n    function generate_label_and_key(k, v){\n      return `\n      <div class=\"value-container\">\n        <div class=\"label\">${k}:</div>\n        <div class=\"value\">${v}</div>\n      </div>\n      `\n    }\n\n\n    /*\n\n      Init Viz\n\n      Generates the basic SVG.\n\n      Takes the ID of the div you want to put the visualization in.\n\n      Returns the SVG object\n\n\n    */\n\n    function initialize_vizualization(div_id, _width = width, _height = height){\n      const svg = d3.select(div_id).append('svg')\n        .attr('width', _width)\n        .attr('height', _height)\n\n      return svg\n    }\n\n\n    /*\n\n      Draw Axis\n\n      Takes the SVG, draws the specific Axis on it. Draws the axis.\n\n      Does not return anything\n\n    */\n\n    function draw_axis(svg, bottom_axis_scale = null,  left_axis_scale = null, top_axis_scale = null, right_axis_scale = null ){\n\n      if(bottom_axis_scale){\n        const bottom_axis = svg.append('g')\n          .call(d3.axisBottom(bottom_axis_scale)\n            .tickSize(0))\n          .attr('transform', bottom_axis_transform)\n\n        bottom_axis\n          .selectAll('text')\n            .style('text-anchor', 'end')\n            .attr('class', 'axis-text')\n            .attr('dx', '-.8em')\n            .attr('dy', '.15em')\n            .attr('transform', bottom_axis_text_transform)\n\n        // DOMAIN BOX\n        bottom_axis\n          .append('g')\n          .attr('transform', bottom_axis_domain_transform)\n          .call(d3.axisBottom(bottom_axis_scale)\n            .tickSize(bottom_axis_tick_size)\n            .tickFormat(\"\"))\n          .selectAll('line')\n          .remove()\n\n        bottom_axis\n          .selectAll('path')\n          .attr('stroke', axis_domain_color)\n\n      }\n\n      if(left_axis_scale){\n        const left_axis = svg.append('g')\n          .call(d3.axisRight(left_axis_scale))\n\n        left_axis\n          .selectAll('line')\n          .remove()\n\n        left_axis\n          .selectAll('path')\n          .remove()\n\n\n        left_axis\n          .selectAll('.domain')\n          .remove()\n\n        left_axis\n          .selectAll('text')\n          .style(\"text-anchor\", \"end\")\n          .attr('class', 'axis-text')\n          .attr(\"dx\", \"-.8em\")\n          .attr(\"dy\", \".15em\")\n          .attr('transform', left_axis_transform)\n\n      }\n    }\n\n\n\n    /*\n\n        CURSOR\n\n    */\n\n\n    function init_point_chart_cursor(svg){\n      let cursor = svg.append('g')\n\n      cursor.append(\"line\")\n        .attr('id', 'x-cursor')\n        .attr('x1', -1000)\n        .attr('y1', horizontal_cursor_y1)\n        .attr('x2', -1000)\n        .attr('y2', horizontal_cursor_y2 )\n        .style(\"stroke-width\", 2)\n        .style(\"stroke\", 'grey')\n        .style(\"stroke-dasharray\", cursor_stroke_pattern)\n        .style(\"fill\", \"none\")\n        .attr('transform', vertical_cursor_transform)\n\n      cursor.append(\"line\")\n        .attr('id', 'y-cursor')\n        .attr('x1', vertical_cursor_x1)\n        .attr('x2', vertical_cursor_x2)\n        .attr('y1', -100)\n        .attr('y2', -100)\n        .style(\"stroke-width\", 2)\n        .style(\"stroke\", chart_cursor_color)\n        .style(\"stroke-dasharray\", cursor_stroke_pattern)\n        .style(\"fill\", \"none\")\n        .attr('transform', horizontal_cursor_transform)\n\n      return cursor\n    }\n\n    function update_point_chart_cursor(cursor, x, y){\n      cursor\n        .select('#x-cursor')\n          .transition(100)\n            .attr('x1', x)\n            .attr('x2', x)\n      cursor\n        .select('#y-cursor')\n          .transition(100)\n            .attr('y1', y)\n            .attr('y2', y)\n\n      let tooltip_x_position = x + point_diameter\n      let tooltip_text_align = x < width / 2 ? 'left' : 'right'\n\n      if(x > (width / 2) - margin.right) tooltip_x_position = x - tooltip_width + point_diameter\n      cursor\n        .select('#tooltip-container')\n        .transition(100)\n          .style('opacity', 1)\n          .style('text-align', tooltip_text_align)\n          .attr('x', tooltip_x_position)\n    }\n\n\n  </script>\n\n  <title>Logo</title>\n</head>\n\n<body>\n\n\n  <!--\n       __  ___________    ____  __________\n       / / / / ____/   |  / __ \\/ ____/ __ \\\n      / /_/ / __/ / /| | / / / / __/ / /_/ /\n     / __  / /___/ ___ |/ /_/ / /___/ _, _/\n    /_/ /_/_____/_/  |_/_____/_____/_/ |_|\n\n-->\n\n\n<header class=\"page-header\">\n  <style type=\"text/css\">\n\n    .page-header {\n      background-color: var(--demo_app-blue);\n      height: 3em;\n      width: 100%;\n      position: fixed;\n      top: 0px;\n      left: 0px;\n      width: 100%;\n      z-index: 101;\n    }\n\n    .logo {\n      height:1.0em;\n      width: auto;\n      margin: 1em;\n    }\n\n    .navbar {\n      float: right;\n      margin-right: 1.2em;\n    }\n\n    .navbar ul {\n      list-style: none;\n    }\n    .navbar ul li {\n      float: left;\n    }\n\n\n    .usertag {\n      font-family: var(--standard-font-family);\n      color: white;\n      padding-top: 1em;\n      float: left;\n      font-size: 1em;\n    }\n\n    .logo-container {\n      float: left;\n    }\n\n  </style>\n  <div class=\"logo-container\">\n    <h1 style=\"color:white;\">DEMO</h1>\n  </div>\n  <span class=\"usertag\">Prepared for <span id=\"client-name\">\n      Client X\n  </span></span>\n\n  <script>\n        $(window).on('load', function(){})\n  </script>\n</header>\n\n\n\n  <!--\n\n          __  ______    _____   __\n         /  |/  /   |  /  _/ | / /\n        / /|_/ / /| |  / //  |/ /\n       / /  / / ___ |_/ // /|  /\n      /_/  /_/_/  |_/___/_/ |_/\n\n  -->\n\n\n\n  <nav class=\"sidebar\">\n    <style>\n\n    </style>\n    <section id=\"header-info\" class=\"sidebar\">\n      <div id=\"nav-content\" class=\"nav-content\"></div>\n        <ul class=\"links\">\n          <li><a href=\"#lift\">Lift</a></li>\n          <li><a href=\"#cost-pers\">Cost Pers</a></li>\n          <li><a href=\"#model-verification\">Model Verification</a></li>\n          <li><a href=\"#response-curve\">Response Curve</a></li>\n        </ul>\n      <script>\n        $(window).on('load', function(){\n\n          $('#nav-content').html(`\n\n            <div class=\"label\">Client Name:</div>\n            <div class=\"value\" id=\"client_name\">${CLIENT_METADATA.client_name}</div>\n\n            <div class=\"label\">Key Performance Indicator:</div>\n            <div class=\"value\" id=\"kpi_name\">${CLIENT_METADATA.kpi_name}</div>\n\n            <div class=\"label\">Most Recent Data:</div>\n            <div class=\"value\" id=\"most_recent_data_date\">\n              ${CLIENT_METADATA.most_recent_data_date.getDate()}\n              ${MONTH_ARRAY[CLIENT_METADATA.most_recent_data_date.getMonth()]}\n              ${CLIENT_METADATA.most_recent_data_date.getFullYear()}\n\n            </div>\n\n            <div class=\"label\">Model Confidence:</div>\n            <div class=\"value\" id=\"training-mape\">91.55%</div>\n          `)\n\n          console.log($('aside').offset({ left:width + 100}))\n\n        })\n\n\n\n\n      </script>\n    </section>\n  </nav>\n\n\n<section id=\"lift\" class=\"chart-container\">\n    <header id=\"lift-header\" class=\"section-header\">\n      <h1>Value 2</h1>\n      <p>Fake Data. </p>\n    </header>\n    <div id=\"lift-viz-container\" class=\"viz-container\"></div>\n\n    <aside class=\"key\" style=\"top: 185px\">\n      <p>\n        <div class=\"dot point lift\"></div>\n        <div class=\"key-description\"><b>Grey Dot</b><br /> Lohenderit in voluptate velit esse\n        cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non\n        proident, sunt in culpa qui officia deserunt mollit anim id est laborum. </div>\n      </p>\n\n      <p><div class=\"dot spend\"></div>\n        <div class=\"key-description\"><b> Green Dot</b><br /> lorem iupsum. </div></p>\n\n      <p><div class=\"square confidence-interval\"></div>\n      <div class=\"key-description\"><b>Shaded Area</b><br /> ute irure dolor in reprehenderit in voluptate velit esse\n      cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non\n      proident, sunt in culpa qui officia deserunt mollit anim id est laborum.. </p>\n    </aside>\n\n</section>\n\n<script>\n  $(window).on('load', function(){\n\n    /*\n\n        CHART GLOBALS\n\n        Sets the variables for the chart\n\n    */\n\n    // override the margins\n    let lift_margin = margin\n    lift_margin.right = 120\n\n    // override the ranges\n\n    const LIFT_X_RANGE = [margin.left, width - margin.left - margin.right]\n\n\n    const svg = initialize_vizualization('#lift-viz-container', width, height)\n      .append('g')\n\n\n\n    const primary_axis_key = 'channel'\n    const secondary_axis_key = 'mean_total_effect'\n    const confidence_interval_low = 'CI_2_5'\n    const confidence_interval_high = 'CI_97_5'\n\n\n    /*\n\n      Lift Data Muxing\n\n      Adjust the data as needed for the graph\n\n    */\n\n    const lift_data = LIFT.map(d => {\n      let new_obj = {}\n      new_obj[primary_axis_key] = d[primary_axis_key]\n      new_obj[secondary_axis_key] = new Number(d[secondary_axis_key])\n      new_obj[confidence_interval_low] = new Number(d[confidence_interval_low])\n      new_obj[confidence_interval_high] = new Number(d[confidence_interval_high])\n      return new_obj\n    })\n\n\n    /*\n\n        SCALES\n        sets the d3 scales according to the data limits.\n\n    */\n\n    const lift_x_scale = d3.scaleBand()\n      .domain(lift_data.map(d=>{return d[primary_axis_key]}))\n      .range(LIFT_X_RANGE)\n\n    const lift_y_scale = d3.scaleLinear()\n      .range(Y_RANGE)\n      .domain(\n        [d3.min(lift_data, d=>d[confidence_interval_low]),\n        d3.max(lift_data, d=>d[confidence_interval_high])])\n\n\n    const SPEND_KEY = 'spend'\n\n    const spend_data = SPEND.map(d => {\n      let new_obj = {}\n      new_obj[primary_axis_key] = d[primary_axis_key]\n      new_obj[SPEND_KEY] = new Number(d[SPEND_KEY])\n\n      return new_obj\n    })\n\n    let spend_y_scale = d3.scaleLinear()\n      .range(Y_RANGE)\n      .domain([d3.min(spend_data, d=>d[SPEND_KEY]), d3.max(spend_data, d=>d[SPEND_KEY])])\n\n\n\n    /*\n\n        AXIS\n\n    */\n\n    const bottom_axis = svg.append('g')\n      .call(d3.axisBottom(lift_x_scale)\n        .tickSize(0)\n        )\n      .attr('transform', bottom_axis_transform)\n\n    bottom_axis\n      .selectAll('text')\n        .style('text-anchor', 'end')\n        .attr('class', 'axis-text')\n        .attr('dx', '-.8em')\n        .attr('dy', '.15em')\n        .attr('transform', bottom_axis_text_transform)\n\n    // DOMAIN BOX\n    bottom_axis\n      .append('g')\n      .attr('transform', bottom_axis_domain_transform)\n      .call(d3.axisBottom(lift_x_scale)\n        .tickSize(bottom_axis_tick_size)\n        .tickFormat(\"\"))\n      .selectAll('line')\n      .remove()\n\n    bottom_axis\n      .selectAll('path')\n      .attr('stroke', axis_domain_color)\n\n    // bottom axis labels\n\n    bottom_axis\n      .append('text')\n      .attr('class', 'axis-label')\n      .text('Channel')\n      .style('text-anchor', 'start')\n      .attr('dx', (width / 2) - lift_margin.right + point_diameter )\n      .attr('dy', lift_margin.top + (lift_margin.bottom - 100) + point_diameter)\n      .style('fill', point_color)\n      .style('text-align', 'center')\n\n    const left_axis = svg.append('g')\n      .call(d3.axisRight(lift_y_scale))\n\n    left_axis\n      .selectAll('line')\n      .remove()\n\n    left_axis\n      .selectAll('path')\n      .remove()\n\n\n    left_axis\n      .selectAll('.domain')\n      .remove()\n\n    left_axis\n      .selectAll('text')\n      .style(\"text-anchor\", \"end\")\n      .attr('class', 'axis-text')\n      .attr(\"dx\", \"-.8em\")\n      .attr(\"dy\", \".15em\")\n      .attr('transform', left_axis_transform)\n\n    // Left Axis Label\n\n    left_axis\n      .append('text')\n      .attr('class', 'axis-label')\n      .text('Visits')\n      .style('fill', point_color)\n      .attr('dx', ((height / 2) * -1) + point_diameter + 70)\n      .attr('dy', 50)\n      .attr('transform', 'rotate(-90)')\n\n\n\n    const right_axis = svg.append('g')\n      .call(d3.axisRight(spend_y_scale)\n        .tickFormat(d3.format(\"$,.2f\"))\n        )\n\n      right_axis\n        .selectAll('line')\n        .remove()\n\n      right_axis\n        .selectAll('path')\n        .remove()\n\n\n      right_axis\n        .selectAll('.domain')\n        .remove()\n\n      right_axis\n        .selectAll('text')\n        .style(\"text-anchor\", \"end\")\n        .attr('class', 'axis-text')\n        .attr(\"dx\", \"-.8em\")\n        .attr(\"dy\", \".15em\")\n        .attr('transform', right_axis_transform)\n\n    right_axis\n      .append('text')\n      .attr('class', 'axis-label')\n\n      .text('Spend')\n      .style('fill', point_color)\n      .attr('dx', ((height / 2) ) - point_diameter - 100)\n      .attr('dy', (width - margin.left - 10) * -1)\n      .attr('transform', 'rotate(90)')\n\n\n\n    /*\n\n      Confidence Interval\n\n    */\n\n    let confidence_intervals = svg.selectAll('.ranges')\n      .data(lift_data)\n      .enter()\n      .append('line')\n      .attr('transform', confidence_interval_transform)\n\n    confidence_intervals\n      .attr('x1', function(d){\n        return lift_x_scale(d[primary_axis_key])\n      })\n      .attr('x2', function(d){\n        return  lift_x_scale(d[primary_axis_key])\n      })\n      .attr('y1', function(d){\n        return lift_y_scale(d[confidence_interval_high])\n      })\n      .attr('y2', function(d){\n        return lift_y_scale(d[confidence_interval_low])\n      })\n      .style('stroke', confidence_interval_color)\n      .style('stroke-width', point_diameter)\n\n\n    /*\n\n        LIFT Points\n\n        The actual chart information\n\n    */\n\n    const data_container = svg.append(\"g\")\n    let lift_data_points = data_container.selectAll(\".dot\")\n      .data(lift_data)\n      .enter()\n      .append('circle')\n      .attr('transform', lift_points_transform)\n\n\n    lift_data_points\n      .attr('cx', function(d){\n        return lift_x_scale(d[primary_axis_key])\n      })\n      .attr('cy',function(d){\n        return lift_y_scale(d[secondary_axis_key])\n      })\n      .attr('r', point_radius)\n      .attr(\"fill\",point_color)\n\n\n    /*\n\n      LIFT CURSOR\n\n    */\n\n      const lift_vertical_cursor_x1 = margin.left\n      const lift_vertical_cursor_x2 = width - lift_margin.left - lift_margin.right\n\n      const cursor = svg.append('g')\n\n      cursor.append(\"line\")\n        .attr('id', 'x-cursor')\n        .attr('x1', -1000)\n        .attr('y1', horizontal_cursor_y1)\n        .attr('x2', -1000)\n        .attr('y2', horizontal_cursor_y2 )\n        .style(\"stroke-width\", 2)\n        .style(\"stroke\", 'grey')\n        .style(\"stroke-dasharray\", cursor_stroke_pattern)\n        .style(\"fill\", \"none\")\n        .attr('transform', vertical_cursor_transform)\n\n      cursor\n        .append(\"foreignObject\")\n        .attr('id', 'tooltip-container')\n        .attr(\"width\", tooltip_width)\n        .attr(\"height\", tooltip_height)\n        .attr('x', 100)\n        .attr('y', 20)\n        .attr('class', 'tooltip')\n        .append(\"xhtml:div\")\n        .html(``)\n\n\n      cursor.append(\"line\")\n        .attr('id', 'y-cursor')\n        .attr('x1', lift_vertical_cursor_x1)\n        .attr('x2', lift_vertical_cursor_x2)\n        .attr('y1', -100)\n        .attr('y2', -100)\n        .style(\"stroke-width\", 2)\n        .style(\"stroke\", chart_cursor_color)\n        .style(\"stroke-dasharray\", cursor_stroke_pattern)\n        .style(\"fill\", \"none\")\n        .attr('transform', horizontal_cursor_transform)\n\n\n\n     /*\n\n        RENDER THE DATA POINTS\n\n     */\n\n     lift_data_points\n      .on('mouseover', function(d){\n\n        d3.selectAll('.hovered')\n          .transition(200)\n          .attr('fill', point_color)\n          .attr('r', point_radius)\n\n        d3.select(this)\n          .classed('hovered', true)\n          .transition(200)\n          .attr('fill', point_color_hovered)\n          .attr('r', point_radius_hovered)\n\n\n\n        let lift_tooltip_content = `\n          <ul class=\"tooltip-values\">\n            <li>${generate_label_and_key('Channel', d[primary_axis_key])}</li>\n            <li>${generate_label_and_key('Total Lift For Visits', d[secondary_axis_key].pretty_integer())}</li>\n            <li>${generate_label_and_key(\n              'Minimum Lift for Visits',\n              isNaN(d[confidence_interval_low]) ? 'NO DATA' : d[confidence_interval_low].pretty_integer())}\n            </li>\n            <li>${generate_label_and_key('Maximum Lift for Visits',\n              isNaN(d[confidence_interval_high]) ? 'NO DATA' : d[confidence_interval_high].pretty_integer())}\n            </li>\n          </ul>\n        `\n\n        d3.select('#tooltip-container')\n          .html(lift_tooltip_content)\n\n        let active_dot_x = d[primary_axis_key]\n        let active_dot_y = d[secondary_axis_key]\n        update_point_chart_cursor(cursor,lift_x_scale(active_dot_x), lift_y_scale(active_dot_y))\n\n      })\n      .on('mouseout', function(d){\n         d3.selectAll('.hovered')\n           .classed('hovered', false)\n           .transition(500)\n          .attr('fill', point_color)\n          .attr('r', point_radius)})\n\n    /*\n\n      SPEND Data Points\n\n    */\n\n    const spend_data_container = svg.append(\"g\")\n    let spend_data_points = data_container.selectAll(\".dot\")\n      .data(spend_data)\n      .enter()\n      .append('circle')\n      .attr('transform', spend_point_transform)\n\n\n    spend_data_points\n      .attr('cx', function(d){\n        return lift_x_scale(d[primary_axis_key])\n      })\n      .attr('cy',function(d){\n        return spend_y_scale(d[SPEND_KEY])\n      })\n      .attr('r', point_radius)\n      .attr(\"fill\",spend_data_point_color)\n\n     spend_data_points\n      .on('mouseover', function(d){\n\n        d3.selectAll('.hovered')\n          .transition(200)\n          .attr('fill', spend_data_point_color)\n          .attr('r', point_radius)\n\n        d3.select(this)\n          .classed('hovered', true)\n          .transition(200)\n          .attr('fill', spend_data_point_color_hovered)\n          .attr('r', point_radius_hovered)\n\n        let active_dot_x = d[primary_axis_key]\n        let active_dot_y = d[SPEND_KEY]\n\n        let spend_tooltip_content = `\n\n          <ul>\n            <li><div class=\"label\">Channel:</div>\n                <div class=\"value\"> ${d[primary_axis_key]}</div>\n            </li>\n            <li><div class=\"label\">Spend:</div>\n            <div class=\"value\">${d[SPEND_KEY].pretty_currency()}</div></li>\n          </ul>\n        `\n\n        d3.select('#tooltip-container')\n          .html(spend_tooltip_content)\n\n\n        update_point_chart_cursor(cursor,lift_x_scale(active_dot_x), spend_y_scale(active_dot_y))\n\n      })\n      .on('mouseout', function(d){\n         d3.selectAll('.hovered')\n           .classed('hovered', false)\n           .transition(500)\n          .attr('fill', spend_data_point_color)\n          .attr('r', point_radius)})\n\n  })\n  </script>\n\n\n\n  <section id=\"cost-pers\" class=\"chart-container\">\n    <header id=\"cost-pers-header\" class=\"section-header\">\n      <h1>Value 1</h1>\n      <p>Here is a description of the algorithm the client used. </p>\n    </header>\n    <div id=\"cost-per-viz\" class=\"viz-container\"></div>\n    <aside class=\"key\">\n      <p> <div class=\"dot point lift\"></div>\n        <div class=\"key-description\"><b>Gray dot</b> <br />\n       Lorem ipsum dolor sit amet,reprehenderit in voluptate velit esse\n       cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non\n       proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p></div>\n\n      <p><div class=\"square confidence-interval\"></div>\n        <div class=\"key-description\"><b>Shaded Area</b><br />\n        Lorem ipsum dolor sit am occaecat cupidatat non\n        proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>\n    </div>\n\n    </aside>\n  </section>\n\n\n  <script>\n  $(window).on('load', function(){\n\n\n    /*\n\n        CHART GLOBALS\n\n        Sets the variables for the chart\n\n    */\n\n    const svg = initialize_vizualization('#cost-per-viz', width, height)\n      .append('g')\n\n    const primary_axis_key = 'channel'\n    const secondary_axis_key = 'mean_cps'\n    const confidence_interval_low = 'CI_2_5'\n    const confidence_interval_high = 'ci_97_5'\n\n\n    /*\n\n      Cost Per Data Muxing\n\n      Adjust the data as needed for the graph\n\n    */\n\n    const cost_pers_data = COST_PER.map(d => {\n      let new_obj = {}\n      new_obj[primary_axis_key] = d[primary_axis_key]\n\n      new_obj[secondary_axis_key] = new Number(d[secondary_axis_key])\n      new_obj[confidence_interval_low] = new Number(d[confidence_interval_low])\n      new_obj[confidence_interval_high] = new Number(d[confidence_interval_high])\n\n      return new_obj\n    })\n\n    const cost_pers_data_with_values = cost_pers_data.filter(d => !isNaN(d[secondary_axis_key]) && d[secondary_axis_key] < 5)\n\n    const cost_pers_data_with_CI = cost_pers_data.filter(d => !isNaN(d[confidence_interval_low]) && !isNaN(d[confidence_interval_high]))\n    /*\n\n        SCALES\n        sets the d3 scales according to the data limits.\n\n    */\n\n\n    let cost_pers_x = d3.scaleBand()\n      .domain(cost_pers_data_with_values.map(d=> d[primary_axis_key]))\n      .range(X_RANGE)\n\n    let cost_pers_y = d3.scaleLinear()\n      .range(Y_RANGE)\n      .domain([\n          d3.min(cost_pers_data_with_values, d => d[secondary_axis_key]),\n          5\n      ])\n\n    draw_axis(svg, cost_pers_x)\n\n      const left_axis = svg.append('g')\n          .call(d3.axisRight(cost_pers_y)\n            .tickFormat(d3.format(\"$,.2f\")))\n\n        left_axis\n          .selectAll('line')\n          .remove()\n\n        left_axis\n          .selectAll('path')\n          .remove()\n\n\n        left_axis\n          .selectAll('.domain')\n          .remove()\n\n        left_axis\n          .selectAll('text')\n          .style(\"text-anchor\", \"end\")\n          .attr('class', 'axis-text')\n          .attr(\"dx\", \"-.8em\")\n          .attr(\"dy\", \".15em\")\n          .attr('transform', left_axis_transform)\n\n        // LEFT AXIS LABEL\n\n        left_axis\n          .append('text')\n          .attr('class', 'axis-label')\n          .text('Cost Per Visit')\n          .style('fill', point_color)\n          .attr('dx', ((height / 2) * -1) + point_diameter + 70)\n          .attr('dy', 50)\n          .attr('transform', 'rotate(-90)')\n\n      /*\n        Bottom Axis Label\n\n      */\n\n      const bottom_axis = svg\n        .append('g')\n        .attr('transform', bottom_axis_transform)\n        .append('text')\n        .text('Channel')\n        .style('text-anchor', 'start')\n        .attr('class', 'axis-label')\n        .attr('dx', (width / 2) - 50 )\n        .attr('dy', margin.top + (margin.bottom - 100) + point_diameter)\n        .style('fill', point_color)\n        .style('text-align', 'center')\n\n\n\n\n    /*\n\n      Confidence Interval\n\n    */\n\n    let confidence_intervals = svg.selectAll('.ranges')\n      .data(cost_pers_data_with_CI)\n      .enter()\n      .append('line')\n      .attr('transform', confidence_interval_transform)\n\n    confidence_intervals\n      .attr('x1', function(d){\n        return cost_pers_x(d[primary_axis_key])\n      })\n      .attr('x2', function(d){\n        return  cost_pers_x(d[primary_axis_key])\n      })\n      .attr('y1', function(d){\n        return cost_pers_y(d[confidence_interval_high])\n      })\n      .attr('y2', function(d){\n        return cost_pers_y(d[confidence_interval_low])\n      })\n      .style('stroke', confidence_interval_color)\n      .style('stroke-width', point_diameter)\n\n\n    /*\n\n        Cost Pers Points\n\n        The actual chart information\n\n    */\n\n    const data_container = svg.append(\"g\")\n    let cost_pers_data_points = data_container.selectAll(\".dot\")\n      .data(cost_pers_data_with_values)\n      .enter()\n      .append('circle')\n      .attr('transform', cost_per_point_transform)\n\n    cost_pers_data_points\n      .attr('cx', function(d){\n        return cost_pers_x(d[primary_axis_key])\n      })\n      .attr('cy',function(d){\n        return cost_pers_y(d[secondary_axis_key])\n      })\n      .attr('r', point_radius)\n      .attr(\"fill\",point_color)\n\n     const cursor = init_point_chart_cursor(svg)\n\n      cursor\n        .append(\"foreignObject\")\n        .attr('id', 'tooltip-container')\n        .attr(\"width\", tooltip_width)\n        .attr(\"height\", tooltip_height)\n        .attr('x', 100)\n        .attr('y', 20)\n        .attr('class', 'tooltip')\n        .append(\"xhtml:div\")\n        .html(``)\n\n     cost_pers_data_points\n      .on('mouseover', function(d){\n\n        d3.selectAll('.hovered')\n          .transition(200)\n          .attr('fill', point_color)\n          .attr('r', point_radius)\n\n        d3.select(this)\n          .classed('hovered', true)\n          .transition(200)\n          .attr('fill', point_color_hovered)\n          .attr('r', point_radius_hovered)\n\n         let cost_per_tooltip_content = `\n          <ul class=\"tooltip-values\">\n            <li>${generate_label_and_key('Channel', d[primary_axis_key])}</li>\n            <li>${generate_label_and_key('Average Cost Per Visit', d[secondary_axis_key].pretty_currency())}</li>\n            <li>${generate_label_and_key(\n              'Minimum Cost per Visit',\n              isNaN(d[confidence_interval_low]) ? 'NO DATA' : d[confidence_interval_low].pretty_currency())}\n            </li>\n            <li>${generate_label_and_key('Maximum Cost per Visit',\n              isNaN(d[confidence_interval_high]) ? 'NO DATA' : d[confidence_interval_high].pretty_currency())}\n            </li>\n          </ul>\n        `\n        cursor.select('#tooltip-container')\n          .html(cost_per_tooltip_content)\n\n        let active_dot_x = d[primary_axis_key]\n        let active_dot_y = d[secondary_axis_key]\n        update_point_chart_cursor(cursor,cost_pers_x(active_dot_x), cost_pers_y(active_dot_y))\n\n      })\n      .on('mouseout', function(d){\n         d3.selectAll('.hovered')\n           .classed('hovered', false)\n           .transition(500)\n          .attr('fill', point_color)\n          .attr('r', point_radius)})\n\n  })\n\n  </script>\n\n\n\n<style>\n  .predicted {\n    background-color: red;\n  }\n\n  .actual {\n    background-color: black;\n  }\n</style>\n<section id=\"model-verification\" class=\"chart-container\">\n  <header id=\"model-verification-header\" class=\"section-header\">\n    <h1>Fake Data</h1>\n    <p>Lorem ipsum dolor atur. Excepteur sint occaecat cupidatat non\n    proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>\n  </header>\n  <div id=\"model-verification-viz\" class=\"viz-container\"></div>\n  <aside class=\"key\"  style=\"top: 240px\">\n    <p><div class=\"dot predicted\"></div>\n      <div class=\"key-description\"><b>Red Line</b><br />\n      as predicted by the model\n      </div>\n\n    </p>\n    <p><div class=\"dot actual\"></div>\n    <div class=\"key-description\"><b>Black Line</b><br />\n      real\n    </div>\n    </p>\n  </aside>\n\n</section>\n\n\n  <script>\n        $(window).on('load', function(){\n          const svg = initialize_vizualization('#model-verification-viz', width, height)\n\n          const primary_axis_key = 'date'\n          const secondary_axis_key = 'y_prediction_weekly'\n          const trinary_axis_key = 'y_true_weekly'\n          const confidence_interval_low = 'CI_weekly_2_5'\n          const confidence_interval_high = 'CI_weekly_97_5'\n\n          const kpi_data = KPI_PREDICTION.map(d => {\n            let new_obj = {}\n\n            new_obj[primary_axis_key] = new Date(d[primary_axis_key])\n            new_obj[secondary_axis_key] = new Number(d[secondary_axis_key])\n            new_obj[trinary_axis_key] = new Number(d[trinary_axis_key])\n\n            new_obj[confidence_interval_low] = new Number(d[confidence_interval_low])\n            new_obj[confidence_interval_high] = new Number(d[confidence_interval_high])\n            return new_obj\n          })\n\n          svg\n            .attr('width', width)\n            .attr('height', height)\n\n\n          /*\n\n            SCALES\n\n          */\n\n\n          let kpi_x_scale = d3.scaleTime()\n            .range(X_RANGE)\n            .domain(d3.extent(kpi_data, function(d){return d.date}))\n\n          let kpi_y_scale = d3.scaleLinear()\n            .range(Y_RANGE)\n            .domain([d3.min(kpi_data, d=>d[secondary_axis_key]), d3.max(kpi_data, d=>d[trinary_axis_key])])\n\n          /*\n            Draw the chart Lines\n          */\n\n\n          svg.append(\"g\")\n            .append(\"path\")\n            .data([kpi_data])\n            .attr('class', `line`)\n            .attr('d',\n              d3.line()\n                .x(function(d){return kpi_x_scale(d[primary_axis_key])})\n                .y(function(d){return kpi_y_scale(d[secondary_axis_key])})\n                .curve(d3.curveBasis))\n            .attr('stroke',line_chart_stroke[0])\n            .attr('fill', 'none')\n            .attr('data-date', d=>d.date)\n            .style(\"stroke-width\", 1)\n\n          svg.append(\"g\")\n            .append(\"path\")\n            .data([kpi_data])\n            .attr('class', `line`)\n            .attr('d',\n              d3.line()\n                .x(function(d){return kpi_x_scale(d[primary_axis_key])})\n                .y(function(d){return kpi_y_scale(d[trinary_axis_key])})\n                .curve(d3.curveBasis)\n            )\n            .attr('fill', 'none')\n            .attr('stroke', line_chart_stroke[1])\n            .style('stroke-width', 1)\n\n\n\n\n            /*\n                ______   __    __  ______   ______\n               /      \\ |  \\  |  \\|      \\ /      \\\n              |  $$$$$$\\| $$  | $$ \\$$$$$$|  $$$$$$\\\n              | $$__| $$ \\$$\\/  $$  | $$  | $$___\\$$\n              | $$    $$  >$$  $$   | $$   \\$$    \\\n              | $$$$$$$$ /  $$$$\\   | $$   _\\$$$$$$\\\n              | $$  | $$|  $$ \\$$\\ _| $$_ |  \\__| $$\n              | $$  | $$| $$  | $$|   $$ \\ \\$$    $$\n               \\$$   \\$$ \\$$   \\$$ \\$$$$$$  \\$$$$$$\n\n\n\n              Draw the axis\n            */\n\n            draw_axis(svg, kpi_x_scale, kpi_y_scale)\n\n            /*\n\n              KPI\n              VERIFICATION\n              CURSOR\n\n            */\n\n            let cursor = svg.append('g')\n\n            cursor.append('line')\n              .attr('id', 'kpi-x-cursor')\n              .attr('x1', -1000)\n              .attr('y1', line_chart_cursor_y1)\n              .attr('x2', -1000)\n              .attr('y2', line_chart_cursor_y2)\n              .style('stroke-width', 2)\n              .style('stroke', 'grey')\n              .style('stroke-dasharray', ('3', '3'))\n              .style('fill', 'none')\n\n            // secondary access key cursor\n            cursor.append('circle')\n              .attr('id', 'kpi-secondary-access-key-cursor')\n              .attr('cx', -1000)\n              .attr('cy', -1000)\n              .attr('fill', 'none')\n              .attr('r', point_radius)\n              .attr('stroke', line_chart_stroke[0])\n\n            cursor.append('circle')\n              .attr('id', 'kpi-trinary-access-key-cursor')\n              .attr('cx', -1000)\n              .attr('cy', -1000)\n              .attr('fill', 'none')\n              .attr('r', point_radius)\n              .attr('stroke', line_chart_stroke[1])\n\n            cursor\n              .append(\"foreignObject\")\n              .attr('id', 'tooltip-container')\n              .attr(\"width\", tooltip_width)\n              .attr(\"height\", tooltip_height)\n              .attr('x', 100)\n              .attr('y', 20)\n              .attr('class', 'tooltip')\n              .append(\"xhtml:div\")\n              .html(``)\n\n        const left_axis = svg\n          .append('g')\n          .attr('transform', left_axis_transform)\n            .append('text')\n            .text('Visits')\n            .attr('class', 'axis-label')\n\n            .style('fill', point_color)\n            .attr('dx', ((height / 2) * -1) + point_diameter + 70)\n            .attr('dy', -70)\n            .attr('transform', 'rotate(-90)')\n\n        const bottom_axis = svg\n          .append('g')\n          .append('text')\n          .text('Date')\n          .style('text-anchor', 'start')\n          .attr('class', 'axis-label')\n          .attr('dx', (width / 2) - margin.right + point_diameter )\n          .attr('dy', height - margin.bottom  + 80)\n          .style('fill', point_color)\n          .style('text-align', 'center')\n\n\n      /*\n\n        KPI Chart\n        MOUSE EVENTS\n\n      */\n\n      svg.on('mouseover', function(){\n        const mouse = d3.mouse(this)\n        const kpi_date = kpi_x_scale.invert(mouse[0])\n        let hover_data = kpi_data.reduce((prev, curr) => {\n          let prev_time = new Date(prev.date)\n          let curr_time = new Date(curr.date)\n          let target_time = new Date(kpi_date)\n          return (Math.abs(curr_time - prev_time) < Math.abs(prev_time - target_time) ? curr : prev)\n          d => d.date === date_string\n        })\n        if(hover_data){\n\n          let cursor_x = kpi_x_scale(new Date(hover_data.date))\n          let secondary_y = kpi_y_scale(hover_data[secondary_axis_key])\n          let trinary_y = kpi_y_scale(hover_data[trinary_axis_key])\n\n          svg.select('#kpi-x-cursor')\n            .transition(100)\n            .attr('x1', cursor_x)\n            .attr('x2', cursor_x)\n\n          svg.select('#kpi-secondary-access-key-cursor')\n             .transition(100)\n            .attr('cx', cursor_x)\n            .attr('cy', secondary_y)\n\n          svg.select('#kpi-trinary-access-key-cursor')\n            .transition(100)\n            .attr('cx', cursor_x)\n            .attr('cy', trinary_y)\n\n\n\n          const kpi_verification_tooltip_content = `\n            <ul class=\"tooltip-values\">\n            <li><div class=\"label\">Date:</div>\n                <div class=\"value\">\n                  ${kpi_date.getDate()}\n                  ${MONTH_ARRAY[kpi_date.getMonth()]}\n                  ${kpi_date.getFullYear()}\n                </div>\n            </li>\n            <li><div class=\"label\">Predicted:</div>\n            <div class=\"value\"> ${hover_data[secondary_axis_key]}</div>\n            <div class=\"label\">Actual:</div>\n            <div class=\"value\"> ${hover_data[trinary_axis_key]}</div>\n          `\n\n          let tooltip_x_position = cursor_x\n          let tooltip_text_align = cursor_x < width / 2 ? 'left' : 'right'\n\n          if(cursor_x > (width / 2) - margin.right) tooltip_x_position = cursor_x - tooltip_width\n\n          cursor\n            .select('#tooltip-container')\n            .html(kpi_verification_tooltip_content)\n            .transition(100)\n              .style('opacity', 1)\n              .style('text-align', tooltip_text_align)\n              .attr('x', tooltip_x_position)\n\n\n        }\n      })\n        })\n\n\n  </script>\n\n  <section id=\"response-curve\" class=\"chart-container\">\n    <header id=\"response-curve-header\" class=\"section-header\">\n      <h1>Response Curve</h1>\n      <p>Lorem ipsum dolor sit amet, atur. Excepteur sint occaecat cupidatat non\n      proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>\n    </header>\n    <div id=\"response-curve-viz\" style=\"margin-top:23px\"></div>\n    <aside class=\"key\" style=\"top: 200px\">\n      <p><div class=\"dot point red\"></div>lorem\n      </p>\n    </aside>\n  </section>\n  <script>\n    $(window).on('load', function(){\n\n      const svg = initialize_vizualization('#response-curve-viz', width, height)\n        .append('g')\n\n      const primary_axis_key = 'spend'\n      const secondary_axis_key = 'lower_bound_response'\n      const trinary_axis_key = 'mean_response'\n      const quaternary_axis_key = 'upper_bound_response'\n\n\n      /*\n\n        Response Curve Data Muxing\n\n        Adjust the data as needed for the graph\n\n      */\n\n      const response_curve_data = RESPONSE_CURVE.map(d => {\n        let new_obj = {}\n        new_obj[primary_axis_key] = new Number(d[primary_axis_key])\n        new_obj[secondary_axis_key] = new Number(d[secondary_axis_key])\n\n        new_obj[trinary_axis_key] = new Number(d[trinary_axis_key])\n        new_obj[quaternary_axis_key] = new Number(d[quaternary_axis_key])\n        return new_obj\n      })\n\n\n      /*\n\n          SCALES\n          sets the d3 scales according to the data limits.\n\n      */\n\n      let response_curve_x_scale = d3.scaleLinear()\n        .domain([d3.min(response_curve_data, d=> d[primary_axis_key]), d3.max(response_curve_data, d => d[primary_axis_key])])\n        .range(X_RANGE)\n\n      let response_curve_y_scale = d3.scaleLinear()\n        .range(Y_RANGE)\n        .domain([d3.min(response_curve_data, d=>d[secondary_axis_key]), d3.max(response_curve_data, d=>d[trinary_axis_key])])\n\n      draw_axis(svg, null, response_curve_y_scale)\n\n      const bottom_axis = svg.append('g')\n        .call(d3.axisBottom(response_curve_x_scale)\n          .tickSize(0)\n           .tickFormat(d3.format(\"$,.2f\"))\n        )\n        .attr('transform', bottom_axis_transform)\n\n      bottom_axis\n        .selectAll('text')\n          .style('text-anchor', 'end')\n          .attr('class', 'axis-text')\n          .attr('dx', '-.8em')\n          .attr('dy', '.15em')\n          .attr('transform', bottom_axis_text_transform)\n\n      // DOMAIN BOX\n      bottom_axis\n        .append('g')\n        .attr('transform', bottom_axis_domain_transform)\n        .call(d3.axisBottom(response_curve_x_scale)\n          .tickSize(bottom_axis_tick_size)\n          .tickFormat(\"\"))\n        .selectAll('line')\n        .remove()\n\n      bottom_axis\n        .selectAll('path')\n        .attr('stroke', axis_domain_color)\n\n\n\n      /*\n\n          Response Curves\n\n          The actual chart information\n\n      */\n\n      const data_container = svg.append(\"g\")\n\n\n      // svg.append(\"g\")\n      //   .append(\"path\")\n      //   .data([response_curve_data])\n      //   .attr('class', `line`)\n      //   .attr('d',\n      //     d3.line()\n      //       .x(function(d){return response_curve_x_scale(d[primary_axis_key])})\n      //       .y(function(d){return response_curve_y_scale(d[secondary_axis_key])})\n      //       .curve(d3.curveBasis))\n      //   .attr('stroke',line_chart_stroke[0])\n      //   .attr('fill', 'none')\n      //   .style(\"stroke-width\", 3)\n\n      svg.append(\"g\")\n        .append(\"path\")\n        .data([response_curve_data])\n        .attr('class', `line`)\n        .attr('d',\n          d3.line()\n            .x(function(d){return response_curve_x_scale(d[primary_axis_key])})\n            .y(function(d){return response_curve_y_scale(d[trinary_axis_key])})\n            .curve(d3.curveBasis))\n        .attr('stroke',line_chart_stroke[1])\n        .attr('fill', 'none')\n        .style(\"stroke-width\", 3)\n\n      // svg.append(\"g\")\n      //   .append(\"path\")\n      //   .data([response_curve_data])\n      //   .attr('class', `line`)\n      //   .attr('d',\n      //     d3.line()\n      //       .x(function(d){return response_curve_x_scale(d[primary_axis_key])})\n      //       .y(function(d){return response_curve_y_scale(d[quaternary_axis_key])})\n      //       .curve(d3.curveBasis))\n      //   .attr('stroke',line_chart_stroke[2])\n      //   .attr('fill', 'none')\n      //   .style(\"stroke-width\", 3)\n\n      let RC_Spend_Channel = 'taboola'\n\n      let spend_amount = SPEND.find(d => d.channel === RC_Spend_Channel).spend\n      console.log(spend_amount)\n\n      let spend_line_color = demo_app_deep_pink\n      let spend_line = svg.append('g')\n\n\n      spend_line\n        .append('line')\n        .attr('id', 'rc-spend-amount')\n        .attr('x1', d=> response_curve_x_scale(spend_amount / 1000))\n        .attr('x2', d=> response_curve_x_scale(spend_amount / 1000))\n        .attr('y1', line_chart_cursor_y1)\n        .attr('y2', line_chart_cursor_y2)\n        .style('stroke', spend_line_color)\n        .style('stroke-dasharray', cursor_stroke_pattern)\n        .style('stroke-width', 2)\n\n      spend_line\n        .append('text')\n        .attr('id', 'spend-amount')\n        .text('Current Spend')\n        .attr('dx', d=>response_curve_x_scale(spend_amount / 1000) + 10)\n        .attr('dy', line_chart_cursor_y1 + 20)\n        .style('fill', spend_line_color)\n\n      let cursor = svg.append('g')\n\n      cursor.append('line')\n        .attr('id', 'curve-x-cursor')\n        .attr('x1', -1000)\n        .attr('y1', line_chart_cursor_y1)\n        .attr('x2', -1000)\n        .attr('y2', line_chart_cursor_y2)\n        .style('stroke-width', 2)\n        .style('stroke', chart_cursor_color)\n        .style('stroke-dasharray', cursor_stroke_pattern)\n        .style('fill', 'none')\n\n        // // secondary access key cursor\n        // cursor.append('circle')\n        //   .attr('id', 'curve-secondary-access-key-cursor')\n        //   .attr('cx', -1000)\n        //   .attr('cy', -1000)\n        //   .attr('fill', 'none')\n        //   .attr('r', point_radius)\n        //   .attr('stroke', line_chart_stroke[0])\n\n        cursor.append('circle')\n          .attr('id', 'curve-trinary-access-key-cursor')\n          .attr('cx', margin.left)\n          .attr('cy', height - margin.bottom - point_diameter)\n          .attr('fill', 'none')\n          .attr('r', point_radius)\n          .attr('stroke', line_chart_stroke[1])\n\n        cursor\n          .append(\"foreignObject\")\n          .attr('id', 'tooltip-container')\n          .attr(\"width\", tooltip_width)\n          .attr(\"height\", tooltip_height - 70)\n          .attr('x', 100)\n          .attr('y', 20)\n          .attr('class', 'tooltip')\n          .append(\"xhtml:div\")\n          .html(``)\n\n\n        // cursor.append('circle')\n        //   .attr('id', 'curve-quaternary-access-key-cursor')\n        //   .attr('cx', -1000)\n        //   .attr('cy', -1000)\n        //   .attr('fill', 'none')\n        //   .attr('r', point_radius)\n        //   .attr('stroke', line_chart_stroke[2])\n\n\n        /*\n\n            AXIS LABELS\n\n        */\n\n        const left_axis = svg\n          .append('g')\n          .attr('transform', left_axis_transform)\n            .append('text')\n            .attr('class', 'axis-label')\n\n            .text('Visits')\n            .style('fill', point_color)\n            .attr('dx', ((height / 2) * -1) + point_diameter + 70)\n            .attr('dy', -70)\n            .attr('transform', 'rotate(-90)')\n\n         bottom_axis\n          .append('g')\n          .append('text')\n          .text('Spend')\n          .style('text-anchor', 'middle')\n          .attr('class', 'axis-label')\n          .attr('dx', (width / 2) - point_diameter)\n          .attr('dy', 120)\n          .style('fill', point_color)\n          .style('text-align', 'center')\n\n\n\n        svg.on('mouseover', function(){\n\n          // scaleBand does not have an .invert function, so here is a version\n          const mouse = d3.mouse(this)\n          const position_on_graph = Math.round(response_curve_x_scale.invert(mouse[0] + point_diameter))\n          const hover_data = response_curve_data.reduce(function(prev, curr){\n            return (Math.abs(curr[primary_axis_key] - prev[primary_axis_key]) < Math.abs(prev[primary_axis_key] - position_on_graph) ? curr : prev)\n          })\n\n          if(hover_data){\n\n            let cursor_x = response_curve_x_scale(new Number(hover_data.spend))\n            let secondary_y = response_curve_y_scale(hover_data[secondary_axis_key])\n            let trinary_y = response_curve_y_scale(hover_data[trinary_axis_key])\n            let quaternary_y = response_curve_y_scale(hover_data[quaternary_axis_key])\n\n            svg.select('#curve-x-cursor')\n              .transition(100)\n              .attr('x1', cursor_x)\n              .attr('x2', cursor_x)\n\n            // svg.select('#curve-secondary-access-key-cursor')\n            //    .transition(100)\n            //   .attr('cx', cursor_x)\n            //   .attr('cy', secondary_y)\n\n            svg.select('#curve-trinary-access-key-cursor')\n              .transition(100)\n              .attr('cx', cursor_x)\n              .attr('cy', trinary_y)\n\n            // svg.select('#curve-quaternary-access-key-cursor')\n            //   .transition(100)\n            //   .attr('cx', cursor_x)\n            //   .attr('cy', quaternary_y)\n\n            const curve_verification_tooltip_content = `\n              <div class=\"value-container\">\n                <div class=\"label\">Spend: </div><div class=\"value\">${hover_data.spend.pretty_currency()}</div>\n              </div>\n              <div class=\"value-container\">\n                <div class=\"label\">Mean Lift For Visits:</div>\n                <div class=\"value\"> ${hover_data[trinary_axis_key].pretty_integer()}</div>\n              </div>\n            `\n\n            let tooltip_x_position = cursor_x\n            let tooltip_text_align = cursor_x < width / 2 ? 'left' : 'right'\n\n            if(cursor_x > (width / 2) - margin.right) tooltip_x_position = cursor_x - tooltip_width\n\n\n            cursor.select('#tooltip-container')\n              .html(curve_verification_tooltip_content)\n              .transition(100)\n              .style('opacity', 1)\n              .style('text-align', tooltip_text_align)\n              .attr('x', tooltip_x_position)\n\n          }\n        })\n    })\n  </script>\n\n\n  </div>\n</div>\n\n<!--\n\n    '########:::::'###::::'########::::'###::::\n     ##.... ##:::'## ##:::... ##..::::'## ##:::\n     ##:::: ##::'##:. ##::::: ##:::::'##:. ##::\n     ##:::: ##:'##:::. ##:::: ##::::'##:::. ##:\n     ##:::: ##: #########:::: ##:::: #########:\n     ##:::: ##: ##.... ##:::: ##:::: ##.... ##:\n     ########:: ##:::: ##:::: ##:::: ##:::: ##:\n    ........:::..:::::..:::::..:::::..:::::..::\n\n    EMBEDDED DATA\n\n    All the data is embedded at the bottom of the page.\n\n    Kick off specific charts with:\n\n    $(window).on('load', function(){\n      initialized_kpi_prediction_chart(KPI_PREDICTION)\n    })\n\n-->\n\n\n<script>\n\n  const CLIENT_METADATA = {\n    client_name:\"Fake Client X\",\n    kpi_name: \"Fake Data\",\n    most_recent_data_date: new Date(),\n    training_mape: '9.45%',\n    cross_validated_mape: '3.21%'\n  }\n\n\n  const LIFT = [\n    {\"channel\":\"search_generic_google\",\"mean_total_effect\":\"40062399\",\"CI_2_5\":\"33343478\",\"CI_97_5\":\"44804965\"},\n    {\"channel\":\"gdn\",\"mean_total_effect\":\"31225735\",\"CI_2_5\":\"25199188\",\"CI_97_5\":\"36081474\"},\n    {\"channel\":\"outbrain\",\"mean_total_effect\":\"30282001\",\"CI_2_5\":\"23523162\",\"CI_97_5\":\"37018084\"},\n    {\"channel\":\"base\",\"mean_total_effect\":\"19118968\",\"CI_2_5\":\"10934088\",\"CI_97_5\":\"30009564\"},\n    {\"channel\":\"facebook\",\"mean_total_effect\":\"16000035\",\"CI_2_5\":\"10461794\",\"CI_97_5\":\"23781437\"},\n    {\"channel\":\"taboola\",\"mean_total_effect\":\"13793090\",\"CI_2_5\":\"10074719\",\"CI_97_5\":\"18144293\"},\n    {\"channel\":\"spotify\",\"mean_total_effect\":\"13774499\",\"CI_2_5\":\"9854463\",\"CI_97_5\":\"17758705\"},\n    {\"channel\":\"pinterest\",\"mean_total_effect\":\"6572802\",\"CI_2_5\":\"350147\",\"CI_97_5\":\"11895337\"},\n    {\"channel\":\"yt_influencers\",\"mean_total_effect\":\"6155257\",\"CI_2_5\":\"3143780\",\"CI_97_5\":\"11367892\"},\n    {\"channel\":\"edge\",\"mean_total_effect\":\"5582177\",\"CI_2_5\":\"4421612\",\"CI_97_5\":\"6877196\"},\n    {\"channel\":\"quora\",\"mean_total_effect\":\"3355008\",\"CI_2_5\":\"1385554\",\"CI_97_5\":\"5399468\"},\n    {\"channel\":\"search_generic_bing\",\"mean_total_effect\":\"1655703\",\"CI_2_5\":\"593024\",\"CI_97_5\":\"2408829\"},\n    {\"channel\":\"streaming\",\"mean_total_effect\":\"1316805\",\"CI_2_5\":\"603436\",\"CI_97_5\":\"2084420\"},\n    {\"channel\":\"tv\",\"mean_total_effect\":\"728822\",\"CI_2_5\":\"81818\",\"CI_97_5\":\"2125785\"},\n    {\"channel\":\"youtube\",\"mean_total_effect\":\"228316\",\"CI_2_5\":\"0\",\"CI_97_5\":\"1967550\"},\n    {\"channel\":\"twitter\",\"mean_total_effect\":\"46742\",\"CI_2_5\":\"0\",\"CI_97_5\":\"314667\"},\n    {\"channel\":\"rokt\",\"mean_total_effect\":\"0\",\"CI_2_5\":\"0\",\"CI_97_5\":\"22325\"},\n    {\"channel\":\"podcast\",\"mean_total_effect\":\"0\",\"CI_2_5\":\"0\",\"CI_97_5\":\"1914042\"}\n    ]\n\n\n  const COST_PER = [\n    {\"channel\":\"podcast\",\"mean_cps\":\"inf\",\"CI_2_5\":\"3.74\",\"ci_97_5\":\"inf\"},\n    {\"channel\":\"rokt\",\"mean_cps\":\"inf\",\"CI_2_5\":\"35.72\",\"ci_97_5\":\"inf\"},\n    {\"channel\":\"youtube\",\"mean_cps\":\"47.2\",\"CI_2_5\":\"5.48\",\"ci_97_5\":\"inf\"},\n    {\"channel\":\"tv\",\"mean_cps\":\"4.76\",\"CI_2_5\":\"1.63\",\"ci_97_5\":\"42.39\"},\n    {\"channel\":\"streaming\",\"mean_cps\":\"3.22\",\"CI_2_5\":\"2.03\",\"ci_97_5\":\"7.02\"},\n    {\"channel\":\"twitter\",\"mean_cps\":\"1.78\",\"CI_2_5\":\"0.26\",\"ci_97_5\":\"inf\"},\n    {\"channel\":\"yt_influencers\",\"mean_cps\":\"1.76\",\"CI_2_5\":\"0.95\",\"ci_97_5\":\"3.44\"},\n    {\"channel\":\"facebook\",\"mean_cps\":\"1.35\",\"CI_2_5\":\"0.91\",\"ci_97_5\":\"2.07\"},\n    {\"channel\":\"edge\",\"mean_cps\":\"0.59\",\"CI_2_5\":\"0.48\",\"ci_97_5\":\"0.74\"},\n    {\"channel\":\"taboola\",\"mean_cps\":\"0.54\",\"CI_2_5\":\"0.41\",\"ci_97_5\":\"0.74\"},\n    {\"channel\":\"gdn\",\"mean_cps\":\"0.23\",\"CI_2_5\":\"0.2\",\"ci_97_5\":\"0.29\"},\n    {\"channel\":\"quora\",\"mean_cps\":\"0.18\",\"CI_2_5\":\"0.11\",\"ci_97_5\":\"0.44\"},\n    {\"channel\":\"pinterest\",\"mean_cps\":\"0.18\",\"CI_2_5\":\"0.1\",\"ci_97_5\":\"3.43\"},\n    {\"channel\":\"search_generic_google\",\"mean_cps\":\"0.17\",\"CI_2_5\":\"0.15\",\"ci_97_5\":\"0.21\"},\n    {\"channel\":\"search_generic_bing\",\"mean_cps\":\"0.16\",\"CI_2_5\":\"0.11\",\"ci_97_5\":\"0.45\"},\n    {\"channel\":\"outbrain\",\"mean_cps\":\"0.06\",\"CI_2_5\":\"0.05\",\"ci_97_5\":\"0.08\"},\n    {\"channel\":\"spotify\",\"mean_cps\":\"0.04\",\"CI_2_5\":\"0.03\",\"ci_97_5\":\"0.06\"}\n  ]\n\n  const SPEND = [\n    {\"channel\":\"facebook\",\"spend\":\"21635677\"},\n    {\"channel\":\"yt_influencers\",\"spend\":\"10813171\"},\n    {\"channel\":\"youtube\",\"spend\":\"10775490\"},\n    {\"channel\":\"taboola\",\"spend\":\"7470627\"},\n    {\"channel\":\"gdn\",\"spend\":\"7314824\"},\n    {\"channel\":\"podcast\",\"spend\":\"7151821\"},\n    {\"channel\":\"search_generic_google\",\"spend\":\"6900236\"},\n    {\"channel\":\"streaming\",\"spend\":\"4236785\"},\n    {\"channel\":\"tv\",\"spend\":\"3468025\"},\n    {\"channel\":\"edge\",\"spend\":\"3283599\"},\n    {\"channel\":\"outbrain\",\"spend\":\"1851991\"},\n    {\"channel\":\"pinterest\",\"spend\":\"1202057\"},\n    {\"channel\":\"rokt\",\"spend\":\"797481\"},\n    {\"channel\":\"quora\",\"spend\":\"615594\"},\n    {\"channel\":\"spotify\",\"spend\":\"603061\"},\n    {\"channel\":\"search_generic_bing\",\"spend\":\"267832\"},\n    {\"channel\":\"twitter\",\"spend\":\"83385\"}\n  ]\n\n\n  const KPI_PREDICTION = [\n{\"date\":\"1/1/18\",\"CI_weekly_2_5\":\"233971\",\"CI_weekly_97_5\":\"261861\",\"y_prediction_weekly\":\"247949\",\"y_true_weekly\":\"250592\"},\n{\"date\":\"1/2/18\",\"CI_weekly_2_5\":\"238608\",\"CI_weekly_97_5\":\"265467\",\"y_prediction_weekly\":\"252191\",\"y_true_weekly\":\"249312\"},\n{\"date\":\"1/3/18\",\"CI_weekly_2_5\":\"230990\",\"CI_weekly_97_5\":\"255705\",\"y_prediction_weekly\":\"243477\",\"y_true_weekly\":\"241842\"},\n{\"date\":\"1/4/18\",\"CI_weekly_2_5\":\"223819\",\"CI_weekly_97_5\":\"245344\",\"y_prediction_weekly\":\"234546\",\"y_true_weekly\":\"238165\"},\n{\"date\":\"1/5/18\",\"CI_weekly_2_5\":\"220905\",\"CI_weekly_97_5\":\"240635\",\"y_prediction_weekly\":\"230661\",\"y_true_weekly\":\"238649\"},\n{\"date\":\"1/6/18\",\"CI_weekly_2_5\":\"222602\",\"CI_weekly_97_5\":\"241201\",\"y_prediction_weekly\":\"231602\",\"y_true_weekly\":\"247335\"},\n{\"date\":\"1/7/18\",\"CI_weekly_2_5\":\"225094\",\"CI_weekly_97_5\":\"244535\",\"y_prediction_weekly\":\"234455\",\"y_true_weekly\":\"256090\"},\n{\"date\":\"1/8/18\",\"CI_weekly_2_5\":\"226660\",\"CI_weekly_97_5\":\"247493\",\"y_prediction_weekly\":\"236603\",\"y_true_weekly\":\"262434\"},\n{\"date\":\"1/9/18\",\"CI_weekly_2_5\":\"229175\",\"CI_weekly_97_5\":\"249774\",\"y_prediction_weekly\":\"238910\",\"y_true_weekly\":\"268709\"},\n{\"date\":\"1/10/18\",\"CI_weekly_2_5\":\"232044\",\"CI_weekly_97_5\":\"251989\",\"y_prediction_weekly\":\"241367\",\"y_true_weekly\":\"270203\"},\n{\"date\":\"1/11/18\",\"CI_weekly_2_5\":\"236540\",\"CI_weekly_97_5\":\"255934\",\"y_prediction_weekly\":\"245577\",\"y_true_weekly\":\"273293\"},\n{\"date\":\"1/12/18\",\"CI_weekly_2_5\":\"237658\",\"CI_weekly_97_5\":\"257274\",\"y_prediction_weekly\":\"246744\",\"y_true_weekly\":\"267132\"},\n{\"date\":\"1/13/18\",\"CI_weekly_2_5\":\"235528\",\"CI_weekly_97_5\":\"254626\",\"y_prediction_weekly\":\"244450\",\"y_true_weekly\":\"254248\"},\n{\"date\":\"1/14/18\",\"CI_weekly_2_5\":\"233539\",\"CI_weekly_97_5\":\"251558\",\"y_prediction_weekly\":\"241894\",\"y_true_weekly\":\"242568\"},\n{\"date\":\"1/15/18\",\"CI_weekly_2_5\":\"232028\",\"CI_weekly_97_5\":\"248926\",\"y_prediction_weekly\":\"239827\",\"y_true_weekly\":\"234992\"},\n{\"date\":\"1/16/18\",\"CI_weekly_2_5\":\"233528\",\"CI_weekly_97_5\":\"249848\",\"y_prediction_weekly\":\"241128\",\"y_true_weekly\":\"230306\"},\n{\"date\":\"1/17/18\",\"CI_weekly_2_5\":\"237305\",\"CI_weekly_97_5\":\"254612\",\"y_prediction_weekly\":\"245344\",\"y_true_weekly\":\"235352\"},\n{\"date\":\"1/18/18\",\"CI_weekly_2_5\":\"236185\",\"CI_weekly_97_5\":\"253523\",\"y_prediction_weekly\":\"244259\",\"y_true_weekly\":\"233098\"},\n{\"date\":\"1/19/18\",\"CI_weekly_2_5\":\"235591\",\"CI_weekly_97_5\":\"252189\",\"y_prediction_weekly\":\"243195\",\"y_true_weekly\":\"234692\"},\n{\"date\":\"1/20/18\",\"CI_weekly_2_5\":\"235110\",\"CI_weekly_97_5\":\"251803\",\"y_prediction_weekly\":\"242749\",\"y_true_weekly\":\"235530\"},\n{\"date\":\"1/21/18\",\"CI_weekly_2_5\":\"234381\",\"CI_weekly_97_5\":\"251030\",\"y_prediction_weekly\":\"241952\",\"y_true_weekly\":\"236171\"},\n{\"date\":\"1/22/18\",\"CI_weekly_2_5\":\"236052\",\"CI_weekly_97_5\":\"253032\",\"y_prediction_weekly\":\"243834\",\"y_true_weekly\":\"241632\"},\n{\"date\":\"1/23/18\",\"CI_weekly_2_5\":\"233317\",\"CI_weekly_97_5\":\"250131\",\"y_prediction_weekly\":\"240928\",\"y_true_weekly\":\"239192\"},\n{\"date\":\"1/24/18\",\"CI_weekly_2_5\":\"227440\",\"CI_weekly_97_5\":\"242992\",\"y_prediction_weekly\":\"234366\",\"y_true_weekly\":\"230936\"},\n{\"date\":\"1/25/18\",\"CI_weekly_2_5\":\"222286\",\"CI_weekly_97_5\":\"237736\",\"y_prediction_weekly\":\"228993\",\"y_true_weekly\":\"226995\"},\n{\"date\":\"1/26/18\",\"CI_weekly_2_5\":\"219567\",\"CI_weekly_97_5\":\"234740\",\"y_prediction_weekly\":\"226350\",\"y_true_weekly\":\"225446\"},\n{\"date\":\"1/27/18\",\"CI_weekly_2_5\":\"218231\",\"CI_weekly_97_5\":\"233188\",\"y_prediction_weekly\":\"224919\",\"y_true_weekly\":\"226105\"},\n{\"date\":\"1/28/18\",\"CI_weekly_2_5\":\"216752\",\"CI_weekly_97_5\":\"231961\",\"y_prediction_weekly\":\"223787\",\"y_true_weekly\":\"227031\"},\n{\"date\":\"1/29/18\",\"CI_weekly_2_5\":\"212349\",\"CI_weekly_97_5\":\"227412\",\"y_prediction_weekly\":\"219384\",\"y_true_weekly\":\"219413\"},\n{\"date\":\"1/30/18\",\"CI_weekly_2_5\":\"209911\",\"CI_weekly_97_5\":\"224470\",\"y_prediction_weekly\":\"216767\",\"y_true_weekly\":\"217004\"},\n{\"date\":\"1/31/18\",\"CI_weekly_2_5\":\"208142\",\"CI_weekly_97_5\":\"222583\",\"y_prediction_weekly\":\"215073\",\"y_true_weekly\":\"215084\"},\n{\"date\":\"2/1/18\",\"CI_weekly_2_5\":\"210537\",\"CI_weekly_97_5\":\"224532\",\"y_prediction_weekly\":\"217436\",\"y_true_weekly\":\"218057\"},\n{\"date\":\"2/2/18\",\"CI_weekly_2_5\":\"211947\",\"CI_weekly_97_5\":\"225967\",\"y_prediction_weekly\":\"218743\",\"y_true_weekly\":\"218185\"},\n{\"date\":\"2/3/18\",\"CI_weekly_2_5\":\"212234\",\"CI_weekly_97_5\":\"226562\",\"y_prediction_weekly\":\"219158\",\"y_true_weekly\":\"216433\"},\n{\"date\":\"2/4/18\",\"CI_weekly_2_5\":\"214276\",\"CI_weekly_97_5\":\"228327\",\"y_prediction_weekly\":\"221051\",\"y_true_weekly\":\"219224\"},\n{\"date\":\"2/5/18\",\"CI_weekly_2_5\":\"218248\",\"CI_weekly_97_5\":\"232216\",\"y_prediction_weekly\":\"225000\",\"y_true_weekly\":\"228509\"},\n{\"date\":\"2/6/18\",\"CI_weekly_2_5\":\"222212\",\"CI_weekly_97_5\":\"237050\",\"y_prediction_weekly\":\"229444\",\"y_true_weekly\":\"235449\"},\n{\"date\":\"2/7/18\",\"CI_weekly_2_5\":\"223161\",\"CI_weekly_97_5\":\"238566\",\"y_prediction_weekly\":\"230795\",\"y_true_weekly\":\"238043\"},\n{\"date\":\"2/8/18\",\"CI_weekly_2_5\":\"220916\",\"CI_weekly_97_5\":\"237103\",\"y_prediction_weekly\":\"229005\",\"y_true_weekly\":\"232916\"},\n{\"date\":\"2/9/18\",\"CI_weekly_2_5\":\"220640\",\"CI_weekly_97_5\":\"238760\",\"y_prediction_weekly\":\"229797\",\"y_true_weekly\":\"231713\"},\n{\"date\":\"2/10/18\",\"CI_weekly_2_5\":\"219315\",\"CI_weekly_97_5\":\"237765\",\"y_prediction_weekly\":\"228674\",\"y_true_weekly\":\"229386\"},\n{\"date\":\"2/11/18\",\"CI_weekly_2_5\":\"215298\",\"CI_weekly_97_5\":\"233620\",\"y_prediction_weekly\":\"224587\",\"y_true_weekly\":\"220571\"},\n{\"date\":\"2/12/18\",\"CI_weekly_2_5\":\"211051\",\"CI_weekly_97_5\":\"228490\",\"y_prediction_weekly\":\"219876\",\"y_true_weekly\":\"210529\"},\n{\"date\":\"2/13/18\",\"CI_weekly_2_5\":\"205737\",\"CI_weekly_97_5\":\"222689\",\"y_prediction_weekly\":\"214246\",\"y_true_weekly\":\"203558\"},\n{\"date\":\"2/14/18\",\"CI_weekly_2_5\":\"205667\",\"CI_weekly_97_5\":\"222423\",\"y_prediction_weekly\":\"213981\",\"y_true_weekly\":\"201675\"},\n{\"date\":\"2/15/18\",\"CI_weekly_2_5\":\"204845\",\"CI_weekly_97_5\":\"221066\",\"y_prediction_weekly\":\"212858\",\"y_true_weekly\":\"201448\"},\n{\"date\":\"2/16/18\",\"CI_weekly_2_5\":\"200623\",\"CI_weekly_97_5\":\"214857\",\"y_prediction_weekly\":\"207652\",\"y_true_weekly\":\"198038\"},\n{\"date\":\"2/17/18\",\"CI_weekly_2_5\":\"198936\",\"CI_weekly_97_5\":\"212239\",\"y_prediction_weekly\":\"205541\",\"y_true_weekly\":\"197185\"},\n{\"date\":\"2/18/18\",\"CI_weekly_2_5\":\"200162\",\"CI_weekly_97_5\":\"213258\",\"y_prediction_weekly\":\"206574\",\"y_true_weekly\":\"200387\"},\n{\"date\":\"2/19/18\",\"CI_weekly_2_5\":\"202115\",\"CI_weekly_97_5\":\"215072\",\"y_prediction_weekly\":\"208421\",\"y_true_weekly\":\"203857\"},\n{\"date\":\"2/20/18\",\"CI_weekly_2_5\":\"203039\",\"CI_weekly_97_5\":\"215722\",\"y_prediction_weekly\":\"209158\",\"y_true_weekly\":\"202661\"},\n{\"date\":\"2/21/18\",\"CI_weekly_2_5\":\"202927\",\"CI_weekly_97_5\":\"215232\",\"y_prediction_weekly\":\"208800\",\"y_true_weekly\":\"202797\"},\n{\"date\":\"2/22/18\",\"CI_weekly_2_5\":\"204963\",\"CI_weekly_97_5\":\"217162\",\"y_prediction_weekly\":\"210628\",\"y_true_weekly\":\"207170\"},\n{\"date\":\"2/23/18\",\"CI_weekly_2_5\":\"207605\",\"CI_weekly_97_5\":\"220102\",\"y_prediction_weekly\":\"213273\",\"y_true_weekly\":\"212028\"},\n{\"date\":\"2/24/18\",\"CI_weekly_2_5\":\"207752\",\"CI_weekly_97_5\":\"220742\",\"y_prediction_weekly\":\"213528\",\"y_true_weekly\":\"214102\"},\n{\"date\":\"2/25/18\",\"CI_weekly_2_5\":\"206495\",\"CI_weekly_97_5\":\"219594\",\"y_prediction_weekly\":\"212367\",\"y_true_weekly\":\"213298\"},\n{\"date\":\"2/26/18\",\"CI_weekly_2_5\":\"202799\",\"CI_weekly_97_5\":\"216170\",\"y_prediction_weekly\":\"208749\",\"y_true_weekly\":\"213130\"},\n{\"date\":\"2/27/18\",\"CI_weekly_2_5\":\"201145\",\"CI_weekly_97_5\":\"214711\",\"y_prediction_weekly\":\"207165\",\"y_true_weekly\":\"214794\"},\n{\"date\":\"2/28/18\",\"CI_weekly_2_5\":\"199420\",\"CI_weekly_97_5\":\"212938\",\"y_prediction_weekly\":\"205438\",\"y_true_weekly\":\"214696\"},\n{\"date\":\"3/1/18\",\"CI_weekly_2_5\":\"197373\",\"CI_weekly_97_5\":\"211005\",\"y_prediction_weekly\":\"203587\",\"y_true_weekly\":\"213155\"},\n{\"date\":\"3/2/18\",\"CI_weekly_2_5\":\"194432\",\"CI_weekly_97_5\":\"207761\",\"y_prediction_weekly\":\"200645\",\"y_true_weekly\":\"209513\"},\n{\"date\":\"3/3/18\",\"CI_weekly_2_5\":\"194179\",\"CI_weekly_97_5\":\"207316\",\"y_prediction_weekly\":\"200403\",\"y_true_weekly\":\"208342\"},\n{\"date\":\"3/4/18\",\"CI_weekly_2_5\":\"193142\",\"CI_weekly_97_5\":\"206728\",\"y_prediction_weekly\":\"199602\",\"y_true_weekly\":\"207452\"},\n{\"date\":\"3/5/18\",\"CI_weekly_2_5\":\"192991\",\"CI_weekly_97_5\":\"206889\",\"y_prediction_weekly\":\"199775\",\"y_true_weekly\":\"202989\"},\n{\"date\":\"3/6/18\",\"CI_weekly_2_5\":\"192392\",\"CI_weekly_97_5\":\"206157\",\"y_prediction_weekly\":\"199211\",\"y_true_weekly\":\"201697\"},\n{\"date\":\"3/7/18\",\"CI_weekly_2_5\":\"192209\",\"CI_weekly_97_5\":\"206094\",\"y_prediction_weekly\":\"199210\",\"y_true_weekly\":\"201485\"},\n{\"date\":\"3/8/18\",\"CI_weekly_2_5\":\"195113\",\"CI_weekly_97_5\":\"210244\",\"y_prediction_weekly\":\"202769\",\"y_true_weekly\":\"198864\"},\n{\"date\":\"3/9/18\",\"CI_weekly_2_5\":\"199648\",\"CI_weekly_97_5\":\"217218\",\"y_prediction_weekly\":\"208587\",\"y_true_weekly\":\"196959\"},\n{\"date\":\"3/10/18\",\"CI_weekly_2_5\":\"201069\",\"CI_weekly_97_5\":\"219596\",\"y_prediction_weekly\":\"210516\",\"y_true_weekly\":\"194065\"},\n{\"date\":\"3/11/18\",\"CI_weekly_2_5\":\"203049\",\"CI_weekly_97_5\":\"221196\",\"y_prediction_weekly\":\"212347\",\"y_true_weekly\":\"191604\"},\n{\"date\":\"3/12/18\",\"CI_weekly_2_5\":\"205064\",\"CI_weekly_97_5\":\"222895\",\"y_prediction_weekly\":\"214135\",\"y_true_weekly\":\"189045\"},\n{\"date\":\"3/13/18\",\"CI_weekly_2_5\":\"206369\",\"CI_weekly_97_5\":\"225383\",\"y_prediction_weekly\":\"216191\",\"y_true_weekly\":\"185839\"},\n{\"date\":\"3/14/18\",\"CI_weekly_2_5\":\"207634\",\"CI_weekly_97_5\":\"226900\",\"y_prediction_weekly\":\"217599\",\"y_true_weekly\":\"183375\"},\n{\"date\":\"3/15/18\",\"CI_weekly_2_5\":\"205839\",\"CI_weekly_97_5\":\"224448\",\"y_prediction_weekly\":\"215510\",\"y_true_weekly\":\"183331\"},\n{\"date\":\"3/16/18\",\"CI_weekly_2_5\":\"201753\",\"CI_weekly_97_5\":\"218083\",\"y_prediction_weekly\":\"210287\",\"y_true_weekly\":\"182838\"},\n{\"date\":\"3/17/18\",\"CI_weekly_2_5\":\"197900\",\"CI_weekly_97_5\":\"213081\",\"y_prediction_weekly\":\"205839\",\"y_true_weekly\":\"182246\"},\n{\"date\":\"3/18/18\",\"CI_weekly_2_5\":\"194628\",\"CI_weekly_97_5\":\"209908\",\"y_prediction_weekly\":\"202688\",\"y_true_weekly\":\"182641\"},\n{\"date\":\"3/19/18\",\"CI_weekly_2_5\":\"191681\",\"CI_weekly_97_5\":\"207410\",\"y_prediction_weekly\":\"200033\",\"y_true_weekly\":\"180739\"},\n{\"date\":\"3/20/18\",\"CI_weekly_2_5\":\"186884\",\"CI_weekly_97_5\":\"201800\",\"y_prediction_weekly\":\"194842\",\"y_true_weekly\":\"177871\"},\n{\"date\":\"3/21/18\",\"CI_weekly_2_5\":\"181135\",\"CI_weekly_97_5\":\"196454\",\"y_prediction_weekly\":\"189283\",\"y_true_weekly\":\"174228\"},\n{\"date\":\"3/22/18\",\"CI_weekly_2_5\":\"173103\",\"CI_weekly_97_5\":\"188153\",\"y_prediction_weekly\":\"181071\",\"y_true_weekly\":\"169518\"},\n{\"date\":\"3/23/18\",\"CI_weekly_2_5\":\"164627\",\"CI_weekly_97_5\":\"180317\",\"y_prediction_weekly\":\"172891\",\"y_true_weekly\":\"165639\"},\n{\"date\":\"3/24/18\",\"CI_weekly_2_5\":\"158548\",\"CI_weekly_97_5\":\"174632\",\"y_prediction_weekly\":\"167112\",\"y_true_weekly\":\"162549\"},\n{\"date\":\"3/25/18\",\"CI_weekly_2_5\":\"153647\",\"CI_weekly_97_5\":\"169890\",\"y_prediction_weekly\":\"162318\",\"y_true_weekly\":\"158100\"},\n{\"date\":\"3/26/18\",\"CI_weekly_2_5\":\"151488\",\"CI_weekly_97_5\":\"167433\",\"y_prediction_weekly\":\"160001\",\"y_true_weekly\":\"155526\"},\n{\"date\":\"3/27/18\",\"CI_weekly_2_5\":\"150729\",\"CI_weekly_97_5\":\"166876\",\"y_prediction_weekly\":\"159390\",\"y_true_weekly\":\"157204\"},\n{\"date\":\"3/28/18\",\"CI_weekly_2_5\":\"148555\",\"CI_weekly_97_5\":\"164775\",\"y_prediction_weekly\":\"157183\",\"y_true_weekly\":\"156931\"},\n{\"date\":\"3/29/18\",\"CI_weekly_2_5\":\"148662\",\"CI_weekly_97_5\":\"165231\",\"y_prediction_weekly\":\"157497\",\"y_true_weekly\":\"157837\"},\n{\"date\":\"3/30/18\",\"CI_weekly_2_5\":\"150024\",\"CI_weekly_97_5\":\"166556\",\"y_prediction_weekly\":\"158800\",\"y_true_weekly\":\"157646\"},\n{\"date\":\"3/31/18\",\"CI_weekly_2_5\":\"152571\",\"CI_weekly_97_5\":\"169137\",\"y_prediction_weekly\":\"161387\",\"y_true_weekly\":\"158903\"},\n{\"date\":\"4/1/18\",\"CI_weekly_2_5\":\"155500\",\"CI_weekly_97_5\":\"171948\",\"y_prediction_weekly\":\"164216\",\"y_true_weekly\":\"161876\"},\n{\"date\":\"4/2/18\",\"CI_weekly_2_5\":\"155401\",\"CI_weekly_97_5\":\"172214\",\"y_prediction_weekly\":\"164280\",\"y_true_weekly\":\"165313\"},\n{\"date\":\"4/3/18\",\"CI_weekly_2_5\":\"154781\",\"CI_weekly_97_5\":\"171390\",\"y_prediction_weekly\":\"163383\",\"y_true_weekly\":\"164714\"},\n{\"date\":\"4/4/18\",\"CI_weekly_2_5\":\"155855\",\"CI_weekly_97_5\":\"172616\",\"y_prediction_weekly\":\"164486\",\"y_true_weekly\":\"174613\"},\n{\"date\":\"4/5/18\",\"CI_weekly_2_5\":\"154845\",\"CI_weekly_97_5\":\"171452\",\"y_prediction_weekly\":\"163296\",\"y_true_weekly\":\"173597\"},\n{\"date\":\"4/6/18\",\"CI_weekly_2_5\":\"155289\",\"CI_weekly_97_5\":\"171541\",\"y_prediction_weekly\":\"163449\",\"y_true_weekly\":\"174807\"},\n{\"date\":\"4/7/18\",\"CI_weekly_2_5\":\"158685\",\"CI_weekly_97_5\":\"175272\",\"y_prediction_weekly\":\"166777\",\"y_true_weekly\":\"175957\"},\n{\"date\":\"4/8/18\",\"CI_weekly_2_5\":\"160697\",\"CI_weekly_97_5\":\"176927\",\"y_prediction_weekly\":\"168454\",\"y_true_weekly\":\"175193\"},\n{\"date\":\"4/9/18\",\"CI_weekly_2_5\":\"163764\",\"CI_weekly_97_5\":\"179552\",\"y_prediction_weekly\":\"171205\",\"y_true_weekly\":\"179233\"},\n{\"date\":\"4/10/18\",\"CI_weekly_2_5\":\"168229\",\"CI_weekly_97_5\":\"184465\",\"y_prediction_weekly\":\"175758\",\"y_true_weekly\":\"182800\"},\n{\"date\":\"4/11/18\",\"CI_weekly_2_5\":\"178408\",\"CI_weekly_97_5\":\"194844\",\"y_prediction_weekly\":\"186088\",\"y_true_weekly\":\"195335\"},\n{\"date\":\"4/12/18\",\"CI_weekly_2_5\":\"190045\",\"CI_weekly_97_5\":\"207523\",\"y_prediction_weekly\":\"198256\",\"y_true_weekly\":\"202190\"},\n{\"date\":\"4/13/18\",\"CI_weekly_2_5\":\"196085\",\"CI_weekly_97_5\":\"213358\",\"y_prediction_weekly\":\"204185\",\"y_true_weekly\":\"206214\"},\n{\"date\":\"4/14/18\",\"CI_weekly_2_5\":\"197124\",\"CI_weekly_97_5\":\"214450\",\"y_prediction_weekly\":\"205292\",\"y_true_weekly\":\"209649\"},\n{\"date\":\"4/15/18\",\"CI_weekly_2_5\":\"197104\",\"CI_weekly_97_5\":\"215355\",\"y_prediction_weekly\":\"205643\",\"y_true_weekly\":\"212191\"},\n{\"date\":\"4/16/18\",\"CI_weekly_2_5\":\"195708\",\"CI_weekly_97_5\":\"214453\",\"y_prediction_weekly\":\"204417\",\"y_true_weekly\":\"216111\"},\n{\"date\":\"4/17/18\",\"CI_weekly_2_5\":\"192215\",\"CI_weekly_97_5\":\"210266\",\"y_prediction_weekly\":\"200603\",\"y_true_weekly\":\"214161\"},\n{\"date\":\"4/18/18\",\"CI_weekly_2_5\":\"189285\",\"CI_weekly_97_5\":\"207564\",\"y_prediction_weekly\":\"197773\",\"y_true_weekly\":\"195727\"},\n{\"date\":\"4/19/18\",\"CI_weekly_2_5\":\"181688\",\"CI_weekly_97_5\":\"198414\",\"y_prediction_weekly\":\"189333\",\"y_true_weekly\":\"195777\"},\n{\"date\":\"4/20/18\",\"CI_weekly_2_5\":\"177616\",\"CI_weekly_97_5\":\"194245\",\"y_prediction_weekly\":\"185127\",\"y_true_weekly\":\"191678\"},\n{\"date\":\"4/21/18\",\"CI_weekly_2_5\":\"176887\",\"CI_weekly_97_5\":\"193202\",\"y_prediction_weekly\":\"184160\",\"y_true_weekly\":\"189857\"},\n{\"date\":\"4/22/18\",\"CI_weekly_2_5\":\"177931\",\"CI_weekly_97_5\":\"193666\",\"y_prediction_weekly\":\"184937\",\"y_true_weekly\":\"190129\"},\n{\"date\":\"4/23/18\",\"CI_weekly_2_5\":\"179007\",\"CI_weekly_97_5\":\"194237\",\"y_prediction_weekly\":\"185850\",\"y_true_weekly\":\"183406\"},\n{\"date\":\"4/24/18\",\"CI_weekly_2_5\":\"183021\",\"CI_weekly_97_5\":\"198949\",\"y_prediction_weekly\":\"190152\",\"y_true_weekly\":\"188585\"},\n{\"date\":\"4/25/18\",\"CI_weekly_2_5\":\"178403\",\"CI_weekly_97_5\":\"194112\",\"y_prediction_weekly\":\"185213\",\"y_true_weekly\":\"206288\"},\n{\"date\":\"4/26/18\",\"CI_weekly_2_5\":\"176733\",\"CI_weekly_97_5\":\"193469\",\"y_prediction_weekly\":\"184043\",\"y_true_weekly\":\"207138\"},\n{\"date\":\"4/27/18\",\"CI_weekly_2_5\":\"178542\",\"CI_weekly_97_5\":\"196021\",\"y_prediction_weekly\":\"186260\",\"y_true_weekly\":\"209865\"},\n{\"date\":\"4/28/18\",\"CI_weekly_2_5\":\"177454\",\"CI_weekly_97_5\":\"195017\",\"y_prediction_weekly\":\"185327\",\"y_true_weekly\":\"207973\"},\n{\"date\":\"4/29/18\",\"CI_weekly_2_5\":\"173181\",\"CI_weekly_97_5\":\"190982\",\"y_prediction_weekly\":\"181224\",\"y_true_weekly\":\"202728\"},\n{\"date\":\"4/30/18\",\"CI_weekly_2_5\":\"170578\",\"CI_weekly_97_5\":\"188779\",\"y_prediction_weekly\":\"178780\",\"y_true_weekly\":\"200029\"},\n{\"date\":\"5/1/18\",\"CI_weekly_2_5\":\"166341\",\"CI_weekly_97_5\":\"184028\",\"y_prediction_weekly\":\"174342\",\"y_true_weekly\":\"192420\"},\n{\"date\":\"5/2/18\",\"CI_weekly_2_5\":\"165788\",\"CI_weekly_97_5\":\"183017\",\"y_prediction_weekly\":\"173661\",\"y_true_weekly\":\"172404\"},\n{\"date\":\"5/3/18\",\"CI_weekly_2_5\":\"166797\",\"CI_weekly_97_5\":\"183570\",\"y_prediction_weekly\":\"174432\",\"y_true_weekly\":\"164634\"},\n{\"date\":\"5/4/18\",\"CI_weekly_2_5\":\"166330\",\"CI_weekly_97_5\":\"183321\",\"y_prediction_weekly\":\"174191\",\"y_true_weekly\":\"169688\"},\n{\"date\":\"5/5/18\",\"CI_weekly_2_5\":\"165321\",\"CI_weekly_97_5\":\"182156\",\"y_prediction_weekly\":\"173115\",\"y_true_weekly\":\"167691\"},\n{\"date\":\"5/6/18\",\"CI_weekly_2_5\":\"165852\",\"CI_weekly_97_5\":\"182627\",\"y_prediction_weekly\":\"173686\",\"y_true_weekly\":\"168132\"},\n{\"date\":\"5/7/18\",\"CI_weekly_2_5\":\"163107\",\"CI_weekly_97_5\":\"179782\",\"y_prediction_weekly\":\"170926\",\"y_true_weekly\":\"163750\"},\n{\"date\":\"5/8/18\",\"CI_weekly_2_5\":\"163436\",\"CI_weekly_97_5\":\"180108\",\"y_prediction_weekly\":\"171265\",\"y_true_weekly\":\"163525\"},\n{\"date\":\"5/9/18\",\"CI_weekly_2_5\":\"165187\",\"CI_weekly_97_5\":\"182039\",\"y_prediction_weekly\":\"173247\",\"y_true_weekly\":\"161852\"},\n{\"date\":\"5/10/18\",\"CI_weekly_2_5\":\"166908\",\"CI_weekly_97_5\":\"183775\",\"y_prediction_weekly\":\"175108\",\"y_true_weekly\":\"161665\"},\n{\"date\":\"5/11/18\",\"CI_weekly_2_5\":\"165264\",\"CI_weekly_97_5\":\"181136\",\"y_prediction_weekly\":\"172980\",\"y_true_weekly\":\"154152\"},\n{\"date\":\"5/12/18\",\"CI_weekly_2_5\":\"168314\",\"CI_weekly_97_5\":\"184496\",\"y_prediction_weekly\":\"176185\",\"y_true_weekly\":\"158933\"},\n{\"date\":\"5/13/18\",\"CI_weekly_2_5\":\"171870\",\"CI_weekly_97_5\":\"187941\",\"y_prediction_weekly\":\"179701\",\"y_true_weekly\":\"164179\"},\n{\"date\":\"5/14/18\",\"CI_weekly_2_5\":\"177323\",\"CI_weekly_97_5\":\"192967\",\"y_prediction_weekly\":\"185029\",\"y_true_weekly\":\"172234\"},\n{\"date\":\"5/15/18\",\"CI_weekly_2_5\":\"178268\",\"CI_weekly_97_5\":\"193887\",\"y_prediction_weekly\":\"186046\",\"y_true_weekly\":\"175671\"},\n{\"date\":\"5/16/18\",\"CI_weekly_2_5\":\"177149\",\"CI_weekly_97_5\":\"192632\",\"y_prediction_weekly\":\"184815\",\"y_true_weekly\":\"180816\"},\n{\"date\":\"5/17/18\",\"CI_weekly_2_5\":\"176724\",\"CI_weekly_97_5\":\"192434\",\"y_prediction_weekly\":\"184449\",\"y_true_weekly\":\"186731\"},\n{\"date\":\"5/18/18\",\"CI_weekly_2_5\":\"180667\",\"CI_weekly_97_5\":\"197437\",\"y_prediction_weekly\":\"188808\",\"y_true_weekly\":\"190817\"},\n{\"date\":\"5/19/18\",\"CI_weekly_2_5\":\"180199\",\"CI_weekly_97_5\":\"196985\",\"y_prediction_weekly\":\"188332\",\"y_true_weekly\":\"191373\"},\n{\"date\":\"5/20/18\",\"CI_weekly_2_5\":\"180726\",\"CI_weekly_97_5\":\"197499\",\"y_prediction_weekly\":\"188797\",\"y_true_weekly\":\"189589\"},\n{\"date\":\"5/21/18\",\"CI_weekly_2_5\":\"178388\",\"CI_weekly_97_5\":\"195161\",\"y_prediction_weekly\":\"186418\",\"y_true_weekly\":\"184716\"},\n{\"date\":\"5/22/18\",\"CI_weekly_2_5\":\"179330\",\"CI_weekly_97_5\":\"196239\",\"y_prediction_weekly\":\"187385\",\"y_true_weekly\":\"184673\"},\n{\"date\":\"5/23/18\",\"CI_weekly_2_5\":\"179792\",\"CI_weekly_97_5\":\"196520\",\"y_prediction_weekly\":\"187835\",\"y_true_weekly\":\"183245\"},\n{\"date\":\"5/24/18\",\"CI_weekly_2_5\":\"180307\",\"CI_weekly_97_5\":\"196709\",\"y_prediction_weekly\":\"188261\",\"y_true_weekly\":\"181878\"},\n{\"date\":\"5/25/18\",\"CI_weekly_2_5\":\"178565\",\"CI_weekly_97_5\":\"194411\",\"y_prediction_weekly\":\"186368\",\"y_true_weekly\":\"180354\"},\n{\"date\":\"5/26/18\",\"CI_weekly_2_5\":\"176417\",\"CI_weekly_97_5\":\"191632\",\"y_prediction_weekly\":\"183924\",\"y_true_weekly\":\"178486\"},\n{\"date\":\"5/27/18\",\"CI_weekly_2_5\":\"175194\",\"CI_weekly_97_5\":\"190252\",\"y_prediction_weekly\":\"182611\",\"y_true_weekly\":\"179360\"},\n{\"date\":\"5/28/18\",\"CI_weekly_2_5\":\"176401\",\"CI_weekly_97_5\":\"191580\",\"y_prediction_weekly\":\"183838\",\"y_true_weekly\":\"194475\"},\n{\"date\":\"5/29/18\",\"CI_weekly_2_5\":\"177245\",\"CI_weekly_97_5\":\"192086\",\"y_prediction_weekly\":\"184480\",\"y_true_weekly\":\"195553\"},\n{\"date\":\"5/30/18\",\"CI_weekly_2_5\":\"174673\",\"CI_weekly_97_5\":\"188846\",\"y_prediction_weekly\":\"181498\",\"y_true_weekly\":\"194839\"},\n{\"date\":\"5/31/18\",\"CI_weekly_2_5\":\"172321\",\"CI_weekly_97_5\":\"186096\",\"y_prediction_weekly\":\"178954\",\"y_true_weekly\":\"193897\"},\n{\"date\":\"6/1/18\",\"CI_weekly_2_5\":\"180331\",\"CI_weekly_97_5\":\"195930\",\"y_prediction_weekly\":\"187787\",\"y_true_weekly\":\"200083\"},\n{\"date\":\"6/2/18\",\"CI_weekly_2_5\":\"181222\",\"CI_weekly_97_5\":\"197293\",\"y_prediction_weekly\":\"188912\",\"y_true_weekly\":\"199453\"},\n{\"date\":\"6/3/18\",\"CI_weekly_2_5\":\"178378\",\"CI_weekly_97_5\":\"194244\",\"y_prediction_weekly\":\"186048\",\"y_true_weekly\":\"197962\"},\n{\"date\":\"6/4/18\",\"CI_weekly_2_5\":\"175431\",\"CI_weekly_97_5\":\"191119\",\"y_prediction_weekly\":\"183142\",\"y_true_weekly\":\"182227\"},\n{\"date\":\"6/5/18\",\"CI_weekly_2_5\":\"178129\",\"CI_weekly_97_5\":\"195448\",\"y_prediction_weekly\":\"186722\",\"y_true_weekly\":\"184489\"},\n{\"date\":\"6/6/18\",\"CI_weekly_2_5\":\"178543\",\"CI_weekly_97_5\":\"195803\",\"y_prediction_weekly\":\"187135\",\"y_true_weekly\":\"182092\"},\n{\"date\":\"6/7/18\",\"CI_weekly_2_5\":\"178606\",\"CI_weekly_97_5\":\"195573\",\"y_prediction_weekly\":\"187126\",\"y_true_weekly\":\"178133\"},\n{\"date\":\"6/8/18\",\"CI_weekly_2_5\":\"167698\",\"CI_weekly_97_5\":\"182032\",\"y_prediction_weekly\":\"175027\",\"y_true_weekly\":\"166966\"},\n{\"date\":\"6/9/18\",\"CI_weekly_2_5\":\"165058\",\"CI_weekly_97_5\":\"178996\",\"y_prediction_weekly\":\"172310\",\"y_true_weekly\":\"164275\"},\n{\"date\":\"6/10/18\",\"CI_weekly_2_5\":\"165490\",\"CI_weekly_97_5\":\"179241\",\"y_prediction_weekly\":\"172672\",\"y_true_weekly\":\"160677\"},\n{\"date\":\"6/11/18\",\"CI_weekly_2_5\":\"168956\",\"CI_weekly_97_5\":\"182825\",\"y_prediction_weekly\":\"176119\",\"y_true_weekly\":\"162132\"},\n{\"date\":\"6/12/18\",\"CI_weekly_2_5\":\"162875\",\"CI_weekly_97_5\":\"175041\",\"y_prediction_weekly\":\"169231\",\"y_true_weekly\":\"155230\"},\n{\"date\":\"6/13/18\",\"CI_weekly_2_5\":\"163455\",\"CI_weekly_97_5\":\"175623\",\"y_prediction_weekly\":\"169871\",\"y_true_weekly\":\"156006\"},\n{\"date\":\"6/14/18\",\"CI_weekly_2_5\":\"161856\",\"CI_weekly_97_5\":\"174605\",\"y_prediction_weekly\":\"168477\",\"y_true_weekly\":\"158225\"},\n{\"date\":\"6/15/18\",\"CI_weekly_2_5\":\"167130\",\"CI_weekly_97_5\":\"181412\",\"y_prediction_weekly\":\"174441\",\"y_true_weekly\":\"168648\"},\n{\"date\":\"6/16/18\",\"CI_weekly_2_5\":\"167495\",\"CI_weekly_97_5\":\"182136\",\"y_prediction_weekly\":\"174823\",\"y_true_weekly\":\"170914\"},\n{\"date\":\"6/17/18\",\"CI_weekly_2_5\":\"168612\",\"CI_weekly_97_5\":\"183247\",\"y_prediction_weekly\":\"175910\",\"y_true_weekly\":\"173437\"},\n{\"date\":\"6/18/18\",\"CI_weekly_2_5\":\"167211\",\"CI_weekly_97_5\":\"181693\",\"y_prediction_weekly\":\"174427\",\"y_true_weekly\":\"177094\"},\n{\"date\":\"6/19/18\",\"CI_weekly_2_5\":\"170464\",\"CI_weekly_97_5\":\"185922\",\"y_prediction_weekly\":\"178137\",\"y_true_weekly\":\"181444\"},\n{\"date\":\"6/20/18\",\"CI_weekly_2_5\":\"167436\",\"CI_weekly_97_5\":\"182949\",\"y_prediction_weekly\":\"175056\",\"y_true_weekly\":\"180527\"},\n{\"date\":\"6/21/18\",\"CI_weekly_2_5\":\"166755\",\"CI_weekly_97_5\":\"181866\",\"y_prediction_weekly\":\"174104\",\"y_true_weekly\":\"179735\"},\n{\"date\":\"6/22/18\",\"CI_weekly_2_5\":\"163562\",\"CI_weekly_97_5\":\"177485\",\"y_prediction_weekly\":\"170339\",\"y_true_weekly\":\"173235\"},\n{\"date\":\"6/23/18\",\"CI_weekly_2_5\":\"166406\",\"CI_weekly_97_5\":\"180191\",\"y_prediction_weekly\":\"173140\",\"y_true_weekly\":\"174260\"},\n{\"date\":\"6/24/18\",\"CI_weekly_2_5\":\"171989\",\"CI_weekly_97_5\":\"186148\",\"y_prediction_weekly\":\"178858\",\"y_true_weekly\":\"178768\"},\n{\"date\":\"6/25/18\",\"CI_weekly_2_5\":\"176382\",\"CI_weekly_97_5\":\"191146\",\"y_prediction_weekly\":\"183522\",\"y_true_weekly\":\"178028\"},\n{\"date\":\"6/26/18\",\"CI_weekly_2_5\":\"178866\",\"CI_weekly_97_5\":\"194622\",\"y_prediction_weekly\":\"186359\",\"y_true_weekly\":\"178715\"},\n{\"date\":\"6/27/18\",\"CI_weekly_2_5\":\"182934\",\"CI_weekly_97_5\":\"200171\",\"y_prediction_weekly\":\"191150\",\"y_true_weekly\":\"180402\"},\n{\"date\":\"6/28/18\",\"CI_weekly_2_5\":\"183058\",\"CI_weekly_97_5\":\"201344\",\"y_prediction_weekly\":\"191801\",\"y_true_weekly\":\"177553\"},\n{\"date\":\"6/29/18\",\"CI_weekly_2_5\":\"183324\",\"CI_weekly_97_5\":\"202790\",\"y_prediction_weekly\":\"192636\",\"y_true_weekly\":\"179241\"},\n{\"date\":\"6/30/18\",\"CI_weekly_2_5\":\"182719\",\"CI_weekly_97_5\":\"203186\",\"y_prediction_weekly\":\"192592\",\"y_true_weekly\":\"180405\"},\n{\"date\":\"7/1/18\",\"CI_weekly_2_5\":\"178119\",\"CI_weekly_97_5\":\"199511\",\"y_prediction_weekly\":\"188461\",\"y_true_weekly\":\"177410\"},\n{\"date\":\"7/2/18\",\"CI_weekly_2_5\":\"175589\",\"CI_weekly_97_5\":\"197246\",\"y_prediction_weekly\":\"186076\",\"y_true_weekly\":\"176998\"},\n{\"date\":\"7/3/18\",\"CI_weekly_2_5\":\"173509\",\"CI_weekly_97_5\":\"194580\",\"y_prediction_weekly\":\"183666\",\"y_true_weekly\":\"177097\"},\n{\"date\":\"7/4/18\",\"CI_weekly_2_5\":\"174580\",\"CI_weekly_97_5\":\"195928\",\"y_prediction_weekly\":\"184766\",\"y_true_weekly\":\"178769\"},\n{\"date\":\"7/5/18\",\"CI_weekly_2_5\":\"178684\",\"CI_weekly_97_5\":\"200264\",\"y_prediction_weekly\":\"188981\",\"y_true_weekly\":\"184708\"},\n{\"date\":\"7/6/18\",\"CI_weekly_2_5\":\"185092\",\"CI_weekly_97_5\":\"207217\",\"y_prediction_weekly\":\"195498\",\"y_true_weekly\":\"186644\"},\n{\"date\":\"7/7/18\",\"CI_weekly_2_5\":\"190282\",\"CI_weekly_97_5\":\"213221\",\"y_prediction_weekly\":\"201020\",\"y_true_weekly\":\"192753\"},\n{\"date\":\"7/8/18\",\"CI_weekly_2_5\":\"193878\",\"CI_weekly_97_5\":\"217464\",\"y_prediction_weekly\":\"204935\",\"y_true_weekly\":\"199484\"},\n{\"date\":\"7/9/18\",\"CI_weekly_2_5\":\"200079\",\"CI_weekly_97_5\":\"224462\",\"y_prediction_weekly\":\"211240\",\"y_true_weekly\":\"209081\"},\n{\"date\":\"7/10/18\",\"CI_weekly_2_5\":\"215834\",\"CI_weekly_97_5\":\"244055\",\"y_prediction_weekly\":\"228748\",\"y_true_weekly\":\"253906\"},\n{\"date\":\"7/11/18\",\"CI_weekly_2_5\":\"218626\",\"CI_weekly_97_5\":\"247925\",\"y_prediction_weekly\":\"232040\",\"y_true_weekly\":\"280849\"},\n{\"date\":\"7/12/18\",\"CI_weekly_2_5\":\"222584\",\"CI_weekly_97_5\":\"252724\",\"y_prediction_weekly\":\"236217\",\"y_true_weekly\":\"289440\"},\n{\"date\":\"7/13/18\",\"CI_weekly_2_5\":\"220893\",\"CI_weekly_97_5\":\"251282\",\"y_prediction_weekly\":\"234673\",\"y_true_weekly\":\"291732\"},\n{\"date\":\"7/14/18\",\"CI_weekly_2_5\":\"218910\",\"CI_weekly_97_5\":\"248635\",\"y_prediction_weekly\":\"232350\",\"y_true_weekly\":\"288650\"},\n{\"date\":\"7/15/18\",\"CI_weekly_2_5\":\"215504\",\"CI_weekly_97_5\":\"244598\",\"y_prediction_weekly\":\"228695\",\"y_true_weekly\":\"283164\"},\n{\"date\":\"7/16/18\",\"CI_weekly_2_5\":\"215366\",\"CI_weekly_97_5\":\"244493\",\"y_prediction_weekly\":\"228824\",\"y_true_weekly\":\"283907\"},\n{\"date\":\"7/17/18\",\"CI_weekly_2_5\":\"204631\",\"CI_weekly_97_5\":\"231862\",\"y_prediction_weekly\":\"217300\",\"y_true_weekly\":\"243439\"},\n{\"date\":\"7/18/18\",\"CI_weekly_2_5\":\"200955\",\"CI_weekly_97_5\":\"227086\",\"y_prediction_weekly\":\"213235\",\"y_true_weekly\":\"217788\"},\n{\"date\":\"7/19/18\",\"CI_weekly_2_5\":\"196381\",\"CI_weekly_97_5\":\"221448\",\"y_prediction_weekly\":\"208331\",\"y_true_weekly\":\"209253\"},\n{\"date\":\"7/20/18\",\"CI_weekly_2_5\":\"195419\",\"CI_weekly_97_5\":\"219808\",\"y_prediction_weekly\":\"207104\",\"y_true_weekly\":\"205258\"},\n{\"date\":\"7/21/18\",\"CI_weekly_2_5\":\"196952\",\"CI_weekly_97_5\":\"221403\",\"y_prediction_weekly\":\"208830\",\"y_true_weekly\":\"204443\"},\n{\"date\":\"7/22/18\",\"CI_weekly_2_5\":\"203226\",\"CI_weekly_97_5\":\"228575\",\"y_prediction_weekly\":\"215538\",\"y_true_weekly\":\"206495\"},\n{\"date\":\"7/23/18\",\"CI_weekly_2_5\":\"200589\",\"CI_weekly_97_5\":\"224875\",\"y_prediction_weekly\":\"212484\",\"y_true_weekly\":\"198015\"},\n{\"date\":\"7/24/18\",\"CI_weekly_2_5\":\"198252\",\"CI_weekly_97_5\":\"220975\",\"y_prediction_weekly\":\"209449\",\"y_true_weekly\":\"195428\"},\n{\"date\":\"7/25/18\",\"CI_weekly_2_5\":\"200786\",\"CI_weekly_97_5\":\"223854\",\"y_prediction_weekly\":\"212014\",\"y_true_weekly\":\"196531\"},\n{\"date\":\"7/26/18\",\"CI_weekly_2_5\":\"203879\",\"CI_weekly_97_5\":\"225933\",\"y_prediction_weekly\":\"214625\",\"y_true_weekly\":\"198071\"},\n{\"date\":\"7/27/18\",\"CI_weekly_2_5\":\"204367\",\"CI_weekly_97_5\":\"225122\",\"y_prediction_weekly\":\"214533\",\"y_true_weekly\":\"200997\"},\n{\"date\":\"7/28/18\",\"CI_weekly_2_5\":\"200116\",\"CI_weekly_97_5\":\"219452\",\"y_prediction_weekly\":\"209486\",\"y_true_weekly\":\"200207\"},\n{\"date\":\"7/29/18\",\"CI_weekly_2_5\":\"194012\",\"CI_weekly_97_5\":\"211617\",\"y_prediction_weekly\":\"202509\",\"y_true_weekly\":\"200096\"},\n{\"date\":\"7/30/18\",\"CI_weekly_2_5\":\"188217\",\"CI_weekly_97_5\":\"205455\",\"y_prediction_weekly\":\"196537\",\"y_true_weekly\":\"199216\"},\n{\"date\":\"7/31/18\",\"CI_weekly_2_5\":\"182989\",\"CI_weekly_97_5\":\"198588\",\"y_prediction_weekly\":\"190590\",\"y_true_weekly\":\"197485\"},\n{\"date\":\"8/1/18\",\"CI_weekly_2_5\":\"177117\",\"CI_weekly_97_5\":\"191416\",\"y_prediction_weekly\":\"184214\",\"y_true_weekly\":\"195238\"},\n{\"date\":\"8/2/18\",\"CI_weekly_2_5\":\"171449\",\"CI_weekly_97_5\":\"185965\",\"y_prediction_weekly\":\"178693\",\"y_true_weekly\":\"193475\"},\n{\"date\":\"8/3/18\",\"CI_weekly_2_5\":\"169756\",\"CI_weekly_97_5\":\"185351\",\"y_prediction_weekly\":\"177482\",\"y_true_weekly\":\"194156\"},\n{\"date\":\"8/4/18\",\"CI_weekly_2_5\":\"166811\",\"CI_weekly_97_5\":\"182616\",\"y_prediction_weekly\":\"174734\",\"y_true_weekly\":\"193173\"},\n{\"date\":\"8/5/18\",\"CI_weekly_2_5\":\"169594\",\"CI_weekly_97_5\":\"185297\",\"y_prediction_weekly\":\"177495\",\"y_true_weekly\":\"194430\"},\n{\"date\":\"8/6/18\",\"CI_weekly_2_5\":\"177294\",\"CI_weekly_97_5\":\"193615\",\"y_prediction_weekly\":\"185526\",\"y_true_weekly\":\"200188\"},\n{\"date\":\"8/7/18\",\"CI_weekly_2_5\":\"183541\",\"CI_weekly_97_5\":\"200971\",\"y_prediction_weekly\":\"192323\",\"y_true_weekly\":\"201845\"},\n{\"date\":\"8/8/18\",\"CI_weekly_2_5\":\"189038\",\"CI_weekly_97_5\":\"207036\",\"y_prediction_weekly\":\"198105\",\"y_true_weekly\":\"203480\"},\n{\"date\":\"8/9/18\",\"CI_weekly_2_5\":\"192419\",\"CI_weekly_97_5\":\"211063\",\"y_prediction_weekly\":\"201728\",\"y_true_weekly\":\"204120\"},\n{\"date\":\"8/10/18\",\"CI_weekly_2_5\":\"196575\",\"CI_weekly_97_5\":\"215894\",\"y_prediction_weekly\":\"206374\",\"y_true_weekly\":\"205790\"},\n{\"date\":\"8/11/18\",\"CI_weekly_2_5\":\"204750\",\"CI_weekly_97_5\":\"226726\",\"y_prediction_weekly\":\"215927\",\"y_true_weekly\":\"206864\"},\n{\"date\":\"8/12/18\",\"CI_weekly_2_5\":\"206206\",\"CI_weekly_97_5\":\"229577\",\"y_prediction_weekly\":\"218037\",\"y_true_weekly\":\"205756\"},\n{\"date\":\"8/13/18\",\"CI_weekly_2_5\":\"201680\",\"CI_weekly_97_5\":\"224431\",\"y_prediction_weekly\":\"213185\",\"y_true_weekly\":\"201938\"},\n{\"date\":\"8/14/18\",\"CI_weekly_2_5\":\"196412\",\"CI_weekly_97_5\":\"218121\",\"y_prediction_weekly\":\"207370\",\"y_true_weekly\":\"200775\"},\n{\"date\":\"8/15/18\",\"CI_weekly_2_5\":\"192812\",\"CI_weekly_97_5\":\"213795\",\"y_prediction_weekly\":\"203441\",\"y_true_weekly\":\"199946\"},\n{\"date\":\"8/16/18\",\"CI_weekly_2_5\":\"188706\",\"CI_weekly_97_5\":\"209026\",\"y_prediction_weekly\":\"199062\",\"y_true_weekly\":\"198604\"},\n{\"date\":\"8/17/18\",\"CI_weekly_2_5\":\"186019\",\"CI_weekly_97_5\":\"205799\",\"y_prediction_weekly\":\"195918\",\"y_true_weekly\":\"195667\"},\n{\"date\":\"8/18/18\",\"CI_weekly_2_5\":\"181319\",\"CI_weekly_97_5\":\"198452\",\"y_prediction_weekly\":\"189722\",\"y_true_weekly\":\"197578\"},\n{\"date\":\"8/19/18\",\"CI_weekly_2_5\":\"177044\",\"CI_weekly_97_5\":\"192632\",\"y_prediction_weekly\":\"184684\",\"y_true_weekly\":\"197645\"},\n{\"date\":\"8/20/18\",\"CI_weekly_2_5\":\"182359\",\"CI_weekly_97_5\":\"198251\",\"y_prediction_weekly\":\"190096\",\"y_true_weekly\":\"201875\"},\n{\"date\":\"8/21/18\",\"CI_weekly_2_5\":\"184961\",\"CI_weekly_97_5\":\"201559\",\"y_prediction_weekly\":\"193125\",\"y_true_weekly\":\"202621\"},\n{\"date\":\"8/22/18\",\"CI_weekly_2_5\":\"188129\",\"CI_weekly_97_5\":\"204815\",\"y_prediction_weekly\":\"196223\",\"y_true_weekly\":\"203507\"},\n{\"date\":\"8/23/18\",\"CI_weekly_2_5\":\"192260\",\"CI_weekly_97_5\":\"209059\",\"y_prediction_weekly\":\"200479\",\"y_true_weekly\":\"202503\"},\n{\"date\":\"8/24/18\",\"CI_weekly_2_5\":\"194824\",\"CI_weekly_97_5\":\"211716\",\"y_prediction_weekly\":\"203110\",\"y_true_weekly\":\"200971\"},\n{\"date\":\"8/25/18\",\"CI_weekly_2_5\":\"199912\",\"CI_weekly_97_5\":\"219787\",\"y_prediction_weekly\":\"209881\",\"y_true_weekly\":\"197032\"},\n{\"date\":\"8/26/18\",\"CI_weekly_2_5\":\"205178\",\"CI_weekly_97_5\":\"227232\",\"y_prediction_weekly\":\"216195\",\"y_true_weekly\":\"195099\"},\n{\"date\":\"8/27/18\",\"CI_weekly_2_5\":\"203660\",\"CI_weekly_97_5\":\"227364\",\"y_prediction_weekly\":\"215525\",\"y_true_weekly\":\"189511\"},\n{\"date\":\"8/28/18\",\"CI_weekly_2_5\":\"208472\",\"CI_weekly_97_5\":\"234493\",\"y_prediction_weekly\":\"221431\",\"y_true_weekly\":\"189710\"},\n{\"date\":\"8/29/18\",\"CI_weekly_2_5\":\"206766\",\"CI_weekly_97_5\":\"232447\",\"y_prediction_weekly\":\"219594\",\"y_true_weekly\":\"186985\"},\n{\"date\":\"8/30/18\",\"CI_weekly_2_5\":\"205797\",\"CI_weekly_97_5\":\"231280\",\"y_prediction_weekly\":\"218393\",\"y_true_weekly\":\"187138\"},\n{\"date\":\"8/31/18\",\"CI_weekly_2_5\":\"200505\",\"CI_weekly_97_5\":\"224955\",\"y_prediction_weekly\":\"212663\",\"y_true_weekly\":\"184243\"},\n{\"date\":\"9/1/18\",\"CI_weekly_2_5\":\"196150\",\"CI_weekly_97_5\":\"217883\",\"y_prediction_weekly\":\"206720\",\"y_true_weekly\":\"184030\"},\n{\"date\":\"9/2/18\",\"CI_weekly_2_5\":\"192515\",\"CI_weekly_97_5\":\"212101\",\"y_prediction_weekly\":\"201983\",\"y_true_weekly\":\"186032\"},\n{\"date\":\"9/3/18\",\"CI_weekly_2_5\":\"190065\",\"CI_weekly_97_5\":\"207576\",\"y_prediction_weekly\":\"198413\",\"y_true_weekly\":\"188029\"},\n{\"date\":\"9/4/18\",\"CI_weekly_2_5\":\"184127\",\"CI_weekly_97_5\":\"199077\",\"y_prediction_weekly\":\"191010\",\"y_true_weekly\":\"185932\"},\n{\"date\":\"9/5/18\",\"CI_weekly_2_5\":\"184983\",\"CI_weekly_97_5\":\"200158\",\"y_prediction_weekly\":\"191911\",\"y_true_weekly\":\"187070\"},\n{\"date\":\"9/6/18\",\"CI_weekly_2_5\":\"185964\",\"CI_weekly_97_5\":\"201194\",\"y_prediction_weekly\":\"192951\",\"y_true_weekly\":\"188088\"},\n{\"date\":\"9/7/18\",\"CI_weekly_2_5\":\"186118\",\"CI_weekly_97_5\":\"201327\",\"y_prediction_weekly\":\"193100\",\"y_true_weekly\":\"189036\"},\n{\"date\":\"9/8/18\",\"CI_weekly_2_5\":\"185083\",\"CI_weekly_97_5\":\"199924\",\"y_prediction_weekly\":\"191920\",\"y_true_weekly\":\"189341\"},\n{\"date\":\"9/9/18\",\"CI_weekly_2_5\":\"183598\",\"CI_weekly_97_5\":\"198580\",\"y_prediction_weekly\":\"190598\",\"y_true_weekly\":\"186658\"},\n{\"date\":\"9/10/18\",\"CI_weekly_2_5\":\"180980\",\"CI_weekly_97_5\":\"195879\",\"y_prediction_weekly\":\"188003\",\"y_true_weekly\":\"183519\"},\n{\"date\":\"9/11/18\",\"CI_weekly_2_5\":\"178347\",\"CI_weekly_97_5\":\"193095\",\"y_prediction_weekly\":\"185486\",\"y_true_weekly\":\"181592\"},\n{\"date\":\"9/12/18\",\"CI_weekly_2_5\":\"174836\",\"CI_weekly_97_5\":\"189830\",\"y_prediction_weekly\":\"182122\",\"y_true_weekly\":\"179968\"},\n{\"date\":\"9/13/18\",\"CI_weekly_2_5\":\"170705\",\"CI_weekly_97_5\":\"185868\",\"y_prediction_weekly\":\"178140\",\"y_true_weekly\":\"177966\"},\n{\"date\":\"9/14/18\",\"CI_weekly_2_5\":\"167060\",\"CI_weekly_97_5\":\"182216\",\"y_prediction_weekly\":\"174541\",\"y_true_weekly\":\"176669\"},\n{\"date\":\"9/15/18\",\"CI_weekly_2_5\":\"164788\",\"CI_weekly_97_5\":\"179924\",\"y_prediction_weekly\":\"172275\",\"y_true_weekly\":\"175822\"},\n{\"date\":\"9/16/18\",\"CI_weekly_2_5\":\"164252\",\"CI_weekly_97_5\":\"179279\",\"y_prediction_weekly\":\"171646\",\"y_true_weekly\":\"174451\"},\n{\"date\":\"9/17/18\",\"CI_weekly_2_5\":\"164812\",\"CI_weekly_97_5\":\"179588\",\"y_prediction_weekly\":\"172034\",\"y_true_weekly\":\"173595\"},\n{\"date\":\"9/18/18\",\"CI_weekly_2_5\":\"167644\",\"CI_weekly_97_5\":\"182662\",\"y_prediction_weekly\":\"174930\",\"y_true_weekly\":\"173019\"},\n{\"date\":\"9/19/18\",\"CI_weekly_2_5\":\"170771\",\"CI_weekly_97_5\":\"185721\",\"y_prediction_weekly\":\"177962\",\"y_true_weekly\":\"186338\"},\n{\"date\":\"9/20/18\",\"CI_weekly_2_5\":\"175154\",\"CI_weekly_97_5\":\"190240\",\"y_prediction_weekly\":\"182175\",\"y_true_weekly\":\"197238\"},\n{\"date\":\"9/21/18\",\"CI_weekly_2_5\":\"180014\",\"CI_weekly_97_5\":\"195460\",\"y_prediction_weekly\":\"186898\",\"y_true_weekly\":\"202914\"},\n{\"date\":\"9/22/18\",\"CI_weekly_2_5\":\"186780\",\"CI_weekly_97_5\":\"202971\",\"y_prediction_weekly\":\"193743\",\"y_true_weekly\":\"209247\"},\n{\"date\":\"9/23/18\",\"CI_weekly_2_5\":\"191579\",\"CI_weekly_97_5\":\"208818\",\"y_prediction_weekly\":\"198617\",\"y_true_weekly\":\"215966\"},\n{\"date\":\"9/24/18\",\"CI_weekly_2_5\":\"195188\",\"CI_weekly_97_5\":\"213314\",\"y_prediction_weekly\":\"202385\",\"y_true_weekly\":\"222824\"},\n{\"date\":\"9/25/18\",\"CI_weekly_2_5\":\"202035\",\"CI_weekly_97_5\":\"221138\",\"y_prediction_weekly\":\"209523\",\"y_true_weekly\":\"234421\"},\n{\"date\":\"9/26/18\",\"CI_weekly_2_5\":\"203521\",\"CI_weekly_97_5\":\"222069\",\"y_prediction_weekly\":\"210834\",\"y_true_weekly\":\"228384\"},\n{\"date\":\"9/27/18\",\"CI_weekly_2_5\":\"201123\",\"CI_weekly_97_5\":\"219455\",\"y_prediction_weekly\":\"208615\",\"y_true_weekly\":\"221742\"},\n{\"date\":\"9/28/18\",\"CI_weekly_2_5\":\"197870\",\"CI_weekly_97_5\":\"215660\",\"y_prediction_weekly\":\"205487\",\"y_true_weekly\":\"218547\"},\n{\"date\":\"9/29/18\",\"CI_weekly_2_5\":\"192933\",\"CI_weekly_97_5\":\"209602\",\"y_prediction_weekly\":\"200411\",\"y_true_weekly\":\"214715\"},\n{\"date\":\"9/30/18\",\"CI_weekly_2_5\":\"190146\",\"CI_weekly_97_5\":\"205263\",\"y_prediction_weekly\":\"197360\",\"y_true_weekly\":\"211318\"},\n{\"date\":\"10/1/18\",\"CI_weekly_2_5\":\"190232\",\"CI_weekly_97_5\":\"204547\",\"y_prediction_weekly\":\"197493\",\"y_true_weekly\":\"209782\"},\n{\"date\":\"10/2/18\",\"CI_weekly_2_5\":\"182508\",\"CI_weekly_97_5\":\"195030\",\"y_prediction_weekly\":\"189158\",\"y_true_weekly\":\"201835\"},\n{\"date\":\"10/3/18\",\"CI_weekly_2_5\":\"177868\",\"CI_weekly_97_5\":\"190674\",\"y_prediction_weekly\":\"184683\",\"y_true_weekly\":\"194819\"},\n{\"date\":\"10/4/18\",\"CI_weekly_2_5\":\"176265\",\"CI_weekly_97_5\":\"188910\",\"y_prediction_weekly\":\"182951\",\"y_true_weekly\":\"192161\"},\n{\"date\":\"10/5/18\",\"CI_weekly_2_5\":\"177275\",\"CI_weekly_97_5\":\"189540\",\"y_prediction_weekly\":\"183713\",\"y_true_weekly\":\"191419\"},\n{\"date\":\"10/6/18\",\"CI_weekly_2_5\":\"176310\",\"CI_weekly_97_5\":\"188536\",\"y_prediction_weekly\":\"182692\",\"y_true_weekly\":\"188586\"},\n{\"date\":\"10/7/18\",\"CI_weekly_2_5\":\"173071\",\"CI_weekly_97_5\":\"185607\",\"y_prediction_weekly\":\"179638\",\"y_true_weekly\":\"185600\"},\n{\"date\":\"10/8/18\",\"CI_weekly_2_5\":\"171408\",\"CI_weekly_97_5\":\"184071\",\"y_prediction_weekly\":\"178034\",\"y_true_weekly\":\"183648\"},\n{\"date\":\"10/9/18\",\"CI_weekly_2_5\":\"170996\",\"CI_weekly_97_5\":\"183605\",\"y_prediction_weekly\":\"177603\",\"y_true_weekly\":\"181904\"},\n{\"date\":\"10/10/18\",\"CI_weekly_2_5\":\"171782\",\"CI_weekly_97_5\":\"184023\",\"y_prediction_weekly\":\"178280\",\"y_true_weekly\":\"182539\"},\n{\"date\":\"10/11/18\",\"CI_weekly_2_5\":\"174583\",\"CI_weekly_97_5\":\"186946\",\"y_prediction_weekly\":\"181174\",\"y_true_weekly\":\"184456\"},\n{\"date\":\"10/12/18\",\"CI_weekly_2_5\":\"174751\",\"CI_weekly_97_5\":\"187153\",\"y_prediction_weekly\":\"181287\",\"y_true_weekly\":\"185293\"},\n{\"date\":\"10/13/18\",\"CI_weekly_2_5\":\"176337\",\"CI_weekly_97_5\":\"189001\",\"y_prediction_weekly\":\"182939\",\"y_true_weekly\":\"186409\"},\n{\"date\":\"10/14/18\",\"CI_weekly_2_5\":\"178445\",\"CI_weekly_97_5\":\"190885\",\"y_prediction_weekly\":\"184829\",\"y_true_weekly\":\"186681\"},\n{\"date\":\"10/15/18\",\"CI_weekly_2_5\":\"183106\",\"CI_weekly_97_5\":\"195892\",\"y_prediction_weekly\":\"189552\",\"y_true_weekly\":\"188990\"},\n{\"date\":\"10/16/18\",\"CI_weekly_2_5\":\"187299\",\"CI_weekly_97_5\":\"200996\",\"y_prediction_weekly\":\"194127\",\"y_true_weekly\":\"190126\"},\n{\"date\":\"10/17/18\",\"CI_weekly_2_5\":\"193067\",\"CI_weekly_97_5\":\"207063\",\"y_prediction_weekly\":\"200003\",\"y_true_weekly\":\"192835\"},\n{\"date\":\"10/18/18\",\"CI_weekly_2_5\":\"196578\",\"CI_weekly_97_5\":\"211722\",\"y_prediction_weekly\":\"204129\",\"y_true_weekly\":\"192023\"},\n{\"date\":\"10/19/18\",\"CI_weekly_2_5\":\"200283\",\"CI_weekly_97_5\":\"216993\",\"y_prediction_weekly\":\"208742\",\"y_true_weekly\":\"189624\"},\n{\"date\":\"10/20/18\",\"CI_weekly_2_5\":\"203469\",\"CI_weekly_97_5\":\"220969\",\"y_prediction_weekly\":\"212359\",\"y_true_weekly\":\"188064\"},\n{\"date\":\"10/21/18\",\"CI_weekly_2_5\":\"205943\",\"CI_weekly_97_5\":\"223884\",\"y_prediction_weekly\":\"215085\",\"y_true_weekly\":\"187975\"},\n{\"date\":\"10/22/18\",\"CI_weekly_2_5\":\"208020\",\"CI_weekly_97_5\":\"226072\",\"y_prediction_weekly\":\"217261\",\"y_true_weekly\":\"185230\"},\n{\"date\":\"10/23/18\",\"CI_weekly_2_5\":\"208207\",\"CI_weekly_97_5\":\"226689\",\"y_prediction_weekly\":\"217743\",\"y_true_weekly\":\"185587\"},\n{\"date\":\"10/24/18\",\"CI_weekly_2_5\":\"209060\",\"CI_weekly_97_5\":\"227504\",\"y_prediction_weekly\":\"218580\",\"y_true_weekly\":\"191253\"},\n{\"date\":\"10/25/18\",\"CI_weekly_2_5\":\"207876\",\"CI_weekly_97_5\":\"224774\",\"y_prediction_weekly\":\"216553\",\"y_true_weekly\":\"187926\"},\n{\"date\":\"10/26/18\",\"CI_weekly_2_5\":\"208904\",\"CI_weekly_97_5\":\"224982\",\"y_prediction_weekly\":\"217102\",\"y_true_weekly\":\"191832\"},\n{\"date\":\"10/27/18\",\"CI_weekly_2_5\":\"208754\",\"CI_weekly_97_5\":\"224585\",\"y_prediction_weekly\":\"216789\",\"y_true_weekly\":\"201922\"},\n{\"date\":\"10/28/18\",\"CI_weekly_2_5\":\"213974\",\"CI_weekly_97_5\":\"229976\",\"y_prediction_weekly\":\"221921\",\"y_true_weekly\":\"211914\"},\n{\"date\":\"10/29/18\",\"CI_weekly_2_5\":\"214859\",\"CI_weekly_97_5\":\"230637\",\"y_prediction_weekly\":\"222445\",\"y_true_weekly\":\"224116\"},\n{\"date\":\"10/30/18\",\"CI_weekly_2_5\":\"219165\",\"CI_weekly_97_5\":\"234459\",\"y_prediction_weekly\":\"226348\",\"y_true_weekly\":\"229298\"},\n{\"date\":\"10/31/18\",\"CI_weekly_2_5\":\"218311\",\"CI_weekly_97_5\":\"233541\",\"y_prediction_weekly\":\"225359\",\"y_true_weekly\":\"227725\"},\n{\"date\":\"11/1/18\",\"CI_weekly_2_5\":\"221972\",\"CI_weekly_97_5\":\"237770\",\"y_prediction_weekly\":\"229205\",\"y_true_weekly\":\"233835\"},\n{\"date\":\"11/2/18\",\"CI_weekly_2_5\":\"228593\",\"CI_weekly_97_5\":\"245752\",\"y_prediction_weekly\":\"236605\",\"y_true_weekly\":\"239085\"},\n{\"date\":\"11/3/18\",\"CI_weekly_2_5\":\"233904\",\"CI_weekly_97_5\":\"251745\",\"y_prediction_weekly\":\"242309\",\"y_true_weekly\":\"236320\"},\n{\"date\":\"11/4/18\",\"CI_weekly_2_5\":\"237252\",\"CI_weekly_97_5\":\"255380\",\"y_prediction_weekly\":\"245883\",\"y_true_weekly\":\"239708\"},\n{\"date\":\"11/5/18\",\"CI_weekly_2_5\":\"242570\",\"CI_weekly_97_5\":\"261967\",\"y_prediction_weekly\":\"252127\",\"y_true_weekly\":\"237900\"},\n{\"date\":\"11/6/18\",\"CI_weekly_2_5\":\"249391\",\"CI_weekly_97_5\":\"269036\",\"y_prediction_weekly\":\"259238\",\"y_true_weekly\":\"242559\"},\n{\"date\":\"11/7/18\",\"CI_weekly_2_5\":\"255301\",\"CI_weekly_97_5\":\"274936\",\"y_prediction_weekly\":\"265168\",\"y_true_weekly\":\"245460\"},\n{\"date\":\"11/8/18\",\"CI_weekly_2_5\":\"260061\",\"CI_weekly_97_5\":\"280293\",\"y_prediction_weekly\":\"270223\",\"y_true_weekly\":\"254617\"},\n{\"date\":\"11/9/18\",\"CI_weekly_2_5\":\"262028\",\"CI_weekly_97_5\":\"282492\",\"y_prediction_weekly\":\"271997\",\"y_true_weekly\":\"261054\"},\n{\"date\":\"11/10/18\",\"CI_weekly_2_5\":\"266862\",\"CI_weekly_97_5\":\"287577\",\"y_prediction_weekly\":\"276906\",\"y_true_weekly\":\"268817\"},\n{\"date\":\"11/11/18\",\"CI_weekly_2_5\":\"278931\",\"CI_weekly_97_5\":\"301707\",\"y_prediction_weekly\":\"289983\",\"y_true_weekly\":\"281555\"},\n{\"date\":\"11/12/18\",\"CI_weekly_2_5\":\"287003\",\"CI_weekly_97_5\":\"314001\",\"y_prediction_weekly\":\"300150\",\"y_true_weekly\":\"292743\"},\n{\"date\":\"11/13/18\",\"CI_weekly_2_5\":\"296413\",\"CI_weekly_97_5\":\"329446\",\"y_prediction_weekly\":\"312543\",\"y_true_weekly\":\"306213\"},\n{\"date\":\"11/14/18\",\"CI_weekly_2_5\":\"311609\",\"CI_weekly_97_5\":\"353227\",\"y_prediction_weekly\":\"331993\",\"y_true_weekly\":\"319531\"},\n{\"date\":\"11/15/18\",\"CI_weekly_2_5\":\"321916\",\"CI_weekly_97_5\":\"367643\",\"y_prediction_weekly\":\"344531\",\"y_true_weekly\":\"327607\"},\n{\"date\":\"11/16/18\",\"CI_weekly_2_5\":\"344844\",\"CI_weekly_97_5\":\"402206\",\"y_prediction_weekly\":\"373923\",\"y_true_weekly\":\"346887\"},\n{\"date\":\"11/17/18\",\"CI_weekly_2_5\":\"369867\",\"CI_weekly_97_5\":\"437533\",\"y_prediction_weekly\":\"404714\",\"y_true_weekly\":\"396129\"},\n{\"date\":\"11/18/18\",\"CI_weekly_2_5\":\"378268\",\"CI_weekly_97_5\":\"448299\",\"y_prediction_weekly\":\"414679\",\"y_true_weekly\":\"409571\"},\n{\"date\":\"11/19/18\",\"CI_weekly_2_5\":\"394687\",\"CI_weekly_97_5\":\"465504\",\"y_prediction_weekly\":\"431908\",\"y_true_weekly\":\"437515\"},\n{\"date\":\"11/20/18\",\"CI_weekly_2_5\":\"417690\",\"CI_weekly_97_5\":\"498386\",\"y_prediction_weekly\":\"460953\",\"y_true_weekly\":\"494030\"},\n{\"date\":\"11/21/18\",\"CI_weekly_2_5\":\"409661\",\"CI_weekly_97_5\":\"483320\",\"y_prediction_weekly\":\"449391\",\"y_true_weekly\":\"490066\"},\n{\"date\":\"11/22/18\",\"CI_weekly_2_5\":\"402954\",\"CI_weekly_97_5\":\"473399\",\"y_prediction_weekly\":\"440874\",\"y_true_weekly\":\"481126\"},\n{\"date\":\"11/23/18\",\"CI_weekly_2_5\":\"379931\",\"CI_weekly_97_5\":\"438733\",\"y_prediction_weekly\":\"411512\",\"y_true_weekly\":\"457904\"},\n{\"date\":\"11/24/18\",\"CI_weekly_2_5\":\"352252\",\"CI_weekly_97_5\":\"400570\",\"y_prediction_weekly\":\"377928\",\"y_true_weekly\":\"406838\"},\n{\"date\":\"11/25/18\",\"CI_weekly_2_5\":\"334554\",\"CI_weekly_97_5\":\"380203\",\"y_prediction_weekly\":\"358810\",\"y_true_weekly\":\"381406\"},\n{\"date\":\"11/26/18\",\"CI_weekly_2_5\":\"306424\",\"CI_weekly_97_5\":\"347320\",\"y_prediction_weekly\":\"328017\",\"y_true_weekly\":\"343727\"},\n{\"date\":\"11/27/18\",\"CI_weekly_2_5\":\"267986\",\"CI_weekly_97_5\":\"293910\",\"y_prediction_weekly\":\"281051\",\"y_true_weekly\":\"275167\"},\n{\"date\":\"11/28/18\",\"CI_weekly_2_5\":\"259466\",\"CI_weekly_97_5\":\"285423\",\"y_prediction_weekly\":\"272882\",\"y_true_weekly\":\"274061\"},\n{\"date\":\"11/29/18\",\"CI_weekly_2_5\":\"254056\",\"CI_weekly_97_5\":\"279669\",\"y_prediction_weekly\":\"267397\",\"y_true_weekly\":\"276860\"},\n{\"date\":\"11/30/18\",\"CI_weekly_2_5\":\"247850\",\"CI_weekly_97_5\":\"273010\",\"y_prediction_weekly\":\"261020\",\"y_true_weekly\":\"277870\"},\n{\"date\":\"12/1/18\",\"CI_weekly_2_5\":\"243572\",\"CI_weekly_97_5\":\"268554\",\"y_prediction_weekly\":\"256802\",\"y_true_weekly\":\"276998\"},\n{\"date\":\"12/2/18\",\"CI_weekly_2_5\":\"238967\",\"CI_weekly_97_5\":\"262932\",\"y_prediction_weekly\":\"251624\",\"y_true_weekly\":\"277353\"},\n{\"date\":\"12/3/18\",\"CI_weekly_2_5\":\"236636\",\"CI_weekly_97_5\":\"259822\",\"y_prediction_weekly\":\"248792\",\"y_true_weekly\":\"279629\"},\n{\"date\":\"12/4/18\",\"CI_weekly_2_5\":\"236477\",\"CI_weekly_97_5\":\"259018\",\"y_prediction_weekly\":\"248186\",\"y_true_weekly\":\"281555\"},\n{\"date\":\"12/5/18\",\"CI_weekly_2_5\":\"235818\",\"CI_weekly_97_5\":\"257456\",\"y_prediction_weekly\":\"247024\",\"y_true_weekly\":\"276304\"},\n{\"date\":\"12/6/18\",\"CI_weekly_2_5\":\"232542\",\"CI_weekly_97_5\":\"253288\",\"y_prediction_weekly\":\"243395\",\"y_true_weekly\":\"269940\"},\n{\"date\":\"12/7/18\",\"CI_weekly_2_5\":\"229580\",\"CI_weekly_97_5\":\"249496\",\"y_prediction_weekly\":\"240071\",\"y_true_weekly\":\"264521\"},\n{\"date\":\"12/8/18\",\"CI_weekly_2_5\":\"228887\",\"CI_weekly_97_5\":\"248427\",\"y_prediction_weekly\":\"239173\",\"y_true_weekly\":\"261792\"},\n{\"date\":\"12/9/18\",\"CI_weekly_2_5\":\"224821\",\"CI_weekly_97_5\":\"243951\",\"y_prediction_weekly\":\"234819\",\"y_true_weekly\":\"255979\"},\n{\"date\":\"12/10/18\",\"CI_weekly_2_5\":\"219644\",\"CI_weekly_97_5\":\"238597\",\"y_prediction_weekly\":\"229599\",\"y_true_weekly\":\"247406\"},\n{\"date\":\"12/11/18\",\"CI_weekly_2_5\":\"213093\",\"CI_weekly_97_5\":\"232475\",\"y_prediction_weekly\":\"223258\",\"y_true_weekly\":\"238018\"},\n{\"date\":\"12/12/18\",\"CI_weekly_2_5\":\"206290\",\"CI_weekly_97_5\":\"225841\",\"y_prediction_weekly\":\"216451\",\"y_true_weekly\":\"228760\"},\n{\"date\":\"12/13/18\",\"CI_weekly_2_5\":\"200423\",\"CI_weekly_97_5\":\"220197\",\"y_prediction_weekly\":\"210643\",\"y_true_weekly\":\"222102\"},\n{\"date\":\"12/14/18\",\"CI_weekly_2_5\":\"195462\",\"CI_weekly_97_5\":\"215472\",\"y_prediction_weekly\":\"205685\",\"y_true_weekly\":\"215369\"},\n{\"date\":\"12/15/18\",\"CI_weekly_2_5\":\"187975\",\"CI_weekly_97_5\":\"208185\",\"y_prediction_weekly\":\"198217\",\"y_true_weekly\":\"204762\"},\n{\"date\":\"12/16/18\",\"CI_weekly_2_5\":\"182468\",\"CI_weekly_97_5\":\"202802\",\"y_prediction_weekly\":\"192663\",\"y_true_weekly\":\"193262\"},\n{\"date\":\"12/17/18\",\"CI_weekly_2_5\":\"176393\",\"CI_weekly_97_5\":\"196631\",\"y_prediction_weekly\":\"186382\",\"y_true_weekly\":\"178491\"},\n{\"date\":\"12/18/18\",\"CI_weekly_2_5\":\"168708\",\"CI_weekly_97_5\":\"188809\",\"y_prediction_weekly\":\"178513\",\"y_true_weekly\":\"161418\"},\n{\"date\":\"12/19/18\",\"CI_weekly_2_5\":\"163303\",\"CI_weekly_97_5\":\"183752\",\"y_prediction_weekly\":\"173063\",\"y_true_weekly\":\"152828\"},\n{\"date\":\"12/20/18\",\"CI_weekly_2_5\":\"164736\",\"CI_weekly_97_5\":\"185981\",\"y_prediction_weekly\":\"174611\",\"y_true_weekly\":\"154570\"},\n{\"date\":\"12/21/18\",\"CI_weekly_2_5\":\"167564\",\"CI_weekly_97_5\":\"189574\",\"y_prediction_weekly\":\"177634\",\"y_true_weekly\":\"159455\"},\n{\"date\":\"12/22/18\",\"CI_weekly_2_5\":\"173192\",\"CI_weekly_97_5\":\"195989\",\"y_prediction_weekly\":\"183475\",\"y_true_weekly\":\"168629\"},\n{\"date\":\"12/23/18\",\"CI_weekly_2_5\":\"177925\",\"CI_weekly_97_5\":\"201391\",\"y_prediction_weekly\":\"188399\",\"y_true_weekly\":\"177619\"},\n{\"date\":\"12/24/18\",\"CI_weekly_2_5\":\"184592\",\"CI_weekly_97_5\":\"209231\",\"y_prediction_weekly\":\"195293\",\"y_true_weekly\":\"189162\"},\n{\"date\":\"12/25/18\",\"CI_weekly_2_5\":\"197542\",\"CI_weekly_97_5\":\"224129\",\"y_prediction_weekly\":\"208903\",\"y_true_weekly\":\"205732\"},\n{\"date\":\"12/26/18\",\"CI_weekly_2_5\":\"211500\",\"CI_weekly_97_5\":\"241790\",\"y_prediction_weekly\":\"224338\",\"y_true_weekly\":\"220328\"},\n{\"date\":\"12/27/18\",\"CI_weekly_2_5\":\"225515\",\"CI_weekly_97_5\":\"261500\",\"y_prediction_weekly\":\"240685\",\"y_true_weekly\":\"233340\"},\n{\"date\":\"12/28/18\",\"CI_weekly_2_5\":\"233833\",\"CI_weekly_97_5\":\"272061\",\"y_prediction_weekly\":\"249814\",\"y_true_weekly\":\"238304\"},\n{\"date\":\"12/29/18\",\"CI_weekly_2_5\":\"239208\",\"CI_weekly_97_5\":\"279951\",\"y_prediction_weekly\":\"256007\",\"y_true_weekly\":\"280886\"},\n{\"date\":\"12/30/18\",\"CI_weekly_2_5\":\"244797\",\"CI_weekly_97_5\":\"286865\",\"y_prediction_weekly\":\"262036\",\"y_true_weekly\":\"283856\"},\n{\"date\":\"12/31/18\",\"CI_weekly_2_5\":\"250783\",\"CI_weekly_97_5\":\"294061\",\"y_prediction_weekly\":\"268544\",\"y_true_weekly\":\"285688\"},\n{\"date\":\"1/1/19\",\"CI_weekly_2_5\":\"251955\",\"CI_weekly_97_5\":\"294762\",\"y_prediction_weekly\":\"269575\",\"y_true_weekly\":\"285202\"},\n{\"date\":\"1/2/19\",\"CI_weekly_2_5\":\"248391\",\"CI_weekly_97_5\":\"287846\",\"y_prediction_weekly\":\"264506\",\"y_true_weekly\":\"279578\"},\n{\"date\":\"1/3/19\",\"CI_weekly_2_5\":\"240689\",\"CI_weekly_97_5\":\"274982\",\"y_prediction_weekly\":\"254465\",\"y_true_weekly\":\"268094\"},\n{\"date\":\"1/4/19\",\"CI_weekly_2_5\":\"237175\",\"CI_weekly_97_5\":\"269437\",\"y_prediction_weekly\":\"249956\",\"y_true_weekly\":\"263754\"},\n{\"date\":\"1/5/19\",\"CI_weekly_2_5\":\"236677\",\"CI_weekly_97_5\":\"267401\",\"y_prediction_weekly\":\"248662\",\"y_true_weekly\":\"226490\"},\n{\"date\":\"1/6/19\",\"CI_weekly_2_5\":\"234448\",\"CI_weekly_97_5\":\"263908\",\"y_prediction_weekly\":\"245781\",\"y_true_weekly\":\"226068\"},\n{\"date\":\"1/7/19\",\"CI_weekly_2_5\":\"232119\",\"CI_weekly_97_5\":\"260581\",\"y_prediction_weekly\":\"243099\",\"y_true_weekly\":\"228725\"},\n{\"date\":\"1/8/19\",\"CI_weekly_2_5\":\"232998\",\"CI_weekly_97_5\":\"260941\",\"y_prediction_weekly\":\"243695\",\"y_true_weekly\":\"230427\"},\n{\"date\":\"1/9/19\",\"CI_weekly_2_5\":\"235147\",\"CI_weekly_97_5\":\"263099\",\"y_prediction_weekly\":\"245771\",\"y_true_weekly\":\"232081\"},\n{\"date\":\"1/10/19\",\"CI_weekly_2_5\":\"234628\",\"CI_weekly_97_5\":\"262360\",\"y_prediction_weekly\":\"245188\",\"y_true_weekly\":\"231579\"},\n{\"date\":\"1/11/19\",\"CI_weekly_2_5\":\"235732\",\"CI_weekly_97_5\":\"263163\",\"y_prediction_weekly\":\"246154\",\"y_true_weekly\":\"232071\"},\n{\"date\":\"1/12/19\",\"CI_weekly_2_5\":\"238904\",\"CI_weekly_97_5\":\"265949\",\"y_prediction_weekly\":\"249334\",\"y_true_weekly\":\"228834\"},\n{\"date\":\"1/13/19\",\"CI_weekly_2_5\":\"238539\",\"CI_weekly_97_5\":\"265322\",\"y_prediction_weekly\":\"248881\",\"y_true_weekly\":\"231829\"},\n{\"date\":\"1/14/19\",\"CI_weekly_2_5\":\"239544\",\"CI_weekly_97_5\":\"265450\",\"y_prediction_weekly\":\"249498\",\"y_true_weekly\":\"233452\"},\n{\"date\":\"1/15/19\",\"CI_weekly_2_5\":\"240869\",\"CI_weekly_97_5\":\"266233\",\"y_prediction_weekly\":\"250626\",\"y_true_weekly\":\"239081\"},\n{\"date\":\"1/16/19\",\"CI_weekly_2_5\":\"238634\",\"CI_weekly_97_5\":\"263397\",\"y_prediction_weekly\":\"248231\",\"y_true_weekly\":\"240141\"},\n{\"date\":\"1/17/19\",\"CI_weekly_2_5\":\"233830\",\"CI_weekly_97_5\":\"257618\",\"y_prediction_weekly\":\"243133\",\"y_true_weekly\":\"238285\"},\n{\"date\":\"1/18/19\",\"CI_weekly_2_5\":\"229875\",\"CI_weekly_97_5\":\"253100\",\"y_prediction_weekly\":\"239057\",\"y_true_weekly\":\"236160\"},\n{\"date\":\"1/19/19\",\"CI_weekly_2_5\":\"224739\",\"CI_weekly_97_5\":\"246612\",\"y_prediction_weekly\":\"233327\",\"y_true_weekly\":\"241322\"},\n{\"date\":\"1/20/19\",\"CI_weekly_2_5\":\"226326\",\"CI_weekly_97_5\":\"248342\",\"y_prediction_weekly\":\"235105\",\"y_true_weekly\":\"238852\"},\n{\"date\":\"1/21/19\",\"CI_weekly_2_5\":\"228874\",\"CI_weekly_97_5\":\"251179\",\"y_prediction_weekly\":\"237838\",\"y_true_weekly\":\"242482\"},\n{\"date\":\"1/22/19\",\"CI_weekly_2_5\":\"223860\",\"CI_weekly_97_5\":\"245479\",\"y_prediction_weekly\":\"232568\",\"y_true_weekly\":\"236015\"},\n{\"date\":\"1/23/19\",\"CI_weekly_2_5\":\"222303\",\"CI_weekly_97_5\":\"243980\",\"y_prediction_weekly\":\"231073\",\"y_true_weekly\":\"234340\"},\n{\"date\":\"1/24/19\",\"CI_weekly_2_5\":\"226768\",\"CI_weekly_97_5\":\"249062\",\"y_prediction_weekly\":\"235710\",\"y_true_weekly\":\"242583\"},\n{\"date\":\"1/25/19\",\"CI_weekly_2_5\":\"236309\",\"CI_weekly_97_5\":\"260032\",\"y_prediction_weekly\":\"245703\",\"y_true_weekly\":\"255098\"},\n{\"date\":\"1/26/19\",\"CI_weekly_2_5\":\"235886\",\"CI_weekly_97_5\":\"259053\",\"y_prediction_weekly\":\"245288\",\"y_true_weekly\":\"249861\"},\n{\"date\":\"1/27/19\",\"CI_weekly_2_5\":\"233916\",\"CI_weekly_97_5\":\"256066\",\"y_prediction_weekly\":\"242959\",\"y_true_weekly\":\"255552\"},\n{\"date\":\"1/28/19\",\"CI_weekly_2_5\":\"229541\",\"CI_weekly_97_5\":\"250785\",\"y_prediction_weekly\":\"238185\",\"y_true_weekly\":\"250046\"},\n{\"date\":\"1/29/19\",\"CI_weekly_2_5\":\"229321\",\"CI_weekly_97_5\":\"250036\",\"y_prediction_weekly\":\"237816\",\"y_true_weekly\":\"251098\"},\n{\"date\":\"1/30/19\",\"CI_weekly_2_5\":\"231701\",\"CI_weekly_97_5\":\"252041\",\"y_prediction_weekly\":\"240171\",\"y_true_weekly\":\"255071\"},\n{\"date\":\"1/31/19\",\"CI_weekly_2_5\":\"228697\",\"CI_weekly_97_5\":\"248180\",\"y_prediction_weekly\":\"237224\",\"y_true_weekly\":\"250630\"},\n{\"date\":\"2/1/19\",\"CI_weekly_2_5\":\"219622\",\"CI_weekly_97_5\":\"236574\",\"y_prediction_weekly\":\"227537\",\"y_true_weekly\":\"241243\"},\n{\"date\":\"2/2/19\",\"CI_weekly_2_5\":\"218011\",\"CI_weekly_97_5\":\"234649\",\"y_prediction_weekly\":\"225841\",\"y_true_weekly\":\"238224\"},\n{\"date\":\"2/3/19\",\"CI_weekly_2_5\":\"217045\",\"CI_weekly_97_5\":\"233024\",\"y_prediction_weekly\":\"224726\",\"y_true_weekly\":\"231892\"},\n{\"date\":\"2/4/19\",\"CI_weekly_2_5\":\"216186\",\"CI_weekly_97_5\":\"231572\",\"y_prediction_weekly\":\"223819\",\"y_true_weekly\":\"231446\"},\n{\"date\":\"2/5/19\",\"CI_weekly_2_5\":\"215119\",\"CI_weekly_97_5\":\"229807\",\"y_prediction_weekly\":\"222477\",\"y_true_weekly\":\"229890\"},\n{\"date\":\"2/6/19\",\"CI_weekly_2_5\":\"212259\",\"CI_weekly_97_5\":\"226187\",\"y_prediction_weekly\":\"219388\",\"y_true_weekly\":\"225768\"},\n{\"date\":\"2/7/19\",\"CI_weekly_2_5\":\"210435\",\"CI_weekly_97_5\":\"223700\",\"y_prediction_weekly\":\"217155\",\"y_true_weekly\":\"220699\"},\n{\"date\":\"2/8/19\",\"CI_weekly_2_5\":\"208053\",\"CI_weekly_97_5\":\"221644\",\"y_prediction_weekly\":\"214883\",\"y_true_weekly\":\"214992\"},\n{\"date\":\"2/9/19\",\"CI_weekly_2_5\":\"205769\",\"CI_weekly_97_5\":\"220175\",\"y_prediction_weekly\":\"213013\",\"y_true_weekly\":\"214043\"},\n{\"date\":\"2/10/19\",\"CI_weekly_2_5\":\"205451\",\"CI_weekly_97_5\":\"219918\",\"y_prediction_weekly\":\"212683\",\"y_true_weekly\":\"212733\"},\n{\"date\":\"2/11/19\",\"CI_weekly_2_5\":\"206055\",\"CI_weekly_97_5\":\"220160\",\"y_prediction_weekly\":\"213100\",\"y_true_weekly\":\"213726\"},\n{\"date\":\"2/12/19\",\"CI_weekly_2_5\":\"211603\",\"CI_weekly_97_5\":\"226842\",\"y_prediction_weekly\":\"219242\",\"y_true_weekly\":\"218264\"},\n{\"date\":\"2/13/19\",\"CI_weekly_2_5\":\"213435\",\"CI_weekly_97_5\":\"228338\",\"y_prediction_weekly\":\"220845\",\"y_true_weekly\":\"216890\"},\n{\"date\":\"2/14/19\",\"CI_weekly_2_5\":\"217476\",\"CI_weekly_97_5\":\"232741\",\"y_prediction_weekly\":\"225064\",\"y_true_weekly\":\"221580\"},\n{\"date\":\"2/15/19\",\"CI_weekly_2_5\":\"223166\",\"CI_weekly_97_5\":\"238704\",\"y_prediction_weekly\":\"230814\",\"y_true_weekly\":\"226057\"},\n{\"date\":\"2/16/19\",\"CI_weekly_2_5\":\"225873\",\"CI_weekly_97_5\":\"240759\",\"y_prediction_weekly\":\"233148\",\"y_true_weekly\":\"226328\"},\n{\"date\":\"2/17/19\",\"CI_weekly_2_5\":\"226155\",\"CI_weekly_97_5\":\"240703\",\"y_prediction_weekly\":\"233278\",\"y_true_weekly\":\"226074\"},\n{\"date\":\"2/18/19\",\"CI_weekly_2_5\":\"225708\",\"CI_weekly_97_5\":\"240208\",\"y_prediction_weekly\":\"232735\",\"y_true_weekly\":\"223328\"},\n{\"date\":\"2/19/19\",\"CI_weekly_2_5\":\"218805\",\"CI_weekly_97_5\":\"231912\",\"y_prediction_weekly\":\"225236\",\"y_true_weekly\":\"216185\"},\n{\"date\":\"2/20/19\",\"CI_weekly_2_5\":\"220883\",\"CI_weekly_97_5\":\"234085\",\"y_prediction_weekly\":\"227353\",\"y_true_weekly\":\"216706\"},\n{\"date\":\"2/21/19\",\"CI_weekly_2_5\":\"220160\",\"CI_weekly_97_5\":\"232532\",\"y_prediction_weekly\":\"226220\",\"y_true_weekly\":\"213940\"},\n{\"date\":\"2/22/19\",\"CI_weekly_2_5\":\"221873\",\"CI_weekly_97_5\":\"234182\",\"y_prediction_weekly\":\"227875\",\"y_true_weekly\":\"216890\"},\n{\"date\":\"2/23/19\",\"CI_weekly_2_5\":\"229123\",\"CI_weekly_97_5\":\"242732\",\"y_prediction_weekly\":\"235886\",\"y_true_weekly\":\"216812\"},\n{\"date\":\"2/24/19\",\"CI_weekly_2_5\":\"235586\",\"CI_weekly_97_5\":\"249970\",\"y_prediction_weekly\":\"242615\",\"y_true_weekly\":\"219525\"},\n{\"date\":\"2/25/19\",\"CI_weekly_2_5\":\"240873\",\"CI_weekly_97_5\":\"255900\",\"y_prediction_weekly\":\"248135\",\"y_true_weekly\":\"225060\"},\n{\"date\":\"2/26/19\",\"CI_weekly_2_5\":\"250048\",\"CI_weekly_97_5\":\"266334\",\"y_prediction_weekly\":\"257691\",\"y_true_weekly\":\"230389\"},\n{\"date\":\"2/27/19\",\"CI_weekly_2_5\":\"254333\",\"CI_weekly_97_5\":\"271724\",\"y_prediction_weekly\":\"262502\",\"y_true_weekly\":\"231855\"},\n{\"date\":\"2/28/19\",\"CI_weekly_2_5\":\"261106\",\"CI_weekly_97_5\":\"279965\",\"y_prediction_weekly\":\"269963\",\"y_true_weekly\":\"233665\"},\n{\"date\":\"3/1/19\",\"CI_weekly_2_5\":\"260243\",\"CI_weekly_97_5\":\"278600\",\"y_prediction_weekly\":\"269071\",\"y_true_weekly\":\"231015\"},\n{\"date\":\"3/2/19\",\"CI_weekly_2_5\":\"256216\",\"CI_weekly_97_5\":\"273362\",\"y_prediction_weekly\":\"264441\",\"y_true_weekly\":\"231406\"},\n{\"date\":\"3/3/19\",\"CI_weekly_2_5\":\"253668\",\"CI_weekly_97_5\":\"270262\",\"y_prediction_weekly\":\"261775\",\"y_true_weekly\":\"230387\"},\n{\"date\":\"3/4/19\",\"CI_weekly_2_5\":\"252317\",\"CI_weekly_97_5\":\"268714\",\"y_prediction_weekly\":\"260475\",\"y_true_weekly\":\"225772\"},\n{\"date\":\"3/5/19\",\"CI_weekly_2_5\":\"248990\",\"CI_weekly_97_5\":\"264814\",\"y_prediction_weekly\":\"257041\",\"y_true_weekly\":\"221888\"},\n{\"date\":\"3/6/19\",\"CI_weekly_2_5\":\"247514\",\"CI_weekly_97_5\":\"262934\",\"y_prediction_weekly\":\"255454\",\"y_true_weekly\":\"221504\"},\n{\"date\":\"3/7/19\",\"CI_weekly_2_5\":\"245967\",\"CI_weekly_97_5\":\"261017\",\"y_prediction_weekly\":\"253762\",\"y_true_weekly\":\"226987\"},\n{\"date\":\"3/8/19\",\"CI_weekly_2_5\":\"249475\",\"CI_weekly_97_5\":\"265656\",\"y_prediction_weekly\":\"257739\",\"y_true_weekly\":\"233576\"},\n{\"date\":\"3/9/19\",\"CI_weekly_2_5\":\"252560\",\"CI_weekly_97_5\":\"269423\",\"y_prediction_weekly\":\"261067\",\"y_true_weekly\":\"239704\"},\n{\"date\":\"3/10/19\",\"CI_weekly_2_5\":\"254849\",\"CI_weekly_97_5\":\"272215\",\"y_prediction_weekly\":\"263426\",\"y_true_weekly\":\"245586\"},\n{\"date\":\"3/11/19\",\"CI_weekly_2_5\":\"256135\",\"CI_weekly_97_5\":\"273697\",\"y_prediction_weekly\":\"264755\",\"y_true_weekly\":\"251064\"},\n{\"date\":\"3/12/19\",\"CI_weekly_2_5\":\"249300\",\"CI_weekly_97_5\":\"266816\",\"y_prediction_weekly\":\"257875\",\"y_true_weekly\":\"253051\"},\n{\"date\":\"3/13/19\",\"CI_weekly_2_5\":\"248113\",\"CI_weekly_97_5\":\"265440\",\"y_prediction_weekly\":\"256568\",\"y_true_weekly\":\"256255\"},\n{\"date\":\"3/14/19\",\"CI_weekly_2_5\":\"245386\",\"CI_weekly_97_5\":\"262036\",\"y_prediction_weekly\":\"253517\",\"y_true_weekly\":\"252870\"},\n{\"date\":\"3/15/19\",\"CI_weekly_2_5\":\"241184\",\"CI_weekly_97_5\":\"256743\",\"y_prediction_weekly\":\"248790\",\"y_true_weekly\":\"248129\"},\n{\"date\":\"3/16/19\",\"CI_weekly_2_5\":\"238131\",\"CI_weekly_97_5\":\"253262\",\"y_prediction_weekly\":\"245558\",\"y_true_weekly\":\"244001\"},\n{\"date\":\"3/17/19\",\"CI_weekly_2_5\":\"234306\",\"CI_weekly_97_5\":\"248974\",\"y_prediction_weekly\":\"241739\",\"y_true_weekly\":\"238785\"},\n{\"date\":\"3/18/19\",\"CI_weekly_2_5\":\"231070\",\"CI_weekly_97_5\":\"245216\",\"y_prediction_weekly\":\"238269\",\"y_true_weekly\":\"238357\"},\n{\"date\":\"3/19/19\",\"CI_weekly_2_5\":\"235937\",\"CI_weekly_97_5\":\"250045\",\"y_prediction_weekly\":\"243099\",\"y_true_weekly\":\"240291\"},\n{\"date\":\"3/20/19\",\"CI_weekly_2_5\":\"233158\",\"CI_weekly_97_5\":\"247068\",\"y_prediction_weekly\":\"240185\",\"y_true_weekly\":\"238255\"},\n{\"date\":\"3/21/19\",\"CI_weekly_2_5\":\"232781\",\"CI_weekly_97_5\":\"246442\",\"y_prediction_weekly\":\"239710\",\"y_true_weekly\":\"237339\"},\n{\"date\":\"3/22/19\",\"CI_weekly_2_5\":\"231446\",\"CI_weekly_97_5\":\"244990\",\"y_prediction_weekly\":\"238353\",\"y_true_weekly\":\"235657\"},\n{\"date\":\"3/23/19\",\"CI_weekly_2_5\":\"229311\",\"CI_weekly_97_5\":\"242400\",\"y_prediction_weekly\":\"235933\",\"y_true_weekly\":\"235615\"},\n{\"date\":\"3/24/19\",\"CI_weekly_2_5\":\"228584\",\"CI_weekly_97_5\":\"241490\",\"y_prediction_weekly\":\"234999\",\"y_true_weekly\":\"237344\"},\n{\"date\":\"3/25/19\",\"CI_weekly_2_5\":\"231654\",\"CI_weekly_97_5\":\"245412\",\"y_prediction_weekly\":\"238552\",\"y_true_weekly\":\"238453\"},\n{\"date\":\"3/26/19\",\"CI_weekly_2_5\":\"238544\",\"CI_weekly_97_5\":\"254019\",\"y_prediction_weekly\":\"246386\",\"y_true_weekly\":\"242516\"},\n{\"date\":\"3/27/19\",\"CI_weekly_2_5\":\"243634\",\"CI_weekly_97_5\":\"260121\",\"y_prediction_weekly\":\"252055\",\"y_true_weekly\":\"245970\"},\n{\"date\":\"3/28/19\",\"CI_weekly_2_5\":\"245804\",\"CI_weekly_97_5\":\"262944\",\"y_prediction_weekly\":\"254559\",\"y_true_weekly\":\"245998\"},\n{\"date\":\"3/29/19\",\"CI_weekly_2_5\":\"249651\",\"CI_weekly_97_5\":\"268028\",\"y_prediction_weekly\":\"258996\",\"y_true_weekly\":\"247078\"},\n{\"date\":\"3/30/19\",\"CI_weekly_2_5\":\"252838\",\"CI_weekly_97_5\":\"271876\",\"y_prediction_weekly\":\"262634\",\"y_true_weekly\":\"249239\"},\n{\"date\":\"3/31/19\",\"CI_weekly_2_5\":\"256279\",\"CI_weekly_97_5\":\"275870\",\"y_prediction_weekly\":\"266399\",\"y_true_weekly\":\"252631\"},\n{\"date\":\"4/1/19\",\"CI_weekly_2_5\":\"254267\",\"CI_weekly_97_5\":\"273378\",\"y_prediction_weekly\":\"264115\",\"y_true_weekly\":\"254905\"},\n{\"date\":\"4/2/19\",\"CI_weekly_2_5\":\"246561\",\"CI_weekly_97_5\":\"264347\",\"y_prediction_weekly\":\"255759\",\"y_true_weekly\":\"251496\"},\n{\"date\":\"4/3/19\",\"CI_weekly_2_5\":\"241580\",\"CI_weekly_97_5\":\"258656\",\"y_prediction_weekly\":\"250394\",\"y_true_weekly\":\"250520\"},\n{\"date\":\"4/4/19\",\"CI_weekly_2_5\":\"240026\",\"CI_weekly_97_5\":\"256860\",\"y_prediction_weekly\":\"248693\",\"y_true_weekly\":\"253930\"},\n{\"date\":\"4/5/19\",\"CI_weekly_2_5\":\"238390\",\"CI_weekly_97_5\":\"254119\",\"y_prediction_weekly\":\"246510\",\"y_true_weekly\":\"255367\"},\n{\"date\":\"4/6/19\",\"CI_weekly_2_5\":\"236800\",\"CI_weekly_97_5\":\"251758\",\"y_prediction_weekly\":\"244493\",\"y_true_weekly\":\"254262\"},\n{\"date\":\"4/7/19\",\"CI_weekly_2_5\":\"236031\",\"CI_weekly_97_5\":\"250684\",\"y_prediction_weekly\":\"243532\",\"y_true_weekly\":\"252292\"},\n{\"date\":\"4/8/19\",\"CI_weekly_2_5\":\"234154\",\"CI_weekly_97_5\":\"248410\",\"y_prediction_weekly\":\"241464\",\"y_true_weekly\":\"247018\"},\n{\"date\":\"4/9/19\",\"CI_weekly_2_5\":\"235298\",\"CI_weekly_97_5\":\"249107\",\"y_prediction_weekly\":\"242383\",\"y_true_weekly\":\"246242\"},\n{\"date\":\"4/10/19\",\"CI_weekly_2_5\":\"235815\",\"CI_weekly_97_5\":\"249178\",\"y_prediction_weekly\":\"242705\",\"y_true_weekly\":\"243878\"},\n{\"date\":\"4/11/19\",\"CI_weekly_2_5\":\"233012\",\"CI_weekly_97_5\":\"245900\",\"y_prediction_weekly\":\"239647\",\"y_true_weekly\":\"239377\"},\n{\"date\":\"4/12/19\",\"CI_weekly_2_5\":\"228448\",\"CI_weekly_97_5\":\"241054\",\"y_prediction_weekly\":\"234914\",\"y_true_weekly\":\"235945\"},\n{\"date\":\"4/13/19\",\"CI_weekly_2_5\":\"224861\",\"CI_weekly_97_5\":\"237435\",\"y_prediction_weekly\":\"231292\",\"y_true_weekly\":\"233139\"},\n{\"date\":\"4/14/19\",\"CI_weekly_2_5\":\"218172\",\"CI_weekly_97_5\":\"230920\",\"y_prediction_weekly\":\"224780\",\"y_true_weekly\":\"229322\"},\n{\"date\":\"4/15/19\",\"CI_weekly_2_5\":\"215396\",\"CI_weekly_97_5\":\"228674\",\"y_prediction_weekly\":\"222224\",\"y_true_weekly\":\"223342\"},\n{\"date\":\"4/16/19\",\"CI_weekly_2_5\":\"209344\",\"CI_weekly_97_5\":\"222090\",\"y_prediction_weekly\":\"215925\",\"y_true_weekly\":\"220919\"},\n{\"date\":\"4/17/19\",\"CI_weekly_2_5\":\"205990\",\"CI_weekly_97_5\":\"218670\",\"y_prediction_weekly\":\"212447\",\"y_true_weekly\":\"220826\"},\n{\"date\":\"4/18/19\",\"CI_weekly_2_5\":\"205573\",\"CI_weekly_97_5\":\"218740\",\"y_prediction_weekly\":\"212301\",\"y_true_weekly\":\"221979\"},\n{\"date\":\"4/19/19\",\"CI_weekly_2_5\":\"206438\",\"CI_weekly_97_5\":\"219851\",\"y_prediction_weekly\":\"213220\",\"y_true_weekly\":\"223266\"},\n{\"date\":\"4/20/19\",\"CI_weekly_2_5\":\"207250\",\"CI_weekly_97_5\":\"220718\",\"y_prediction_weekly\":\"214002\",\"y_true_weekly\":\"225328\"},\n{\"date\":\"4/21/19\",\"CI_weekly_2_5\":\"212236\",\"CI_weekly_97_5\":\"225742\",\"y_prediction_weekly\":\"218867\",\"y_true_weekly\":\"229146\"},\n{\"date\":\"4/22/19\",\"CI_weekly_2_5\":\"212712\",\"CI_weekly_97_5\":\"225976\",\"y_prediction_weekly\":\"219241\",\"y_true_weekly\":\"233455\"},\n{\"date\":\"4/23/19\",\"CI_weekly_2_5\":\"215366\",\"CI_weekly_97_5\":\"228905\",\"y_prediction_weekly\":\"222020\",\"y_true_weekly\":\"235010\"},\n{\"date\":\"4/24/19\",\"CI_weekly_2_5\":\"216486\",\"CI_weekly_97_5\":\"230976\",\"y_prediction_weekly\":\"223445\",\"y_true_weekly\":\"237795\"},\n{\"date\":\"4/25/19\",\"CI_weekly_2_5\":\"219394\",\"CI_weekly_97_5\":\"234327\",\"y_prediction_weekly\":\"226450\",\"y_true_weekly\":\"239134\"},\n{\"date\":\"4/26/19\",\"CI_weekly_2_5\":\"225200\",\"CI_weekly_97_5\":\"241494\",\"y_prediction_weekly\":\"232958\",\"y_true_weekly\":\"249273\"},\n{\"date\":\"4/27/19\",\"CI_weekly_2_5\":\"224668\",\"CI_weekly_97_5\":\"241284\",\"y_prediction_weekly\":\"232665\",\"y_true_weekly\":\"248886\"},\n{\"date\":\"4/28/19\",\"CI_weekly_2_5\":\"220466\",\"CI_weekly_97_5\":\"237361\",\"y_prediction_weekly\":\"228590\",\"y_true_weekly\":\"245529\"},\n{\"date\":\"4/29/19\",\"CI_weekly_2_5\":\"223864\",\"CI_weekly_97_5\":\"241417\",\"y_prediction_weekly\":\"232246\",\"y_true_weekly\":\"248055\"},\n{\"date\":\"4/30/19\",\"CI_weekly_2_5\":\"222569\",\"CI_weekly_97_5\":\"240530\",\"y_prediction_weekly\":\"230990\",\"y_true_weekly\":\"244746\"},\n{\"date\":\"5/1/19\",\"CI_weekly_2_5\":\"220004\",\"CI_weekly_97_5\":\"237784\",\"y_prediction_weekly\":\"228524\",\"y_true_weekly\":\"239438\"},\n{\"date\":\"5/2/19\",\"CI_weekly_2_5\":\"213343\",\"CI_weekly_97_5\":\"230549\",\"y_prediction_weekly\":\"221701\",\"y_true_weekly\":\"235397\"},\n{\"date\":\"5/3/19\",\"CI_weekly_2_5\":\"204079\",\"CI_weekly_97_5\":\"219981\",\"y_prediction_weekly\":\"211958\",\"y_true_weekly\":\"222208\"},\n{\"date\":\"5/4/19\",\"CI_weekly_2_5\":\"200487\",\"CI_weekly_97_5\":\"216265\",\"y_prediction_weekly\":\"208398\",\"y_true_weekly\":\"219937\"},\n{\"date\":\"5/5/19\",\"CI_weekly_2_5\":\"197874\",\"CI_weekly_97_5\":\"213255\",\"y_prediction_weekly\":\"205695\",\"y_true_weekly\":\"217441\"},\n{\"date\":\"5/6/19\",\"CI_weekly_2_5\":\"194015\",\"CI_weekly_97_5\":\"209034\",\"y_prediction_weekly\":\"201734\",\"y_true_weekly\":\"213774\"},\n{\"date\":\"5/7/19\",\"CI_weekly_2_5\":\"190992\",\"CI_weekly_97_5\":\"205771\",\"y_prediction_weekly\":\"198725\",\"y_true_weekly\":\"212901\"},\n{\"date\":\"5/8/19\",\"CI_weekly_2_5\":\"190864\",\"CI_weekly_97_5\":\"205257\",\"y_prediction_weekly\":\"198485\",\"y_true_weekly\":\"215652\"},\n{\"date\":\"5/9/19\",\"CI_weekly_2_5\":\"191278\",\"CI_weekly_97_5\":\"205569\",\"y_prediction_weekly\":\"198867\",\"y_true_weekly\":\"216074\"},\n{\"date\":\"5/10/19\",\"CI_weekly_2_5\":\"190539\",\"CI_weekly_97_5\":\"204890\",\"y_prediction_weekly\":\"198049\",\"y_true_weekly\":\"215896\"},\n{\"date\":\"5/11/19\",\"CI_weekly_2_5\":\"191857\",\"CI_weekly_97_5\":\"206185\",\"y_prediction_weekly\":\"199203\",\"y_true_weekly\":\"215619\"},\n{\"date\":\"5/12/19\",\"CI_weekly_2_5\":\"197530\",\"CI_weekly_97_5\":\"212513\",\"y_prediction_weekly\":\"205152\",\"y_true_weekly\":\"219850\"},\n{\"date\":\"5/13/19\",\"CI_weekly_2_5\":\"198663\",\"CI_weekly_97_5\":\"213549\",\"y_prediction_weekly\":\"206114\",\"y_true_weekly\":\"220985\"},\n{\"date\":\"5/14/19\",\"CI_weekly_2_5\":\"200516\",\"CI_weekly_97_5\":\"215495\",\"y_prediction_weekly\":\"207960\",\"y_true_weekly\":\"222545\"},\n{\"date\":\"5/15/19\",\"CI_weekly_2_5\":\"205091\",\"CI_weekly_97_5\":\"220864\",\"y_prediction_weekly\":\"212786\",\"y_true_weekly\":\"221236\"},\n{\"date\":\"5/16/19\",\"CI_weekly_2_5\":\"207326\",\"CI_weekly_97_5\":\"223497\",\"y_prediction_weekly\":\"215219\",\"y_true_weekly\":\"221373\"},\n{\"date\":\"5/17/19\",\"CI_weekly_2_5\":\"214577\",\"CI_weekly_97_5\":\"231018\",\"y_prediction_weekly\":\"222635\",\"y_true_weekly\":\"230540\"},\n{\"date\":\"5/18/19\",\"CI_weekly_2_5\":\"215859\",\"CI_weekly_97_5\":\"232277\",\"y_prediction_weekly\":\"223870\",\"y_true_weekly\":\"229006\"},\n{\"date\":\"5/19/19\",\"CI_weekly_2_5\":\"217073\",\"CI_weekly_97_5\":\"233334\",\"y_prediction_weekly\":\"224899\",\"y_true_weekly\":\"227858\"},\n{\"date\":\"5/20/19\",\"CI_weekly_2_5\":\"219513\",\"CI_weekly_97_5\":\"236007\",\"y_prediction_weekly\":\"227454\",\"y_true_weekly\":\"224724\"},\n{\"date\":\"5/21/19\",\"CI_weekly_2_5\":\"222666\",\"CI_weekly_97_5\":\"239480\",\"y_prediction_weekly\":\"230782\",\"y_true_weekly\":\"226175\"},\n{\"date\":\"5/22/19\",\"CI_weekly_2_5\":\"220189\",\"CI_weekly_97_5\":\"236035\",\"y_prediction_weekly\":\"227862\",\"y_true_weekly\":\"227472\"},\n{\"date\":\"5/23/19\",\"CI_weekly_2_5\":\"220665\",\"CI_weekly_97_5\":\"236013\",\"y_prediction_weekly\":\"228051\",\"y_true_weekly\":\"227981\"},\n{\"date\":\"5/24/19\",\"CI_weekly_2_5\":\"224612\",\"CI_weekly_97_5\":\"240777\",\"y_prediction_weekly\":\"232347\",\"y_true_weekly\":\"228620\"},\n{\"date\":\"5/25/19\",\"CI_weekly_2_5\":\"232200\",\"CI_weekly_97_5\":\"248899\",\"y_prediction_weekly\":\"240194\",\"y_true_weekly\":\"240891\"},\n{\"date\":\"5/26/19\",\"CI_weekly_2_5\":\"232269\",\"CI_weekly_97_5\":\"248457\",\"y_prediction_weekly\":\"239995\",\"y_true_weekly\":\"246421\"},\n{\"date\":\"5/27/19\",\"CI_weekly_2_5\":\"231823\",\"CI_weekly_97_5\":\"247892\",\"y_prediction_weekly\":\"239466\",\"y_true_weekly\":\"250881\"},\n{\"date\":\"5/28/19\",\"CI_weekly_2_5\":\"231551\",\"CI_weekly_97_5\":\"247225\",\"y_prediction_weekly\":\"239004\",\"y_true_weekly\":\"254201\"},\n{\"date\":\"5/29/19\",\"CI_weekly_2_5\":\"232123\",\"CI_weekly_97_5\":\"248117\",\"y_prediction_weekly\":\"239751\",\"y_true_weekly\":\"256696\"},\n{\"date\":\"5/30/19\",\"CI_weekly_2_5\":\"232468\",\"CI_weekly_97_5\":\"248803\",\"y_prediction_weekly\":\"240193\",\"y_true_weekly\":\"261320\"},\n{\"date\":\"5/31/19\",\"CI_weekly_2_5\":\"232634\",\"CI_weekly_97_5\":\"248649\",\"y_prediction_weekly\":\"240101\",\"y_true_weekly\":\"261901\"},\n{\"date\":\"6/1/19\",\"CI_weekly_2_5\":\"226980\",\"CI_weekly_97_5\":\"242379\",\"y_prediction_weekly\":\"234209\",\"y_true_weekly\":\"254569\"},\n{\"date\":\"6/2/19\",\"CI_weekly_2_5\":\"227842\",\"CI_weekly_97_5\":\"243269\",\"y_prediction_weekly\":\"235143\",\"y_true_weekly\":\"252157\"},\n{\"date\":\"6/3/19\",\"CI_weekly_2_5\":\"228475\",\"CI_weekly_97_5\":\"243842\",\"y_prediction_weekly\":\"235737\",\"y_true_weekly\":\"251392\"},\n{\"date\":\"6/4/19\",\"CI_weekly_2_5\":\"227670\",\"CI_weekly_97_5\":\"242794\",\"y_prediction_weekly\":\"234872\",\"y_true_weekly\":\"249642\"},\n{\"date\":\"6/5/19\",\"CI_weekly_2_5\":\"225732\",\"CI_weekly_97_5\":\"240637\",\"y_prediction_weekly\":\"232885\",\"y_true_weekly\":\"248773\"},\n{\"date\":\"6/6/19\",\"CI_weekly_2_5\":\"229697\",\"CI_weekly_97_5\":\"245021\",\"y_prediction_weekly\":\"237113\",\"y_true_weekly\":\"253667\"},\n{\"date\":\"6/7/19\",\"CI_weekly_2_5\":\"221184\",\"CI_weekly_97_5\":\"235848\",\"y_prediction_weekly\":\"228498\",\"y_true_weekly\":\"248827\"},\n{\"date\":\"6/8/19\",\"CI_weekly_2_5\":\"226138\",\"CI_weekly_97_5\":\"241581\",\"y_prediction_weekly\":\"233787\",\"y_true_weekly\":\"252013\"},\n{\"date\":\"6/9/19\",\"CI_weekly_2_5\":\"225759\",\"CI_weekly_97_5\":\"241129\",\"y_prediction_weekly\":\"233363\",\"y_true_weekly\":\"250974\"},\n{\"date\":\"6/10/19\",\"CI_weekly_2_5\":\"226431\",\"CI_weekly_97_5\":\"241640\",\"y_prediction_weekly\":\"234010\",\"y_true_weekly\":\"249905\"},\n{\"date\":\"6/11/19\",\"CI_weekly_2_5\":\"226577\",\"CI_weekly_97_5\":\"241887\",\"y_prediction_weekly\":\"234217\",\"y_true_weekly\":\"248790\"},\n{\"date\":\"6/12/19\",\"CI_weekly_2_5\":\"228946\",\"CI_weekly_97_5\":\"244256\",\"y_prediction_weekly\":\"236632\",\"y_true_weekly\":\"247728\"},\n{\"date\":\"6/13/19\",\"CI_weekly_2_5\":\"226121\",\"CI_weekly_97_5\":\"240796\",\"y_prediction_weekly\":\"233575\",\"y_true_weekly\":\"241038\"},\n{\"date\":\"6/14/19\",\"CI_weekly_2_5\":\"228475\",\"CI_weekly_97_5\":\"243089\",\"y_prediction_weekly\":\"235850\",\"y_true_weekly\":\"241457\"},\n{\"date\":\"6/15/19\",\"CI_weekly_2_5\":\"225230\",\"CI_weekly_97_5\":\"239486\",\"y_prediction_weekly\":\"232394\",\"y_true_weekly\":\"245240\"},\n{\"date\":\"6/16/19\",\"CI_weekly_2_5\":\"227389\",\"CI_weekly_97_5\":\"242453\",\"y_prediction_weekly\":\"234713\",\"y_true_weekly\":\"249870\"},\n{\"date\":\"6/17/19\",\"CI_weekly_2_5\":\"229885\",\"CI_weekly_97_5\":\"245505\",\"y_prediction_weekly\":\"237429\",\"y_true_weekly\":\"256731\"},\n{\"date\":\"6/18/19\",\"CI_weekly_2_5\":\"235822\",\"CI_weekly_97_5\":\"252591\",\"y_prediction_weekly\":\"243791\",\"y_true_weekly\":\"264538\"},\n{\"date\":\"6/19/19\",\"CI_weekly_2_5\":\"244061\",\"CI_weekly_97_5\":\"263121\",\"y_prediction_weekly\":\"253189\",\"y_true_weekly\":\"270996\"},\n{\"date\":\"6/20/19\",\"CI_weekly_2_5\":\"258902\",\"CI_weekly_97_5\":\"281769\",\"y_prediction_weekly\":\"269772\",\"y_true_weekly\":\"280624\"},\n{\"date\":\"6/21/19\",\"CI_weekly_2_5\":\"271768\",\"CI_weekly_97_5\":\"296323\",\"y_prediction_weekly\":\"283237\",\"y_true_weekly\":\"287863\"},\n{\"date\":\"6/22/19\",\"CI_weekly_2_5\":\"278233\",\"CI_weekly_97_5\":\"303156\",\"y_prediction_weekly\":\"290034\",\"y_true_weekly\":\"285615\"},\n{\"date\":\"6/23/19\",\"CI_weekly_2_5\":\"282253\",\"CI_weekly_97_5\":\"306649\",\"y_prediction_weekly\":\"294034\",\"y_true_weekly\":\"285001\"},\n{\"date\":\"6/24/19\",\"CI_weekly_2_5\":\"286944\",\"CI_weekly_97_5\":\"311163\",\"y_prediction_weekly\":\"298725\",\"y_true_weekly\":\"283526\"},\n{\"date\":\"6/25/19\",\"CI_weekly_2_5\":\"290433\",\"CI_weekly_97_5\":\"314965\",\"y_prediction_weekly\":\"302424\",\"y_true_weekly\":\"282341\"},\n{\"date\":\"6/26/19\",\"CI_weekly_2_5\":\"288901\",\"CI_weekly_97_5\":\"312955\",\"y_prediction_weekly\":\"300388\",\"y_true_weekly\":\"279520\"},\n{\"date\":\"6/27/19\",\"CI_weekly_2_5\":\"280201\",\"CI_weekly_97_5\":\"301628\",\"y_prediction_weekly\":\"290385\",\"y_true_weekly\":\"271250\"},\n{\"date\":\"6/28/19\",\"CI_weekly_2_5\":\"270012\",\"CI_weekly_97_5\":\"290982\",\"y_prediction_weekly\":\"279987\",\"y_true_weekly\":\"258170\"},\n{\"date\":\"6/29/19\",\"CI_weekly_2_5\":\"265422\",\"CI_weekly_97_5\":\"286680\",\"y_prediction_weekly\":\"275318\",\"y_true_weekly\":\"254599\"},\n{\"date\":\"6/30/19\",\"CI_weekly_2_5\":\"260657\",\"CI_weekly_97_5\":\"282823\",\"y_prediction_weekly\":\"270939\",\"y_true_weekly\":\"250441\"},\n{\"date\":\"7/1/19\",\"CI_weekly_2_5\":\"254873\",\"CI_weekly_97_5\":\"277585\",\"y_prediction_weekly\":\"265358\",\"y_true_weekly\":\"250052\"},\n{\"date\":\"7/2/19\",\"CI_weekly_2_5\":\"252706\",\"CI_weekly_97_5\":\"275994\",\"y_prediction_weekly\":\"263399\",\"y_true_weekly\":\"249957\"},\n{\"date\":\"7/3/19\",\"CI_weekly_2_5\":\"253856\",\"CI_weekly_97_5\":\"277813\",\"y_prediction_weekly\":\"264892\",\"y_true_weekly\":\"250484\"},\n{\"date\":\"7/4/19\",\"CI_weekly_2_5\":\"253600\",\"CI_weekly_97_5\":\"278547\",\"y_prediction_weekly\":\"265135\",\"y_true_weekly\":\"253419\"},\n{\"date\":\"7/5/19\",\"CI_weekly_2_5\":\"258231\",\"CI_weekly_97_5\":\"284207\",\"y_prediction_weekly\":\"270327\",\"y_true_weekly\":\"263265\"},\n{\"date\":\"7/6/19\",\"CI_weekly_2_5\":\"266262\",\"CI_weekly_97_5\":\"295322\",\"y_prediction_weekly\":\"280168\",\"y_true_weekly\":\"270732\"},\n{\"date\":\"7/7/19\",\"CI_weekly_2_5\":\"277308\",\"CI_weekly_97_5\":\"311518\",\"y_prediction_weekly\":\"293630\",\"y_true_weekly\":\"276290\"},\n{\"date\":\"7/8/19\",\"CI_weekly_2_5\":\"287535\",\"CI_weekly_97_5\":\"325044\",\"y_prediction_weekly\":\"305506\",\"y_true_weekly\":\"285653\"},\n{\"date\":\"7/9/19\",\"CI_weekly_2_5\":\"304053\",\"CI_weekly_97_5\":\"348137\",\"y_prediction_weekly\":\"325238\",\"y_true_weekly\":\"338816\"},\n{\"date\":\"7/10/19\",\"CI_weekly_2_5\":\"313150\",\"CI_weekly_97_5\":\"358879\",\"y_prediction_weekly\":\"335399\",\"y_true_weekly\":\"369712\"},\n{\"date\":\"7/11/19\",\"CI_weekly_2_5\":\"315486\",\"CI_weekly_97_5\":\"361146\",\"y_prediction_weekly\":\"337759\",\"y_true_weekly\":\"374458\"},\n{\"date\":\"7/12/19\",\"CI_weekly_2_5\":\"314688\",\"CI_weekly_97_5\":\"359578\",\"y_prediction_weekly\":\"336635\",\"y_true_weekly\":\"376592\"},\n{\"date\":\"7/13/19\",\"CI_weekly_2_5\":\"314287\",\"CI_weekly_97_5\":\"357000\",\"y_prediction_weekly\":\"335032\",\"y_true_weekly\":\"378536\"},\n{\"date\":\"7/14/19\",\"CI_weekly_2_5\":\"307953\",\"CI_weekly_97_5\":\"345866\",\"y_prediction_weekly\":\"326620\",\"y_true_weekly\":\"378254\"},\n{\"date\":\"7/15/19\",\"CI_weekly_2_5\":\"303781\",\"CI_weekly_97_5\":\"338940\",\"y_prediction_weekly\":\"321237\",\"y_true_weekly\":\"374382\"},\n{\"date\":\"7/16/19\",\"CI_weekly_2_5\":\"289413\",\"CI_weekly_97_5\":\"317628\",\"y_prediction_weekly\":\"303661\",\"y_true_weekly\":\"322768\"},\n{\"date\":\"7/17/19\",\"CI_weekly_2_5\":\"281271\",\"CI_weekly_97_5\":\"306854\",\"y_prediction_weekly\":\"293995\",\"y_true_weekly\":\"296815\"},\n{\"date\":\"7/18/19\",\"CI_weekly_2_5\":\"279825\",\"CI_weekly_97_5\":\"305718\",\"y_prediction_weekly\":\"292788\",\"y_true_weekly\":\"292202\"},\n{\"date\":\"7/19/19\",\"CI_weekly_2_5\":\"280044\",\"CI_weekly_97_5\":\"305678\",\"y_prediction_weekly\":\"293005\",\"y_true_weekly\":\"290673\"},\n{\"date\":\"7/20/19\",\"CI_weekly_2_5\":\"275836\",\"CI_weekly_97_5\":\"300316\",\"y_prediction_weekly\":\"288313\",\"y_true_weekly\":\"285847\"},\n{\"date\":\"7/21/19\",\"CI_weekly_2_5\":\"275750\",\"CI_weekly_97_5\":\"299869\",\"y_prediction_weekly\":\"288084\",\"y_true_weekly\":\"285294\"},\n{\"date\":\"7/22/19\",\"CI_weekly_2_5\":\"276392\",\"CI_weekly_97_5\":\"300621\",\"y_prediction_weekly\":\"288798\",\"y_true_weekly\":\"284501\"},\n{\"date\":\"7/23/19\",\"CI_weekly_2_5\":\"275745\",\"CI_weekly_97_5\":\"299604\",\"y_prediction_weekly\":\"288097\",\"y_true_weekly\":\"288075\"},\n{\"date\":\"7/24/19\",\"CI_weekly_2_5\":\"278829\",\"CI_weekly_97_5\":\"302808\",\"y_prediction_weekly\":\"291510\",\"y_true_weekly\":\"289235\"},\n{\"date\":\"7/25/19\",\"CI_weekly_2_5\":\"282271\",\"CI_weekly_97_5\":\"304816\",\"y_prediction_weekly\":\"294254\",\"y_true_weekly\":\"294538\"},\n{\"date\":\"7/26/19\",\"CI_weekly_2_5\":\"282552\",\"CI_weekly_97_5\":\"305624\",\"y_prediction_weekly\":\"294721\",\"y_true_weekly\":\"296507\"},\n{\"date\":\"7/27/19\",\"CI_weekly_2_5\":\"283509\",\"CI_weekly_97_5\":\"307399\",\"y_prediction_weekly\":\"296033\",\"y_true_weekly\":\"296593\"},\n{\"date\":\"7/28/19\",\"CI_weekly_2_5\":\"278586\",\"CI_weekly_97_5\":\"302994\",\"y_prediction_weekly\":\"291209\",\"y_true_weekly\":\"292613\"},\n{\"date\":\"7/29/19\",\"CI_weekly_2_5\":\"271003\",\"CI_weekly_97_5\":\"295000\",\"y_prediction_weekly\":\"283267\",\"y_true_weekly\":\"289052\"},\n{\"date\":\"7/30/19\",\"CI_weekly_2_5\":\"270164\",\"CI_weekly_97_5\":\"293559\",\"y_prediction_weekly\":\"281794\",\"y_true_weekly\":\"283942\"},\n{\"date\":\"7/31/19\",\"CI_weekly_2_5\":\"264509\",\"CI_weekly_97_5\":\"286390\",\"y_prediction_weekly\":\"275142\",\"y_true_weekly\":\"278835\"},\n{\"date\":\"8/1/19\",\"CI_weekly_2_5\":\"261794\",\"CI_weekly_97_5\":\"283149\",\"y_prediction_weekly\":\"272106\",\"y_true_weekly\":\"275016\"},\n{\"date\":\"8/2/19\",\"CI_weekly_2_5\":\"260389\",\"CI_weekly_97_5\":\"280134\",\"y_prediction_weekly\":\"269892\",\"y_true_weekly\":\"270083\"},\n{\"date\":\"8/3/19\",\"CI_weekly_2_5\":\"257166\",\"CI_weekly_97_5\":\"275797\",\"y_prediction_weekly\":\"266058\",\"y_true_weekly\":\"269731\"},\n{\"date\":\"8/4/19\",\"CI_weekly_2_5\":\"256534\",\"CI_weekly_97_5\":\"273813\",\"y_prediction_weekly\":\"264883\",\"y_true_weekly\":\"271024\"},\n{\"date\":\"8/5/19\",\"CI_weekly_2_5\":\"256651\",\"CI_weekly_97_5\":\"272827\",\"y_prediction_weekly\":\"264442\",\"y_true_weekly\":\"272558\"},\n{\"date\":\"8/6/19\",\"CI_weekly_2_5\":\"257629\",\"CI_weekly_97_5\":\"273357\",\"y_prediction_weekly\":\"265337\",\"y_true_weekly\":\"274497\"},\n{\"date\":\"8/7/19\",\"CI_weekly_2_5\":\"260171\",\"CI_weekly_97_5\":\"277376\",\"y_prediction_weekly\":\"268663\",\"y_true_weekly\":\"277499\"},\n{\"date\":\"8/8/19\",\"CI_weekly_2_5\":\"259399\",\"CI_weekly_97_5\":\"277054\",\"y_prediction_weekly\":\"268189\",\"y_true_weekly\":\"277844\"},\n{\"date\":\"8/9/19\",\"CI_weekly_2_5\":\"260673\",\"CI_weekly_97_5\":\"278232\",\"y_prediction_weekly\":\"269378\",\"y_true_weekly\":\"282851\"},\n{\"date\":\"8/10/19\",\"CI_weekly_2_5\":\"269501\",\"CI_weekly_97_5\":\"288005\",\"y_prediction_weekly\":\"278674\",\"y_true_weekly\":\"299262\"},\n{\"date\":\"8/11/19\",\"CI_weekly_2_5\":\"271711\",\"CI_weekly_97_5\":\"290187\",\"y_prediction_weekly\":\"280863\",\"y_true_weekly\":\"307154\"},\n{\"date\":\"8/12/19\",\"CI_weekly_2_5\":\"272821\",\"CI_weekly_97_5\":\"291465\",\"y_prediction_weekly\":\"282006\",\"y_true_weekly\":\"308985\"},\n{\"date\":\"8/13/19\",\"CI_weekly_2_5\":\"271173\",\"CI_weekly_97_5\":\"289928\",\"y_prediction_weekly\":\"280313\",\"y_true_weekly\":\"307945\"},\n{\"date\":\"8/14/19\",\"CI_weekly_2_5\":\"272056\",\"CI_weekly_97_5\":\"289246\",\"y_prediction_weekly\":\"280437\",\"y_true_weekly\":\"307533\"},\n{\"date\":\"8/15/19\",\"CI_weekly_2_5\":\"282844\",\"CI_weekly_97_5\":\"300834\",\"y_prediction_weekly\":\"291521\",\"y_true_weekly\":\"318781\"},\n{\"date\":\"8/16/19\",\"CI_weekly_2_5\":\"284950\",\"CI_weekly_97_5\":\"302817\",\"y_prediction_weekly\":\"293638\",\"y_true_weekly\":\"318629\"},\n{\"date\":\"8/17/19\",\"CI_weekly_2_5\":\"279712\",\"CI_weekly_97_5\":\"296996\",\"y_prediction_weekly\":\"288207\",\"y_true_weekly\":\"305030\"},\n{\"date\":\"8/18/19\",\"CI_weekly_2_5\":\"287259\",\"CI_weekly_97_5\":\"305119\",\"y_prediction_weekly\":\"295745\",\"y_true_weekly\":\"309862\"},\n{\"date\":\"8/19/19\",\"CI_weekly_2_5\":\"300868\",\"CI_weekly_97_5\":\"319917\",\"y_prediction_weekly\":\"310042\",\"y_true_weekly\":\"318846\"},\n{\"date\":\"8/20/19\",\"CI_weekly_2_5\":\"307474\",\"CI_weekly_97_5\":\"326852\",\"y_prediction_weekly\":\"316744\",\"y_true_weekly\":\"324103\"},\n{\"date\":\"8/21/19\",\"CI_weekly_2_5\":\"312392\",\"CI_weekly_97_5\":\"333153\",\"y_prediction_weekly\":\"322293\",\"y_true_weekly\":\"327624\"},\n{\"date\":\"8/22/19\",\"CI_weekly_2_5\":\"308024\",\"CI_weekly_97_5\":\"328286\",\"y_prediction_weekly\":\"317689\",\"y_true_weekly\":\"315160\"},\n{\"date\":\"8/23/19\",\"CI_weekly_2_5\":\"310489\",\"CI_weekly_97_5\":\"331880\",\"y_prediction_weekly\":\"320603\",\"y_true_weekly\":\"310357\"},\n{\"date\":\"8/24/19\",\"CI_weekly_2_5\":\"315125\",\"CI_weekly_97_5\":\"336663\",\"y_prediction_weekly\":\"325265\",\"y_true_weekly\":\"308133\"},\n{\"date\":\"8/25/19\",\"CI_weekly_2_5\":\"316424\",\"CI_weekly_97_5\":\"338068\",\"y_prediction_weekly\":\"326885\",\"y_true_weekly\":\"302622\"},\n{\"date\":\"8/26/19\",\"CI_weekly_2_5\":\"308382\",\"CI_weekly_97_5\":\"329042\",\"y_prediction_weekly\":\"318261\",\"y_true_weekly\":\"293973\"},\n{\"date\":\"8/27/19\",\"CI_weekly_2_5\":\"309009\",\"CI_weekly_97_5\":\"329827\",\"y_prediction_weekly\":\"319131\",\"y_true_weekly\":\"296599\"},\n{\"date\":\"8/28/19\",\"CI_weekly_2_5\":\"309958\",\"CI_weekly_97_5\":\"330808\",\"y_prediction_weekly\":\"320189\",\"y_true_weekly\":\"294121\"},\n{\"date\":\"8/29/19\",\"CI_weekly_2_5\":\"309449\",\"CI_weekly_97_5\":\"330786\",\"y_prediction_weekly\":\"319828\",\"y_true_weekly\":\"295844\"},\n{\"date\":\"8/30/19\",\"CI_weekly_2_5\":\"314196\",\"CI_weekly_97_5\":\"336179\",\"y_prediction_weekly\":\"325030\",\"y_true_weekly\":\"310919\"},\n{\"date\":\"8/31/19\",\"CI_weekly_2_5\":\"306456\",\"CI_weekly_97_5\":\"328238\",\"y_prediction_weekly\":\"317265\",\"y_true_weekly\":\"310417\"},\n{\"date\":\"9/1/19\",\"CI_weekly_2_5\":\"308002\",\"CI_weekly_97_5\":\"329887\",\"y_prediction_weekly\":\"318758\",\"y_true_weekly\":\"313511\"},\n{\"date\":\"9/2/19\",\"CI_weekly_2_5\":\"305714\",\"CI_weekly_97_5\":\"327929\",\"y_prediction_weekly\":\"316755\",\"y_true_weekly\":\"315180\"},\n{\"date\":\"9/3/19\",\"CI_weekly_2_5\":\"303183\",\"CI_weekly_97_5\":\"324628\",\"y_prediction_weekly\":\"313932\",\"y_true_weekly\":\"306076\"},\n{\"date\":\"9/4/19\",\"CI_weekly_2_5\":\"301126\",\"CI_weekly_97_5\":\"338859\",\"y_prediction_weekly\":\"313102\",\"y_true_weekly\":\"308869\"},\n{\"date\":\"9/5/19\",\"CI_weekly_2_5\":\"296534\",\"CI_weekly_97_5\":\"332804\",\"y_prediction_weekly\":\"307820\",\"y_true_weekly\":\"308705\"},\n{\"date\":\"9/6/19\",\"CI_weekly_2_5\":\"287680\",\"CI_weekly_97_5\":\"322422\",\"y_prediction_weekly\":\"298101\",\"y_true_weekly\":\"297308\"},\n{\"date\":\"9/7/19\",\"CI_weekly_2_5\":\"289045\",\"CI_weekly_97_5\":\"323555\",\"y_prediction_weekly\":\"299230\",\"y_true_weekly\":\"298284\"},\n{\"date\":\"9/8/19\",\"CI_weekly_2_5\":\"283765\",\"CI_weekly_97_5\":\"317860\",\"y_prediction_weekly\":\"293870\",\"y_true_weekly\":\"294854\"},\n{\"date\":\"9/9/19\",\"CI_weekly_2_5\":\"288520\",\"CI_weekly_97_5\":\"322537\",\"y_prediction_weekly\":\"298615\",\"y_true_weekly\":\"296802\"},\n{\"date\":\"9/10/19\",\"CI_weekly_2_5\":\"284235\",\"CI_weekly_97_5\":\"318239\",\"y_prediction_weekly\":\"294315\",\"y_true_weekly\":\"296921\"},\n{\"date\":\"9/11/19\",\"CI_weekly_2_5\":\"279760\",\"CI_weekly_97_5\":\"296365\",\"y_prediction_weekly\":\"288147\",\"y_true_weekly\":\"292572\"},\n{\"date\":\"9/12/19\",\"CI_weekly_2_5\":\"278570\",\"CI_weekly_97_5\":\"295473\",\"y_prediction_weekly\":\"287215\",\"y_true_weekly\":\"291466\"},\n{\"date\":\"9/13/19\",\"CI_weekly_2_5\":\"286252\",\"CI_weekly_97_5\":\"304188\",\"y_prediction_weekly\":\"295554\",\"y_true_weekly\":\"299495\"},\n{\"date\":\"9/14/19\",\"CI_weekly_2_5\":\"289281\",\"CI_weekly_97_5\":\"307262\",\"y_prediction_weekly\":\"298565\",\"y_true_weekly\":\"301513\"},\n{\"date\":\"9/15/19\",\"CI_weekly_2_5\":\"286266\",\"CI_weekly_97_5\":\"304171\",\"y_prediction_weekly\":\"295541\",\"y_true_weekly\":\"300110\"},\n{\"date\":\"9/16/19\",\"CI_weekly_2_5\":\"283359\",\"CI_weekly_97_5\":\"301083\",\"y_prediction_weekly\":\"292547\",\"y_true_weekly\":\"298687\"},\n{\"date\":\"9/17/19\",\"CI_weekly_2_5\":\"289239\",\"CI_weekly_97_5\":\"308110\",\"y_prediction_weekly\":\"298652\",\"y_true_weekly\":\"301624\"},\n{\"date\":\"9/18/19\",\"CI_weekly_2_5\":\"289573\",\"CI_weekly_97_5\":\"308671\",\"y_prediction_weekly\":\"298935\",\"y_true_weekly\":\"301088\"},\n{\"date\":\"9/19/19\",\"CI_weekly_2_5\":\"290717\",\"CI_weekly_97_5\":\"309837\",\"y_prediction_weekly\":\"300018\",\"y_true_weekly\":\"299212\"},\n{\"date\":\"9/20/19\",\"CI_weekly_2_5\":\"288752\",\"CI_weekly_97_5\":\"307905\",\"y_prediction_weekly\":\"297949\",\"y_true_weekly\":\"295082\"},\n{\"date\":\"9/21/19\",\"CI_weekly_2_5\":\"284087\",\"CI_weekly_97_5\":\"302887\",\"y_prediction_weekly\":\"293202\",\"y_true_weekly\":\"288526\"},\n{\"date\":\"9/22/19\",\"CI_weekly_2_5\":\"286966\",\"CI_weekly_97_5\":\"305699\",\"y_prediction_weekly\":\"296066\",\"y_true_weekly\":\"284603\"},\n{\"date\":\"9/23/19\",\"CI_weekly_2_5\":\"282673\",\"CI_weekly_97_5\":\"301443\",\"y_prediction_weekly\":\"291879\",\"y_true_weekly\":\"279973\"},\n{\"date\":\"9/24/19\",\"CI_weekly_2_5\":\"277500\",\"CI_weekly_97_5\":\"295132\",\"y_prediction_weekly\":\"286466\",\"y_true_weekly\":\"277108\"},\n{\"date\":\"9/25/19\",\"CI_weekly_2_5\":\"277915\",\"CI_weekly_97_5\":\"295078\",\"y_prediction_weekly\":\"286778\",\"y_true_weekly\":\"282003\"},\n{\"date\":\"9/26/19\",\"CI_weekly_2_5\":\"283538\",\"CI_weekly_97_5\":\"301875\",\"y_prediction_weekly\":\"292880\",\"y_true_weekly\":\"293486\"},\n{\"date\":\"9/27/19\",\"CI_weekly_2_5\":\"278254\",\"CI_weekly_97_5\":\"295350\",\"y_prediction_weekly\":\"286939\",\"y_true_weekly\":\"289294\"},\n{\"date\":\"9/28/19\",\"CI_weekly_2_5\":\"278784\",\"CI_weekly_97_5\":\"295738\",\"y_prediction_weekly\":\"287378\",\"y_true_weekly\":\"290844\"},\n{\"date\":\"9/29/19\",\"CI_weekly_2_5\":\"270911\",\"CI_weekly_97_5\":\"288453\",\"y_prediction_weekly\":\"279589\",\"y_true_weekly\":\"289537\"},\n{\"date\":\"9/30/19\",\"CI_weekly_2_5\":\"269119\",\"CI_weekly_97_5\":\"286799\",\"y_prediction_weekly\":\"277675\",\"y_true_weekly\":\"287494\"},\n{\"date\":\"10/1/19\",\"CI_weekly_2_5\":\"271450\",\"CI_weekly_97_5\":\"291437\",\"y_prediction_weekly\":\"280957\",\"y_true_weekly\":\"292151\"},\n{\"date\":\"10/2/19\",\"CI_weekly_2_5\":\"262231\",\"CI_weekly_97_5\":\"282932\",\"y_prediction_weekly\":\"271984\",\"y_true_weekly\":\"284964\"},\n{\"date\":\"10/3/19\",\"CI_weekly_2_5\":\"249542\",\"CI_weekly_97_5\":\"268999\",\"y_prediction_weekly\":\"258925\",\"y_true_weekly\":\"274330\"},\n{\"date\":\"10/4/19\",\"CI_weekly_2_5\":\"242856\",\"CI_weekly_97_5\":\"262365\",\"y_prediction_weekly\":\"252426\",\"y_true_weekly\":\"269868\"},\n{\"date\":\"10/5/19\",\"CI_weekly_2_5\":\"242161\",\"CI_weekly_97_5\":\"262176\",\"y_prediction_weekly\":\"252007\",\"y_true_weekly\":\"269708\"},\n{\"date\":\"10/6/19\",\"CI_weekly_2_5\":\"244372\",\"CI_weekly_97_5\":\"263556\",\"y_prediction_weekly\":\"254020\",\"y_true_weekly\":\"269861\"},\n{\"date\":\"10/7/19\",\"CI_weekly_2_5\":\"246986\",\"CI_weekly_97_5\":\"265892\",\"y_prediction_weekly\":\"256792\",\"y_true_weekly\":\"268517\"},\n{\"date\":\"10/8/19\",\"CI_weekly_2_5\":\"246175\",\"CI_weekly_97_5\":\"263377\",\"y_prediction_weekly\":\"255394\",\"y_true_weekly\":\"263355\"},\n{\"date\":\"10/9/19\",\"CI_weekly_2_5\":\"258155\",\"CI_weekly_97_5\":\"275554\",\"y_prediction_weekly\":\"267548\",\"y_true_weekly\":\"267905\"},\n{\"date\":\"10/10/19\",\"CI_weekly_2_5\":\"270659\",\"CI_weekly_97_5\":\"288455\",\"y_prediction_weekly\":\"280174\",\"y_true_weekly\":\"270855\"},\n{\"date\":\"10/11/19\",\"CI_weekly_2_5\":\"276659\",\"CI_weekly_97_5\":\"295160\",\"y_prediction_weekly\":\"286587\",\"y_true_weekly\":\"272719\"},\n{\"date\":\"10/12/19\",\"CI_weekly_2_5\":\"284899\",\"CI_weekly_97_5\":\"304035\",\"y_prediction_weekly\":\"295065\",\"y_true_weekly\":\"276686\"},\n{\"date\":\"10/13/19\",\"CI_weekly_2_5\":\"285202\",\"CI_weekly_97_5\":\"305074\",\"y_prediction_weekly\":\"295806\",\"y_true_weekly\":\"273979\"},\n{\"date\":\"10/14/19\",\"CI_weekly_2_5\":\"284715\",\"CI_weekly_97_5\":\"304945\",\"y_prediction_weekly\":\"295443\",\"y_true_weekly\":\"272855\"},\n{\"date\":\"10/15/19\",\"CI_weekly_2_5\":\"287952\",\"CI_weekly_97_5\":\"309525\",\"y_prediction_weekly\":\"299245\",\"y_true_weekly\":\"278778\"},\n{\"date\":\"10/16/19\",\"CI_weekly_2_5\":\"280909\",\"CI_weekly_97_5\":\"302358\",\"y_prediction_weekly\":\"292181\",\"y_true_weekly\":\"271627\"},\n{\"date\":\"10/17/19\",\"CI_weekly_2_5\":\"276161\",\"CI_weekly_97_5\":\"298019\",\"y_prediction_weekly\":\"287510\",\"y_true_weekly\":\"270725\"},\n{\"date\":\"10/18/19\",\"CI_weekly_2_5\":\"273772\",\"CI_weekly_97_5\":\"295002\",\"y_prediction_weekly\":\"284468\",\"y_true_weekly\":\"266217\"},\n{\"date\":\"10/19/19\",\"CI_weekly_2_5\":\"269364\",\"CI_weekly_97_5\":\"290901\",\"y_prediction_weekly\":\"280183\",\"y_true_weekly\":\"264958\"},\n{\"date\":\"10/20/19\",\"CI_weekly_2_5\":\"265363\",\"CI_weekly_97_5\":\"285957\",\"y_prediction_weekly\":\"275618\",\"y_true_weekly\":\"263879\"},\n{\"date\":\"10/21/19\",\"CI_weekly_2_5\":\"269394\",\"CI_weekly_97_5\":\"290754\",\"y_prediction_weekly\":\"279929\",\"y_true_weekly\":\"267728\"},\n{\"date\":\"10/22/19\",\"CI_weekly_2_5\":\"262828\",\"CI_weekly_97_5\":\"283043\",\"y_prediction_weekly\":\"272553\",\"y_true_weekly\":\"260803\"},\n{\"date\":\"10/23/19\",\"CI_weekly_2_5\":\"270230\",\"CI_weekly_97_5\":\"291912\",\"y_prediction_weekly\":\"280573\",\"y_true_weekly\":\"268447\"},\n{\"date\":\"10/24/19\",\"CI_weekly_2_5\":\"267413\",\"CI_weekly_97_5\":\"288816\",\"y_prediction_weekly\":\"277495\",\"y_true_weekly\":\"265481\"},\n{\"date\":\"10/25/19\",\"CI_weekly_2_5\":\"265886\",\"CI_weekly_97_5\":\"289462\",\"y_prediction_weekly\":\"276403\",\"y_true_weekly\":\"269329\"},\n{\"date\":\"10/26/19\",\"CI_weekly_2_5\":\"264104\",\"CI_weekly_97_5\":\"287204\",\"y_prediction_weekly\":\"274279\",\"y_true_weekly\":\"271150\"},\n{\"date\":\"10/27/19\",\"CI_weekly_2_5\":\"269987\",\"CI_weekly_97_5\":\"294232\",\"y_prediction_weekly\":\"280382\",\"y_true_weekly\":\"278908\"},\n{\"date\":\"10/28/19\",\"CI_weekly_2_5\":\"273851\",\"CI_weekly_97_5\":\"298470\",\"y_prediction_weekly\":\"284194\",\"y_true_weekly\":\"290702\"},\n{\"date\":\"10/29/19\",\"CI_weekly_2_5\":\"277514\",\"CI_weekly_97_5\":\"302075\",\"y_prediction_weekly\":\"287978\",\"y_true_weekly\":\"295422\"},\n{\"date\":\"10/30/19\",\"CI_weekly_2_5\":\"272112\",\"CI_weekly_97_5\":\"295344\",\"y_prediction_weekly\":\"281883\",\"y_true_weekly\":\"295823\"},\n{\"date\":\"10/31/19\",\"CI_weekly_2_5\":\"273674\",\"CI_weekly_97_5\":\"296980\",\"y_prediction_weekly\":\"283600\",\"y_true_weekly\":\"300000\"},\n{\"date\":\"11/1/19\",\"CI_weekly_2_5\":\"282735\",\"CI_weekly_97_5\":\"305485\",\"y_prediction_weekly\":\"293268\",\"y_true_weekly\":\"305000\"},\n{\"date\":\"11/2/19\",\"CI_weekly_2_5\":\"294729\",\"CI_weekly_97_5\":\"319043\",\"y_prediction_weekly\":\"306107\",\"y_true_weekly\":\"308998\"},\n{\"date\":\"11/3/19\",\"CI_weekly_2_5\":\"298101\",\"CI_weekly_97_5\":\"322429\",\"y_prediction_weekly\":\"309791\",\"y_true_weekly\":\"307031\"},\n{\"date\":\"11/4/19\",\"CI_weekly_2_5\":\"308703\",\"CI_weekly_97_5\":\"334363\",\"y_prediction_weekly\":\"321415\",\"y_true_weekly\":\"300883\"},\n{\"date\":\"11/5/19\",\"CI_weekly_2_5\":\"320196\",\"CI_weekly_97_5\":\"349093\",\"y_prediction_weekly\":\"335007\",\"y_true_weekly\":\"302825\"},\n{\"date\":\"11/6/19\",\"CI_weekly_2_5\":\"330230\",\"CI_weekly_97_5\":\"360763\",\"y_prediction_weekly\":\"346095\",\"y_true_weekly\":\"301845\"},\n{\"date\":\"11/7/19\",\"CI_weekly_2_5\":\"345294\",\"CI_weekly_97_5\":\"377725\",\"y_prediction_weekly\":\"362220\",\"y_true_weekly\":\"306836\"},\n{\"date\":\"11/8/19\",\"CI_weekly_2_5\":\"347712\",\"CI_weekly_97_5\":\"380513\",\"y_prediction_weekly\":\"364982\",\"y_true_weekly\":\"307759\"},\n{\"date\":\"11/9/19\",\"CI_weekly_2_5\":\"342341\",\"CI_weekly_97_5\":\"374662\",\"y_prediction_weekly\":\"359567\",\"y_true_weekly\":\"303437\"},\n{\"date\":\"11/10/19\",\"CI_weekly_2_5\":\"352265\",\"CI_weekly_97_5\":\"385778\",\"y_prediction_weekly\":\"370074\",\"y_true_weekly\":\"313003\"},\n{\"date\":\"11/11/19\",\"CI_weekly_2_5\":\"343446\",\"CI_weekly_97_5\":\"375354\",\"y_prediction_weekly\":\"360450\",\"y_true_weekly\":\"312422\"},\n{\"date\":\"11/12/19\",\"CI_weekly_2_5\":\"344674\",\"CI_weekly_97_5\":\"375673\",\"y_prediction_weekly\":\"360823\",\"y_true_weekly\":\"317241\"},\n{\"date\":\"11/13/19\",\"CI_weekly_2_5\":\"340778\",\"CI_weekly_97_5\":\"370471\",\"y_prediction_weekly\":\"356241\",\"y_true_weekly\":\"317115\"},\n{\"date\":\"11/14/19\",\"CI_weekly_2_5\":\"332422\",\"CI_weekly_97_5\":\"361349\",\"y_prediction_weekly\":\"347590\",\"y_true_weekly\":\"313828\"},\n{\"date\":\"11/15/19\",\"CI_weekly_2_5\":\"334039\",\"CI_weekly_97_5\":\"363144\",\"y_prediction_weekly\":\"349063\",\"y_true_weekly\":\"320748\"},\n{\"date\":\"11/16/19\",\"CI_weekly_2_5\":\"331835\",\"CI_weekly_97_5\":\"360838\",\"y_prediction_weekly\":\"346693\",\"y_true_weekly\":\"324904\"},\n{\"date\":\"11/17/19\",\"CI_weekly_2_5\":\"329877\",\"CI_weekly_97_5\":\"359043\",\"y_prediction_weekly\":\"344843\",\"y_true_weekly\":\"326480\"},\n{\"date\":\"11/18/19\",\"CI_weekly_2_5\":\"332116\",\"CI_weekly_97_5\":\"362546\",\"y_prediction_weekly\":\"347651\",\"y_true_weekly\":\"328231\"},\n{\"date\":\"11/19/19\",\"CI_weekly_2_5\":\"336116\",\"CI_weekly_97_5\":\"367829\",\"y_prediction_weekly\":\"352680\",\"y_true_weekly\":\"331028\"},\n{\"date\":\"11/20/19\",\"CI_weekly_2_5\":\"348414\",\"CI_weekly_97_5\":\"382505\",\"y_prediction_weekly\":\"366224\",\"y_true_weekly\":\"344695\"},\n{\"date\":\"11/21/19\",\"CI_weekly_2_5\":\"356754\",\"CI_weekly_97_5\":\"392918\",\"y_prediction_weekly\":\"375593\",\"y_true_weekly\":\"356230\"},\n{\"date\":\"11/22/19\",\"CI_weekly_2_5\":\"357850\",\"CI_weekly_97_5\":\"395482\",\"y_prediction_weekly\":\"377268\",\"y_true_weekly\":\"375322\"},\n{\"date\":\"11/23/19\",\"CI_weekly_2_5\":\"389255\",\"CI_weekly_97_5\":\"435433\",\"y_prediction_weekly\":\"413174\",\"y_true_weekly\":\"446572\"},\n{\"date\":\"11/24/19\",\"CI_weekly_2_5\":\"402557\",\"CI_weekly_97_5\":\"451269\",\"y_prediction_weekly\":\"427922\",\"y_true_weekly\":\"475657\"},\n{\"date\":\"11/25/19\",\"CI_weekly_2_5\":\"423395\",\"CI_weekly_97_5\":\"474441\",\"y_prediction_weekly\":\"450179\",\"y_true_weekly\":\"508873\"},\n{\"date\":\"11/26/19\",\"CI_weekly_2_5\":\"489157\",\"CI_weekly_97_5\":\"554955\",\"y_prediction_weekly\":\"524792\",\"y_true_weekly\":\"593070\"},\n{\"date\":\"11/27/19\",\"CI_weekly_2_5\":\"495248\",\"CI_weekly_97_5\":\"560865\",\"y_prediction_weekly\":\"530597\",\"y_true_weekly\":\"604435\"},\n{\"date\":\"11/28/19\",\"CI_weekly_2_5\":\"495593\",\"CI_weekly_97_5\":\"559584\",\"y_prediction_weekly\":\"529915\",\"y_true_weekly\":\"601452\"},\n{\"date\":\"11/29/19\",\"CI_weekly_2_5\":\"503076\",\"CI_weekly_97_5\":\"566233\",\"y_prediction_weekly\":\"537159\",\"y_true_weekly\":\"583339\"},\n{\"date\":\"11/30/19\",\"CI_weekly_2_5\":\"487145\",\"CI_weekly_97_5\":\"542823\",\"y_prediction_weekly\":\"517326\",\"y_true_weekly\":\"524052\"},\n{\"date\":\"12/1/19\",\"CI_weekly_2_5\":\"477955\",\"CI_weekly_97_5\":\"531427\",\"y_prediction_weekly\":\"506975\",\"y_true_weekly\":\"502831\"},\n{\"date\":\"12/2/19\",\"CI_weekly_2_5\":\"455765\",\"CI_weekly_97_5\":\"506582\",\"y_prediction_weekly\":\"483080\",\"y_true_weekly\":\"478389\"},\n{\"date\":\"12/3/19\",\"CI_weekly_2_5\":\"390043\",\"CI_weekly_97_5\":\"424720\",\"y_prediction_weekly\":\"407390\",\"y_true_weekly\":\"403586\"},\n{\"date\":\"12/4/19\",\"CI_weekly_2_5\":\"376134\",\"CI_weekly_97_5\":\"409746\",\"y_prediction_weekly\":\"393232\",\"y_true_weekly\":\"390047\"},\n{\"date\":\"12/5/19\",\"CI_weekly_2_5\":\"375348\",\"CI_weekly_97_5\":\"408797\",\"y_prediction_weekly\":\"392511\",\"y_true_weekly\":\"396495\"},\n{\"date\":\"12/6/19\",\"CI_weekly_2_5\":\"365801\",\"CI_weekly_97_5\":\"399085\",\"y_prediction_weekly\":\"383215\",\"y_true_weekly\":\"395945\"},\n{\"date\":\"12/7/19\",\"CI_weekly_2_5\":\"354129\",\"CI_weekly_97_5\":\"386980\",\"y_prediction_weekly\":\"371563\",\"y_true_weekly\":\"389117\"},\n{\"date\":\"12/8/19\",\"CI_weekly_2_5\":\"352125\",\"CI_weekly_97_5\":\"384928\",\"y_prediction_weekly\":\"369562\",\"y_true_weekly\":\"390607\"},\n{\"date\":\"12/9/19\",\"CI_weekly_2_5\":\"351934\",\"CI_weekly_97_5\":\"385405\",\"y_prediction_weekly\":\"369870\",\"y_true_weekly\":\"393511\"},\n{\"date\":\"12/10/19\",\"CI_weekly_2_5\":\"350431\",\"CI_weekly_97_5\":\"383826\",\"y_prediction_weekly\":\"368377\",\"y_true_weekly\":\"385362\"},\n{\"date\":\"12/11/19\",\"CI_weekly_2_5\":\"350883\",\"CI_weekly_97_5\":\"384391\",\"y_prediction_weekly\":\"368839\",\"y_true_weekly\":\"386163\"},\n{\"date\":\"12/12/19\",\"CI_weekly_2_5\":\"344747\",\"CI_weekly_97_5\":\"377945\",\"y_prediction_weekly\":\"362630\",\"y_true_weekly\":\"378065\"},\n{\"date\":\"12/13/19\",\"CI_weekly_2_5\":\"340893\",\"CI_weekly_97_5\":\"372811\",\"y_prediction_weekly\":\"357848\",\"y_true_weekly\":\"374471\"},\n{\"date\":\"12/14/19\",\"CI_weekly_2_5\":\"335473\",\"CI_weekly_97_5\":\"366584\",\"y_prediction_weekly\":\"351777\",\"y_true_weekly\":\"367561\"},\n{\"date\":\"12/15/19\",\"CI_weekly_2_5\":\"320425\",\"CI_weekly_97_5\":\"350111\",\"y_prediction_weekly\":\"335806\",\"y_true_weekly\":\"346151\"},\n{\"date\":\"12/16/19\",\"CI_weekly_2_5\":\"308890\",\"CI_weekly_97_5\":\"336284\",\"y_prediction_weekly\":\"322909\",\"y_true_weekly\":\"324201\"},\n{\"date\":\"12/17/19\",\"CI_weekly_2_5\":\"287381\",\"CI_weekly_97_5\":\"312780\",\"y_prediction_weekly\":\"300346\",\"y_true_weekly\":\"306312\"},\n{\"date\":\"12/18/19\",\"CI_weekly_2_5\":\"268479\",\"CI_weekly_97_5\":\"292715\",\"y_prediction_weekly\":\"280482\",\"y_true_weekly\":\"279336\"},\n{\"date\":\"12/19/19\",\"CI_weekly_2_5\":\"260673\",\"CI_weekly_97_5\":\"285253\",\"y_prediction_weekly\":\"272678\",\"y_true_weekly\":\"264408\"},\n{\"date\":\"12/20/19\",\"CI_weekly_2_5\":\"264210\",\"CI_weekly_97_5\":\"288933\",\"y_prediction_weekly\":\"276310\",\"y_true_weekly\":\"267392\"},\n{\"date\":\"12/21/19\",\"CI_weekly_2_5\":\"267734\",\"CI_weekly_97_5\":\"292637\",\"y_prediction_weekly\":\"280000\",\"y_true_weekly\":\"269711\"},\n{\"date\":\"12/22/19\",\"CI_weekly_2_5\":\"276800\",\"CI_weekly_97_5\":\"304357\",\"y_prediction_weekly\":\"290662\",\"y_true_weekly\":\"277020\"},\n{\"date\":\"12/23/19\",\"CI_weekly_2_5\":\"290941\",\"CI_weekly_97_5\":\"320342\",\"y_prediction_weekly\":\"305865\",\"y_true_weekly\":\"287245\"},\n{\"date\":\"12/24/19\",\"CI_weekly_2_5\":\"308534\",\"CI_weekly_97_5\":\"339958\",\"y_prediction_weekly\":\"324508\",\"y_true_weekly\":\"296783\"},\n{\"date\":\"12/25/19\",\"CI_weekly_2_5\":\"321792\",\"CI_weekly_97_5\":\"353735\",\"y_prediction_weekly\":\"338211\",\"y_true_weekly\":\"306397\"},\n{\"date\":\"12/26/19\",\"CI_weekly_2_5\":\"329225\",\"CI_weekly_97_5\":\"360509\",\"y_prediction_weekly\":\"345132\",\"y_true_weekly\":\"311245\"},\n{\"date\":\"12/27/19\",\"CI_weekly_2_5\":\"328725\",\"CI_weekly_97_5\":\"360432\",\"y_prediction_weekly\":\"344598\",\"y_true_weekly\":\"306305\"},\n{\"date\":\"12/28/19\",\"CI_weekly_2_5\":\"331010\",\"CI_weekly_97_5\":\"362881\",\"y_prediction_weekly\":\"346860\",\"y_true_weekly\":\"307215\"},\n{\"date\":\"12/29/19\",\"CI_weekly_2_5\":\"333715\",\"CI_weekly_97_5\":\"363767\",\"y_prediction_weekly\":\"348472\",\"y_true_weekly\":\"307524\"},\n{\"date\":\"12/30/19\",\"CI_weekly_2_5\":\"335571\",\"CI_weekly_97_5\":\"364892\",\"y_prediction_weekly\":\"349682\",\"y_true_weekly\":\"306762\"},\n{\"date\":\"12/31/19\",\"CI_weekly_2_5\":\"334597\",\"CI_weekly_97_5\":\"363107\",\"y_prediction_weekly\":\"348124\",\"y_true_weekly\":\"337178\"},\n{\"date\":\"1/1/20\",\"CI_weekly_2_5\":\"336857\",\"CI_weekly_97_5\":\"365006\",\"y_prediction_weekly\":\"350275\",\"y_true_weekly\":\"355421\"},\n{\"date\":\"1/2/20\",\"CI_weekly_2_5\":\"336923\",\"CI_weekly_97_5\":\"364929\",\"y_prediction_weekly\":\"350604\",\"y_true_weekly\":\"363892\"},\n{\"date\":\"1/3/20\",\"CI_weekly_2_5\":\"337320\",\"CI_weekly_97_5\":\"364605\",\"y_prediction_weekly\":\"350759\",\"y_true_weekly\":\"368979\"},\n{\"date\":\"1/4/20\",\"CI_weekly_2_5\":\"336984\",\"CI_weekly_97_5\":\"363398\",\"y_prediction_weekly\":\"349965\",\"y_true_weekly\":\"374532\"},\n{\"date\":\"1/5/20\",\"CI_weekly_2_5\":\"337331\",\"CI_weekly_97_5\":\"363025\",\"y_prediction_weekly\":\"349744\",\"y_true_weekly\":\"381167\"},\n{\"date\":\"1/6/20\",\"CI_weekly_2_5\":\"337687\",\"CI_weekly_97_5\":\"362885\",\"y_prediction_weekly\":\"349706\",\"y_true_weekly\":\"391631\"},\n{\"date\":\"1/7/20\",\"CI_weekly_2_5\":\"330677\",\"CI_weekly_97_5\":\"355491\",\"y_prediction_weekly\":\"342616\",\"y_true_weekly\":\"361089\"},\n{\"date\":\"1/8/20\",\"CI_weekly_2_5\":\"333034\",\"CI_weekly_97_5\":\"357547\",\"y_prediction_weekly\":\"344492\",\"y_true_weekly\":\"357778\"},\n{\"date\":\"1/9/20\",\"CI_weekly_2_5\":\"329122\",\"CI_weekly_97_5\":\"353484\",\"y_prediction_weekly\":\"340361\",\"y_true_weekly\":\"355555\"},\n{\"date\":\"1/10/20\",\"CI_weekly_2_5\":\"329002\",\"CI_weekly_97_5\":\"354517\",\"y_prediction_weekly\":\"340746\",\"y_true_weekly\":\"353397\"},\n{\"date\":\"1/11/20\",\"CI_weekly_2_5\":\"336862\",\"CI_weekly_97_5\":\"364245\",\"y_prediction_weekly\":\"349186\",\"y_true_weekly\":\"351077\"},\n{\"date\":\"1/12/20\",\"CI_weekly_2_5\":\"334599\",\"CI_weekly_97_5\":\"362741\",\"y_prediction_weekly\":\"347255\",\"y_true_weekly\":\"347490\"},\n{\"date\":\"1/13/20\",\"CI_weekly_2_5\":\"332617\",\"CI_weekly_97_5\":\"360961\",\"y_prediction_weekly\":\"345387\",\"y_true_weekly\":\"340486\"},\n{\"date\":\"1/14/20\",\"CI_weekly_2_5\":\"335414\",\"CI_weekly_97_5\":\"363838\",\"y_prediction_weekly\":\"348003\",\"y_true_weekly\":\"344656\"},\n{\"date\":\"1/15/20\",\"CI_weekly_2_5\":\"338004\",\"CI_weekly_97_5\":\"367500\",\"y_prediction_weekly\":\"351008\",\"y_true_weekly\":\"340167\"},\n{\"date\":\"1/16/20\",\"CI_weekly_2_5\":\"340585\",\"CI_weekly_97_5\":\"371268\",\"y_prediction_weekly\":\"354034\",\"y_true_weekly\":\"338925\"},\n{\"date\":\"1/17/20\",\"CI_weekly_2_5\":\"339861\",\"CI_weekly_97_5\":\"370106\",\"y_prediction_weekly\":\"353072\",\"y_true_weekly\":\"336762\"},\n{\"date\":\"1/18/20\",\"CI_weekly_2_5\":\"335963\",\"CI_weekly_97_5\":\"365528\",\"y_prediction_weekly\":\"348844\",\"y_true_weekly\":\"336524\"},\n{\"date\":\"1/19/20\",\"CI_weekly_2_5\":\"334854\",\"CI_weekly_97_5\":\"363972\",\"y_prediction_weekly\":\"347370\",\"y_true_weekly\":\"337157\"},\n{\"date\":\"1/20/20\",\"CI_weekly_2_5\":\"341169\",\"CI_weekly_97_5\":\"372019\",\"y_prediction_weekly\":\"354605\",\"y_true_weekly\":\"343254\"},\n{\"date\":\"1/21/20\",\"CI_weekly_2_5\":\"347736\",\"CI_weekly_97_5\":\"379542\",\"y_prediction_weekly\":\"361660\",\"y_true_weekly\":\"343661\"},\n{\"date\":\"1/22/20\",\"CI_weekly_2_5\":\"349905\",\"CI_weekly_97_5\":\"381397\",\"y_prediction_weekly\":\"363765\",\"y_true_weekly\":\"346191\"},\n{\"date\":\"1/23/20\",\"CI_weekly_2_5\":\"355208\",\"CI_weekly_97_5\":\"386725\",\"y_prediction_weekly\":\"369104\",\"y_true_weekly\":\"348042\"},\n{\"date\":\"1/24/20\",\"CI_weekly_2_5\":\"361493\",\"CI_weekly_97_5\":\"393607\",\"y_prediction_weekly\":\"375473\",\"y_true_weekly\":\"350715\"},\n{\"date\":\"1/25/20\",\"CI_weekly_2_5\":\"359897\",\"CI_weekly_97_5\":\"391993\",\"y_prediction_weekly\":\"373958\",\"y_true_weekly\":\"349712\"},\n{\"date\":\"1/26/20\",\"CI_weekly_2_5\":\"364745\",\"CI_weekly_97_5\":\"398197\",\"y_prediction_weekly\":\"379715\",\"y_true_weekly\":\"350622\"},\n{\"date\":\"1/27/20\",\"CI_weekly_2_5\":\"354258\",\"CI_weekly_97_5\":\"386493\",\"y_prediction_weekly\":\"368909\",\"y_true_weekly\":\"342201\"},\n{\"date\":\"1/28/20\",\"CI_weekly_2_5\":\"350130\",\"CI_weekly_97_5\":\"381984\",\"y_prediction_weekly\":\"364615\",\"y_true_weekly\":\"340367\"},\n{\"date\":\"1/29/20\",\"CI_weekly_2_5\":\"344032\",\"CI_weekly_97_5\":\"376404\",\"y_prediction_weekly\":\"358919\",\"y_true_weekly\":\"337254\"},\n{\"date\":\"1/30/20\",\"CI_weekly_2_5\":\"340205\",\"CI_weekly_97_5\":\"372698\",\"y_prediction_weekly\":\"355076\",\"y_true_weekly\":\"337577\"},\n{\"date\":\"1/31/20\",\"CI_weekly_2_5\":\"332680\",\"CI_weekly_97_5\":\"365385\",\"y_prediction_weekly\":\"347955\",\"y_true_weekly\":\"338082\"},\n{\"date\":\"2/1/20\",\"CI_weekly_2_5\":\"332172\",\"CI_weekly_97_5\":\"365535\",\"y_prediction_weekly\":\"348472\",\"y_true_weekly\":\"340404\"},\n{\"date\":\"2/2/20\",\"CI_weekly_2_5\":\"326850\",\"CI_weekly_97_5\":\"358107\",\"y_prediction_weekly\":\"342334\",\"y_true_weekly\":\"334800\"}\n]\n\nconst RESPONSE_CURVE = [\n{\"spend\":\"0\",\"lower_bound_response\":\"0\",\"mean_response\":\"0\",\"upper_bound_response\":\"0\"},\n{\"spend\":\"764\",\"lower_bound_response\":\"0\",\"mean_response\":\"627.0115245\",\"upper_bound_response\":\"4183.972453\"},\n{\"spend\":\"955\",\"lower_bound_response\":\"0\",\"mean_response\":\"783.2807519\",\"upper_bound_response\":\"5229.853285\"},\n{\"spend\":\"1024\",\"lower_bound_response\":\"0\",\"mean_response\":\"839.6583541\",\"upper_bound_response\":\"5607.666961\"},\n{\"spend\":\"1477\",\"lower_bound_response\":\"0\",\"mean_response\":\"1208.53769\",\"upper_bound_response\":\"8087.803307\"},\n{\"spend\":\"1682\",\"lower_bound_response\":\"0\",\"mean_response\":\"1374.609585\",\"upper_bound_response\":\"9209.958846\"},\n{\"spend\":\"1940\",\"lower_bound_response\":\"0\",\"mean_response\":\"1582.694861\",\"upper_bound_response\":\"10622.01468\"},\n{\"spend\":\"2160\",\"lower_bound_response\":\"0\",\"mean_response\":\"1759.216925\",\"upper_bound_response\":\"11825.87575\"},\n{\"spend\":\"2317\",\"lower_bound_response\":\"0\",\"mean_response\":\"1884.621547\",\"upper_bound_response\":\"12684.85892\"},\n{\"spend\":\"2498\",\"lower_bound_response\":\"0\",\"mean_response\":\"2028.562152\",\"upper_bound_response\":\"13674.99903\"},\n{\"spend\":\"2663\",\"lower_bound_response\":\"0\",\"mean_response\":\"2159.148081\",\"upper_bound_response\":\"14577.46029\"},\n{\"spend\":\"2936\",\"lower_bound_response\":\"0\",\"mean_response\":\"2373.78966\",\"upper_bound_response\":\"16070.27738\"},\n{\"spend\":\"3103\",\"lower_bound_response\":\"0\",\"mean_response\":\"2504.161361\",\"upper_bound_response\":\"16983.23737\"},\n{\"spend\":\"3159\",\"lower_bound_response\":\"0\",\"mean_response\":\"2547.713092\",\"upper_bound_response\":\"17289.33861\"},\n{\"spend\":\"3239\",\"lower_bound_response\":\"0\",\"mean_response\":\"2609.781397\",\"upper_bound_response\":\"17726.58917\"},\n{\"spend\":\"3353\",\"lower_bound_response\":\"0\",\"mean_response\":\"2697.920249\",\"upper_bound_response\":\"18349.59419\"},\n{\"spend\":\"3440\",\"lower_bound_response\":\"0\",\"mean_response\":\"2764.934305\",\"upper_bound_response\":\"18824.98275\"},\n{\"spend\":\"3618\",\"lower_bound_response\":\"0\",\"mean_response\":\"2901.348671\",\"upper_bound_response\":\"19797.44149\"},\n{\"spend\":\"3809\",\"lower_bound_response\":\"0\",\"mean_response\":\"3046.650802\",\"upper_bound_response\":\"20840.64915\"},\n{\"spend\":\"3890\",\"lower_bound_response\":\"0\",\"mean_response\":\"3107.923901\",\"upper_bound_response\":\"21282.96763\"},\n{\"spend\":\"4041\",\"lower_bound_response\":\"0\",\"mean_response\":\"3221.580911\",\"upper_bound_response\":\"22107.38993\"},\n{\"spend\":\"4160\",\"lower_bound_response\":\"0\",\"mean_response\":\"3310.618635\",\"upper_bound_response\":\"22756.96168\"},\n{\"spend\":\"4244\",\"lower_bound_response\":\"0\",\"mean_response\":\"3373.179654\",\"upper_bound_response\":\"23215.40726\"},\n{\"spend\":\"4402\",\"lower_bound_response\":\"0\",\"mean_response\":\"3490.191703\",\"upper_bound_response\":\"24077.54704\"},\n{\"spend\":\"4458\",\"lower_bound_response\":\"0\",\"mean_response\":\"3531.453252\",\"upper_bound_response\":\"24383.05961\"},\n{\"spend\":\"4516\",\"lower_bound_response\":\"0\",\"mean_response\":\"3574.070235\",\"upper_bound_response\":\"24699.45183\"},\n{\"spend\":\"4642\",\"lower_bound_response\":\"0\",\"mean_response\":\"3666.232296\",\"upper_bound_response\":\"25386.67421\"},\n{\"spend\":\"4708\",\"lower_bound_response\":\"0\",\"mean_response\":\"3714.275354\",\"upper_bound_response\":\"25746.58526\"},\n{\"spend\":\"4807\",\"lower_bound_response\":\"0\",\"mean_response\":\"3786.036188\",\"upper_bound_response\":\"26286.3695\"},\n{\"spend\":\"4922\",\"lower_bound_response\":\"0\",\"mean_response\":\"3868.931037\",\"upper_bound_response\":\"26913.26512\"},\n{\"spend\":\"5013\",\"lower_bound_response\":\"0\",\"mean_response\":\"3934.167973\",\"upper_bound_response\":\"27409.232\"},\n{\"spend\":\"5150\",\"lower_bound_response\":\"0\",\"mean_response\":\"4031.776178\",\"upper_bound_response\":\"28155.73978\"},\n{\"spend\":\"5265\",\"lower_bound_response\":\"0\",\"mean_response\":\"4113.140159\",\"upper_bound_response\":\"28782.21138\"},\n{\"spend\":\"5408\",\"lower_bound_response\":\"0\",\"mean_response\":\"4213.577625\",\"upper_bound_response\":\"29561.00764\"},\n{\"spend\":\"5511\",\"lower_bound_response\":\"0\",\"mean_response\":\"4285.407785\",\"upper_bound_response\":\"30121.81304\"},\n{\"spend\":\"5689\",\"lower_bound_response\":\"0\",\"mean_response\":\"4408.51378\",\"upper_bound_response\":\"31090.67677\"},\n{\"spend\":\"5786\",\"lower_bound_response\":\"0\",\"mean_response\":\"4475.044656\",\"upper_bound_response\":\"31618.49216\"},\n{\"spend\":\"5872\",\"lower_bound_response\":\"0\",\"mean_response\":\"4533.69963\",\"upper_bound_response\":\"32086.35527\"},\n{\"spend\":\"6000\",\"lower_bound_response\":\"0\",\"mean_response\":\"4620.418312\",\"upper_bound_response\":\"32782.538\"},\n{\"spend\":\"6089\",\"lower_bound_response\":\"0\",\"mean_response\":\"4680.301194\",\"upper_bound_response\":\"33266.47949\"},\n{\"spend\":\"6183\",\"lower_bound_response\":\"0\",\"mean_response\":\"4743.176692\",\"upper_bound_response\":\"33777.49722\"},\n{\"spend\":\"6308\",\"lower_bound_response\":\"0\",\"mean_response\":\"4826.191701\",\"upper_bound_response\":\"34456.86173\"},\n{\"spend\":\"6475\",\"lower_bound_response\":\"0\",\"mean_response\":\"4936.028106\",\"upper_bound_response\":\"35364.16494\"},\n{\"spend\":\"6608\",\"lower_bound_response\":\"0\",\"mean_response\":\"5022.617327\",\"upper_bound_response\":\"36086.47366\"},\n{\"spend\":\"6725\",\"lower_bound_response\":\"0\",\"mean_response\":\"5098.135136\",\"upper_bound_response\":\"36721.68294\"},\n{\"spend\":\"6838\",\"lower_bound_response\":\"0\",\"mean_response\":\"5170.485338\",\"upper_bound_response\":\"37334.99013\"},\n{\"spend\":\"7024\",\"lower_bound_response\":\"0\",\"mean_response\":\"5288.312197\",\"upper_bound_response\":\"38344.09959\"},\n{\"spend\":\"7127\",\"lower_bound_response\":\"0\",\"mean_response\":\"5352.879992\",\"upper_bound_response\":\"38902.68661\"},\n{\"spend\":\"7242\",\"lower_bound_response\":\"0\",\"mean_response\":\"5424.393705\",\"upper_bound_response\":\"39526.16219\"},\n{\"spend\":\"7520\",\"lower_bound_response\":\"0\",\"mean_response\":\"5594.741109\",\"upper_bound_response\":\"41032.50199\"},\n{\"spend\":\"7675\",\"lower_bound_response\":\"0\",\"mean_response\":\"5688.155266\",\"upper_bound_response\":\"41871.83623\"},\n{\"spend\":\"7779\",\"lower_bound_response\":\"0\",\"mean_response\":\"5750.202141\",\"upper_bound_response\":\"42434.78417\"},\n{\"spend\":\"7859\",\"lower_bound_response\":\"0\",\"mean_response\":\"5797.58465\",\"upper_bound_response\":\"42867.70008\"},\n{\"spend\":\"7978\",\"lower_bound_response\":\"0\",\"mean_response\":\"5867.508435\",\"upper_bound_response\":\"43511.46541\"},\n{\"spend\":\"8172\",\"lower_bound_response\":\"0\",\"mean_response\":\"5980.068096\",\"upper_bound_response\":\"44560.45175\"},\n{\"spend\":\"8253\",\"lower_bound_response\":\"0\",\"mean_response\":\"6026.537555\",\"upper_bound_response\":\"44998.23924\"},\n{\"spend\":\"8490\",\"lower_bound_response\":\"0\",\"mean_response\":\"6160.716464\",\"upper_bound_response\":\"46278.51253\"},\n{\"spend\":\"8673\",\"lower_bound_response\":\"0\",\"mean_response\":\"6262.497667\",\"upper_bound_response\":\"47266.39136\"},\n{\"spend\":\"8791\",\"lower_bound_response\":\"0\",\"mean_response\":\"6327.282859\",\"upper_bound_response\":\"47903.06051\"},\n{\"spend\":\"8878\",\"lower_bound_response\":\"0\",\"mean_response\":\"6374.624232\",\"upper_bound_response\":\"48372.30422\"},\n{\"spend\":\"8976\",\"lower_bound_response\":\"0\",\"mean_response\":\"6427.520372\",\"upper_bound_response\":\"48900.70812\"},\n{\"spend\":\"9227\",\"lower_bound_response\":\"0\",\"mean_response\":\"6560.918557\",\"upper_bound_response\":\"50253.23739\"},\n{\"spend\":\"9562\",\"lower_bound_response\":\"0\",\"mean_response\":\"6734.306372\",\"upper_bound_response\":\"52056.49707\"},\n{\"spend\":\"9851\",\"lower_bound_response\":\"0\",\"mean_response\":\"6879.627915\",\"upper_bound_response\":\"53610.33875\"},\n{\"spend\":\"10020\",\"lower_bound_response\":\"0\",\"mean_response\":\"6962.789977\",\"upper_bound_response\":\"54518.19098\"},\n{\"spend\":\"10239\",\"lower_bound_response\":\"0\",\"mean_response\":\"7068.570688\",\"upper_bound_response\":\"55693.74601\"},\n{\"spend\":\"10554\",\"lower_bound_response\":\"0\",\"mean_response\":\"7216.816497\",\"upper_bound_response\":\"57382.80697\"},\n{\"spend\":\"10967\",\"lower_bound_response\":\"0\",\"mean_response\":\"7404.276816\",\"upper_bound_response\":\"59594.0322\"},\n{\"spend\":\"11174\",\"lower_bound_response\":\"0\",\"mean_response\":\"7495.320628\",\"upper_bound_response\":\"60700.86489\"},\n{\"spend\":\"11323\",\"lower_bound_response\":\"0\",\"mean_response\":\"7559.663514\",\"upper_bound_response\":\"61496.95511\"},\n{\"spend\":\"11620\",\"lower_bound_response\":\"0\",\"mean_response\":\"7684.973067\",\"upper_bound_response\":\"63082.22778\"},\n{\"spend\":\"11875\",\"lower_bound_response\":\"0\",\"mean_response\":\"7789.469482\",\"upper_bound_response\":\"64441.62578\"},\n{\"spend\":\"12091\",\"lower_bound_response\":\"0\",\"mean_response\":\"7875.779114\",\"upper_bound_response\":\"65591.86591\"},\n{\"spend\":\"12310\",\"lower_bound_response\":\"0\",\"mean_response\":\"7961.24947\",\"upper_bound_response\":\"66756.89016\"},\n{\"spend\":\"12635\",\"lower_bound_response\":\"0\",\"mean_response\":\"8084.363742\",\"upper_bound_response\":\"68483.55358\"},\n{\"spend\":\"13244\",\"lower_bound_response\":\"0\",\"mean_response\":\"8303.36792\",\"upper_bound_response\":\"71711.59702\"},\n{\"spend\":\"13599\",\"lower_bound_response\":\"0\",\"mean_response\":\"8424.200545\",\"upper_bound_response\":\"73588.67191\"},\n{\"spend\":\"14349\",\"lower_bound_response\":\"0\",\"mean_response\":\"8663.630948\",\"upper_bound_response\":\"77542.68212\"},\n{\"spend\":\"14684\",\"lower_bound_response\":\"0\",\"mean_response\":\"8763.8873\",\"upper_bound_response\":\"79303.54093\"},\n{\"spend\":\"14965\",\"lower_bound_response\":\"0\",\"mean_response\":\"8844.917784\",\"upper_bound_response\":\"80777.98045\"},\n{\"spend\":\"15294\",\"lower_bound_response\":\"0\",\"mean_response\":\"8936.333531\",\"upper_bound_response\":\"82501.2341\"},\n{\"spend\":\"15559\",\"lower_bound_response\":\"0\",\"mean_response\":\"9007.326408\",\"upper_bound_response\":\"83886.83391\"},\n{\"spend\":\"15834\",\"lower_bound_response\":\"0\",\"mean_response\":\"9078.574349\",\"upper_bound_response\":\"85322.38873\"},\n{\"spend\":\"16140\",\"lower_bound_response\":\"0\",\"mean_response\":\"9155.029278\",\"upper_bound_response\":\"86916.93399\"},\n{\"spend\":\"16674\",\"lower_bound_response\":\"0\",\"mean_response\":\"9281.579655\",\"upper_bound_response\":\"89692.27174\"},\n{\"spend\":\"17066\",\"lower_bound_response\":\"0\",\"mean_response\":\"9369.144073\",\"upper_bound_response\":\"91723.56219\"},\n{\"spend\":\"17506\",\"lower_bound_response\":\"0\",\"mean_response\":\"9462.300626\",\"upper_bound_response\":\"93997.35242\"},\n{\"spend\":\"17943\",\"lower_bound_response\":\"0\",\"mean_response\":\"9549.689148\",\"upper_bound_response\":\"96248.98121\"},\n{\"spend\":\"18309\",\"lower_bound_response\":\"0\",\"mean_response\":\"9619.11821\",\"upper_bound_response\":\"98129.57743\"},\n{\"spend\":\"18936\",\"lower_bound_response\":\"0\",\"mean_response\":\"9730.504512\",\"upper_bound_response\":\"101339.9798\"},\n{\"spend\":\"19267\",\"lower_bound_response\":\"0\",\"mean_response\":\"9785.649336\",\"upper_bound_response\":\"103028.9301\"},\n{\"spend\":\"20132\",\"lower_bound_response\":\"0\",\"mean_response\":\"9918.646966\",\"upper_bound_response\":\"107423.0492\"},\n{\"spend\":\"20725\",\"lower_bound_response\":\"0\",\"mean_response\":\"10001.17747\",\"upper_bound_response\":\"110418.6498\"},\n{\"spend\":\"21369\",\"lower_bound_response\":\"0\",\"mean_response\":\"10083.49762\",\"upper_bound_response\":\"113655.9925\"},\n{\"spend\":\"22031\",\"lower_bound_response\":\"0\",\"mean_response\":\"10160.79214\",\"upper_bound_response\":\"116966.1684\"},\n{\"spend\":\"24000\",\"lower_bound_response\":\"0\",\"mean_response\":\"10352.46838\",\"upper_bound_response\":\"126701.879\"},\n{\"spend\":\"25434\",\"lower_bound_response\":\"0\",\"mean_response\":\"10461.91007\",\"upper_bound_response\":\"133684.3353\"},\n{\"spend\":\"27042\",\"lower_bound_response\":\"0\",\"mean_response\":\"10560.5484\",\"upper_bound_response\":\"141400.5991\"},\n{\"spend\":\"30198\",\"lower_bound_response\":\"0\",\"mean_response\":\"10698.31481\",\"upper_bound_response\":\"156178.5597\"},\n{\"spend\":\"35698\",\"lower_bound_response\":\"0\",\"mean_response\":\"10827.54559\",\"upper_bound_response\":\"180691.6186\"}\n]\n\n\n\n\n\n</script>\n\n\n<!--\n\n    END DATA EMBED\n-->\n\n</body>\n</html>\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.202Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "D3 Map Boilerplate",
      "content": "\n\n\nGenerates this\n\n![[Screen Shot 2022-03-21 at 14.26.32 1.png]]\n\n```html\n<!DOCTYPE html>\n<meta charset=\"utf-8\">\n\n<!-- Load d3.js -->\n<script src=\"https://d3js.org/d3.v7.js\"></script>\n\n<!-- Create an element where the map will take place -->\n<svg id=\"my_dataviz\" width=\"1080\" height=\"800\"></svg>\n\n\n<script>\n\n// The svg\nconst svg = d3.select(\"svg\"),\n    width = +svg.attr(\"width\"),\n    height = +svg.attr(\"height\");\n\nconst epsilon = 1e-6;\n\n// Map and projection\nconst projection = geoAlbersUsaPr().scale(1300).translate([487.5, 305]);\n\nfunction multiplex(streams) {\n  const n = streams.length;\n  return {\n    point(x, y) { for (const s of streams) s.point(x, y); },\n    sphere() { for (const s of streams) s.sphere(); },\n    lineStart() { for (const s of streams) s.lineStart(); },\n    lineEnd() { for (const s of streams) s.lineEnd(); },\n    polygonStart() { for (const s of streams) s.polygonStart(); },\n    polygonEnd() { for (const s of streams) s.polygonEnd(); }\n  };\n}\n\n\nfunction geoAlbersUsaPr() {\n  var cache,\n      cacheStream,\n      lower48 = d3.geoAlbers(), lower48Point,\n      alaska = d3.geoConicEqualArea().rotate([154, 0]).center([-2, 58.5]).parallels([55, 65]),\n      alaskaPoint,\n      hawaii = d3.geoConicEqualArea().rotate([157, 0]).center([-3, 19.9]).parallels([8, 18]),\n      hawaiiPoint,\n      puertoRico = d3.geoConicEqualArea().rotate([66, 0]).center([0, 18]).parallels([8, 18]),\n      puertoRicoPoint,\n      point,\n      pointStream = {point: function(x, y) { point = [x, y]; }};\n\n  function albersUsa(coordinates) {\n    var x = coordinates[0], y = coordinates[1];\n    return point = null,\n        (lower48Point.point(x, y), point)\n        || (alaskaPoint.point(x, y), point)\n        || (hawaiiPoint.point(x, y), point)\n        || (puertoRicoPoint.point(x, y), point);\n  }\n\n  albersUsa.invert = function(coordinates) {\n    var k = lower48.scale(),\n        t = lower48.translate(),\n        x = (coordinates[0] - t[0]) / k,\n        y = (coordinates[1] - t[1]) / k;\n    return (y >= 0.120 && y < 0.234 && x >= -0.425 && x < -0.214 ? alaska\n        : y >= 0.166 && y < 0.234 && x >= -0.214 && x < -0.115 ? hawaii\n        : y >= 0.204 && y < 0.234 && x >= 0.320 && x < 0.380 ? puertoRico\n        : lower48).invert(coordinates);\n  };\n\n  albersUsa.stream = function(stream) {\n    return cache && cacheStream === stream ? cache : cache = multiplex([lower48.stream(cacheStream = stream), alaska.stream(stream), hawaii.stream(stream), puertoRico.stream(stream)]);\n  };\n\n  albersUsa.precision = function(_) {\n    if (!arguments.length) return lower48.precision();\n    lower48.precision(_), alaska.precision(_), hawaii.precision(_), puertoRico.precision(_);\n    return reset();\n  };\n\n  albersUsa.scale = function(_) {\n    if (!arguments.length) return lower48.scale();\n    lower48.scale(_), alaska.scale(_ * 0.35), hawaii.scale(_), puertoRico.scale(_);\n    return albersUsa.translate(lower48.translate());\n  };\n\n  albersUsa.translate = function(_) {\n    if (!arguments.length) return lower48.translate();\n    var k = lower48.scale(), x = +_[0], y = +_[1];\n\n    lower48Point = lower48\n        .translate(_)\n        .clipExtent([[x - 0.455 * k, y - 0.238 * k], [x + 0.455 * k, y + 0.238 * k]])\n        .stream(pointStream);\n\n    alaskaPoint = alaska\n        .translate([x - 0.307 * k, y + 0.201 * k])\n        .clipExtent([[x - 0.425 * k + epsilon, y + 0.120 * k + epsilon], [x - 0.214 * k - epsilon, y + 0.234 * k - epsilon]])\n        .stream(pointStream);\n\n    hawaiiPoint = hawaii\n        .translate([x - 0.205 * k, y + 0.212 * k])\n        .clipExtent([[x - 0.214 * k + epsilon, y + 0.166 * k + epsilon], [x - 0.115 * k - epsilon, y + 0.234 * k - epsilon]])\n        .stream(pointStream);\n\n    puertoRicoPoint = puertoRico\n        .translate([x + 0.350 * k, y + 0.224 * k])\n        .clipExtent([[x + 0.320 * k, y + 0.204 * k], [x + 0.380 * k, y + 0.234 * k]])\n        .stream(pointStream).point;\n\n    return reset();\n  };\n\n  function reset() {\n    cache = cacheStream = null;\n    return albersUsa;\n  }\n\n  return albersUsa.scale(1070);\n}\n\n// Create data for circles:\nconst markers = [\n  {long: -118.243683, lat: 34.052235, size: 34, color:'ff0000'}, // Los Angeles\n  {long: -147.723056, lat: 64.843611, size: 14, color:'00ff00'}, //fairbanks ak\n  {long: -77.016389, lat:38.904722, size: 56, color: '0000ff'},\n  {long: -157.9868, lat: 21.473, size: 24, color: 'ffff00'}\n];\n\n// Load external data and boot\nd3.json(\"https://raw.githubusercontent.com/holtzy/D3-graph-gallery/master/DATA/world.geojson\").then( function(data){\n\n    console.log(data.features)\n    // Filter data\n    data.features = data.features.filter( d => d.id==\"USA\")\n\n    // Draw the map\n    svg.append(\"g\")\n        .selectAll(\"path\")\n        .data(data.features)\n        .join(\"path\")\n          .attr(\"fill\", \"#b8b8b8\")\n          .attr(\"d\", d3.geoPath()\n              .projection(projection)\n          )\n        .style(\"stroke\", \"black\")\n        .style(\"opacity\", .3)\n\n    // Add circles:\n    svg\n      .selectAll(\"myCircles\")\n      .data(markers)\n      .join(\"circle\")\n        .attr(\"cx\", d => projection([d.long, d.lat])[0])\n        .attr(\"cy\", d => projection([d.long, d.lat])[1])\n        .attr(\"r\", d => d.size)\n        .style(\"fill\", d => '#'+d.color)\n        .attr(\"stroke\", \"#69b3a2\")\n        .attr(\"stroke-width\", 3)\n        .attr(\"fill-opacity\", .4)\n})\n</script>![[Screen Shot 2022-03-21 at 14.26.32.png]]\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.202Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "D3.js Centroid",
      "content": "```javascript\n\n    const svg = d3.select(DOM.svg(width, height))\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom);\n  \n  svg.selectAll(\"path\")\n    .data(geojson.features)\n    .enter()\n      .append(\"path\")\n      .attr(\"d\", path)\n      .attr('fill', '#aaa')\n      .attr('stroke', '#333')\n  \n  svg.selectAll(\"circle\")\n    .data(geojson.features)\n    .enter()\n      .append(\"circle\")\n        .attr(\"transform\", function(d) {\n          let coords = path.centroid(d.geometry);\n\n          return `translate(${coords[0]}, ${coords[1]})`\n        })\n        .attr(\"r\", \"4px\")\n        .attr(\"fill\", \"red\")\n  \n  return svg.node();\n```\n\n```js\npath =  d3.geoPath()\n  .projection(projection)\n\n```\n[[D3.js]]\n\nhttps://github.com/d3/d3/wiki/#path_centroid\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.203Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "D3.js",
      "content": "\nTo queu \n\n\n```javascript\n\nradius = d3.scaleSqrt([0, d3.max(data, d => d.value)], [0, 40])\n\n```\n\n\n\n# D3 Geo mapping\nhttps://github.com/d3/d3-geo-projection\n\nAn interesting combination of tiling and vector: \nhttps://observablehq.com/@d3/raster-vector\n\n\n# Density contours with linear binning\nhttps://observablehq.com/@d3/contourdensity-linear-binning\n\nCollision Detection\nhttps://observablehq.com/@d3/collision-detection\n\nhttps://observablehq.com/@d3/multitouch\n\nhttps://observablehq.com/@d3/sticky-force-layout\n\nhttps://observablehq.com/@d3/d3-interpolate\n\nhttps://observablehq.com/@analyzer2004/plot-gallery\n\n# [[Mapping]]\n\n#d3-mapping\n\n\nhttps://d3-graph-gallery.com/graph/bubblemap_template.html\n\n\nhttps://www.npmjs.com/package/d3-geo\nhttps://github.com/yaph/d3-geomap\n\nhttps://observablehq.com/@d3/spike-map\n\n### standard us map\nhttps://observablehq.com/@d3/u-s-map\n\n### Map w/ puerto rico\nhttps://observablehq.com/@d3/u-s-map-with-puerto-rico\nhttps://github.com/stamen/geo-albers-usa-territories\n\nhttps://observablehq.com/@d3/state-choropleth\n\nhttps://observablehq.com/@d3/zoom-to-bounding-box\n\nhttps://observablehq.com/@d3/threshold-choropleth\n\nhttps://observablehq.com/@d3/u-s-state-capitals\n\nhttps://observablehq.com/@d3/hexbin-map\n\nhttps://medium.com/geekculture/advanced-map-visualization-and-cartography-with-d3-js-geojson-topojson-2de786ece0c3\n\n\n\n### D3 and leaflet example\n\nhttps://gist.github.com/shawnbot/e6a857780ec2fe6002f7\n\n# Colors\n\nhttps://d3-graph-gallery.com/graph/custom_color.html\n\n\n---\n\n\nBubble Map With controls: \nhttps://d3-graph-gallery.com/graph/bubblemap_buttonControl.html\n\n\n---\n\n[[D3.js Centroid]]\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.204Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "DAG",
      "content": "everything is dataroom is a direct acylic graph.\n\na DAG\n\nFollowing code from: https://github.com/floatdrop/dag/blob/master/index.js\n\n``` js\nvar Dag = function Dag() {\n    if (!(this instanceof Dag)) {\n        return new Dag();\n    }\n    this._rEdges = {};\n};\n\nDag.prototype.findCycle = function findCycle(verticle) {\n    var self = this;\n    function find(start) {\n        if (!self._rEdges[start]) { return false; }\n        for (var i = 0; i < self._rEdges[start].length; i++) {\n            var parent = self._rEdges[start][i];\n            if (parent === verticle || find(parent)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    return find(verticle);\n};\n\nDag.prototype.addEdge = function addEdge(from, to) {\n    if (!this._rEdges[to]) {\n        this._rEdges[to] = [];\n    }\n\n    this._rEdges[to].push(from);\n\n    if (this.findCycle(from)) {\n        throw new Error('Cycle found: ' + from + ' -> ' + to);\n    }\n};\n\n```\n"
    },
    {
      "aliases": [],
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.205Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "DATAROOM",
      "content": "\n## Funding Model\nhttps://polar.sh/\n\n\nhttps://nwjs.readthedocs.io/en/latest/\n\n\nhttps://news.ycombinator.com/item?id=37295192\n\n```\n  Part A: Install llama.cpp and get it to serve the model:\n  --------------------------------------------------------\n  1. Install the llama.cpp repo and run make.\n  2. Download the relevant model (e.g. wizardcoder-python-34b-v1.0.Q4_K_S.gguf).\n  3. Run the llama.cpp server (e.g., ./server -t 8 -m models/wizardcoder-python-34b-v1.0.Q4_K_S.gguf -c 16384 --mlock).\n  4. Run the OpenAI like API server [also included in llama.cpp] (e.g., python ./examples/server/api_like_OAI.py).\n\n  Part B: Install Continue and connect it to llama.cpp's OpenAI like API:\n  -----------------------------------------------------------------------\n  5. Install the Continue extension in VS Code.\n  6. In the Continue extension's sidebar, click through the tutorial and then type /config to access the configuration.\n  7. In the Continue configuration, add \"from continuedev.src.continuedev.libs.llm.ggml import GGML\" at the top of the file.\n  8. In the Continue configuration, replace lines 57 to 62 (or around) with:\n\n    models=Models(\n        default=GGML(\n            max_context_length=16384,\n            server_url=\"http://localhost:8081\"\n        )\n    ),\n\n  9. Restart VS Code, and enjoy!\n```\n\n---\n\n\n\n[[firefox-plugin]]\n\nhttps://huggingface.co/EleutherAI/gpt-j-6b\n\nhttps://huggingface.co/TheBloke/WizardLM-7B-uncensored-GPTQ\n\nhttps://huggingface.co/mosaicml/mpt-7b\n\nhttps://huggingface.co/mosaicml/mpt-7b-storywriter\n\nhttps://huggingface.co/mosaicml/mpt-7b-chatl vb                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n\nhttps://pile.eleuther.ai/\n\n1679279356 #2023-03-19\n\nChatGPT wrote me this code: \n```js\nAFRAME.registerComponent('line-between', {\n  schema: {\n    start: { type: 'selector' },\n    end: { type: 'selector' }\n  },\n\n  init: function () {\n    this.line = document.createElement('a-entity');\n    this.line.setAttribute('line', {\n      color: 'red'\n    });\n    this.el.appendChild(this.line);\n    this.update();\n  },\n\n  update: function () {\n    if (!this.data.start || !this.data.end) { return; }\n\n    this.data.start.addEventListener('loaded', this.update.bind(this));\n    this.data.end.addEventListener('loaded', this.update.bind(this));\n    this.data.start.addEventListener('componentchanged', this.update.bind(this));\n    this.data.end.addEventListener('componentchanged', this.update.bind(this));\n\n    var startPos = new THREE.Vector3().setFromMatrixPosition(this.data.start.object3D.matrixWorld);\n    var endPos = new THREE.Vector3().setFromMatrixPosition(this.data.end.object3D.matrixWorld);\n    this.line.setAttribute('line', { start: startPos, end: endPos });\n  },\n\n  remove: function () {\n    this.data.start.removeEventListener('loaded', this.update.bind(this));\n    this.data.end.removeEventListener('loaded', this.update.bind(this));\n    this.data.start.removeEventListener('componentchanged', this.update.bind(this));\n    this.data.end.removeEventListener('componentchanged', this.update.bind(this));\n  }\n});\n\n```\n\n```html\n<head>\n  <title>My A-Frame Scene</title>\n  <script src=\"https://unpkg.com/aframe\"></script>\n  <script src=\"https://unpkg.com/aframe-forcegraph-component\"></script>\n</head>\n\n<body>\n  <a-scene>\n    <a-entity forcegraph=\"json-url: myGraphData.json\"></a-entity>\n  </a-scene>\n</body>\n\n```\n---\n\n# Philosophy\n\n1. As little software as possible\n2. Speak to existing engineering standards\n\t1. Dataroom is not about inventing a new standard, just revealing what is already there\n\n\n---\n\n\nLatest Version is as [[Obsidian Plugins]]\n\n\nA device, ala ModDwarf duo, that lets user plug into computer and go to a URL. \n\nGives a QR code and a Passcode / link to log in. Hooked up to Thermal printer\n\n\n---\nOEM: https://wiki.freebsd.org/arm/Raspberry%20Pi\n\n---\n\nWhen a link is added, it finds the element and updates the attribute on update. \n\n```html\n\n<component-one target=\"component-2\"></component-one>\n<component-two id=\"component-2\"></component-two>\n\n\n```\n\nif component-one updates, it sends its default attributes to component two: \n\n```html\n  <component-two id=\"component-2\" height=\"4\"\n  ></component-two>\n\n```\n\n\nJSON\n\n\n\n---\n\nBackend ?: \nhttps://docs.hathora.dev/#/tutorial_among_us\n\n---\n\n\ndesign: \n\nScan QR -code, \nwebsite gets geolocation of tag\nadd / remove information if logged in\n\ndocker up\n\n\nuses\n[[QR Code Element]]\n\n[[programming/Routes]]\n\n---\n\n\n\nDATAROOM is a web framework for generating distributed browser based software. It's ultimate goal is to make sharing high-stakes data between non-trusting parties secure and safe. Right now, think about it as JQuery for web3.\n\nAn interface for reasoning about large data pipelines written in pure HTML, CSS and Javascript.\n\nLeveraging WebRTC, WebGPU and WebASM API's, for rapid prototyping of distributed systems.\n\nhttps://github.com/lindseyjohnasterius/custom-html-element\nhttps://github.com/lindseyjohnasterius/qr-code-element\nhttps://github.com/lindseyjohnasterius/keystone-corners\nhttps://github.com/lindseyjohnasterius/html-partial\nhttps://github.com/lindseyjohnasterius/EYE (https://3y3.app/)\nhttps://github.com/lindseyjohnasterius/e-y-e\nhttps://github.com/lindseyjohnasterius/geo-map-component\nhttps://github.com/lindseyjohnasterius/geo-video-prototype\nhttps://github.com/lindseyjohnasterius/local-variable-component\nhttps://github.com/lindseyjohnasterius/zine.css\nhttps://github.com/lindseyjohnasterius/search-component\nhttps://github.com/lindseyjohnasterius/mailbranche\nhttps://github.com/lindseyjohnasterius/peer-component\nhttps://github.com/lindseyjohnasterius/upload-component\nhttps://github.com/lindseyjohnasterius/montage-organ\nhttps://github.com/lindseyjohnasterius/speech-command-component\nhttps://github.com/lindseyjohnasterius/LNSY-EDIT\nhttps://github.com/lindseyjohnasterius/generate-index\nhttps://github.com/lindseyjohnasterius/evaluate-text-expression-component\nhttps://github.com/lindseyjohnasterius/3d-graph-prototype\n\nFor hardware Checkout [[CrashDeck/README]]\n\n\n# Double Scan webRTC Sync\n\ncurrently I am using a webrtc signal server form peer.js. Unfortunately, I am seeing the problems with this. \n\n\n```js\n/*\n  *** begin ascii art ***\n\n          ,a8a,\n         ,8\" \"8,                       8I\n         d8   8b                       8I\n         88   88                       8I\n         88   88                       8I\n         Y8   8P  ,ggg,,ggg,     ,gggg,8I   ,ggg,      ,gg,   ,gg\n         `8, ,8' ,8\" \"8P\" \"8,   dP\"  \"Y8I  i8\" \"8i    d8\"\"8b,dP\"\n    8888  \"8,8\"  I8   8I   8I  i8'    ,8I  I8, ,8I   dP   ,88\"\n    `8b,  ,d8b, ,dP   8I   Yb,,d8,   ,d8b, `YbadP' ,dP  ,dP\"Y8,\n      \"Y88P\" \"Y88P'   8I   `Y8P\"Y8888P\"`Y8888P\"Y8888\"  dP\"   \"Y88\n\n  *** end ascii art ***\n\n  index.js,\n\n  This is to wire together components and prototype quick ideas, not run the \n  business logic.\n\n  Software is, above all things, a human / computer interface. This bundle of \n  text is your interface between the server and you: keep it clear and humane.\n\n*/\nimport dotenv from 'dotenv'\nimport express  from 'express'\nimport { fileURLToPath } from 'url'\nimport { dirname } from 'path'\nimport fs from 'fs'\n\nconst __filename = fileURLToPath(import.meta.url)\nconst __dirname = dirname(__filename)\ndotenv.config()\n\n\n\nconst app = express()\n\nlet PORT = process.env.PORT\nif(!PORT){\n  PORT = 3000\n}\n\n\n// Import the functions you need from the SDKs you need\n\napp.get('/',(req,res) => { \n  res.cookie('dtrm', JSON.stringify({\n    DATAROOM_KEY: process.env.DATAROOM_KEY\n  }));\n  res.sendFile(`${__dirname}/client/index.html`)\n})\n\napp.use('/', express.static(`${__dirname}/client/public`))\napp.use('/files', express.static(`${__dirname}/files`))\n\napp.post('/save-graph/:filename', express.json(), (req, res) => {\n  console.log(req.body, req.params.filename)\n  fs.writeFile(`${__dirname}/files/${req.params.filename}`, JSON.stringify(req.body), function(e){\n    res.json({'status':'complete'})\n\n  })\n})\n\n\napp.listen(3000, function () {\n    console.log('Example app listening on port 3000.');\n});\n\nfs.readdir(`${__dirname}/files/`, (err, files) => {\n    if (err) {\n        throw err;\n    }\n    files.forEach(file => {\n        console.log(file);\n    });\n});\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.205Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Data Visualization",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.206Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Databases",
      "content": "https://github.com/Level/levelup\n\n[[saisquoi.ai/MongoDB|MongoDB]]\n\n[[SQL]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.206Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Date Formatting in Javascript",
      "content": "from: https://chasem.co/notes/vanilla-js\n```js\n\nconst date = new Date()\n\nconst months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'];\n\nconst month = months[date.getMonth()]\nconst day = date.getDate()\nconst year = date.getFullYear()\n\n// January 1, 2021\nreturn `${month} ${day}, ${year}`\n\n// 1/1/2021\nreturn `${date.getMonth() + 1}/${day}/${year}`\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.206Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Development setup for Flipper Zero",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.207Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Docker",
      "content": "\n\n``` shell\ndocker-compose down -t0\n\ndocker-compose up -d\n\ndocker system prune\n\ndocker-compose run component-library /bin/sh\n\n\ndocker run -it fairenough_component-library /bin/sh\n\n```\n\n\t \nhttps://hub.docker.com/r/dynaum/node-sqlite\nhttps://stackoverflow.com/questions/57813439/how-can-i-run-my-node-js-process-with-a-permanent-sqlite-database\n\n---\n\nhttps://docs.docker.com/develop/develop-images/baseimages/\n\n---\n\nfrom: https://www.geeksforgeeks.org/how-to-create-your-own-docker-customised-image/\n\n\n\n# How to create your own Docker Customised Image ?\n\n-   Difficulty Level : [Easy](https://www.geeksforgeeks.org/easy/)\n-   Last Updated : 01 Jul, 2021\n\n**Docker** is an open-source container management service and one of the most popular tools of **DevOps** which is being popular among the deployment team. Docker is mostly used in Agile-based projects which require continuous delivery of the software. The founder, Chief Technical Officer, and Chief Architect Officer of the Docker Open source project is **Soloman Hykes**. It was launched in 2013 by **Dotcloud**, since then it is the world’s leading software container platform. For more details about the containerization using docker and it’s internal architecture [click here](https://www.geeksforgeeks.org/containerization-using-docker/). \n\nIn this article, we will see how we can create our own customized Docker images and how we can push it to the **docker hub** profile. It is good practice to push your images to docker hub profile as you don’t have to create it again and you can pull those images in your system as well as in cloud with all your work saved in it. \n\nCreating docker images is not a tedious task. We can create a docker image easily with few commands. There are two ways of creating a docker image depending upon the purpose for which you want to create the image. The first method is using **commit command** and another method is by using **Dockerfile** concept. To read more details about the components of docker ie, Docker images and Docker File [click here](https://www.geeksforgeeks.org/containerization-using-docker/). \n\nNow let’s start creating our own customized docker image using the **commit** command. Before going with our own docker image we should first set up and configure docker in our operating system. To learn more about how to setup docker you can refer to [this article](https://www.geeksforgeeks.org/how-to-install-and-configure-docker-in-ubuntu/). After successful installation let’s learn some of the docker commands which we will be using. \n\n### Commands Required\n\nThe first command is **pull** command. This command will download/pull the complete operating system within seconds depending upon your internet connectivity. The syntax is like, **docker pull image_name**. Here I am pulling alex43/ubuntu-with-git:v1.0 which is my own customized image. \n\ndocker pull alex43/ubuntu-with-git:v1.0\n\nThe second command is **run** command which we will use to run the pulled image. This command will launch my image and we will get an interactive shell/terminal of that image. The syntax is like, **-it** for an interactive terminal, **–name** to give reference name for my image launched and then my **image_name**. \n\ndocker run -it --name myos alex43/ubuntu-with-git:v1.0\n\nThe third command and the most important command for creating our own image is **commit** command. By using this command we can simply create our own image with the packages which we want from the existing image. The syntax is like, **docker commit Nameof_RunningImage your_own_name:tag**. \n\ndocker commit myos ubuntu-basicbundle:v1.0\n\nThe fourth command is **tag** command. By using this command we need to rename our image with syntax **username/image-name:tag**. Before executing this command you need to create an account on the Docker hub and you have to give the same username which you have given in the docker hub profile. \n\ndocker tag alex43/ubuntu-with-git:v1.0 alex43/ubuntu-basicbundle:v1.0\n\nThe fifth command is **login** command. By using this command we will logged in to the docker hub account through our terminal and it is required to upload our docker image to the docker hub profile.  \n\ndocker login --username alex43 --password your_passwd\n\nThe fifth command is **push** command. By using this command we can upload our own created docker image to the docker hub profile and can use it anywhere from our local system to cloud by pulling it.  \n\ndocker push alex43/ubuntu-basicbundle:v1.0\n\nSo these were the few commands with the concept which we will be using in this tutorial and I will be uploading one fresh image so that you guys can understand it in a better way.  \n\n### My Own Image\n\nNow we will create our own image from existing **alex43/ubuntu-with-git:v1.0** image and we will customize it with our needs and we will upload it. \n\n**Step 1:** The very first step is to pull the image as I have shown in the upper commands. Use the command and pull the image into your system.   \ndocker pull alex43/ubuntu-with-git:v1.0 \n\n**Step 2:** Launch that image so that we can customize it as per our needs. In the below picture you can see that at 1st we were not having vim editor in our image so it was giving error of command not found. Then I installed vim in our system by using **apt-get install vim** command. \n\n![](media/1406-5.png)\n\nIn the below image you can see that after installing vim editor when I opened abhi.txt with vim editor it didn’t gave any error and I was able to write content in that. You can also see the content using **cat** command which we already have in alex43/ubuntu-with-git:v1.0 image.  \n\n![](media/myos.png)\n\nSo it was only the step that you need to understand and apply your own concepts. You can create lots of more useful docker images to solve some industry use cases like launching a WordPress blogging site using a docker image, creating your own MySQL database image, etc. It is the basic concept which you need to understand and apply as per your needs. \n\n**Step 3:** Come out of the image by pressing **ctrl+p+q** and commit the modified image as I have explained in the above command.   \n**Step 4:** Create an account at docker hub and change the name of the image with proper syntax as explained above.   \n**Step 5:** Log in into docker hub profile from terminal using **docker login** command as explained above.   \n**Step 6:** The final task is to upload the image using push command to docker hub profile as explained above. \n\nFor step-3, step-5, and step-6 you can see the image below. Pushing your image might take some time depending upon the size of the image and the internet speed of your system. In the image, you can see I have used the commands which I explained above and it successfully uploaded my image at my docker hub profile.  \n\n![](media/img59.png)\n\nSo in this way we can create our own docker image and push it to docker hub just by using few commands.\n\n\n\n---\n\n\nhttps://aws.amazon.com/getting-started/hands-on/deploy-docker-containers/\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.207Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Drag To Right to File",
      "content": "idea: \n\nMac Os X / Windows/ Linux plugin that lets you drag a file to the right of your screen, it would then upload what ever you drug (clipping, image, file) to Obsidian notebook and add a link to it on the daily note page\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.207Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Draggable div",
      "content": "```js\n\nconst draggable = document.getElementById(\"draggable\");\nlet initialX, currentX;\n\ndraggable.addEventListener(\"dragstart\", function(event) {\n  initialX = event.clientX;\n});\n\ndraggable.addEventListener(\"drag\", function(event) {\n  currentX = event.clientX;\n});\n\ndraggable.addEventListener(\"dragend\", function() {\n  const distanceFromCenter = currentX - initialX;\n  console.log(distanceFromCenter);\n});\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.208Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Drawing AI",
      "content": "https://distill.pub/2017/feature-visualization/\n\n[[aa0ae14c9a1e05d3b105799060b7e326_MD5.png|Open: Pasted image 20231107200044.png]]\n![[aa0ae14c9a1e05d3b105799060b7e326_MD5.png]]\n\nhttps://github.com/enjalot/visxai-pattern-language\n\n\nhttps://illustrated-machine-learning.github.io/#/machine-learning/categorization\n\nhttps://www.researchgate.net/figure/Diagram-of-the-AI-data-management-system_fig1_340020862\n\nhttps://www.gptechblog.com/5-diagrams-to-help-you-understand-generative-ai/\n\nhttps://neptune.ai/blog/visualization-in-machine-learning\n\nhttps://jalammar.github.io/\n\nhttps://medium.com/analytics-vidhya/awesome-machine-learning-visualizations-5208f1617ec5\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.208Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Dürer graph",
      "content": "> In the mathematical field of graph theory, the **Dürer graph** is an undirected graph with 12 vertices and 18 edges. It is named after Albrecht Dürer, whose 1514 engraving Melencolia I includes a depiction of Dürer's solid, a convex polyhedron having the Dürer graph as its skeleton. Dürer's solid is one of only four well-covered simple convex polyhedra.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/D%C3%BCrer%20graph)\n\n\n![Durer Graph](media/Durer_Graph.jpg)\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.208Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "EE DNA Extractor Map",
      "content": "https://observablehq.com/@gena/google-earth-engine-and-mapbox-sentinel-1\n\nhttps://colab.research.google.com/drive/1cSQuYfXhXRgoPdhp7ndvVL8KbnUxuhKX#scrollTo=xbxZn3d9QUD-\n\nhttps://docs.google.com/document/d/1MKsBPTW4Dl-wgCxY7zv_rcux3wWJM_AdvGg5tHHONIw/edit\n\nExport.image is deprecated, shit\n\nhttps://gist.github.com/Hirosaji/9613b45348e785027cbcff576591ca1b\n\nhttps://blog.mapbox.com/3d-mapping-global-population-density-how-i-built-it-141785c91107\n\nhttps://observablehq.com/@gena/google-earth-engine-and-mapbox-water\n\nhttps://blog.mapbox.com/raster-imagery-to-mapbox-in-one-step-bb5f1352bbfd\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.209Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Easy Form Component",
      "content": "```js\n/*\n  \n  EASY FORM\n  by LNSY\n  lnsy.studio\n\n*/\n\n\nclass EasyForm extends HTMLElement {\n  connectedCallback(){\n    const submit = this.querySelector('input[type=\"submit\"');\n    if(submit !== null){\n      submit.addEventListener('click', (e)=>{\n        e.preventDefault(); \n        const values = this.getFormValues();\n        this.dispatchEvent(new CustomEvent('submit', {detail: values}))\n      })\n    }\n  }\n\n  getFormValues(){\n    let values = {};\n    [...this.querySelectorAll('input')].forEach(el => {\n      if(el.name === \"\" && el.type !== 'submit') return console.error('All inputs need an Name attribute');\n      switch(el.type){\n      case \"submit\":\n        break;\n      case \"number\":\n      case \"range\":\n        values[el.name] = Number(el.value);\n        break;\n      case \"checkbox\":\n        values[el.name] = el.checked;\n        break;\n      case \"text\":\n      default:\n        values[el.name] = el.value;\n      }\n    });\n\n\n    [...this.querySelectorAll('textarea')].forEach(el => {\n      if(el.name === \"\") return console.error(\"All inputs require an name attribute\");\n      values[el.name] = el.value\n    })\n    return values;\n  }\n}\n\ncustomElements.define('easy-form', EasyForm)\n\n\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.209Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Editor",
      "content": "text area, markdown.\n\n```\n#hashtags are links to other files\n@embeddings are html elements\n```\n\n[[Hashtags]]\n[[Embeddings]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.209Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Elementary Audio",
      "content": "https://github.com/elemaudio/web-examples/blob/master/planets/genSynth.js\n\nhttps://github.com/elemaudio/web-examples/blob/master/planets/drawing.js\n\nhttps://github.com/elemaudio/web-examples/blob/master/planets/app.js\n\nhttps://github.com/elemaudio/web-examples/blob/master/planets/Synth.js\n\nhttps://github.com/elemaudio/web-examples/blob/master/planets/index.html\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.210Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Embed CSS with Javascript",
      "content": "\n```js\nfunction loadCss(url) {\n    var link = document.createElement(\"link\");\n    link.type = \"text/css\";\n    link.rel = \"stylesheet\";\n    link.href = url;\n    document.getElementsByTagName(\"head\")[0].appendChild(link);\n}\n```\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.211Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Embeddings",
      "content": "Markup:\n```\n@embedding id:value; context:value\n```\n\nor\n\n```\n<d-embedding\n  id=\"embedding-id\"\n  context=\"value\"\n  \n>\n</d-embedding>\n```\nwhen rendered replaces itself with specific rendering\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.212Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Express.js",
      "content": "```js\n\n/*\n  *** begin ascii art ***\n          ,a8a,\n         ,8\" \"8,                       8I\n         d8   8b                       8I\n         88   88                       8I\n         88   88                       8I\n         Y8   8P  ,ggg,,ggg,     ,gggg,8I   ,ggg,      ,gg,   ,gg\n         `8, ,8' ,8\" \"8P\" \"8,   dP\"  \"Y8I  i8\" \"8i    d8\"\"8b,dP\"\n    8888  \"8,8\"  I8   8I   8I  i8'    ,8I  I8, ,8I   dP   ,88\"\n    `8b,  ,d8b, ,dP   8I   Yb,,d8,   ,d8b, `YbadP' ,dP  ,dP\"Y8,\n      \"Y88P\" \"Y88P'   8I   `Y8P\"Y8888P\"`Y8888P\"Y8888\"  dP\"   \"Y88\n  *** end ascii art ***\n  index.js,\n  This is to wire together components and prototype quick ideas, not run the \n  business logic.\n  Software is, above all things, a human / computer interface. This bundle of \n  text is your interface between the server and you: keep it clear and humane.\n*/\n\n\n\nconst express = require( 'express' )\nconst app = express()\nconst server = require( 'http' ).Server( app )\nconst opn = require('better-opn')\nconst Pinboard = require('node-pinboard').default;\n\nconst dotenv = require(\"dotenv\")\ndotenv.config()\n\nconst helpers = require(__dirname + '/server/helpers.js')\n\n\nlet PORT = process.env.PORT\nif(!PORT){\n  PORT = 3000\n}\n\nlet EDIT_KEY = process.env.EDIT_KEY\nif(!EDIT_KEY){\n  EDIT_KEY = 'EDITOR'\n}\n\n\n\n/*\n  APP USE\n  More on .use here: https://expressjs.com/en/guide/writing-middleware.html#writing-middleware-for-use-in-express-apps\n  Mostly for declaring which resources are available to clients\n*/\n\napp.use(express.json())\napp.use('/', express.static(`${__dirname}/client/public`))\napp.use('/', express.static(`${__dirname}/client/styles`))\napp.use('/', express.static(`${__dirname}/client/scripts`))\napp.use('/', express.static(`${__dirname}/client/scripts/vendor`))\napp.use('/', express.static(`${__dirname}/client/public`))\napp.use('/', express.static(`${__dirname}/client/public/favicon`))\n\n\n// let sessions = {\n\n// }\n\napp.get('/',(req,res) => { \n  res.cookie('dtrm', JSON.stringify({\n    DATAROOM_KEY: process.env.DATAROOM_KEY\n  }));\n  res.sendFile(`${__dirname}/client/index.html`)\n})\n\n\n/*\n    PINBOARD\n*/\n\nconst pinboard_api_token = process.env.PINBOARD_API_TOKEN\n\n\nconst pinboard = new Pinboard(pinboard_api_token);\n\n\napp.get('/pinboard',async (req,res) => { \n  res.cookie('dtrm', JSON.stringify({\n    DATAROOM_KEY: process.env.DATAROOM_KEY\n  }));\n  res.sendFile(`${__dirname}/client/pinboard.html`)\n})\n\napp.get('/pinboard-tags', async (req, res) => {\n  const all_tags = await pinboard.getTags()\n  console.log(all_tags)\n  res.json(all_tags)\n})\n\napp.get('/pinboard-posts', async (req, res) => {\n  const all_posts = await pinboard.all()\n  res.json(all_posts)\n})\n\napp.get('/pinboard-tag/:tag', async (req, res) => {\n  pinboard.get({ tag: req.params.tag, extended: true }, (err, pins) => {\n    console.log(pins)\n    res.send(pins)\n    //date: date,\n    //user: 'user',\n    //posts:\n    //[ { href: 'https://github.com/maxmechanic/node-pinboard',\n    //description: 'node pinboard',\n    //extended: '',\n    //meta: 'meta',\n    //hash: 'hash',\n    //time: 'time',\n    //shared: 'no',\n    //toread: 'yes',\n    //tags: 'git node-pinboard test' } ] }\n  })\n\n})\n\n\napp.get(`/${EDIT_KEY}`, (req, res) => {\n  res.sendFile(`${__dirname}/client/editor.html`)\n})\n\n// const isValidPhoneNumber = require(__dirname + '/server/phone-number-check.js')\n// const sendOneTimeCode = require(__dirname + '/server/one-time-code.js')\n// app.get('/verify/:phonenumber', (req, res) => {\n//   const phone_number = req.params.phonenumber\n//   isValidPhoneNumber(phone_number).then(response => {\n//     const session_id = sendOneTimeCode(phone_number)\n//     sessions[session_id] = {\n//       SESSION_ID: session_id,\n//       SESSION_KEY: helpers.getNewID(),\n//       USER_UPLOAD_KEY: helpers.getNewID(),\n//       PUBLIC_KEY: process.env.DATAROOM_KEY,\n//       STATUS: 'UNCLAIMED'\n//     }\n\n//     console.log(session_id)\n//   }).catch(e => console.log(e))\n// })\n\n// const getSignedUrl = require(__dirname + '/server/s3-upload.js')\n// app.get(`/${process.env.UPLOAD_KEY}`, async (req, res) => {\n//   res.send.json(await getSignedUrl())\n// })\n\n// app.get('/:dataroomkey', (req, res) => {\n//   const dtrm_key = req.params.dataroomkey\n//   const session = sessions[dtrm_key]\n//   if(typeof(sessions[dtrm_key]) !== 'undefined' \n//   && session.STATUS !== 'CLAIMED'){\n//     // @todo: remove the following line to enforce one login per dataroom key\n//     // session.STATUS = 'CLAIMED'\n//     res.cookie('dtrm', JSON.stringify(session));\n//     res.sendFile(`${__dirname}/client/logged-in.html`)\n//   } else {\n//     res.status(401).sendFile(`${__dirname}/client/login.html`)    \n//   }\n// })\n\n\n\n\napp.listen(PORT,() => { \n    console.log(`Running on PORT ${PORT}`)\n}) \n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.213Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Facial Recognition",
      "content": "https://justadudewhohacks.github.io/face-api.js/docs/index.html\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.213Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Fetch From Google",
      "content": "\n"
    },
    {
      "aliases": [
        "Watching Files in Node",
        "Node File Handling",
        "Files in Node.Js"
      ],
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.215Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "File Handling in Node.js",
      "content": "\n\n```js\nconst fs = require('fs');\nconst chokidar = require('chokidar');\n\nconst folderPath = '/path/to/your/folder'; // Replace with your desired folder path\n\nfunction send_command(command) {\n  console.log(`Sending command: ${command}`);\n  // Replace this with your actual code to send the command\n}\n\nfunction watchFolder(folderPath) {\n  const watcher = chokidar.watch(folderPath, {\n    persistent: true,\n    ignored: /(^|[/\\\\])\\../, // Ignore dot files\n    ignoreInitial: true, // Don't trigger on existing files when starting\n    awaitWriteFinish: true // Wait for write operations to finish before triggering\n  });\n\n  watcher.on('all', (event, filePath) => {\n    console.log(`File ${filePath} changed. Event: ${event}`);\n    send_command('RESET');\n  });\n\n  console.log(`Watching folder: ${folderPath}`);\n}\n\nwatchFolder(folderPath);\n\n\n\n```\n\nIndex: \n\n[[Watch a folder in node.js]]\n\n\nThis code reads a file, writes a file out. \n[[Node.js]]\n\n\n\n---\n\n\nThis should be reduced into a more generalized file in and writing manual. \n\nhttps://nodejs.dev/learn/the-nodejs-fs-module\n\nhttps://nodejs.org/api/fs.html\n\n```js\n\nconst fs = require('fs')\nconst matter = require('gray-matter')\nconst parser = require('@deskeen/markdown')\n\nconst dirs = [\"stubs\"]\nlet stubs = ''\n\nfunction getNewID() {\n  return 'dtrm-xxxxxxxxxxxxxxxx-'\n    .replace(/[xy]/g, function(c) {\n      var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);\n      return v.toString(16)\n  }) + Date.now()\n}\n\n\n\nwhile(dirs.length > 0){\n\tconst dir = dirs.shift()\n\tfs.readdir(dir, async (err, files) => {\n\t\tif (err) {\n\t\t\tthrow err\n\t\t}\n\t\tfiles.forEach(async file => {\n\t\t\tif(file.slice(-2) !== 'md') return\n\n\t\t\tconst yaml = matter.read(`${__dirname}/${dir}/${file}`);\n\t\t\tconst data = yaml.data\n\t\t\tconst html_code = parser.parse(yaml.content).innerHTML;\n\t\t\t\n\t\t\tif(!data.id){\n\t\t\t\tdata.id = getNewID()\n\t\t\t}\n\t\t\t\n\t\t\tif(!data.title){\n\t\t\t\tdata.title = data.id\n\t\t\t}\n\n\n\t\t\tstubs += `\n      <map-location\n        latitude=${data.latitude}\n        longitude=${data.longitude}\n        zoom=${data.zoom}\n        bearing=${data.bearing}\n        pitch=${data.pitch}\n        id=${data.id}\n      >\n        <map-marker>\n          <img src=${data.img} />\n        </map-marker>\n        <h1>${data.title}</h1>\n        <article class=\"content\">\n          ${html_code}\n        </article>\n\n      </map-location>\n\t\t\t`\n\n\n\t\t})//end files\n\n\t\tconsole.log(stubs)\n\n\t\tfs.writeFile(`${__dirname}/stubs.html`, stubs, function(err){\n\t\t\tif(err){\n\t\t\t\tconsole.log(err)\n\t\t\t}\n\t\t})\n\n\t}) // end fs.readdir\n\n\n}\n```\n\nBuilds a map file. \n\nCopy a folder with fs-extra\n```javascript\nvar fs = require('fs');\nvar fse = require('fs-extra');\n\nvar sourceDir = '/tmp/mydir';\nvar destDir = '/tmp/mynewdir';\n\n\n// if folder doesn't exists create it\nif (!fs.existsSync(destDir)){\n    fs.mkdirSync(destDir, { recursive: true });\n}\n\n//copy directory content including subfolders\nfse.copy(sourceDir, destDir, function (err) {\n  if (err) {\n    console.error(err);\n  } else {\n    console.log(\"success!\");\n  }\n}); \n```\n\n```js\nfs.readFile('./random-word.csv', (err, data) => {\n\n})\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.215Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "File handling in Browser",
      "content": "Handling files in the [[Browser]]\n\nhttps://macwright.com/2022/03/04/browsers-and-files.html\n\nhttps://github.com/GoogleChromeLabs/browser-fs-access\n\n\n\n\n\nSplit and Join files:\n\nAs an AI language model, I cannot directly write and execute code like a programmer, but I can provide you with an example of how to define a custom HTML element in JavaScript that includes the functionality you described.\n\nHere is an example implementation of the \"file-splitter\" element:\n\n```javascript\nclass FileSplitter extends HTMLElement {\n  constructor() {\n    super();\n  }\n\n  // function to split a dataURL into chunks no bigger than 14kb\n  splitFiles(dataURL) {\n    const CHUNK_SIZE = 14000;\n    const totalChunks = Math.ceil(dataURL.length / CHUNK_SIZE);\n    const chunks = [];\n\n    for (let i = 0; i < totalChunks; i++) {\n      const startIndex = i * CHUNK_SIZE;\n      const endIndex = (i + 1) * CHUNK_SIZE;\n      const chunk = {\n        index: i,\n        data: dataURL.slice(startIndex, endIndex),\n      };\n      chunks.push(chunk);\n    }\n\n    return chunks;\n  }\n\n  // function to join an array of indexed objects and return a dataURL\n  joinFiles(chunks) {\n    const data = chunks.map(chunk => chunk.data).join('');\n    const contentType = chunks[0].data.slice(5, chunks[0].data.indexOf(';'));\n    const joinedDataURL = `data:${contentType};base64,${btoa(data)}`;\n    return joinedDataURL;\n  }\n}\n\n// Define the custom element\ncustomElements.define('file-splitter', FileSplitter);\n```\n\nYou can then use this element in your HTML code as follows:\n\n```html\n<file-splitter id=\"my-file-splitter\"></file-splitter>\n\n<script>\n  const fileSplitter = document.getElementById('my-file-splitter');\n\n  // Split a dataURL into chunks\n  const chunks = fileSplitter.splitFiles('data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD...');\n\n  // Join the chunks into a dataURL\n  const joinedDataURL = fileSplitter.joinFiles(chunks);\n</script>\n```\n\nNote that this implementation assumes that the input dataURL is a base64-encoded string. If your input is a binary file or a text file in a different encoding, you will need to modify the implementation accordingly.\n\n---\n\nSure! Here is an updated implementation of the \"file-splitter\" element with a notification function that displays the progress of the split or join operation:\n\n```javascript\nclass FileSplitter extends HTMLElement {\n  constructor() {\n    super();\n  }\n\n  // function to split a dataURL into chunks no bigger than 14kb\n  splitFiles(dataURL, progressCallback) {\n    const CHUNK_SIZE = 14000;\n    const totalChunks = Math.ceil(dataURL.length / CHUNK_SIZE);\n    const chunks = [];\n\n    for (let i = 0; i < totalChunks; i++) {\n      const startIndex = i * CHUNK_SIZE;\n      const endIndex = (i + 1) * CHUNK_SIZE;\n      const chunk = {\n        index: i,\n        data: dataURL.slice(startIndex, endIndex),\n      };\n      chunks.push(chunk);\n\n      const percentage = Math.round(((i + 1) / totalChunks) * 100);\n      if (typeof progressCallback === 'function') {\n        progressCallback(percentage);\n      }\n    }\n\n    return chunks;\n  }\n\n  // function to join an array of indexed objects and return a dataURL\n  joinFiles(chunks, progressCallback) {\n    const data = chunks.map(chunk => chunk.data).join('');\n    const contentType = chunks[0].data.slice(5, chunks[0].data.indexOf(';'));\n    const joinedDataURL = `data:${contentType};base64,${btoa(data)}`;\n\n    for (let i = 0; i < chunks.length; i++) {\n      const percentage = Math.round(((i + 1) / chunks.length) * 100);\n      if (typeof progressCallback === 'function') {\n        progressCallback(percentage);\n      }\n    }\n\n    return joinedDataURL;\n  }\n}\n\n// Define the custom element\ncustomElements.define('file-splitter', FileSplitter);\n```\n\nTo use the progress callback, you can pass a function as the second argument to the `splitFiles` or `joinFiles` method. For example:\n\n```html\n<file-splitter id=\"my-file-splitter\"></file-splitter>\n\n<script>\n  const fileSplitter = document.getElementById('my-file-splitter');\n\n  // Split a dataURL into chunks and display progress\n  fileSplitter.splitFiles('data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD...', (percentage) => {\n    console.log(`Splitting progress: ${percentage}%`);\n  });\n\n  // Join the chunks into a dataURL and display progress\n  fileSplitter.joinFiles(chunks, (percentage) => {\n    console.log(`Joining progress: ${percentage}%`);\n  });\n</script>\n```\n\nThe progress callback function will be called multiple times during the split or join operation, each time with a new percentage value indicating the progress.\\\\\n\n---\n\nSure, here's an updated implementation of `joinFiles` that uses the index value to order the chunks:\n\n```javascript\njoinFiles(chunks, progressCallback) {\n  // Sort the chunks by index\n  chunks.sort((a, b) => a.index - b.index);\n\n  // Concatenate the data from each chunk\n  let data = '';\n  for (let i = 0; i < chunks.length; i++) {\n    data += chunks[i].data;\n\n    const percentage = Math.round(((i + 1) / chunks.length) * 100);\n    if (typeof progressCallback === 'function') {\n      progressCallback(percentage);\n    }\n  }\n\n  // Create the joined data URL\n  const contentType = chunks[0].data.slice(5, chunks[0].data.indexOf(';'));\n  const joinedDataURL = `data:${contentType};base64,${btoa(data)}`;\n  return joinedDataURL;\n}\n```\n\nIn this implementation, we first sort the chunks by index using the `sort` method, which takes a comparison function that compares the `index` property of each chunk. Then we concatenate the data from each chunk in order, and update the progress using the same logic as before. Finally, we create the joined data URL using the concatenated data and the content type from the first chunk.\n\nNote that this implementation assumes that the `index` property of each chunk is a unique integer value, and that the chunks are already in the correct order except for any missing chunks. If the chunks are not in order, or if some chunks are missing, you may need to modify the implementation to handle these cases.\n\n---\n\nSure, here's the updated implementation of `joinFiles` without the progress callback:\n\n```javascript\njoinFiles(chunks) {\n  // Sort the chunks by index\n  chunks.sort((a, b) => a.index - b.index);\n\n  // Concatenate the data from each chunk\n  let data = '';\n  for (let i = 0; i < chunks.length; i++) {\n    data += chunks[i].data;\n  }\n\n  // Create the joined data URL\n  const contentType = chunks[0].data.slice(5, chunks[0].data.indexOf(';'));\n  const joinedDataURL = `data:${contentType};base64,${btoa(data)}`;\n  return joinedDataURL;\n}\n```\n\nThis implementation is similar to the previous one, except that we've removed the `progressCallback` parameter and the logic that updates the progress. If you don't need to display the progress to the user, you can simply call the `joinFiles` method with the array of chunks, like this:\n\n```javascript\nconst chunks = [\n  { index: 0, data: 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAYAAACNMs+9AAAAFElEQVQYlWNkwAIYlBpU6AAhIA4m4gCQM5Fjx5c5AAAAAElFTkSuQmCC' },\n  { index: 1, data: 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAYAAACNMs+9AAAAFElEQVQYlWNkwAIYlBpU6AAhIA4m4gCQM5Fjx5c5AAAAAElFTkSuQmCC' },\n  { index: 2, data: 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAYAAACNMs+9AAAAFElEQVQYlWNkwAIYlBpU6AAhIA4m4gCQM5Fjx5c5AAAAAElFTkSuQmCC' }\n];\n\nconst fileSplitter = document.querySelector('file-splitter');\nconst joinedDataURL = fileSplitter.joinFiles(chunks);\nconsole.log(joinedDataURL);\n```\n\nThis will output the joined data URL to the console.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.216Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "FileViewer Component",
      "content": "# file-viewer\n\n`file-viewer` is a custom HTML element that can render various types of files in the browser, including images, videos, audio, text, and PDF files. The component uses the `FileReader` API to read the file data as a data URL, and then determines the file type based on the MIME type of the data URL.\n\n## Usage\n\nTo use the `file-viewer` component in your HTML page, you need to include the `file-viewer.js` script in your HTML file:\n\nhtmlCopy code\n\n`<script src=\"file-viewer.js\"></script>`\n\nYou can then use the `file-viewer` element in your HTML markup:\n\nhtmlCopy code\n\n`<file-viewer></file-viewer>`\n\nTo open a file in the `file-viewer` component, you can call the `openFile` method on the element and pass in the file data as a data URL:\n\njavascriptCopy code\n\n`const fileViewer = document.querySelector('file-viewer'); const fileDataUrl = 'data:image/png;base64,iVBORw0KG...'; fileViewer.openFile(fileDataUrl);`\n\nThe `openFile` method will determine the file type based on the MIME type of the data URL and render the file in the `file-viewer` component.\n\n## Supported File Types\n\nThe `file-viewer` component can render the following file types:\n\n-   Images: JPEG and PNG files\n-   Videos: MP4 files\n-   Audio: MP3 files\n-   Text: Plain text files\n-   PDF: PDF files\n\n## API Reference\n\n### `openFile(fileDataUrl: string)`\n\nOpens the specified file in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the file data.\n\n### `renderImage(fileDataUrl: string)`\n\nRenders the specified image in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the image data.\n\n### `renderVideo(fileDataUrl: string)`\n\nRenders the specified video in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the video data.\n\n### `renderAudio(fileDataUrl: string)`\n\nRenders the specified audio file in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the audio file data.\n\n### `renderText(fileDataUrl: string)`\n\nRenders the specified text file in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the text file data.\n\n### `renderPdf(fileDataUrl: string)`\n\nRenders the specified PDF file in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the PDF file data.# file-viewer\n\n`file-viewer` is a custom HTML element that can render various types of files in the browser, including images, videos, audio, text, and PDF files. The component uses the `FileReader` API to read the file data as a data URL, and then determines the file type based on the MIME type of the data URL.\n\n## Usage\n\nTo use the `file-viewer` component in your HTML page, you need to include the `file-viewer.js` script in your HTML file:\n\nhtmlCopy code\n\n`<script src=\"file-viewer.js\"></script>`\n\nYou can then use the `file-viewer` element in your HTML markup:\n\nhtmlCopy code\n\n`<file-viewer></file-viewer>`\n\nTo open a file in the `file-viewer` component, you can call the `openFile` method on the element and pass in the file data as a data URL:\n\njavascriptCopy code\n\n`const fileViewer = document.querySelector('file-viewer'); const fileDataUrl = 'data:image/png;base64,iVBORw0KG...'; fileViewer.openFile(fileDataUrl);`\n\nThe `openFile` method will determine the file type based on the MIME type of the data URL and render the file in the `file-viewer` component.\n\n## Supported File Types\n\nThe `file-viewer` component can render the following file types:\n\n-   Images: JPEG and PNG files\n-   Videos: MP4 files\n-   Audio: MP3 files\n-   Text: Plain text files\n-   PDF: PDF files\n\n## API Reference\n\n### `openFile(fileDataUrl: string)`\n\nOpens the specified file in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the file data.\n\n### `renderImage(fileDataUrl: string)`\n\nRenders the specified image in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the image data.\n\n### `renderVideo(fileDataUrl: string)`\n\nRenders the specified video in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the video data.\n\n### `renderAudio(fileDataUrl: string)`\n\nRenders the specified audio file in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the audio file data.\n\n### `renderText(fileDataUrl: string)`\n\nRenders the specified text file in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the text file data.\n\n### `renderPdf(fileDataUrl: string)`\n\nRenders the specified PDF file in the `file-viewer` component.\n\n-   `fileDataUrl` - A data URL that represents the PDF file data.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.217Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Flipper Runes",
      "content": "Idea: gather radio waves from around, generate a ruinic reading on flipper zero\n\n\n[[Runes]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.218Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Flipper Zero",
      "content": "https://github.com/flipperdevices/flipperzero-firmware/blob/dev/lib/subghz/protocols/princeton.c#L11\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.218Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Fretted MIDI keyboard in Javascript",
      "content": "expand / contract -- turns on / off .\n\n\n\nBrief: Fretted JS powered keyboard.\n\nhttps://stackoverflow.com/questions/22029033/can-javascript-tell-the-difference-between-left-and-right-shift-key\n\nleft -right shift key is octave down, up, respectively. \n\nArrow Keys can shift octaves, also\n\n```HTML\n<key-board></key-board> \n\n```\n\nGenerates Keyboard, single control point event to subscribe to.\n\nEditable SVG -- all states, for each key. \n\nWhen you press a key it lights up\nclick events to output key, also. Optimized for small mobile\n\n\nUp and down arrows change \"strings\"\nwhich go up and down in 4th's. \n\ntrack mouse for vibratto\n\nTop symbol keys on the right of the keyboard change the mode for that \"string\", \n\noptions: \n\ndrone, \nsustain\nsingle\n\n\n\n\nMouse -- for trackball on [[DevTerm]] and pointing stick on thinkpad -- use mouse for vibrato. \n\nXY controller outputs. \n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.219Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Full Screen API",
      "content": "```js\n// Create a full screen button\nvar fullScreenButton = document.createElement('button');\nfullScreenButton.innerText = 'Toggle Full Screen';\n\n// Add button to the document body\ndocument.body.appendChild(fullScreenButton);\n\n// Function to toggle full screen mode\nfunction toggleFullScreen() {\n  if (!document.fullscreenElement) {\n    // Enter full screen\n    if (document.documentElement.requestFullscreen) {\n      document.documentElement.requestFullscreen();\n    } else if (document.documentElement.mozRequestFullScreen) { // Firefox\n      document.documentElement.mozRequestFullScreen();\n    } else if (document.documentElement.webkitRequestFullscreen) { // Chrome, Safari and Opera\n      document.documentElement.webkitRequestFullscreen();\n    } else if (document.documentElement.msRequestFullscreen) { // IE/Edge\n      document.documentElement.msRequestFullscreen();\n    }\n  } else {\n    // Exit full screen\n    if (document.exitFullscreen) {\n      document.exitFullscreen();\n    } else if (document.mozCancelFullScreen) { // Firefox\n      document.mozCancelFullScreen();\n    } else if (document.webkitExitFullscreen) { // Chrome, Safari and Opera\n      document.webkitExitFullscreen();\n    } else if (document.msExitFullscreen) { // IE/Edge\n      document.msExitFullscreen();\n    }\n  }\n}\n\n// Attach click event listener to the full screen button\nfullScreenButton.addEventListener('click', toggleFullScreen);\n\n```\n\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.219Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Fuzzy Search node.js",
      "content": "```js\n\nconst express = require('express');\nconst fs = require('fs');\nconst path = require('path');\nconst fuzzysort = require('fuzzysort');\n\nconst app = express();\n\n// Define the folder path where your Markdown files are located\nconst folderPath = '/path/to/markdown/files';\n\n// Endpoint for fuzzy search\napp.get('/search', (req, res) => {\n  // Extract the search term from the query parameter\n  const searchTerm = req.query.term;\n\n  // Read the files in the folder\n  fs.readdirSync(folderPath).forEach(file => {\n    // Skip directories\n    if (fs.statSync(path.join(folderPath, file)).isDirectory()) {\n      return;\n    }\n\n    // Read the file content\n    const content = fs.readFileSync(path.join(folderPath, file), 'utf8');\n\n    // Perform fuzzy search on the file content\n    const result = fuzzysort.single(searchTerm, content);\n\n    // Check if the result has a match\n    if (result) {\n      const match = {\n        file: file,\n        score: result.score,\n        index: result.index,\n        target: result.target,\n      };\n      res.write(JSON.stringify(match) + '\\n');\n    }\n  });\n\n  res.end();\n});\n\n// Start the server\nconst port = 3000; // Change the port number if needed\napp.listen(port, () => {\n  console.log(`Server listening on port ${port}`);\n});\n\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.220Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Generate Index",
      "content": "Generates an index of a folder, runs OCR on it. \n\n\n```js\n#!/usr/bin/node\n\n\n\nconst fs = require('fs')\nconst sizeOf = require('image-size')\nconst FileType = require('file-type')\nconst tesseract = require(\"node-tesseract-ocr\")\n\nconst config = {\n  lang: \"eng\",\n  oem: 1,\n  psm: 3,\n}\n\n\n\n\nconst args = process.argv.slice(2)\n\nconst directory = args[0]\n\nfs.readdir(directory, (err, files) => {\n    if (err) {\n        throw err\n    }\n\n    // files object contains all files names\n    // log them on console\n\n    let index = {}\n\n    files.forEach(async file => {\n        try {\n            const file_type = await FileType.fromFile(directory + file)\n            const transcription = await tesseract.recognize(directory + file, config)\n              \n\n            const dimensions = sizeOf(directory + file)\n            index[file] = {\n                file,\n                file_type,\n                dimensions,\n                transcription\n            }\n\n            writeIndex(JSON.stringify(index))\n            console.log(index)\n        } catch(e){\n            console.log(e)\n        }\n    })\n\n})\n\n\nfunction writeIndex(index_data){\n\tfs.writeFile(`${directory}/index.json`, index_data, err => {\n\t  if (err) {\n\t    console.error(err)\n\t    return\n\t  }\n\t  //file written successfully\n\t})\n\n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.220Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Geo Map Component",
      "content": "Where we are,\n\nMarkup: \n\nResult: \n\nHTMLElement \n\nThings I need to know:\nhow to detect add  /\n\nbetter delete cycle \n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.220Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "GeoJSON",
      "content": "Discussing GeoJSON\n\nI need a verifiable way to generate a county map. \n\nCurrently I have a counties.geojson of unknown provenance (I think I downloaded it from topojson) that I can ship with, but I really think I need something that h\n\n[[tippecanoe]]\n\n\n\n## Edit GEOJSON with Node\n\nThis code works for parsing large geojson files\n\n```js\n\n//stream all data\n\nconst geojsonStream = require('geojson-stream');\nconst fs = require('fs');\nconst out = fs.createWriteStream('buildings-with-id.geojson');\nfs\n    .createReadStream(`LA_Roof_2018_geojson.geojson`)\n    .pipe(geojsonStream.parse((building, index) => {\n        if (building.geometry.coordinates === null) {\n            return null;\n        }\n        console.log(building)\n        building.id = building.properties.roof_no.toString();\n        return building;\n    }))\n    .pipe(geojsonStream.stringify())\n    .pipe(out);\n\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.221Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Get New ID",
      "content": "```javascript \n\n/*\n\n          .-.      .-.--------'\n   .--.`-' .---;`-' (_)   /\n  /  (_;  (   (_)        /\n /         )--          /\n(     --;-(      /   .-/._\n `.___.'  `\\___.'   (_/  `-\n      .-.             .-\n        /  |  .---;`-'..-.     .-.\n       /\\  | (   (_)     )   (\n      /  \\ |  )--       /     \\\n .-' /    \\| (      /  (   .   )\n(__.'      `.`\\___.'    `-' `-'\n      .----.  .-.\n        /   `(_) )-.\n       /        /   \\\n      /        /     \\\n     /      .-/.      )\n.---------'(_/  `----'\n\nGet New ID\n\nrandom gnar char generator\n\n*/\n\nfunction getNewID() {\n  return 'dtrm-xxxxxxxxxxxxxxxx-'\n    .replace(/[xy]/g, function(c) {\n      var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);\n      return v.toString(16)\n  }) + Date.now()\n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.221Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Get all Attributes",
      "content": "get all #attributes of an HTML Element\n\n```js\n\n\nclass GeoMapComponent extends HTMLElement {\n  connectedCallback(){\n    this.attrs = this.getAttributeNames().reduce((acc, name) => {\n      return {...acc, [name]: this.getAttribute(name)};\n    }, {});\n\n\n    const required_attributes = ['blah', 'blah-1', 'blah-2'];\n    this.observedAttributes = requireed_attributes;\n\n    required_attributes.forEach(attribute => {\n      if(typeof this.attrs[attribute] === 'undefined'){\n        return console.error(`The attribute ${attribute} is required;`)\n      }\n    })\n\n  }\n\n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n  \n    switch(name){\n      default:\n    }\n  }\n\n}\n\ncustomElements.define('geo-map', GeoMapComponent)\n\n\n\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.222Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Get and Set URL values",
      "content": "\n```javascript\n\n\nfunction getValuesFromURL(URL = window.location.href ){\n  const search_params = new URLSearchParams(URL)\n  let options = {\n  }\n  for (const [key, unparsed_value] of search_params) {\n    if(key !== window.location.origin + window.location.pathname + '?' ){\n      try {\n        const value = JSON.parse(decodeURI(unparsed_value))\n        options[key] = value\n      } catch {\n        options[key] = decodeURI(unparsed_value)\n      }\n    }\n  }\n  return options\n}\n\nfunction setURLValues(obj){\n  let url = window.location.origin + window.location.pathname + '?'\n  Object.keys(obj).forEach(key => {\n    url += `&${key}=${obj[key]}`\n  })\n  history.pushState(obj, '', url)\n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.223Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Git History Export",
      "content": "```bash\ngit log --pretty=format:'%h - %ad - %s' > git_history.md\n```\n\n```bash\ngit log --pretty=format: --date=relative --since=\"2023-09-01\" --until=\"2023-10-16\" > git_history.md\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.223Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Git Submodules",
      "content": "\n\n```sh\n\ngit submodule init\ngit checkout {branch name}\ngit fetch origin\ngit submodule update\n\n\n```\n\nhttps://git-scm.com/book/en/v2/Git-Tools-Submodules\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.224Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Git",
      "content": "[[Git Submodules]]\n\n[[Github SFTP Instructions]]\n\n[[Oh Shit, Git!.pdf]]\n\n\n\n\n![[Oh Shit, Git!.pdf]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.224Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Github SFTP Instructions",
      "content": "## About SSH key generation\n\nIf you don't already have an SSH key, you must generate a new SSH key to use for authentication. If you're unsure whether you already have an SSH key, you can check for existing keys. For more information, see \"[Checking for existing SSH keys](https://docs.github.com/en/github/authenticating-to-github/checking-for-existing-ssh-keys).\"\n\nIf you want to use a hardware security key to authenticate to GitHub, you must generate a new SSH key for your hardware security key. You must connect your hardware security key to your computer when you authenticate with the key pair. For more information, see the [OpenSSH 8.2 release notes](https://www.openssh.com/txt/release-8.2).\n\nIf you don't want to reenter your passphrase every time you use your SSH key, you can add your key to the SSH agent, which manages your SSH keys and remembers your passphrase.\n\n## [](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#generating-a-new-ssh-key)Generating a new SSH key\n\n1.  Open Terminal.\n    \n2.  Paste the text below, substituting in your GitHub email address.\n    \n    ```shell\n    $ ssh-keygen -t ed25519 -C \"your_email@example.com\"\n    ```\n    \n    **Note:** If you are using a legacy system that doesn't support the Ed25519 algorithm, use:\n    \n    ```shell\n    $ ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"\n    ```\n    \n\nThis creates a new SSH key, using the provided email as a label.\n\n```shell\n> Generating public/private algorithm key pair.\n```\n\n3.  When you're prompted to \"Enter a file in which to save the key,\" press Enter. This accepts the default file location.\n    \n    ```shell\n    > Enter a file in which to save the key (/home/you/.ssh/algorithm): [Press enter]\n    ```\n    \n4.  At the prompt, type a secure passphrase. For more information, see [\"Working with SSH key passphrases](https://docs.github.com/en/articles/working-with-ssh-key-passphrases).\"\n    \n    ```shell\n    > Enter passphrase (empty for no passphrase): [Type a passphrase]\n    > Enter same passphrase again: [Type passphrase again]\n    ```\n    \n\n## [](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#adding-your-ssh-key-to-the-ssh-agent)Adding your SSH key to the ssh-agent\n\nBefore adding a new SSH key to the ssh-agent to manage your keys, you should have checked for existing SSH keys and generated a new SSH key.\n\n1.  Start the ssh-agent in the background.\n    \n    ```shell\n    $ eval \"$(ssh-agent -s)\"\n    > Agent pid 59566\n    ```\n    \n    Depending on your environment, you may need to use a different command. For example, you may need to use root access by running `sudo -s -H` before starting the ssh-agent, or you may need to use `exec ssh-agent bash` or `exec ssh-agent zsh` to run the ssh-agent.\n    \n2.  Add your SSH private key to the ssh-agent. If you created your key with a different name, or if you are adding an existing key that has a different name, replace _id_ed25519_ in the command with the name of your private key file.\n    \n    ```shell\n    $ ssh-add ~/.ssh/id_ed25519\n    ```\n    \n3.  Add the SSH key to your account on GitHub. For more information, see \"[Adding a new SSH key to your GitHub account](https://docs.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account).\"\n    \n\n## [](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#generating-a-new-ssh-key-for-a-hardware-security-key)Generating a new SSH key for a hardware security key\n\nIf you are using macOS or Linux, you may need to update your SSH client or install a new SSH client prior to generating a new SSH key. For more information, see \"[Error: Unknown key type](https://docs.github.com/en/github/authenticating-to-github/error-unknown-key-type).\"\n\n1.  Insert your hardware security key into your computer.\n    \n2.  Open Terminal.\n    \n3.  Paste the text below, substituting in the email address for your account on GitHub.\n    \n    ```shell\n    $ ssh-keygen -t ed25519-sk -C \"your_email@example.com\"\n    ```\n    \n    **Note:** If the command fails and you receive the error `invalid format` or `feature not supported,` you may be using a hardware security key that does not support the Ed25519 algorithm. Enter the following command instead.\n    \n    ```shell\n    $ ssh-keygen -t ecdsa-sk -C \"your_email@example.com\"\n    ```\n    \n4.  When you are prompted, touch the button on your hardware security key.\n    \n5.  When you are prompted to \"Enter a file in which to save the key,\" press Enter to accept the default file location.\n    \n    ```shell\n    > Enter a file in which to save the key (/home/you/.ssh/id_ed25519_sk): [Press enter]\n    ```\n    \n6.  When you are prompted to type a passphrase, press **Enter**.\n    \n    ```shell\n    > Enter passphrase (empty for no passphrase): [Type a passphrase]\n    > Enter same passphrase again: [Type passphrase again]\n    ```\n    \n7.  Add the SSH key to your account on GitHub. For more information, see \"[Adding a new SSH key to your GitHub account](https://docs.github.com/en/github/authenticating-to-github/adding-a-new-ssh-key-to-your-github-account).\"\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.225Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Google Cloud Services",
      "content": "https://console.cloud.google.com/carbon\n\nCarbon offsets\n\nhttps://console.cloud.google.com/ai/document-ai?project=data-dictionary-338617\n\n\n--- \n\nBew install of google-cloud-sdk\n\nhttps://formulae.brew.sh/cask/google-cloud-sdk#default\n\nbrew install --cask google-cloud-sdk\n\nhttps://cloud.google.com/sdk/docs/install\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.225Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Google Sheets API",
      "content": "https://developers.google.com/sheets/api/guides/values\n\nhttps://developers.google.com/sheets/api/quickstart/nodejs\n\n```js\n\nconst { GoogleSpreadsheet } = require('google-spreadsheet');\n\nconst creds = require('./creds.json');\n\n/*\n\n  Columns in the spreadsheet to access\n  \n*/\n\nconst columns = [\n    \"Field Name\",\n    \"Human Name\",\n    \"Required Column\",\n    \"Nullable\",\n    \"Type\",\n    \"Human definition\",\n    \"Example\",\n    \"Specification\",\n    \"Use/reason\",\n    \"PII\"\n  ];                                   \n\n/*\n  \n  FETCH SPREADSHEET\n\n  fetches the spreadsheet from google docs\n\n  returns a promise that contains a result\n  of these values\n\n*/\nasync function fetch_spreadsheet(id){\n  console.log('Fetching Data from Google SpreadSheet...')\n  const doc = new GoogleSpreadsheet('KEY HERE');\n\n  await doc.useServiceAccountAuth({\n    client_email: creds.client_email,\n    private_key: creds.private_key ,\n  })\n\n  await doc.loadInfo(); \n  const sheet = doc.sheetsByIndex[0];\n  const rows = await sheet.getRows();\n\n  let values = [];\n  for (var i = rows.length - 1; i >= 0; i--) {\n    let new_row_values = {};\n    columns.forEach(column => {\n      const value = new Object();\n      new_row_values[column] = rows[i][column];\n    })\n    values.push(new_row_values);\n  }\n\n  return values\n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.226Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Google Slides",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.226Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Google",
      "content": "[[Reflective Earth]]\n[[Google Earth Engine]]\n\n#company\n\n\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.227Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Graduated Symbol Map Plot",
      "content": "https://map.garden/earthquakes.html\n\nhttps://observablehq.com/@nschoen28/graduated-symbol-mapping/2\n\nhttps://observablehq.com/@uwdata/cartographic-visualization\n![[Pasted image 20220224092931.png]]\nThis uses [[Vega Lite]]\n\n\nWill use an [[Albers USA Projection]]\n\n\n# D3 options\nhttps://mappingwithd3.com/getting-started/\n\n```js\n d3.json('data.geojson').then(function(bb) {\n   let width = 200, height = 200;\n   let projection = d3.geoEqualEarth();\n   projection.fitSize([width, height], bb);\n   let geoGenerator = d3.geoPath()\n   .projection(projection);\n \n   let svg = d3.select(\"body\").append('svg')\n   .style(\"width\", width).style(\"height\", height);\n\n  svg.append('g').selectAll('path')\n  .data(bb.features)\n  .join('path')\n  .attr('d', geoGenerator)\n  .attr('fill', '#088')\n  .attr('stroke', '#000');\n});\n```\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.227Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "HTML Accessibility",
      "content": "https://developer.mozilla.org/en-US/docs/Learn/Accessibility/HTML\n\nA great deal of web content can be made accessible just by making sure the correct Hypertext Markup Language elements are used for the correct purpose at all times.\n\nhttps://developer.mozilla.org/en-US/docs/Learn/Accessibility/WAI-ARIA_basics\n\n[[WAI-ARIA]] seems like a good first start\n\n[[WCAG]] \n\nhttps://wcag.com/developers/\nhttps://wcag.com/developers/3-3-2-labels-instructions/\nhttps://wcag.com/designers/\nhttps://www.w3.org/WAI/standards-guidelines/wcag/\n\nhttps://www.a11yproject.com/checklist/\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.227Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "HTML Boilerplate",
      "content": "My standard HTML Boilerplate\n```HTML\n\n<!DOCTYPE html>\n\n<html>\n  <head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"/assets/normalize.css\">\n    <title></title>\n</head>\n<body>\n\n</body>\n</html>\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.228Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "HTML Partial",
      "content": "# html-partial\n\nUntil there are proper [[HTML]] Includes you can do it the wrong way.  This component will fetch the targeted file and inject it as a string into the divs inner HTML.\n\nYou shouldn't use this in production. \n\n## Usage\n\nInclude the html-partial.js file, then you can use it like so: \n\n```html\n<html-partial src=\"html-url\"></html-partial>\n```\nor: \n\n```html\n<html-partial src=\"html-url\" shadowroot></html-partial>\n```\nThis partial will then fetch the targeted file and inject it as a string into the divs inner HTML. \n\n\nThis is the code:\n```javascript\n\nclass HTMLPartial extends HTMLElement {\n\n connectedCallback(){\n   this.shadowdom = this.getAttribute('shadowdom')\n   this.src = this.getAttribute('src')\n   if(this.src === null){\n      this.innerHTML = '<error>HTML PARTIAL REQUIRES SOURCE</error>'\n   }\n   fetch(this.src)\n    .then(res => res.text())\n    .then(res => {\n      if(this.shadowdom){\n        this.shadow = this.attachShadow({mode: 'open'})\n        this.shadow.innerHTML = res\n      } else {\n        this.innerHTML = res\n      }\n    })\n  }\n}\n\ncustomElements.define('html-partial', HTMLPartial)\n```\n\n\n```js\nclass HTMLPartial extends HTMLElement {\n\n connectedCallback(){\n   this.shadowdom = this.getAttribute('shadowdom')\n   this.src = this.getAttribute('src')\n   if(this.src === null){\n      this.innerHTML = '<error>HTML PARTIAL REQUIRES SOURCE</error>'\n   }\n   fetch(this.src)\n    .then(res => res.text())\n    .then(res => {\n      if(this.shadowdom){\n        this.shadow = this.attachShadow({mode: 'open'})\n        this.shadow.innerHTML = res\n      } else {\n        this.innerHTML = res\n      }\n    })\n  }\n}\n\ncustomElements.define('html-partial', HTMLPartial)\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.230Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "HTML Redirect",
      "content": "While trying to find a way to redirect NoScript users to the [text version of my site](https://apitman.com/txt/feed), I discovered [HTML redirects](https://www.w3docs.com/snippets/html/how-to-redirect-a-web-page-in-html.html). How did I not know about these before?! Basically, it's a way to tell the browser to navigate to a different URL, without HTTP codes or JavaScript. To use it on my site, I just put the following in the head of my index.html:\n\n```html\n<noscript>\n  <meta http-equiv=\"refresh\" content=\"0; URL='https://apitman.com/txt/feed'\" />\n</noscript>\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.232Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "HTML is Cool",
      "content": "Hi Kids, \n\nI'm here to tell you about a maddeningly fiddly, onery and often dangerous programming paradigm called \"HTML\". \n\nYou can do a lot of things with HTML, and it's important to know it for two reasons: \n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.232Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "HTML to IMG expiriment",
      "content": "Uses [[Puppeteer]] to fetch a website and generate a  png. \n\n```json\n{\n  \"name\": \"html-to-img-expiriment\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"keywords\": [\n    \"lol\"\n  ],\n  \"author\": \"LNSY\",\n  \"license\": \"ISC\",\n  \"dependencies\": {\n    \"html-to-image\": \"^1.9.0\",\n    \"puppeteer\": \"^13.3.2\"\n  }\n}\n\n\n\n```\n\n```js\n\nconst puppeteer = require('puppeteer');\nconst myArgs = process.argv.slice(2);\n\n(async () => {\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  await page.goto(myArgs[0]);\n  await page.screenshot({ path: 'example.png' });\n\n  await browser.close();\n})();\n\n\n\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.233Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "HTMLCad",
      "content": "An [[Aframe.js]] plugin that allows planning with\n- lumber and \n- shipping containers\n- \n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.233Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Hashtags",
      "content": "Each hashtag is a notebook page. \n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.234Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Headless Browser",
      "content": "[[Chrome Commands]] can be controlled from the command line\n\n\nhttps://tecadmin.net/capture-screenshot-google-chrome-headless/\n\n\n\nhttps://developers.google.com/web/updates/2017/04/headless-chrome\n\n### REPL mode (read-eval-print loop)\n\n```\nchrome --headless --disable-gpu --repl --crash-dumps-dir=./tmp https://www.chromestatus.com/[0608/112805.245285:INFO:headless_shell.cc(278)] Type a Javascript expression to evaluate or \"quit\" to exit.>>> location.href{\"result\":{\"type\":\"string\",\"value\":\"https://www.chromestatus.com/features\"}}>>> quit\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.234Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "How We Should Write Software for Environmental Purposes",
      "content": "open source, \nfew frameworks -- to build civic architecture we can't take\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.235Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Image to DataURL",
      "content": "```javascript\nfunction toDataURL(src, callback, outputFormat) {\n  let image = new Image();\n  image.crossOrigin = 'Anonymous';\n  image.onload = function () {\n    let canvas = document.createElement('canvas');\n    let ctx = canvas.getContext('2d');\n    let dataURL;\n    canvas.height = this.naturalHeight;\n    canvas.width = this.naturalWidth;\n    ctx.drawImage(this, 0, 0);\n    dataURL = canvas.toDataURL(outputFormat);\n    callback(dataURL);\n  };\n  image.src = src;\n}\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.235Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Intersphere.earth",
      "content": "https://docs.mapbox.com/help/tutorials/show-changes-over-time/\n\n\n\n\n1678303386 #2023-03-08\n\nI pitched 60 grand over 3 months for a prototype. \n\nAuth: \nhttps://firebase.google.com/docs/auth/web/firebaseui\n\n\n\n1678215638 #2023-03-07\n\n\n[[Ben Toms]]\n\nhttps://intersphere.earth/posts/HelloWorld\n\nWhat does the data format look like? \nDo you have multiple layers of wind? \n\nReducing \n\nComputational Science, \n\nEarth Engine -- Levi\n\nMapbox API is Soc 2 Type 2 compliant -- I am comfortable using its API and storage on banking applications. \n\nhttps://www.mapbox.com/platform/security/\n\n\nhttps://intersphere.earth/blog/NSFSBIR\n\n\n\nTypes of Data: \n\nBase Web Application, Screen comes up as a map,\ngeospatial viz\n\npanel: left hand corner\n\nvariable, wind speed, temp, forcast, \ndate forcast for, \n\ntexas and germany\n\n---\n\nClick on a specific point, another panel, \nother visualizations\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.236Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "JavaScript Proxy",
      "content": "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy\n\n# Proxy\n\nThe `Proxy` object enables you to create a proxy for another object, which can intercept and redefine fundamental operations for that object.\n\n## [Description](#description \"Permalink to Description\")\n\nThe `Proxy` object allows you to create an object that can be used in place of the original object, but which may redefine fundamental `Object` operations like getting, setting, and defining properties. Proxy objects are commonly used to log property accesses, validate, format, or sanitize inputs, and so on.\n\nYou create a `Proxy` with two parameters:\n\n-   `target`: the original object which you want to proxy\n-   `handler`: an object that defines which operations will be intercepted and how to redefine intercepted operations.\n\nFor example, this code defines a simple target with just two properties, and an even simpler handler with no properties:\n\n```\nconst target = {\n  message1: \"hello\",\n  message2: \"everyone\"\n};\n\nconst handler1 = {};\n\nconst proxy1 = new Proxy(target, handler1);\n```\n\nBecause the handler is empty, this proxy behaves just like the original target:\n\n```\nconsole.log(proxy1.message1); // hello\nconsole.log(proxy1.message2); // everyone\n```\n\nTo customize the proxy, we define functions on the handler object:\n\n```\nconst target = {\n  message1: \"hello\",\n  message2: \"everyone\"\n};\n\nconst handler2 = {\n  get(target, prop, receiver) {\n    return \"world\";\n  }\n};\n\nconst proxy2 = new Proxy(target, handler2);\n```\n\nHere we've provided an implementation of the [`get()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy/Proxy/get) handler, which intercepts attempts to access properties in the target.\n\nHandler functions are sometimes called _traps_, presumably because they trap calls to the target object. The very simple trap in `handler2` above redefines all property accessors:\n\n```\nconsole.log(proxy2.message1); // world\nconsole.log(proxy2.message2); // world\n```\n\nWith the help of the [`Reflect`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Reflect) class we can give some accessors the original behavior and redefine others:\n\n```\nconst target = {\n  message1: \"hello\",\n  message2: \"everyone\"\n};\n\nconst handler3 = {\n  get(target, prop, receiver) {\n    if (prop === \"message2\") {\n      return \"world\";\n    }\n    return Reflect.get(...arguments);\n  },\n};\n\nconst proxy3 = new Proxy(target, handler3);\n\nconsole.log(proxy3.message1); // hello\nconsole.log(proxy3.message2); // world\n```\n\n## [Constructor](#constructor \"Permalink to Constructor\")\n\n[`Proxy()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy/Proxy)\n\nCreates a new `Proxy` object.\n\n## [Static methods](#static_methods \"Permalink to Static methods\")\n\n[`Proxy.revocable()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy/revocable)\n\nCreates a revocable `Proxy` object.\n\n## [Examples](#examples \"Permalink to Examples\")\n\n### [Basic example](#basic_example \"Permalink to Basic example\")\n\nIn this simple example, the number `37` gets returned as the default value when the property name is not in the object. It is using the [`get()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy/Proxy/get) handler.\n\n```\nconst handler = {\n  get(obj, prop) {\n    return prop in obj ?\n      obj[prop] :\n      37;\n  }\n};\n\nconst p = new Proxy({}, handler);\np.a = 1;\np.b = undefined;\n\nconsole.log(p.a, p.b);\n//  1, undefined\n\nconsole.log('c' in p, p.c);\n//  false, 37\n```\n\n### [No-op forwarding proxy](#no-op_forwarding_proxy \"Permalink to No-op forwarding proxy\")\n\nIn this example, we are using a native JavaScript object to which our proxy will forward all operations that are applied to it.\n\n```\nconst target = {};\nconst p = new Proxy(target, {});\n\np.a = 37;\n//  operation forwarded to the target\n\nconsole.log(target.a);\n//  37\n//  (The operation has been properly forwarded!)\n```\n\nNote that while this \"no-op\" works for plain JavaScript objects, it does not work for native objects, such as DOM elements, [`Map`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map) objects, or anything that has internal slots. See [no private property forwarding](#no_private_property_forwarding) for more information.\n\n### [No private property forwarding](#no_private_property_forwarding \"Permalink to No private property forwarding\")\n\nA proxy is still another object with a different identity — it's a _proxy_ that operates between the wrapped object and the outside. As such, the proxy does not have direct access to the original object's [private properties](/en-US/docs/Web/JavaScript/Reference/Classes/Private_class_fields).\n\n```\nclass Secret {\n  #secret;\n  constructor(secret) {\n    this.#secret = secret;\n  }\n  get secret() {\n    return this.#secret.replace(/\\d+/, \"[REDACTED]\");\n  }\n}\n\nconst aSecret = new Secret(\"123456\");\nconsole.log(aSecret.secret); // [REDACTED]\n// Looks like a no-op forwarding...\nconst proxy = new Proxy(aSecret, {});\nconsole.log(proxy.secret); // TypeError: Cannot read private member #secret from an object whose class did not declare it\n```\n\nThis is because when the proxy's `get` trap is invoked, the `this` value is the `proxy` instead of the original `secret`, so `#secret` is not accessible. To fix this, use the original `secret` as `this`:\n\n```\nconst proxy = new Proxy(aSecret, {\n  get(target, prop, receiver) {\n    // By default, it looks like Reflect.get(target, prop, receiver)\n    // which has a different value of `this`\n    return target[prop];\n  },\n});\nconsole.log(proxy.secret);\n```\n\nFor methods, this means you have to redirect the method's `this` value to the original object as well:\n\n```\nclass Secret {\n  #x = 1;\n  x() { return this.#x; }\n}\n\nconst aSecret = new Secret();\nconst proxy = new Proxy(aSecret, {\n  get(target, prop, receiver) {\n    const value = target[prop];\n    if (value instanceof Function) {\n      return function (...args) {\n        return value.apply(this === receiver ? target : this, args);\n      };\n    }\n    return value;\n  },\n});\nconsole.log(proxy.x());\n```\n\nSome native JavaScript objects have properties called _[internal slots](https://tc39.es/ecma262/#sec-object-internal-methods-and-internal-slots)_, which are not accessible from JavaScript code. For example, [`Map`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map) objects have an internal slot called `[[MapData]]`, which stores the key-value pairs of the map. As such, you cannot trivially create a forwarding proxy for a map:\n\n```\nconst proxy = new Proxy(new Map(), {});\nconsole.log(proxy.size); // TypeError: get size method called on incompatible Proxy\n```\n\nYou have to use the \"`this`-recovering\" proxy illustrated above to work around this.\n\n### [Validation](#validation \"Permalink to Validation\")\n\nWith a `Proxy`, you can easily validate the passed value for an object. This example uses the [`set()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy/Proxy/set) handler.\n\n```\nconst validator = {\n  set(obj, prop, value) {\n    if (prop === 'age') {\n      if (!Number.isInteger(value)) {\n        throw new TypeError('The age is not an integer');\n      }\n      if (value > 200) {\n        throw new RangeError('The age seems invalid');\n      }\n    }\n\n    // The default behavior to store the value\n    obj[prop] = value;\n\n    // Indicate success\n    return true;\n  }\n};\n\nconst person = new Proxy({}, validator);\n\nperson.age = 100;\nconsole.log(person.age); // 100\nperson.age = 'young';    // Throws an exception\nperson.age = 300;        // Throws an exception\n```\n\n### [Extending constructor](#extending_constructor \"Permalink to Extending constructor\")\n\nA function proxy could easily extend a constructor with a new constructor. This example uses the [`construct()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy/Proxy/construct) and [`apply()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy/Proxy/apply) handlers.\n\n```\nfunction extend(sup, base) {\n  base.prototype = Object.create(sup.prototype);\n  base.prototype.constructor = new Proxy(base, {\n    construct(target, args) {\n      const obj = Object.create(base.prototype);\n      this.apply(target, obj, args);\n      return obj;\n    },\n    apply(target, that, args) {\n      sup.apply(that, args);\n      base.apply(that, args);\n    }\n  });\n  return base.prototype.constructor;\n}\n\nconst Person = function (name) {\n  this.name = name;\n};\n\nconst Boy = extend(Person, function (name, age) {\n  this.age = age;\n});\n\nBoy.prototype.gender = 'M';\n\nconst peter = new Boy('Peter', 13);\n\nconsole.log(peter.gender);  // \"M\"\nconsole.log(peter.name);    // \"Peter\"\nconsole.log(peter.age);     // 13\n```\n\n### [Manipulating DOM nodes](#manipulating_dom_nodes \"Permalink to Manipulating DOM nodes\")\n\nIn this example we use `Proxy` to toggle an attribute of two different elements: so when we set the attribute on one element, the attribute is unset on the other one.\n\nWe create a `view` object which is a proxy for an object with a `selected` property. The proxy handler defines the [`set()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy/Proxy/set) handler.\n\nWhen we assign an HTML element to `view.selected`, the element's `'aria-selected'` attribute is set to `true`. If we then assign a different element to `view.selected`, this element's `'aria-selected'` attribute is set to `true` and the previous element's `'aria-selected'` attribute is automatically set to `false`.\n\n```\nconst view = new Proxy({\n  selected: null,\n},\n{\n  set(obj, prop, newval) {\n    const oldval = obj[prop];\n\n    if (prop === 'selected') {\n      if (oldval) {\n        oldval.setAttribute('aria-selected', 'false');\n      }\n      if (newval) {\n        newval.setAttribute('aria-selected', 'true');\n      }\n    }\n\n    // The default behavior to store the value\n    obj[prop] = newval;\n\n    // Indicate success\n    return true;\n  }\n});\n\nconst item1 = document.getElementById('item-1');\nconst item2 = document.getElementById('item-2');\n\n// select item1:\nview.selected = item1;\n\nconsole.log(`item1: ${item1.getAttribute('aria-selected')}`);\n// item1: true\n\n// selecting item2 de-selects item1:\nview.selected = item2;\n\nconsole.log(`item1: ${item1.getAttribute('aria-selected')}`);\n// item1: false\n\nconsole.log(`item2: ${item2.getAttribute('aria-selected')}`);\n// item2: true\n```\n\n### [Value correction and an extra property](#value_correction_and_an_extra_property \"Permalink to Value correction and an extra property\")\n\nThe `products` proxy object evaluates the passed value and converts it to an array if needed. The object also supports an extra property called `latestBrowser` both as a getter and a setter.\n\n```\nconst products = new Proxy({\n  browsers: ['Internet Explorer', 'Netscape']\n},\n{\n  get(obj, prop) {\n    // An extra property\n    if (prop === 'latestBrowser') {\n      return obj.browsers[obj.browsers.length - 1];\n    }\n\n    // The default behavior to return the value\n    return obj[prop];\n  },\n  set(obj, prop, value) {\n    // An extra property\n    if (prop === 'latestBrowser') {\n      obj.browsers.push(value);\n      return true;\n    }\n\n    // Convert the value if it is not an array\n    if (typeof value === 'string') {\n      value = [value];\n    }\n\n    // The default behavior to store the value\n    obj[prop] = value;\n\n    // Indicate success\n    return true;\n  }\n});\n\nconsole.log(products.browsers);\n//  ['Internet Explorer', 'Netscape']\n\nproducts.browsers = 'Firefox';\n//  pass a string (by mistake)\n\nconsole.log(products.browsers);\n//  ['Firefox'] <- no problem, the value is an array\n\nproducts.latestBrowser = 'Chrome';\n\nconsole.log(products.browsers);\n//  ['Firefox', 'Chrome']\n\nconsole.log(products.latestBrowser);\n//  'Chrome'\n```\n\n### [Finding an array item object by its property](#finding_an_array_item_object_by_its_property \"Permalink to Finding an array item object by its property\")\n\nThis proxy extends an array with some utility features. As you see, you can flexibly \"define\" properties without using [`Object.defineProperties()`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/defineProperties). This example can be adapted to find a table row by its cell. In that case, the target will be [`table.rows`](/en-US/docs/Web/API/HTMLTableElement/rows \"table.rows\").\n\n```\nconst products = new Proxy([\n  { name: 'Firefox', type: 'browser' },\n  { name: 'SeaMonkey', type: 'browser' },\n  { name: 'Thunderbird', type: 'mailer' }\n],\n{\n  get(obj, prop) {\n    // The default behavior to return the value; prop is usually an integer\n    if (prop in obj) {\n      return obj[prop];\n    }\n\n    // Get the number of products; an alias of products.length\n    if (prop === 'number') {\n      return obj.length;\n    }\n\n    let result;\n    const types = {};\n\n    for (const product of obj) {\n      if (product.name === prop) {\n        result = product;\n      }\n      if (types[product.type]) {\n        types[product.type].push(product);\n      } else {\n        types[product.type] = [product];\n      }\n    }\n\n    // Get a product by name\n    if (result) {\n      return result;\n    }\n\n    // Get products by type\n    if (prop in types) {\n      return types[prop];\n    }\n\n    // Get product types\n    if (prop === 'types') {\n      return Object.keys(types);\n    }\n\n    return undefined;\n  }\n});\n\nconsole.log(products[0]);          // { name: 'Firefox', type: 'browser' }\nconsole.log(products['Firefox']);  // { name: 'Firefox', type: 'browser' }\nconsole.log(products['Chrome']);   // undefined\nconsole.log(products.browser);     // [{ name: 'Firefox', type: 'browser' }, { name: 'SeaMonkey', type: 'browser' }]\nconsole.log(products.types);       // ['browser', 'mailer']\nconsole.log(products.number);      // 3\n```\n\n### [A complete traps list example](#a_complete_traps_list_example \"Permalink to A complete traps list example\")\n\nNow in order to create a complete sample `traps` list, for didactic purposes, we will try to proxify a _non-native_ object that is particularly suited to this type of operation: the `docCookies` global object created by [a simple cookie framework](https://reference.codeproject.com/dom/document/cookie/simple_document.cookie_framework).\n\n```\n/*\n  const docCookies = ... get the \"docCookies\" object here:\n  https://reference.codeproject.com/dom/document/cookie/simple_document.cookie_framework\n*/\n\nconst docCookies = new Proxy(docCookies, {\n  get(target, key) {\n    return target[key] || target.getItem(key) || undefined;\n  },\n  set(target, key, value) {\n    if (key in target) { return false; }\n    return target.setItem(key, value);\n  },\n  deleteProperty(target, key) {\n    if (!(key in target)) { return false; }\n    return target.removeItem(key);\n  },\n  ownKeys(target) {\n    return target.keys();\n  },\n  has(target, key) {\n    return key in target || target.hasItem(key);\n  },\n  defineProperty(target, key, descriptor) {\n    if (descriptor && 'value' in descriptor) {\n      target.setItem(key, descriptor.value);\n    }\n    return target;\n  },\n  getOwnPropertyDescriptor(target, key) {\n    const value = target.getItem(key);\n    return value ? {\n      value,\n      writable: true,\n      enumerable: true,\n      configurable: false,\n    } : undefined;\n  },\n});\n\n/* Cookies test */\n\nconsole.log(docCookies.myCookie1 = 'First value');\nconsole.log(docCookies.getItem('myCookie1'));\n\ndocCookies.setItem('myCookie1', 'Changed value');\nconsole.log(docCookies.myCookie1);\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.238Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "JavaScript Sort",
      "content": "The call to [arr.sort()](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/sort) sorts the array _in place_, changing its element order.\n\nIt also returns the sorted array, but the returned value is usually ignored, as `arr` itself is modified.\n\nFor instance:\n\n`let arr = [ 1, 2, 15 ];  // the method reorders the content of arr arr.sort();  alert( arr );  // _1, 15, 2_`\n\nDid you notice anything strange in the outcome?\n\nThe order became `1, 15, 2`. Incorrect. But why?\n\n**The items are sorted as strings by default.**\n\nLiterally, all elements are converted to strings for comparisons. For strings, lexicographic ordering is applied and indeed `\"2\" > \"15\"`.\n\nTo use our own sorting order, we need to supply a function as the argument of `arr.sort()`.\n\nThe function should compare two arbitrary values and return:\n\n`function compare(a, b) {   if (a > b) return 1; // if the first value is greater than the second   if (a == b) return 0; // if values are equal   if (a < b) return -1; // if the first value is less than the second }`\n\nFor instance, to sort as numbers:\n\n[](https://javascript.info/array-methods# \"run\")\n\n[](https://javascript.info/array-methods# \"open in sandbox\")\n\n`function compareNumeric(a, b) {   if (a > b) return 1;   if (a == b) return 0;   if (a < b) return -1; }  let arr = [ 1, 2, 15 ];  _arr.sort(compareNumeric);_  alert(arr);  // _1, 2, 15_`\n\nNow it works as intended.\n\nLet’s step aside and think what’s happening. The `arr` can be array of anything, right? It may contain numbers or strings or objects or whatever. We have a set of _some items_. To sort it, we need an _ordering function_ that knows how to compare its elements. The default is a string order.\n\nThe `arr.sort(fn)` method implements a generic sorting algorithm. We don’t need to care how it internally works (an optimized [quicksort](https://en.wikipedia.org/wiki/Quicksort) or [Timsort](https://en.wikipedia.org/wiki/Timsort) most of the time). It will walk the array, compare its elements using the provided function and reorder them, all we need is to provide the `fn` which does the comparison.\n\nBy the way, if we ever want to know which elements are compared – nothing prevents from alerting them:\n\n[](https://javascript.info/array-methods# \"run\")\n\n[](https://javascript.info/array-methods# \"open in sandbox\")\n\n`[1, -2, 15, 2, 0, 8].sort(function(a, b) {   alert( a + \" <> \" + b );   return a - b; });`\n\nThe algorithm may compare an element with multiple others in the process, but it tries to make as few comparisons as possible.\n\nA comparison function may return any number\n\nActually, a comparison function is only required to return a positive number to say “greater” and a negative number to say “less”.\n\nThat allows to write shorter functions:\n\n[](https://javascript.info/array-methods# \"run\")\n\n[](https://javascript.info/array-methods# \"open in sandbox\")\n\n`let arr = [ 1, 2, 15 ];  arr.sort(function(a, b) { return a - b; });  alert(arr);  // _1, 2, 15_`\n\nArrow functions for the best\n\nRemember [arrow functions](https://javascript.info/arrow-functions-basics)? We can use them here for neater sorting:\n\n`arr.sort( (a, b) => a - b );`\n\nThis works exactly the same as the longer version above.\n\nUse `localeCompare` for strings\n\nRemember [strings](https://javascript.info/string#correct-comparisons) comparison algorithm? It compares letters by their codes by default.\n\nFor many alphabets, it’s better to use `str.localeCompare` method to correctly sort letters, such as `Ö`.\n\nFor example, let’s sort a few countries in German:\n\n[](https://javascript.info/array-methods# \"run\")\n\n[](https://javascript.info/array-methods# \"open in sandbox\")\n\n`let countries = ['Österreich', 'Andorra', 'Vietnam'];  alert( countries.sort( (a, b) => a > b ? 1 : -1) ); // Andorra, Vietnam, Österreich (wrong)  alert( countries.sort( (a, b) => a.localeCompare(b) ) ); // Andorra,Österreich,Vietnam (correct!)`\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.239Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "JavaScript",
      "content": "javascript is inverted c -- \nwhere c has you define parts of memory and assign it variables of a type,\njavascript lets you assign whatever to whatever, so you really should think about every variable as a snippet of memory\n\n```js\n\tthis.width = +this.svg.attr('width');\n    this.height = +this.svg.attr('height');\n```\n\n'+' before a variable casts it to a number in Javascript. \n\n---\n\nhttps://gist.github.com/yuval-a/d5794cc1439c08af085f\n\n```javascript\n// Array literal (= []) is faster than Array constructor (new Array())\n// http://jsperf.com/new-array-vs-literal/15\nvar array = [];\n\n// Object literal (={}) is faster than Object constructor (new Object())\n// http://jsperf.com/new-array-vs-literal/26\nvar obj = {};\n\n// property === undefined is faster than hasOwnProperty(property)\n// Note: don't use this in cases where 'undefined' is a possible value for your properties\n// http://jsperf.com/hasownproperty-vs-in-vs-undefined/17\n\nif (obj.property === undefined) { ... }\n\n// createElement('img') is faster than new Image()\n// http://jsperf.com/new-image-vs-createelement-img/8\nvar img = createElement('img');\n\n// fastest way to set *any* attribute on an element object is element[attribute] = value\n// to set a data attribute, use setAttribute (see below).\n// For getting data attributes you can use camelCase (e.g. elem['dataName']) - *but! \n// only if the data-attribute was not created dynamically (i.e. it was already inside the html element),\n// otherwise use getAttribute('data-x');\n// http://jsperf.com/attribute-vs-setattribute/3\nvar elem = document.getElementById('bla');\nelem['attribute'] = value;\n\n\n// className = is faster than classList.add\n// http://jsperf.com/classname-vs-classlist-showdown/5\nvar element.className = 'classa classb classc';\n\n// textContent = is faster than appendChild(createTextNode)\n// http://jsperf.com/textcontent-vs-createtextelement/49\nelement.textContent = 'text';\n\n// setAttribute('data-x') is faster than dataset.x = \n// http://jsperf.com/dataset-vs-setattribute-simple\nelement.setAttribute('data-x','x value');\n\n// Array.isArray() is currently the fastest way to check if a variable is an Array (this is a 2017 update for the gist!)\n// https://jsperf.com/array-isarray-vs-instanceof-array/5\nArray.isArray(arr);\n\n                                 \n// Using substring and indexOf is *always* much faster than using RegEx\n// http://jsperf.com/regex-vs-substring-one-way-data-binding\n\n\n// If you need to dereference more than once - store in a var:\n// http://jsperf.com/assign-first-vs-direct-reference\nvar n = o.one.two.three.four.name;\nif (n !== undefined) var w = n;\n\n// this || that, faster than if (!this) that:\n// http://jsperf.com/false-vs-or\nvar yes = false;\nvar v = yes || 2;\n\n// typeof faster than isNaN():\n// http://jsperf.com/isnan-vs-typeof/9\ntypeof(n) === 'number'\n\n// A short, fast way to do String.startsWith() check,\n// taken from: http://stackoverflow.com/a/4579228/522169\nhaystack.lastIndexOf(needle, 0) === 0\n\n// document.getElementById is faster than document.querySelector\ndocument.getElementById('id');\n\n// Use x | 0 instead of Math.floor\n// from https://hacks.mozilla.org/2013/05/optimizing-your-javascript-game-for-firefox-os/\nvar x = 5.4563432 | 0; // x = 5;\n\n// A list of comprehensive bitwise optimizations (using bitwise operations for common math functions \n// instead of the native ones)\nhttps://galacticmilk.com/journal/2011/11/bitwise-gems-and-other-optimizations/\n\n\n// Array.filter() faster than filtering \"manually\" with a for loop:\n// https://www.measurethat.net/Benchmarks/ShowResult/88\n\n// Trim last character: slice is fastest\n// https://jsperf.com/trim-last-char\nvar str = \"Dollar$\";\nstr = str.slice(0,-1); // str = \"Dollar\"\n\n// if you have a function working on an array, the best place to check for the length of the array - is inside of the function in the\n// beginning. It is FASTER than first checking for length outside and then calling - and it is FASTER than initializing a for loop\n// for an empty array. Also tested and measured on NodeJS\n// https://jsperf.com/where-to-check-length\n\nfunction iterate(arr) {\n   if (arr.length === 0) return;\n}\n\n```\n\n\nI've seen somewhere that when doing a simple for loop, it is more performant  \nto count backwards, but I've always been to lazy to check.  \n\n```js\nfor (let i=10; i>0; i--)\n```\n\nis more performant than\n\n```js\n\nfor (let i=0; i<10; i++)\n\n```\n\nAlso, in very big arrays it is nice to cache the length of the array when looping over them.  \nI wrote a post a while ago if you are curious! [http://estebansastre.com/blog/index.php?controller=post&action=view&id_post=25](http://estebansastre.com/blog/index.php?controller=post&action=view&id_post=25)\n\n\nCounting backward, it's not really more performant. It's just \"better\" because you can write it this way (remember 0 means false) :\n\n```js\n\tfor (let i=10; i--;)\n```\n\nLess character, only one variable and testing the value (not an expression).  \nBy the way, since the last version of browser : let and var have the same performance.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.240Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "JavasScript Promises",
      "content": "```javascript\n\nconst promise1 = Promise.resolve(3);\nconst promise2 = 42;\nconst promise3 = new Promise((resolve, reject) => {\n  setTimeout(resolve, 100, 'foo');\n});\n\nPromise.all([promise1, promise2, promise3]).then((values) => {\n  console.log(values);\n});\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.241Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Javascript Arrays",
      "content": "![[Screenshot 2023-07-26 at 10.10.46 AM.png]]\n\n![[Screenshot 2023-07-26 at 10.10.42 AM.png]]\n\n![[Screenshot 2023-07-26 at 10.10.37 AM.png]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.241Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Javascript Imports",
      "content": "# Javascript Imports\n## Overview\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.241Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Javascript Libraries",
      "content": "[[Javascript Spreadsheets]]\n\nhttps://jspreadsheets.com/clusterize/\nhttps://jspreadsheets.com/ag-grid/\nhttps://jspreadsheets.com/luckysheet/\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.242Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Jetson Nano",
      "content": "https://developer.nvidia.com/embedded/jetson-nano-developer-kit\nhttps://www.waveshare.com/pr%C3%A5oduct/ai/boards-kits/jetson-nano/jetson-nano-dev-kit-a.htm?sku=21659\n\nhttps://www.reddit.com/r/MachineLearning/comments/12220vj/d_is_it_possible_to_run_large_language_models/\n\n\nhttps://www.amazon.com/NVIDIA-Jetson-Orin-64GB-Developer/dp/B0BYGB3WV4?source=ps-sl-shoppingads-lpcontext&ref_=fplfs&psc=1&smid=ATVPDKIKX0DER\n\n[[AI BOX]]\n"
    },
    {
      "aliases": [
        "D3 Legends"
      ],
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.243Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Legends in D3.js",
      "content": "\n[[D3.js]]\n\n\nhttps://d3-graph-gallery.com/graph/bubble_legend.html\n\n![[Pasted image 20220518141648.png]]\n\n```html\n<!DOCTYPE html>\n<meta charset=\"utf-8\">\n\n<!-- Load d3.js -->\n<script src=\"https://d3js.org/d3.v6.js\"></script>\n\n<!-- Create a div where the graph will take place -->\n<div id=\"my_dataviz\"></div>\n\n```\n\n```javascript\n\n// append the svg object to the body of the page\nconst height = 460\nconst width = 460\nconst svg = d3.select(\"#my_dataviz\")\n  .append(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n\n// The scale you use for bubble size\nconst size = d3.scaleSqrt()\n  .domain([1, 100])  // What's in the data, let's say it is percentage\n  .range([1, 100])  // Size in pixel\n\n// Add legend: circles\nconst valuesToShow = [10, 50, 100]\nconst xCircle = 230\nconst xLabel = 380\nconst yCircle = 330\nsvg\n  .selectAll(\"legend\")\n  .data(valuesToShow)\n  .join(\"circle\")\n    .attr(\"cx\", xCircle)\n    .attr(\"cy\", d => yCircle - size(d))\n    .attr(\"r\", d => size(d))\n    .style(\"fill\", \"none\")\n    .attr(\"stroke\", \"black\")\n\n// Add legend: segments\nsvg\n  .selectAll(\"legend\")\n  .data(valuesToShow)\n  .join(\"line\")\n    .attr('x1', d => xCircle + size(d))\n    .attr('x2', xLabel)\n    .attr('y1', d => yCircle - size(d))\n    .attr('y2', d => yCircle - size(d))\n    .attr('stroke', 'black')\n    .style('stroke-dasharray', ('2,2'))\n\n// Add legend: labels\nsvg\n  .selectAll(\"legend\")\n  .data(valuesToShow)\n  .join(\"text\")\n    .attr('x', xLabel)\n    .attr('y', d => yCircle - size(d))\n    .text( d => d)\n    .style(\"font-size\", 10)\n    .attr('alignment-baseline', 'middle')\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.244Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Library Supply Chain Study",
      "content": "Idea: \n\nSay I have nothing\nbut an idea. \n\nHow could I get a prototype of an object or piece of clothing prototyped for free in DTLA, centering at the LAPL. \n\nHow could I get it to production and given away to 1 dozen people\nfor free\n\nOpen source Wiki, accessible via laptop checked out of library.\n\nIf you buy the luxury item, you buy the production rights to the copies. So if the product is a hit you make money, \n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.245Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Lie Economy",
      "content": " [[Lie Economy]], the marketplace where gullible viewers are sorted from the skeptical and delivered to advertisers who make the most of their naïveté. \n-Jack Shafer, Politico August 10, 2022\n\nSee [[News Dive August 15 2022]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.245Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Local Variable Component",
      "content": "# local-variable-component\n\nCreates an Input with a name that  saves its value to local storage.\nDemo: https://lindseyjohnasterius.github.io/local-variable-component/demo.html\n\n## Usage\n\nInclude the JS in local-variable.js and then you can use the local variable component like so: \n\n```HTML\n  <local-variable id=\"hello-world\"></local-variable>\n \n  <local-variable source=\"hello-world\"></local-variable>\n  <local-variable source=\"hello-world\"></local-variable>\n```\n\nYou can use value attribute like so: \n\n```javascript\n  document.querySelector('#hello-world').getAttribute('value')\n```\n\n```js\n/*\n\n  LOCAL VARIABLE\n\n  This is a little input component.  \n\n*/\n\n\nclass LocalVariable extends HTMLElement {\n\n  getNewID() {\n    return 'dtrm-xxxxxxxxxxxxxxxx-'\n      .replace(/[xy]/g, function(c) {\n        var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);\n        return v.toString(16)\n    }) + Date.now()\n  }\n\n  getValuesFromURL(URL = window.location.href ){\n    const search_params = new URLSearchParams(URL)\n    let options = {\n    }\n    for (const [key, unparsed_value] of search_params) {\n      if(key !== window.location.origin + window.location.pathname + '?' ){\n        try {\n          const value = JSON.parse(decodeURI(unparsed_value))\n          options[key] = value\n        } catch {\n          options[key] = decodeURI(unparsed_value)\n        }\n      }\n    }\n    return options\n  }\n\n\n  connectedCallback(){\n    this.id = this.getAttribute('id')\n    if(this.id === null){\n      this.id = getNewID()\n    }    \n    \n    this.name = this.getAttribute('name')\n    if(this.name === null){\n      this.name = this.id\n    }\n\n    this.source = this.getAttribute('source')\n    if(this.source === null){\n      this.initializeInput()\n    } else {\n      this.initializeOutput()\n    }\n  }\n\n  initializeOutput(){\n    try {\n      this.innerText = document.querySelector(`#${this.source}`).value\n      document.querySelector(`#${this.source}`)\n        .addEventListener('UPDATED', (e) => {\n          this.innerText = e.detail[this.source]\n      })\n    } catch(e){\n      this.innerText = `SEARCHING FOR ${this.source}`\n      setTimeout(()=>{this.initializeOutput()},50 + Math.floor(Math.random() * 100))\n    }\n  }\n\n  initializeInput(){\n    const url_vars = this.getValuesFromURL()\n    const local_var_value = localStorage.getItem(this.id)\n\n    if(local_var_value !== null){\n      this.value = local_var_value\n    } else if(typeof(url_vars[this.id]) !== 'undefined'){\n        this.value = url_vars.id\n    } else {\n      this.value = this.getAttribute('value')\n      if(this.value === null){\n        this.value = ''\n      }\n    }\n\n    this.input = document.createElement('input')\n    this.input.setAttribute('value', this.value)\n    this.input.setAttribute('name', this.name)\n    this.input.addEventListener('keydown', (e) => {\n      if(e.key === \"Enter\" && !e.ctrlKey){\n        this.setAttribute('value', e.target.value)\n      }\n    })\n    \n    this.input.addEventListener('blur', (e) => {\n      this.setAttribute('value', e.target.value)\n    })\n\n    this.placeholder = this.getAttribute('placeholder')\n    if(this.placeholder !== null){\n      this.input.setAttribute('placeholder', this.placeholder)\n    } else {\n      this.input.setAttribute('placeholder', this.id)\n    }\n    this.appendChild(this.input)\n    const create_event = new CustomEvent('CREATED', {id:this.id})\n    this.dispatchEvent(create_event)\n  }\n  \n  static get observedAttributes() {\n    return ['value', 'id'];\n  }\n\n  update(new_value){\n    this.value = new_value\n    let detail = new Object()\n    detail[this.id] = this.value\n    localStorage.setItem(this.id, this.value)\n    const new_event = new CustomEvent('UPDATED', {detail})\n    this.dispatchEvent(new_event)\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n    if(name === 'value' && old_value !== new_value){\n      this.update(new_value)\n    }\n\n    if(name === 'id' && old_value !== new_value){\n      const delete_event = new CustomEvent('DELETED', {id:this.id})\n      this.dispatchEvent(delete_event)\n    }\n  }\n\n  disconnectedCallback() {\n    const delete_event = new CustomEvent('DELETED', {id:this.id})\n    this.dispatchEvent(delete_event)\n  }\n}\n\n/*\n  this component can be placed in the document using the notation\n  <custom-element title=\"element name here\"></custom-element>\n  to change the name of the element in the dom, change the \n  value in the quotation marks. \n*/\n\ncustomElements.define('local-variable', LocalVariable)\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.247Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Machine Learning",
      "content": "https://archive.ics.uci.edu/ml/datasets/Iris\n\n[[attention-is-all-you-need.pdf]]\n\nhttps://brain.js.org/#/getting-started\n\nhttps://github.com/BrainJS/brain.js/blob/master/examples/javascript/cross-validate.js\n\n```javascript\nconst brain = require('brain.js');\n\nconst trainingData = [\n  // xor data, repeating to simulate that we have a lot of data\n  { input: [0, 1], output: [1] },\n  { input: [0, 0], output: [0] },\n  { input: [1, 1], output: [0] },\n  { input: [1, 0], output: [1] },\n\n  // repeat xor data to have enough to train with\n  { input: [0, 1], output: [1] },\n  { input: [0, 0], output: [0] },\n  { input: [1, 1], output: [0] },\n  { input: [1, 0], output: [1] },\n];\n\nconst netOptions = {\n  hiddenLayers: [3],\n};\n\nconst trainingOptions = {\n  iterations: 20000,\n  log: (details) => console.log(details),\n};\n\nconst crossValidate = new brain.CrossValidate(brain.NeuralNetwork, netOptions);\nconst stats = crossValidate.train(trainingData, trainingOptions);\nconsole.log(stats);\nconst net = crossValidate.toNeuralNetwork();\nconst result01 = net.run([0, 1]);\nconst result00 = net.run([0, 0]);\nconst result11 = net.run([1, 1]);\nconst result10 = net.run([1, 0]);\n\nconsole.log('0 XOR 1: ', result01); // 0.987\nconsole.log('0 XOR 0: ', result00); // 0.058\nconsole.log('1 XOR 1: ', result11); // 0.087\nconsole.log('1 XOR 0: ', result10); // 0.934\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.248Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Manual",
      "content": "Dataroom is a editor interface to \n\n[[programming/README]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.249Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Map View",
      "content": "Takes a lat lng,\n\nallows setting a notebook pages lat lng via search\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.249Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "MapBox Filters",
      "content": "OMG\n\nThis is so poorly documented\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.250Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "MapBox",
      "content": "\n1678391598 #2023-03-09\nhttps://docs.mapbox.com/help/tutorials/show-changes-over-time/\nhttps://docs.mapbox.com/help/tutorials/mapbox-gl-js-expressions/\n\n```js\nmapboxgl.accessToken = 'pk.eyJ1IjoibG5zeWFzdGVyaXVzIiwiYSI6ImNsNXp0bG1zZTFnOWszYnF2Nm1jbjdxamUifQ.NBU_Y2rMUWOKon2Z2WY7MQ';\nconst map = new mapboxgl.Map({\ncontainer: 'map',\nzoom: 3,\ncenter: [7.5, 58],\n// Choose from Mapbox's core styles, or make your own style with Mapbox Studio\nstyle: 'mapbox://styles/mapbox/light-v11',\nantialias: true, // create the gl context with MSAA antialiasing, so custom layers are antialiased\nprojection: 'mercator'\n});\n \n// create a custom style layer to implement the WebGL content\nconst highlightLayer = {\n\tid: 'highlight',\n\ttype: 'custom',\n\t \n\t// method called when the layer is added to the map\n\t// https://docs.mapbox.com/mapbox-gl-js/api/#styleimageinterface#onadd\n\tonAdd: function (map, gl) {\n\t\t// create GLSL source for vertex shader\n\t\tconst vertexSource = `\n\t\t\tuniform mat4 u_matrix;\n\t\t\tattribute vec2 a_pos;\n\t\t\tvoid main() {\n\t\t\tgl_Position = u_matrix * vec4(a_pos, 0.0, 1.0);\n\t\t}`;\n\t\t \n\t\t// create GLSL source for fragment shader\n\t\tconst fragmentSource = `\n\t\tvoid main() {\n\t\tgl_FragColor = vec4(1.0, 0.0, 0.0, 0.5);\n\t\t}`;\n\t\t \n\t\t// create a vertex shader\n\t\tconst vertexShader = gl.createShader(gl.VERTEX_SHADER);\n\t\tgl.shaderSource(vertexShader, vertexSource);\n\t\tgl.compileShader(vertexShader);\n\t\t \n\t\t// create a fragment shader\n\t\tconst fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);\n\t\tgl.shaderSource(fragmentShader, fragmentSource);\n\t\tgl.compileShader(fragmentShader);\n\t\t \n\t\t// link the two shaders into a WebGL program\n\t\tthis.program = gl.createProgram();\n\t\tgl.attachShader(this.program, vertexShader);\n\t\tgl.attachShader(this.program, fragmentShader);\n\t\tgl.linkProgram(this.program);\n\t\t \n\t\tthis.aPos = gl.getAttribLocation(this.program, 'a_pos');\n\t\t \n\t\t// define vertices of the triangle to be rendered in the custom style layer\n\t\tconst helsinki = mapboxgl.MercatorCoordinate.fromLngLat({\n\t\tlng: 25.004,\n\t\tlat: 60.239\n\t\t});\n\t\tconst berlin = mapboxgl.MercatorCoordinate.fromLngLat({\n\t\tlng: 13.403,\n\t\tlat: 52.562\n\t\t});\n\t\tconst kyiv = mapboxgl.MercatorCoordinate.fromLngLat({\n\t\tlng: 30.498,\n\t\tlat: 50.541\n\t\t});\n\t\t \n\t\t// create and initialize a WebGLBuffer to store vertex and color data\n\t\tthis.buffer = gl.createBuffer();\n\t\tgl.bindBuffer(gl.ARRAY_BUFFER, this.buffer);\n\t\tgl.bufferData(\n\t\tgl.ARRAY_BUFFER,\n\t\tnew Float32Array([\n\t\thelsinki.x,\n\t\thelsinki.y,\n\t\tberlin.x,\n\t\tberlin.y,\n\t\tkyiv.x,\n\t\tkyiv.y\n\t\t]),\n\t\tgl.STATIC_DRAW\n\t\t);\n\t\t},\n\t\t \n\t\t// method fired on each animation frame\n\t\t// https://docs.mapbox.com/mapbox-gl-js/api/#map.event:render\n\t\trender: function (gl, matrix) {\n\t\tgl.useProgram(this.program);\n\t\tgl.uniformMatrix4fv(\n\t\tgl.getUniformLocation(this.program, 'u_matrix'),\n\t\tfalse,\n\t\tmatrix\n\t\t);\n\t\tgl.bindBuffer(gl.ARRAY_BUFFER, this.buffer);\n\t\tgl.enableVertexAttribArray(this.aPos);\n\t\tgl.vertexAttribPointer(this.aPos, 2, gl.FLOAT, false, 0, 0);\n\t\tgl.enable(gl.BLEND);\n\t\tgl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);\n\t\tgl.drawArrays(gl.TRIANGLE_STRIP, 0, 3);\n\t\t}\n};\n \n// add the custom style layer to the map\nmap.on('load', () => {\n\tmap.addLayer(highlightLayer, 'building');\n});\n\n\n```\n\n\n---\n[[MapBox Filters]]\n\n\n[[Albers USA Projection]]\n\n\nGame controls for interacting with map: \nhttps://docs.mapbox.com/mapbox-gl-js/example/game-controls/\n\nScaling Choropleth\nhttps://docs.mapbox.com/mapbox-gl-js/example/updating-choropleth/\n\nChoropleth plugin:\n\nhttps://github.com/stevage/mapbox-choropleth\n---\nhttps://docs.mapbox.com/mapbox-gl-js/api/map/#map-parameters\n\nhttps://docs.mapbox.com/mapbox-gl-js/example/cluster-html/\n\ngenerates a legend: \nhttps://github.com/watergis/mapbox-gl-legend\n\n\nCompare: https://github.com/mapbox/mapbox-gl-compare\n\nhttps://turfjs.org/\n\n--- \n\n# Globe Spinning Code\n```html\n\n<script type=\"text/javascript\">\n  geo_map.addEventListener('loaded', function(){\n    const map = geo_map.map\n\n    let last_popup = null;\n\n    const secondsPerRevolution = 120;\n    // Above zoom level 5, do not rotate.\n    const maxSpinZoom = 5;\n    // Rotate at intermediate speeds between zoom levels 3 and 5.\n    const slowSpinZoom = 3;\n     \n    let userInteracting = false;\n    let spinEnabled = true;\n     \n    function spinGlobe() {\n      const zoom = map.getZoom();\n      if (spinEnabled && !userInteracting && zoom < maxSpinZoom) {\n        let distancePerSecond = 360 / secondsPerRevolution;\n        if (zoom > slowSpinZoom) {\n          // Slow spinning at higher zooms\n          const zoomDif =\n          (maxSpinZoom - zoom) / (maxSpinZoom - slowSpinZoom);\n          distancePerSecond *= zoomDif;\n        }\n        const center = map.getCenter();\n        center.lng -= distancePerSecond;\n        // Smoothly animate the map over one second.\n        // When this animation is complete, it calls a 'moveend' event.\n        map.easeTo({ center, duration: 1000, easing: (n) => n });\n      }\n    }\n     \n    // Pause spinning on interaction\n    map.on('mousedown', (e) => {\n      userInteracting = true;\n      console.log(e.lngLat)\n    });\n     \n    // Restart spinning the globe when interaction is complete\n    map.on('mouseup', () => {\n      userInteracting = false;\n      spinGlobe();\n    });\n     \n    // These events account for cases where the mouse has moved\n    // off the map, so 'mouseup' will not be fired.\n    map.on('dragend', () => {\n      userInteracting = false;\n      spinGlobe();\n    });\n    map.on('pitchend', () => {\n      userInteracting = false;\n      spinGlobe();\n    });\n    map.on('rotateend', () => {\n      userInteracting = false;\n      spinGlobe();\n    });\n     \n    // When animation is complete, start spinning if there is no ongoing interaction\n    map.on('moveend', () => {\n      spinGlobe();\n      console.log(map.getCenter(), map.getZoom());\n    });\n\n    spinGlobe();\n\n    geo_map.addEventListener('LOCATION FOUND', (e) => {\n      const coords = e.detail\n\n      map.once('moveend', async (e) => {\n        if(map.getZoom() < 14) return\n        const all_features = map.queryRenderedFeatures({layers: ['la-roof-2018-geojson']});\n\n        const all_albedo = all_features.map(f => {\n          return Math.floor(f.properties.albedo * 100);\n        })\n\n        document.querySelector('re-histogram')?.setAttribute('values', JSON.stringify(all_albedo))\n      })\n\n    })\n\n  })\n</script>\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.251Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "MapLibre",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.258Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "MapShaper",
      "content": "https://github.com/mbloch/mapshaper/wiki\n\nhttps://github.com/mbloch/mapshaper/wiki/Command-Reference\n\nhttps://github.com/mbloch/mapshaper\n\nhttps://github.com/developmentseed/dirty-reprojectors\n\n**\n\nMerging layers is also called dissolve\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.258Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Mapping",
      "content": "1654278311 #2022-06-03\n\nTrying this again. \n\n\n---\n\nHMDA Data\n\n```bash\nbrew install gdal\nbrew install teppecanoe\n\n```\n\nconverted to GeoJSON with: \n\n```bash\nogr2ogr -f GeoJSON census_blocks.json cb_2021_us_bg_500k.shp\n```\n\nThen I used Tippecanoe:\n\n```bash\ntippecanoe -zg -o 2021_census_blocks.mbtiles census_blocks.json\n```\n\n\n\n\n[[HMDA Map]]\n\n\n\n\n\n\nhttps://data.maptiler.com/downloads/dataset/terrain_quantized_mesh/\n3d Terrain Map with Quantized Mesh: \nhttps://data.maptiler.com/downloads/tileset/terrain_quantized_mesh/\nhttps://documentation.maptiler.com/hc/en-us/articles/4404723578897-How-to-run-MapTiler-Server-on-Linux\n\nhttps://sandcastle.cesium.com/?src=Terrain.html\n\nhttps://data.maptiler.com/downloads/dataset/satellite-2021/#0.22/0/0\n\nThat USA / Alaska Hawaii view is called Albers\nhttps://www.mapbox.com/elections/albers-usa-projection-style\n\n\nhttps://observablehq.com/@uwdata/cartographic-visualization\n\nGreat Overview \n\n![[Pasted image 20220224093625.png]]\n\nhttps://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n\n\n[[Fairplay Mapping Product Design Brief]]\n\nAll the parts of a map.\n\n# Demos of Maps\n\nThese maps were done with a combination of using the geo-map-component and the Mapbox API.\n\n[https://blog.mapbox.com/introducing-mapbox-tiling-service-df1df636c7cf](https://blog.mapbox.com/introducing-mapbox-tiling-service-df1df636c7cf)\n\nThis is what mapbox says about their tiling service:\n\n> **Private Data**\n> \n> Maps are locked and set to private by default, giving developers total control over who is looking at  the data. Mapbox never accesses customer created data layers. Our [management interface](https://www.mapbox.com/studio/account/tokens/) empowers developers to create, revoke, and monitor access control tokens directly. For more information, see our [Tokens API documentation](https://docs.mapbox.com/api/accounts/#token-metadata-object). [SAML single sign-on](https://blog.mapbox.com/saml-single-sign-on-sso-in-general-availability-79c8bfc423e0) is also available for all Mapbox customers, enabling teams with multiple users to collaborate securely.\n\nInterfacing between Mapbox and Fairplay could be automated using the Tiling Server API.\n\nHere is some pricing data: [https://www.mapbox.com/pricing#tilesets](https://www.mapbox.com/pricing#tilesets)\n\n[https://docs.mapbox.com/api/maps/mapbox-tiling-service/](https://docs.mapbox.com/api/maps/mapbox-tiling-service/)\n\n[https://docs.mapbox.com/mapbox-tiling-service/guides/](https://docs.mapbox.com/mapbox-tiling-service/guides/)\n\nA demo of geomap component:\n\n[https://map.garden/earthquakes.html](https://map.garden/earthquakes.html)\n\nHere is a large data example, where I used land use data artistically. Click on next, previous buttons in the upper right to switch between slides / locations:\n\n[https://map.garden/real-estate-listing.html](https://map.garden/real-estate-listing.html)\n\nHere is a demo that captures the earthquakes from the past hour\n\n[https://map.garden/earthquakes.html](https://map.garden/earthquakes.html)\n\n# Ideas\n\n-   Unity Engine in web window running maps:[https://www.mapbox.com/unity](https://www.mapbox.com/unity) We could do a bare bones AR application. We could also use it to render MP4’s of reports.\n\n\nhttps://observablehq.com/@d3/raster-vector\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.259Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Markdown Component",
      "content": "```js\nimport \"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"\n\nclass MarkdownComponent extends HTMLElement {\n  connectedCallback(){\n    const content = this.textContent\n    this.innerHTML = marked.parse(content)\n  }\n}\n\ncustomElements.define('mark-down', MarkdownComponent)\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.264Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Markdown Emojis",
      "content": "# :fire: All the emojis :tada:\n\n---\n---\n\n## People\n\n|                               All                               |                              The                                |                   Emojies                   |\n| :-------------------------------------------------------------: | :-------------------------------------------------------------: | :-----------------------------------------: |\n|                       :bowtie: `:bowtie:`                       |                        :smile: `:smile:`                        |           :laughing: `:laughing:`           |\n|                        :blush: `:blush:`                        |                       :smiley: `:smiley:`                       |            :relaxed: `:relaxed:`            |\n|                        :smirk: `:smirk:`                        |                   :heart_eyes: `:heart_eyes:`                   |      :kissing_heart: `:kissing_heart:`      |\n|          :kissing_closed_eyes: `:kissing_closed_eyes:`          |                      :flushed: `:flushed:`                      |           :relieved: `:relieved:`           |\n|                    :satisfied: `:satisfied:`                    |                         :grin: `:grin:`                         |               :wink: `:wink:`               |\n| :stuck_out_tongue_winking_eye: `:stuck_out_tongue_winking_eye:` | :stuck_out_tongue_closed_eyes: `:stuck_out_tongue_closed_eyes:` |           :grinning: `:grinning:`           |\n|                      :kissing: `:kissing:`                      |         :kissing_smiling_eyes: `:kissing_smiling_eyes:`         |   :stuck_out_tongue: `:stuck_out_tongue:`   |\n|                     :sleeping: `:sleeping:`                     |                      :worried: `:worried:`                      |           :frowning: `:frowning:`           |\n|                    :anguished: `:anguished:`                    |                   :open_mouth: `:open_mouth:`                   |          :grimacing: `:grimacing:`          |\n|                     :confused: `:confused:`                     |                       :hushed: `:hushed:`                       |     :expressionless: `:expressionless:`     |\n|                     :unamused: `:unamused:`                     |                  :sweat_smile: `:sweat_smile:`                  |              :sweat: `:sweat:`              |\n|        :disappointed_relieved: `:disappointed_relieved:`        |                        :weary: `:weary:`                        |            :pensive: `:pensive:`            |\n|                 :disappointed: `:disappointed:`                 |                   :confounded: `:confounded:`                   |            :fearful: `:fearful:`            |\n|                   :cold_sweat: `:cold_sweat:`                   |                    :persevere: `:persevere:`                    |                :cry: `:cry:`                |\n|                          :sob: `:sob:`                          |                          :joy: `:joy:`                          |         :astonished: `:astonished:`         |\n|                       :scream: `:scream:`                       |                    :neckbeard: `:neckbeard:`                    |         :tired_face: `:tired_face:`         |\n|                        :angry: `:angry:`                        |                         :rage: `:rage:`                         |            :triumph: `:triumph:`            |\n|                       :sleepy: `:sleepy:`                       |                          :yum: `:yum:`                          |               :mask: `:mask:`               |\n|                   :sunglasses: `:sunglasses:`                   |                   :dizzy_face: `:dizzy_face:`                   |                :imp: `:imp:`                |\n|                  :smiling_imp: `:smiling_imp:`                  |                 :neutral_face: `:neutral_face:`                 |           :no_mouth: `:no_mouth:`           |\n|                     :innocent: `:innocent:`                     |                        :alien: `:alien:`                        |                                             |\n\n## Heart and special emojies\n\n|                 :yellow_heart: `:yellow_heart:`                 |                  :black_heart: `:black_heart:`                  |  :gift_heart: `:gift_heart`  |\n| :-------------------------------------------------------------: | :-------------------------------------------------------------: | :-----------------------------------------: |\n|                   :blue_heart: `:blue_heart:`                   |                 :purple_heart: `:purple_heart:`                 |              :heart: `:heart:`              |\n|                  :green_heart: `:green_heart:`                  |                 :broken_heart: `:broken_heart:`                 |          :heartbeat: `:heartbeat:`          |\n|                   :heartpulse: `:heartpulse:`                   |                   :two_hearts: `:two_hearts:`                   |   :revolving_hearts: `:revolving_hearts:`   |\n|                        :cupid: `:cupid:`                        |              :sparkling_heart: `:sparkling_heart:`              |           :sparkles: `:sparkles:`           |\n|                         :star: `:star:`                         |                        :star2: `:star2:`                        |              :dizzy: `:dizzy:`              |\n|                         :boom: `:boom:`                         |                    :collision: `:collision:`                    |              :anger: `:anger:`              |\n|                  :exclamation: `:exclamation:`                  |                     :question: `:question:`                     |   :grey_exclamation: `:grey_exclamation:`   |\n|                :grey_question: `:grey_question:`                |                          :zzz: `:zzz:`                          |               :dash: `:dash:`               |\n|                  :sweat_drops: `:sweat_drops:`                  |                        :notes: `:notes:`                        |       :musical_note: `:musical_note:`       |\n|                         :fire: `:fire:`                         |                       :hankey: `:hankey:`                       |               :poop: `:poop:`               |\n\n## Pointers and signs\n\n|                         :shit: `:shit:`                         |                           :+1: `:+1:`                           |           :thumbsup: `:thumbsup:`           |\n| :-------------------------------------------------------------: | :-------------------------------------------------------------: | :-----------------------------------------: |\n|                           :-1: `:-1:`                           |                   :thumbsdown: `:thumbsdown:`                   |            :ok_hand: `:ok_hand:`            |\n|                        :punch: `:punch:`                        |                    :facepunch: `:facepunch:`                    |               :fist: `:fist:`               |\n|                            :v: `:v:`                            |                         :wave: `:wave:`                         |               :hand: `:hand:`               |\n|                  :raised_hand: `:raised_hand:`                  |                   :open_hands: `:open_hands:`                   |           :point_up: `:point_up:`           |\n|                   :point_down: `:point_down:`                   |                   :point_left: `:point_left:`                   |        :point_right: `:point_right:`        |\n|                 :raised_hands: `:raised_hands:`                 |                         :pray: `:pray:`                         |         :point_up_2: `:point_up_2:`         |\n|                         :clap: `:clap:`                         |                       :muscle: `:muscle:`                       |              :metal: `:metal:`              |\n|                           :fu: `:fu:`                           |                      :walking: `:walking:`                      |             :runner: `:runner:`             |\n|                      :running: `:running:`                      |                       :couple: `:couple:`                       |             :family: `:family:`             |\n|        :two_men_holding_hands: `:two_men_holding_hands:`        |      :two_women_holding_hands: `:two_women_holding_hands:`      |             :dancer: `:dancer:`             |\n|                      :dancers: `:dancers:`                      |                     :ok_woman: `:ok_woman:`                     |            :no_good: `:no_good:`            |\n|      :information_desk_person: `:information_desk_person:`      |                 :raising_hand: `:raising_hand:`                 |    :bride_with_veil: `:bride_with_veil:`    |\n|     :person_with_pouting_face: `:person_with_pouting_face:`     |              :person_frowning: `:person_frowning:`              |                :bow: `:bow:`                |\n|                   :couplekiss: `:couplekiss:`                   |            :couple_with_heart: `:couple_with_heart:`            |            :massage: `:massage:`            |\n|                      :haircut: `:haircut:`                      |                    :nail_care: `:nail_care:`                    |                :boy: `:boy:`                |\n|                         :girl: `:girl:`                         |                        :woman: `:woman:`                        |                :man: `:man:`                |\n|                         :baby: `:baby:`                         |                  :older_woman: `:older_woman:`                  |          :older_man: `:older_man:`          |\n|       :person_with_blond_hair: `:person_with_blond_hair:`       |          :man_with_gua_pi_mao: `:man_with_gua_pi_mao:`          |    :man_with_turban: `:man_with_turban:`    |\n|          :construction_worker: `:construction_worker:`          |                          :cop: `:cop:`                          |              :angel: `:angel:`              |\n|                     :princess: `:princess:`                     |                   :smiley_cat: `:smiley_cat:`                   |          :smile_cat: `:smile_cat:`          |\n|               :heart_eyes_cat: `:heart_eyes_cat:`               |                  :kissing_cat: `:kissing_cat:`                  |          :smirk_cat: `:smirk_cat:`          |\n|                   :scream_cat: `:scream_cat:`                   |              :crying_cat_face: `:crying_cat_face:`              |            :joy_cat: `:joy_cat:`            |\n|                  :pouting_cat: `:pouting_cat:`                  |                :japanese_ogre: `:japanese_ogre:`                |    :japanese_goblin: `:japanese_goblin:`    |\n|                  :see_no_evil: `:see_no_evil:`                  |                 :hear_no_evil: `:hear_no_evil:`                 |      :speak_no_evil: `:speak_no_evil:`      |\n|                    :guardsman: `:guardsman:`                    |                        :skull: `:skull:`                        |               :feet: `:feet:`               |\n|                         :lips: `:lips:`                         |                         :kiss: `:kiss:`                         |            :droplet: `:droplet:`            |\n|                          :ear: `:ear:`                          |                         :eyes: `:eyes:`                         |               :nose: `:nose:`               |\n|                       :tongue: `:tongue:`                       |                  :love_letter: `:love_letter:`                  | :bust_in_silhouette: `:bust_in_silhouette:` |\n|          :busts_in_silhouette: `:busts_in_silhouette:`          |               :speech_balloon: `:speech_balloon:`               |    :thought_balloon: `:thought_balloon:`    |\n\n\n\n## Nature\n\n|                        :sunny: `:sunny:`                        |             :umbrella: `:umbrella:`             |                       :cloud: `:cloud:`                       |\n| :-------------------------------------------------------------: | :---------------------------------------------: | :-----------------------------------------------------------: |\n|                    :snowflake: `:snowflake:`                    |              :snowman: `:snowman:`              |                         :zap: `:zap:`                         |\n|                      :cyclone: `:cyclone:`                      |                :foggy: `:foggy:`                |                       :ocean: `:ocean:`                       |\n|                          :cat: `:cat:`                          |                  :dog: `:dog:`                  |                       :mouse: `:mouse:`                       |\n|                      :hamster: `:hamster:`                      |               :rabbit: `:rabbit:`               |                        :wolf: `:wolf:`                        |\n|                         :frog: `:frog:`                         |                :tiger: `:tiger:`                |                       :koala: `:koala:`                       |\n|                         :bear: `:bear:`                         |                  :pig: `:pig:`                  |                    :pig_nose: `:pig_nose:`                    |\n|                          :cow: `:cow:`                          |                 :boar: `:boar:`                 |                 :monkey_face: `:monkey_face:`                 |\n|                       :monkey: `:monkey:`                       |                :horse: `:horse:`                |                   :racehorse: `:racehorse:`                   |\n|                        :camel: `:camel:`                        |                :sheep: `:sheep:`                |                    :elephant: `:elephant:`                    |\n|                   :panda_face: `:panda_face:`                   |                :snake: `:snake:`                |                        :bird: `:bird:`                        |\n|                   :baby_chick: `:baby_chick:`                   |        :hatched_chick: `:hatched_chick:`        |              :hatching_chick: `:hatching_chick:`              |\n|                      :chicken: `:chicken:`                      |              :penguin: `:penguin:`              |                      :turtle: `:turtle:`                      |\n|                          :bug: `:bug:`                          |             :honeybee: `:honeybee:`             |                         :ant: `:ant:`                         |\n|                       :beetle: `:beetle:`                       |                :snail: `:snail:`                |                     :octopus: `:octopus:`                     |\n|                :tropical_fish: `:tropical_fish:`                |                 :fish: `:fish:`                 |                       :whale: `:whale:`                       |\n|                       :whale2: `:whale2:`                       |              :dolphin: `:dolphin:`              |                        :cow2: `:cow2:`                        |\n|                          :ram: `:ram:`                          |                  :rat: `:rat:`                  |               :water_buffalo: `:water_buffalo:`               |\n|                       :tiger2: `:tiger2:`                       |              :rabbit2: `:rabbit2:`              |                      :dragon: `:dragon:`                      |\n|                         :goat: `:goat:`                         |              :rooster: `:rooster:`              |                        :dog2: `:dog2:`                        |\n|                         :pig2: `:pig2:`                         |               :mouse2: `:mouse2:`               |                          :ox: `:ox:`                          |\n|                  :dragon_face: `:dragon_face:`                  |             :blowfish: `:blowfish:`             |                   :crocodile: `:crocodile:`                   |\n|              :dromedary_camel: `:dromedary_camel:`              |              :leopard: `:leopard:`              |                        :cat2: `:cat2:`                        |\n|                       :poodle: `:poodle:`                       |           :paw_prints: `:paw_prints:`           |                     :bouquet: `:bouquet:`                     |\n|               :cherry_blossom: `:cherry_blossom:`               |                :tulip: `:tulip:`                |            :four_leaf_clover: `:four_leaf_clover:`            |\n|                         :rose: `:rose:`                         |            :sunflower: `:sunflower:`            |                    :hibiscus: `:hibiscus:`                    |\n|                   :maple_leaf: `:maple_leaf:`                   |               :leaves: `:leaves:`               |                 :fallen_leaf: `:fallen_leaf:`                 |\n|                         :herb: `:herb:`                         |             :mushroom: `:mushroom:`             |                      :cactus: `:cactus:`                      |\n|                    :palm_tree: `:palm_tree:`                    |       :evergreen_tree: `:evergreen_tree:`       |              :deciduous_tree: `:deciduous_tree:`              |\n|                     :chestnut: `:chestnut:`                     |             :seedling: `:seedling:`             |                     :blossom: `:blossom:`                     |\n|                  :ear_of_rice: `:ear_of_rice:`                  |                :shell: `:shell:`                |        :globe_with_meridians: `:globe_with_meridians:`        |\n|                :sun_with_face: `:sun_with_face:`                |  :full_moon_with_face: `:full_moon_with_face:`  |          :new_moon_with_face: `:new_moon_with_face:`          |\n|                     :new_moon: `:new_moon:`                     | :waxing_crescent_moon: `:waxing_crescent_moon:` |          :first_quarter_moon: `:first_quarter_moon:`          |\n|          :waxing_gibbous_moon: `:waxing_gibbous_moon:`          |            :full_moon: `:full_moon:`            |         :waning_gibbous_moon: `:waning_gibbous_moon:`         |\n|            :last_quarter_moon: `:last_quarter_moon:`            | :waning_crescent_moon: `:waning_crescent_moon:` | :last_quarter_moon_with_face: `:last_quarter_moon_with_face:` |\n| :first_quarter_moon_with_face: `:first_quarter_moon_with_face:` |                 :moon: `:moon:`                 |                :earth_africa: `:earth_africa:`                |\n|               :earth_americas: `:earth_americas:`               |           :earth_asia: `:earth_asia:`           |                     :volcano: `:volcano:`                     |\n|                    :milky_way: `:milky_way:`                    |         :partly_sunny: `:partly_sunny:`         |                     :octocat: `:octocat:`                     |\n|                     :shipit: `:shipit:`                     |\n\n## Food items\n\n|                           :apple: `:apple:`                        |                 :green_apple: `:green_apple:`                |                    :pear: `:pear:`                     |\n| :----------------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------: |\n|                           :lemon: `:lemon:`                        |                      :banana: `:banana:`                     |              :watermelon: `:watermelon:`               |\n|                          :grapes: `:grapes:`                       |                   :croissant: `:croissant:`                  |              :strawberry: `:strawberry:`               |\n|                           :melon: `:melon:`                        |                    :cherries: `:cherries:`                   |                   :peach: `:peach:`                    |\n|                           :bread: `:bread:`                        |                   :pineapple: `:pineapple:`                  |                  :cheese: `:cheese:`                   |\n|                             :egg: `:egg:`                          |                      :tomato: `:tomato:`                     |                :eggplant: `:eggplant:`                 |\n|                         :avocado: `:avocado:`                      |                    :pancakes: `:pancakes:`                   |                   :bacon: `:bacon:`                    |\n|                        :cucumber: `:cucumber:`                     |                  :hot_pepper: `:hot_pepper:`                 |                    :corn: `:corn:`                     |\n|                          :carrot: `:carrot:`                       |                      :hotdog: `:hotdog:`                     |               :hamburger: `:hamburger:`                |\n|                          :potato: `:potato:`                       |                :sweet_potato: `:sweet_potato:`               |                   :fries: `:fries:`                    |\n|                           :pizza: `:pizza:`                        |                        :taco: `:taco:`                       |                 :burrito: `:burrito:`                  |\n|                       :spaghetti: `:spaghetti:`                    |                       :ramen: `:ramen:`                      |                    :stew: `:stew:`                     |\n|                           :curry: `:curry:`                        |                       :sushi: `:sushi:`                      |                   :bento: `:bento:`                    |\n|                       :rice_ball: `:rice_ball:`                    |                        :rice: `:rice:`                       |                    :oden: `:oden:`                     |\n|                           :dango: `:dango:`                        |                   :ice_cream: `:ice_cream:`                  |                :icecream: `:icecream:`                 |\n|                            :cake: `:cake:`                         |                    :lollipop: `:lollipop:`                   |                   :candy: `:candy:`                    |\n|                         :popcorn: `:popcorn:`                      |                      :cookie: `:cookie:`                     |                :doughnut: `:doughnut:`                 |\n|                       :honey_pot: `:honey_pot:`                    |                         :tea: `:tea:`                        |                  :coffee: `:coffee:`                   |\n|                            :sake: `:sake:`                         |                        :beer: `:beer:`                       |                   :beers: `:beers:`                    |\n|                      :wine_glass: `:wine_glass:`                   |               :tumbler_glass: `:tumbler_glass:`              |                :cocktail: `:cocktail:`                 |\n|                       :champagne: `:champagne:`                    |                                                              |                                                        |\n\n## Objects\n\n|                         :bamboo: `:bamboo:`                         |                 :gift_heart: `:gift_heart:`                 |                  :dolls: `:dolls:`                  |\n| :-----------------------------------------------------------------: | :---------------------------------------------------------: | :-------------------------------------------------: |\n|                 :school_satchel: `:school_satchel:`                 |               :mortar_board: `:mortar_board:`               |                  :flags: `:flags:`                  |\n|                      :fireworks: `:fireworks:`                      |                   :sparkler: `:sparkler:`                   |             :wind_chime: `:wind_chime:`             |\n|                     :rice_scene: `:rice_scene:`                     |             :jack_o_lantern: `:jack_o_lantern:`             |                  :ghost: `:ghost:`                  |\n|                          :santa: `:santa:`                          |             :christmas_tree: `:christmas_tree:`             |                   :gift: `:gift:`                   |\n|                           :bell: `:bell:`                           |                    :no_bell: `:no_bell:`                    |          :tanabata_tree: `:tanabata_tree:`          |\n|                           :tada: `:tada:`                           |              :confetti_ball: `:confetti_ball:`              |                :balloon: `:balloon:`                |\n|                   :crystal_ball: `:crystal_ball:`                   |                         :cd: `:cd:`                         |                    :dvd: `:dvd:`                    |\n|                    :floppy_disk: `:floppy_disk:`                    |                     :camera: `:camera:`                     |           :video_camera: `:video_camera:`           |\n|                   :movie_camera: `:movie_camera:`                   |                   :computer: `:computer:`                   |                     :tv: `:tv:`                     |\n|                         :iphone: `:iphone:`                         |                      :phone: `:phone:`                      |              :telephone: `:telephone:`              |\n|             :telephone_receiver: `:telephone_receiver:`             |                      :pager: `:pager:`                      |                    :fax: `:fax:`                    |\n|                       :minidisc: `:minidisc:`                       |                        :vhs: `:vhs:`                        |                  :sound: `:sound:`                  |\n|                        :speaker: `:speaker:`                        |                       :mute: `:mute:`                       |            :loudspeaker: `:loudspeaker:`            |\n|                           :mega: `:mega:`                           |                  :hourglass: `:hourglass:`                  | :hourglass_flowing_sand: `:hourglass_flowing_sand:` |\n|                    :alarm_clock: `:alarm_clock:`                    |                      :watch: `:watch:`                      |                  :radio: `:radio:`                  |\n|                      :satellite: `:satellite:`                      |                       :loop: `:loop:`                       |                    :mag: `:mag:`                    |\n|                      :mag_right: `:mag_right:`                      |                     :unlock: `:unlock:`                     |                   :lock: `:lock:`                   |\n|              :lock_with_ink_pen: `:lock_with_ink_pen:`              |       :closed_lock_with_key: `:closed_lock_with_key:`       |                    :key: `:key:`                    |\n|                           :bulb: `:bulb:`                           |                 :flashlight: `:flashlight:`                 |        :high_brightness: `:high_brightness:`        |\n|                 :low_brightness: `:low_brightness:`                 |              :electric_plug: `:electric_plug:`              |                :battery: `:battery:`                |\n|                        :calling: `:calling:`                        |                      :email: `:email:`                      |                :mailbox: `:mailbox:`                |\n|                        :postbox: `:postbox:`                        |                       :bath: `:bath:`                       |                :bathtub: `:bathtub:`                |\n|                         :shower: `:shower:`                         |                     :toilet: `:toilet:`                     |                 :wrench: `:wrench:`                 |\n|                   :nut_and_bolt: `:nut_and_bolt:`                   |                     :hammer: `:hammer:`                     |                   :seat: `:seat:`                   |\n|                       :moneybag: `:moneybag:`                       |                        :yen: `:yen:`                        |                 :dollar: `:dollar:`                 |\n|                          :pound: `:pound:`                          |                       :euro: `:euro:`                       |            :credit_card: `:credit_card:`            |\n|               :money_with_wings: `:money_with_wings:`               |                     :e-mail: `:e-mail:`                     |             :inbox_tray: `:inbox_tray:`             |\n|                    :outbox_tray: `:outbox_tray:`                    |                   :envelope: `:envelope:`                   |      :incoming_envelope: `:incoming_envelope:`      |\n|                    :postal_horn: `:postal_horn:`                    |             :mailbox_closed: `:mailbox_closed:`             |      :mailbox_with_mail: `:mailbox_with_mail:`      |\n|           :mailbox_with_no_mail: `:mailbox_with_no_mail:`           |                       :door: `:door:`                       |                :smoking: `:smoking:`                |\n|                           :bomb: `:bomb:`                           |                        :gun: `:gun:`                        |                  :hocho: `:hocho:`                  |\n|                           :pill: `:pill:`                           |                    :syringe: `:syringe:`                    |         :page_facing_up: `:page_facing_up:`         |\n|                 :page_with_curl: `:page_with_curl:`                 |              :bookmark_tabs: `:bookmark_tabs:`              |              :bar_chart: `:bar_chart:`              |\n|       :chart_with_upwards_trend: `:chart_with_upwards_trend:`       | :chart_with_downwards_trend: `:chart_with_downwards_trend:` |                 :scroll: `:scroll:`                 |\n|                      :clipboard: `:clipboard:`                      |                   :calendar: `:calendar:`                   |                   :date: `:date:`                   |\n|                     :card_index: `:card_index:`                     |                :file_folder: `:file_folder:`                |       :open_file_folder: `:open_file_folder:`       |\n|                       :scissors: `:scissors:`                       |                    :pushpin: `:pushpin:`                    |              :paperclip: `:paperclip:`              |\n|                      :black_nib: `:black_nib:`                      |                    :pencil2: `:pencil2:`                    |         :straight_ruler: `:straight_ruler:`         |\n|               :triangular_ruler: `:triangular_ruler:`               |                :closed_book: `:closed_book:`                |             :green_book: `:green_book:`             |\n|                      :blue_book: `:blue_book:`                      |                :orange_book: `:orange_book:`                |               :notebook: `:notebook:`               |\n| :notebook_with_decorative_cover: `:notebook_with_decorative_cover:` |                     :ledger: `:ledger:`                     |                  :books: `:books:`                  |\n|                       :bookmark: `:bookmark:`                       |                 :name_badge: `:name_badge:`                 |             :microscope: `:microscope:`             |\n|                      :telescope: `:telescope:`                      |                  :newspaper: `:newspaper:`                  |               :football: `:football:`               |\n|                     :basketball: `:basketball:`                     |                     :soccer: `:soccer:`                     |               :baseball: `:baseball:`               |\n|                         :tennis: `:tennis:`                         |                      :8ball: `:8ball:`                      |         :rugby_football: `:rugby_football:`         |\n|                        :bowling: `:bowling:`                        |                       :golf: `:golf:`                       |     :mountain_bicyclist: `:mountain_bicyclist:`     |\n|                      :bicyclist: `:bicyclist:`                      |               :horse_racing: `:horse_racing:`               |            :snowboarder: `:snowboarder:`            |\n|                        :swimmer: `:swimmer:`                        |                     :surfer: `:surfer:`                     |                    :ski: `:ski:`                    |\n|                         :spades: `:spades:`                         |                     :hearts: `:hearts:`                     |                  :clubs: `:clubs:`                  |\n|                       :diamonds: `:diamonds:`                       |                        :gem: `:gem:`                        |                   :ring: `:ring:`                   |\n|                         :trophy: `:trophy:`                         |              :musical_score: `:musical_score:`              |       :musical_keyboard: `:musical_keyboard:`       |\n|                         :violin: `:violin:`                         |              :space_invader: `:space_invader:`              |             :video_game: `:video_game:`             |\n|                    :black_joker: `:black_joker:`                    |       :flower_playing_cards: `:flower_playing_cards:`       |               :game_die: `:game_die:`               |\n|                           :dart: `:dart:`                           |                    :mahjong: `:mahjong:`                    |                :clapper: `:clapper:`                |\n|                           :memo: `:memo:`                           |                     :pencil: `:pencil:`                     |                   :book: `:book:`                   |\n|                            :art: `:art:`                            |                 :microphone: `:microphone:`                 |             :headphones: `:headphones:`             |\n|                        :trumpet: `:trumpet:`                        |                  :saxophone: `:saxophone:`                  |                 :guitar: `:guitar:`                 |\n|                           :shoe: `:shoe:`                           |                     :sandal: `:sandal:`                     |              :high_heel: `:high_heel:`              |\n|                       :lipstick: `:lipstick:`                       |                       :boot: `:boot:`                       |                  :shirt: `:shirt:`                  |\n|                         :tshirt: `:tshirt:`                         |                    :necktie: `:necktie:`                    |         :womans_clothes: `:womans_clothes:`         |\n|                          :dress: `:dress:`                          |    :running_shirt_with_sash: `:running_shirt_with_sash:`    |                  :jeans: `:jeans:`                  |\n|                         :kimono: `:kimono:`                         |                     :bikini: `:bikini:`                     |                 :ribbon: `:ribbon:`                 |\n|                         :tophat: `:tophat:`                         |                      :crown: `:crown:`                      |             :womans_hat: `:womans_hat:`             |\n|                      :mans_shoe: `:mans_shoe:`                      |            :closed_umbrella: `:closed_umbrella:`            |              :briefcase: `:briefcase:`              |\n|                        :handbag: `:handbag:`                        |                      :pouch: `:pouch:`                      |                  :purse: `:purse:`                  |\n|                     :eyeglasses: `:eyeglasses:`                     |      :fishing_pole_and_fish: `:fishing_pole_and_fish:`      |                 :coffee: `:coffee:`                 |\n|                            :tea: `:tea:`                            |                       :sake: `:sake:`                       |            :baby_bottle: `:baby_bottle:`            |\n|                           :beer: `:beer:`                           |                      :beers: `:beers:`                      |               :cocktail: `:cocktail:`               |\n|                 :tropical_drink: `:tropical_drink:`                 |                 :wine_glass: `:wine_glass:`                 |         :fork_and_knife: `:fork_and_knife:`         |\n|                          :pizza: `:pizza:`                          |                  :hamburger: `:hamburger:`                  |                  :fries: `:fries:`                  |\n|                    :poultry_leg: `:poultry_leg:`                    |               :meat_on_bone: `:meat_on_bone:`               |              :spaghetti: `:spaghetti:`              |\n|                          :curry: `:curry:`                          |               :fried_shrimp: `:fried_shrimp:`               |                  :bento: `:bento:`                  |\n|                          :sushi: `:sushi:`                          |                  :fish_cake: `:fish_cake:`                  |              :rice_ball: `:rice_ball:`              |\n|                   :rice_cracker: `:rice_cracker:`                   |                       :rice: `:rice:`                       |                  :ramen: `:ramen:`                  |\n|                           :stew: `:stew:`                           |                       :oden: `:oden:`                       |                  :dango: `:dango:`                  |\n|                            :egg: `:egg:`                            |                      :bread: `:bread:`                      |               :doughnut: `:doughnut:`               |\n|                        :custard: `:custard:`                        |                   :icecream: `:icecream:`                   |              :ice_cream: `:ice_cream:`              |\n|                     :shaved_ice: `:shaved_ice:`                     |                   :birthday: `:birthday:`                   |                   :cake: `:cake:`                   |\n|                         :cookie: `:cookie:`                         |              :chocolate_bar: `:chocolate_bar:`              |                  :candy: `:candy:`                  |\n|                       :lollipop: `:lollipop:`                       |                  :honey_pot: `:honey_pot:`                  |                  :apple: `:apple:`                  |\n|                    :green_apple: `:green_apple:`                    |                  :tangerine: `:tangerine:`                  |                  :lemon: `:lemon:`                  |\n|                       :cherries: `:cherries:`                       |                     :grapes: `:grapes:`                     |             :watermelon: `:watermelon:`             |\n|                     :strawberry: `:strawberry:`                     |                      :peach: `:peach:`                      |                  :melon: `:melon:`                  |\n|                         :banana: `:banana:`                         |                       :pear: `:pear:`                       |              :pineapple: `:pineapple:`              |\n|                   :sweet_potato: `:sweet_potato:`                   |                   :eggplant: `:eggplant:`                   |                 :tomato: `:tomato:`                 |\n|                           :corn: `:corn:`                           |\n\n## Places\n\n|               :house: `:house:`               |       :house_with_garden: `:house_with_garden:`       |                 :school: `:school:`                 |\n| :-------------------------------------------: | :---------------------------------------------------: | :-------------------------------------------------: |\n|              :office: `:office:`              |             :post_office: `:post_office:`             |               :hospital: `:hospital:`               |\n|                :bank: `:bank:`                |       :convenience_store: `:convenience_store:`       |             :love_hotel: `:love_hotel:`             |\n|               :hotel: `:hotel:`               |                 :wedding: `:wedding:`                 |                 :church: `:church:`                 |\n|    :department_store: `:department_store:`    |    :european_post_office: `:european_post_office:`    |           :city_sunrise: `:city_sunrise:`           |\n|         :city_sunset: `:city_sunset:`         |         :japanese_castle: `:japanese_castle:`         |        :european_castle: `:european_castle:`        |\n|                :tent: `:tent:`                |                 :factory: `:factory:`                 |            :tokyo_tower: `:tokyo_tower:`            |\n|               :japan: `:japan:`               |              :mount_fuji: `:mount_fuji:`              | :sunrise_over_mountains: `:sunrise_over_mountains:` |\n|             :sunrise: `:sunrise:`             |                   :stars: `:stars:`                   |      :statue_of_liberty: `:statue_of_liberty:`      |\n|     :bridge_at_night: `:bridge_at_night:`     |          :carousel_horse: `:carousel_horse:`          |                :rainbow: `:rainbow:`                |\n|        :ferris_wheel: `:ferris_wheel:`        |                :fountain: `:fountain:`                |         :roller_coaster: `:roller_coaster:`         |\n|                :ship: `:ship:`                |               :speedboat: `:speedboat:`               |                   :boat: `:boat:`                   |\n|            :sailboat: `:sailboat:`            |                 :rowboat: `:rowboat:`                 |                 :anchor: `:anchor:`                 |\n|              :rocket: `:rocket:`              |                :airplane: `:airplane:`                |             :helicopter: `:helicopter:`             |\n|    :steam_locomotive: `:steam_locomotive:`    |                    :tram: `:tram:`                    |       :mountain_railway: `:mountain_railway:`       |\n|                :bike: `:bike:`                |          :aerial_tramway: `:aerial_tramway:`          |     :suspension_railway: `:suspension_railway:`     |\n|   :mountain_cableway: `:mountain_cableway:`   |                 :tractor: `:tractor:`                 |               :blue_car: `:blue_car:`               |\n| :oncoming_automobile: `:oncoming_automobile:` |                     :car: `:car:`                     |                :red_car: `:red_car:`                |\n|                :taxi: `:taxi:`                |           :oncoming_taxi: `:oncoming_taxi:`           |      :articulated_lorry: `:articulated_lorry:`      |\n|                 :bus: `:bus:`                 |            :oncoming_bus: `:oncoming_bus:`            |         :rotating_light: `:rotating_light:`         |\n|          :police_car: `:police_car:`          |     :oncoming_police_car: `:oncoming_police_car:`     |            :fire_engine: `:fire_engine:`            |\n|           :ambulance: `:ambulance:`           |                 :minibus: `:minibus:`                 |                  :truck: `:truck:`                  |\n|               :train: `:train:`               |                 :station: `:station:`                 |                 :train2: `:train2:`                 |\n|   :bullettrain_front: `:bullettrain_front:`   |        :bullettrain_side: `:bullettrain_side:`        |             :light_rail: `:light_rail:`             |\n|            :monorail: `:monorail:`            |             :railway_car: `:railway_car:`             |             :trolleybus: `:trolleybus:`             |\n|              :ticket: `:ticket:`              |                :fuelpump: `:fuelpump:`                | :vertical_traffic_light: `:vertical_traffic_light:` |\n|       :traffic_light: `:traffic_light:`       |                 :warning: `:warning:`                 |           :construction: `:construction:`           |\n|            :beginner: `:beginner:`            |                     :atm: `:atm:`                     |           :slot_machine: `:slot_machine:`           |\n|             :busstop: `:busstop:`             |                  :barber: `:barber:`                  |             :hotsprings: `:hotsprings:`             |\n|      :checkered_flag: `:checkered_flag:`      |           :crossed_flags: `:crossed_flags:`           |        :izakaya_lantern: `:izakaya_lantern:`        |\n|               :moyai: `:moyai:`               |             :circus_tent: `:circus_tent:`             |        :performing_arts: `:performing_arts:`        |\n|       :round_pushpin: `:round_pushpin:`       | :triangular_flag_on_post: `:triangular_flag_on_post:` |                     :jp: `:jp:`                     |\n|                  :kr: `:kr:`                  |                      :cn: `:cn:`                      |                     :us: `:us:`                     |\n|                  :fr: `:fr:`                  |                      :es: `:es:`                      |                     :it: `:it:`                     |\n|                  :ru: `:ru:`                  |                      :gb: `:gb:`                      |                     :uk: `:uk:`                     |\n|                  :de: `:de:`                  |\n\n## Symbols\n\n|                             :one: `:one:`                             |                         :two: `:two:`                         |                     :three: `:three:`                     |\n| :-------------------------------------------------------------------: | :-----------------------------------------------------------: | :-------------------------------------------------------: |\n|                            :four: `:four:`                            |                        :five: `:five:`                        |                       :six: `:six:`                       |\n|                           :seven: `:seven:`                           |                       :eight: `:eight:`                       |                      :nine: `:nine:`                      |\n|                      :keycap_ten: `:keycap_ten:`                      |                        :1234: `:1234:`                        |                      :zero: `:zero:`                      |\n|                            :hash: `:hash:`                            |                     :symbols: `:symbols:`                     |            :arrow_backward: `:arrow_backward:`            |\n|                      :arrow_down: `:arrow_down:`                      |               :arrow_forward: `:arrow_forward:`               |                :arrow_left: `:arrow_left:`                |\n|                    :capital_abcd: `:capital_abcd:`                    |                        :abcd: `:abcd:`                        |                       :abc: `:abc:`                       |\n|                :arrow_lower_left: `:arrow_lower_left:`                |           :arrow_lower_right: `:arrow_lower_right:`           |               :arrow_right: `:arrow_right:`               |\n|                        :arrow_up: `:arrow_up:`                        |            :arrow_upper_left: `:arrow_upper_left:`            |         :arrow_upper_right: `:arrow_upper_right:`         |\n|               :arrow_double_down: `:arrow_double_down:`               |             :arrow_double_up: `:arrow_double_up:`             |          :arrow_down_small: `:arrow_down_small:`          |\n|              :arrow_heading_down: `:arrow_heading_down:`              |            :arrow_heading_up: `:arrow_heading_up:`            | :leftwards_arrow_with_hook: `:leftwards_arrow_with_hook:` |\n|                :arrow_right_hook: `:arrow_right_hook:`                |            :left_right_arrow: `:left_right_arrow:`            |             :arrow_up_down: `:arrow_up_down:`             |\n|                  :arrow_up_small: `:arrow_up_small:`                  |            :arrows_clockwise: `:arrows_clockwise:`            |   :arrows_counterclockwise: `:arrows_counterclockwise:`   |\n|                          :rewind: `:rewind:`                          |                :fast_forward: `:fast_forward:`                |        :information_source: `:information_source:`        |\n|                              :ok: `:ok:`                              |   :twisted_rightwards_arrows: `:twisted_rightwards_arrows:`   |                    :repeat: `:repeat:`                    |\n|                      :repeat_one: `:repeat_one:`                      |                         :new: `:new:`                         |                       :top: `:top:`                       |\n|                              :up: `:up:`                              |                        :cool: `:cool:`                        |                      :free: `:free:`                      |\n|                              :ng: `:ng:`                              |                      :cinema: `:cinema:`                      |                      :koko: `:koko:`                      |\n|                 :signal_strength: `:signal_strength:`                 |                       :u5272: `:u5272:`                       |                     :u5408: `:u5408:`                     |\n|                           :u55b6: `:u55b6:`                           |                       :u6307: `:u6307:`                       |                     :u6708: `:u6708:`                     |\n|                           :u6709: `:u6709:`                           |                       :u6e80: `:u6e80:`                       |                     :u7121: `:u7121:`                     |\n|                           :u7533: `:u7533:`                           |                       :u7a7a: `:u7a7a:`                       |                     :u7981: `:u7981:`                     |\n|                              :sa: `:sa:`                              |                    :restroom: `:restroom:`                    |                      :mens: `:mens:`                      |\n|                          :womens: `:womens:`                          |                 :baby_symbol: `:baby_symbol:`                 |                :no_smoking: `:no_smoking:`                |\n|                         :parking: `:parking:`                         |                  :wheelchair: `:wheelchair:`                  |                     :metro: `:metro:`                     |\n|                   :baggage_claim: `:baggage_claim:`                   |                      :accept: `:accept:`                      |                        :wc: `:wc:`                        |\n|                   :potable_water: `:potable_water:`                   |     :put_litter_in_its_place: `:put_litter_in_its_place:`     |                    :secret: `:secret:`                    |\n|                 :congratulations: `:congratulations:`                 |                           :m: `:m:`                           |          :passport_control: `:passport_control:`          |\n|                    :left_luggage: `:left_luggage:`                    |                     :customs: `:customs:`                     |       :ideograph_advantage: `:ideograph_advantage:`       |\n|                              :cl: `:cl:`                              |                         :sos: `:sos:`                         |                        :id: `:id:`                        |\n|                   :no_entry_sign: `:no_entry_sign:`                   |                    :underage: `:underage:`                    |          :no_mobile_phones: `:no_mobile_phones:`          |\n|                   :do_not_litter: `:do_not_litter:`                   |           :non-potable_water: `:non-potable_water:`           |               :no_bicycles: `:no_bicycles:`               |\n|                  :no_pedestrians: `:no_pedestrians:`                  |           :children_crossing: `:children_crossing:`           |                  :no_entry: `:no_entry:`                  |\n|           :eight_spoked_asterisk: `:eight_spoked_asterisk:`           |    :eight_pointed_black_star: `:eight_pointed_black_star:`    |          :heart_decoration: `:heart_decoration:`          |\n|                              :vs: `:vs:`                              |              :vibration_mode: `:vibration_mode:`              |          :mobile_phone_off: `:mobile_phone_off:`          |\n|                           :chart: `:chart:`                           |           :currency_exchange: `:currency_exchange:`           |                     :aries: `:aries:`                     |\n|                          :taurus: `:taurus:`                          |                      :gemini: `:gemini:`                      |                    :cancer: `:cancer:`                    |\n|                             :leo: `:leo:`                             |                       :virgo: `:virgo:`                       |                     :libra: `:libra:`                     |\n|                        :scorpius: `:scorpius:`                        |                 :sagittarius: `:sagittarius:`                 |                 :capricorn: `:capricorn:`                 |\n|                        :aquarius: `:aquarius:`                        |                      :pisces: `:pisces:`                      |                 :ophiuchus: `:ophiuchus:`                 |\n|                :six_pointed_star: `:six_pointed_star:`                | :negative_squared_cross_mark: `:negative_squared_cross_mark:` |                         :a: `:a:`                         |\n|                               :b: `:b:`                               |                          :ab: `:ab:`                          |                        :o2: `:o2:`                        |\n| :diamond_shape_with_a_dot_inside: `:diamond_shape_with_a_dot_inside:` |                     :recycle: `:recycle:`                     |                       :end: `:end:`                       |\n|                              :on: `:on:`                              |                        :soon: `:soon:`                        |                    :clock1: `:clock1:`                    |\n|                        :clock130: `:clock130:`                        |                     :clock10: `:clock10:`                     |                 :clock1030: `:clock1030:`                 |\n|                         :clock11: `:clock11:`                         |                   :clock1130: `:clock1130:`                   |                   :clock12: `:clock12:`                   |\n|                       :clock1230: `:clock1230:`                       |                      :clock2: `:clock2:`                      |                  :clock230: `:clock230:`                  |\n|                          :clock3: `:clock3:`                          |                    :clock330: `:clock330:`                    |                    :clock4: `:clock4:`                    |\n|                        :clock430: `:clock430:`                        |                      :clock5: `:clock5:`                      |                  :clock530: `:clock530:`                  |\n|                          :clock6: `:clock6:`                          |                    :clock630: `:clock630:`                    |                    :clock7: `:clock7:`                    |\n|                        :clock730: `:clock730:`                        |                      :clock8: `:clock8:`                      |                  :clock830: `:clock830:`                  |\n|                          :clock9: `:clock9:`                          |                    :clock930: `:clock930:`                    |         :heavy_dollar_sign: `:heavy_dollar_sign:`         |\n|                       :copyright: `:copyright:`                       |                  :registered: `:registered:`                  |                        :tm: `:tm:`                        |\n|                               :x: `:x:`                               |      :heavy_exclamation_mark: `:heavy_exclamation_mark:`      |                  :bangbang: `:bangbang:`                  |\n|                     :interrobang: `:interrobang:`                     |                           :o: `:o:`                           |    :heavy_multiplication_x: `:heavy_multiplication_x:`    |\n|                 :heavy_plus_sign: `:heavy_plus_sign:`                 |            :heavy_minus_sign: `:heavy_minus_sign:`            |       :heavy_division_sign: `:heavy_division_sign:`       |\n|                    :white_flower: `:white_flower:`                    |                         :100: `:100:`                         |          :heavy_check_mark: `:heavy_check_mark:`          |\n|           :ballot_box_with_check: `:ballot_box_with_check:`           |                :radio_button: `:radio_button:`                |                      :link: `:link:`                      |\n|                      :curly_loop: `:curly_loop:`                      |                   :wavy_dash: `:wavy_dash:`                   |     :part_alternation_mark: `:part_alternation_mark:`     |\n|                         :trident: `:trident:`                         |                :black_square: `:black_square:`                |              :white_square: `:white_square:`              |\n|                :white_check_mark: `:white_check_mark:`                |         :black_square_button: `:black_square_button:`         |       :white_square_button: `:white_square_button:`       |\n|                    :black_circle: `:black_circle:`                    |                :white_circle: `:white_circle:`                |                :red_circle: `:red_circle:`                |\n|               :large_blue_circle: `:large_blue_circle:`               |          :large_blue_diamond: `:large_blue_diamond:`          |      :large_orange_diamond: `:large_orange_diamond:`      |\n|              :small_blue_diamond: `:small_blue_diamond:`              |        :small_orange_diamond: `:small_orange_diamond:`        |        :small_red_triangle: `:small_red_triangle:`        |\n|         :small_red_triangle_down: `:small_red_triangle_down:`         |                                                               |\n\n<sup>Source: [https://gist.github.com/rxaviers/7360908](https://gist.github.com/rxaviers/7360908) (with additional change)</sup>\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.265Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Mastodon",
      "content": "https://www.npmjs.com/package/megalodon\n\nhttps://docs.joinmastodon.org/\n\nhttps://www.npmjs.com/package/mastodon\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.265Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Minotaur.Agency Website",
      "content": "```html\n<!DOCTYPE html>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\" />\n\n  <title>M1N0TAUR</title>\n  <style type=\"text/css\">\n    body {\n      background-color: #fff;\n      color: #020202;\n      font-family: monospace;\n    }\n\n\n\n    #splash {\n      line-height: 10pt;\n      position: absolute;\n      top: 50%;\n    }\n\n\n\n    .spaced-letter {\n      display: inline-block;\n      width: 10px;\n    }\n\n    .f1 {\n      color: #333;\n    }\n\n    .f2 {\n      color: #999;\n    }\n\n    .f3 {\n      color: #666;\n    }\n\n    .f4 {\n      color: #fff;\n    }\n\n    .f5 {\n      color: #eee;\n    }\n\n    .invert {\n      color: #fff;\n      background-color: #020202;\n    }\n\n  </style>\n\n</head>\n<body>\n\n  <div id=\"splash\">\n    <span id=\"splash-text\">M1N0TAUR</span>\n    <span class=\"invert\">ASYMETRICAL INFORMATION STRATEGIES</span>\n  </div>\n\n\n  <script type=\"text/javascript\">\n    function randomInt(max){\n      return Math.floor(Math.random() * max)\n    }\n\n\n\n    const logo = document.getElementById(\"splash-text\")\n    const glitches = {\n      M: [\"M\", \"▼\"],\n      I: ['1', \"I\"],\n      N: [\"N\",],\n      O: [\"0\", \"O\", \"◌\"],\n      T: [\"T\", \"†\"],\n      A: [\"A\", \"◮\",\"◬\"],\n      U: [\"U\", \"▽\"],\n      R: [\"R\"],\n      G: [\"G\", \"⅁\",],\n      E: [\"E\", \"3\",\"ℇ\"],\n      C: [\"C\",\"℃\"],\n      Y: [\"Y\", \"⅄\"],\n      \".\": [\".\", \" \",\"|\",\">\",\"<\"]\n    }\n\n    const text = \"MINOTAUR.\".split(\"\")\n    let newText = text.slice();\n\n    setInterval(function(){\n      const amount = randomInt(5)\n      let i = 0;\n\n      while(i < amount){\n        let textAddress = randomInt(text.length)\n        let textKey = text[textAddress]\n\n        newText[textAddress] = glitches[textKey][randomInt(glitches[textKey].length)]\n\n        document.title = newText.join(\"\")\n        logo.innerHTML = newText.map(t => `<span class=\"spaced-letter\">${t}</span>`).join(\"\")\n        i++\n      }\n\n\n    },100)\n\n\n  </script>\n\n</body>\n</html>\n\n```\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:38:13.396Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Mixed Reality",
      "content": ""
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-13T20:02:23.893Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "MongoDB prototypes",
      "content": "```js\nconst dotenv = require(\"dotenv\");\ndotenv.config();\nconst { MongoClient, ServerApiVersion } = require('mongodb');\n\nconst uri = `mongodb+srv://LNSY:${process.env.MONGO_KEY}@hans-js.1h3yhsa.mongodb.net/?retryWrites=true&w=majority`;\n\n// Create a MongoClient with a MongoClientOptions object to set the Stable API version\nconst client = new MongoClient(uri, {\n  serverApi: {\n    version: ServerApiVersion.v1,\n    strict: true,\n    deprecationErrors: true,\n  }\n});\n\nasync function run() {\n  try {\n    // Connect the client to the server (optional starting in v4.7)\n    await client.connect();\n    // Send a ping to confirm a successful connection\n    await client.db(\"admin\").command({ ping: 1 });\n    console.log(\"Pinged your deployment. You successfully connected to MongoDB!\");\n  } finally {\n    // Ensures that the client will close when you finish/error\n    await client.close();\n  }\n}\nrun().catch(console.dir);\n\n\n/*\n\nasync function createDocument(imageId, targetId, sessionId) {\n  const uri = 'mongodb://localhost:27017'; // Replace with your MongoDB connection URI\n  const client = new MongoClient(uri);\n\n  try {\n    await client.connect();\n\n    const database = client.db('your_database_name'); // Replace with your database name\n    const collection = database.collection('your_collection_name'); // Replace with your collection name\n\n    const document = {\n      \"image-id\": imageId,\n      \"target-id\": targetId,\n      \"session-id\": sessionId\n    };\n\n    const result = await collection.insertOne(document);\n    console.log(`Document created with ID: ${result.insertedId}`);\n  } catch (error) {\n    console.error('Error occurred while creating the document:', error);\n  } finally {\n    await client.close();\n  }\n}\n\n// Usage\ncreateDocument(\"image id here\", \"target image id here\", \"user session id here\");\n\n\n*/\n\n\n/*\n\nHere's an example function in Node.js that finds all \ndocuments in MongoDB with the same \"image-id\" field \nand returns the corresponding \"target-id\" values:\n\n\nconst MongoClient = require('mongodb').MongoClient;\n\nasync function findDocumentsByImageId(imageId) {\n  const uri = 'mongodb://localhost:27017'; // Replace with your MongoDB connection URI\n  const client = new MongoClient(uri);\n\n  try {\n    await client.connect();\n\n    const database = client.db('your_database_name'); // Replace with your database name\n    const collection = database.collection('your_collection_name'); // Replace with your collection name\n\n    const query = { \"image-id\": imageId };\n    const projection = { \"target-id\": 1, _id: 0 }; // Only retrieve the \"target-id\" field, exclude the _id field\n\n    const result = await collection.find(query).project(projection).toArray();\n    const targetIds = result.map(document => document[\"target-id\"]);\n\n    console.log(`Target IDs for image ID ${imageId}:`, targetIds);\n    return targetIds;\n  } catch (error) {\n    console.error('Error occurred while finding documents:', error);\n  } finally {\n    await client.close();\n  }\n}\n\n// Usage\nfindDocumentsByImageId(\"image id here\");\n\n*/\n\n\n/*\n\n\nconst MongoClient = require('mongodb').MongoClient;\n\nasync function findDocumentsByKeyValue(key, value) {\n  const uri = 'mongodb://localhost:27017'; // Replace with your MongoDB connection URI\n  const client = new MongoClient(uri);\n\n  try {\n    await client.connect();\n\n    const database = client.db('your_database_name'); // Replace with your database name\n    const collection = database.collection('your_collection_name'); // Replace with your collection name\n\n    const query = { [key]: value };\n\n    const result = await collection.find(query).toArray();\n\n    console.log(`Documents matching ${key} = ${value}:`, result);\n    return result;\n  } catch (error) {\n    console.error('Error occurred while finding documents:', error);\n  } finally {\n    await client.close();\n  }\n}\n\n// Usage\nfindDocumentsByKeyValue(\"key here\", \"value here\");\n\n\n*/\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-05-22T22:53:14.995Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "MongoDB",
      "content": "\n\n\n\n```js\nconst { MongoClient, ServerApiVersion } = require('mongodb');\nconst uri = \"?retryWrites=true&w=majority\";\nconst client = new MongoClient(uri, { useNewUrlParser: true, useUnifiedTopology: true, serverApi: ServerApiVersion.v1 });\nclient.connect(err => {\n  const collection = client.db(\"test\").collection(\"devices\");\n  // perform actions on the collection object\n  client.close();\n});\n```\n\n\nhttps://github.com/mongodb-university/atlas_starter_nodejs\n\n```js\n\nconst { MongoClient } = require(\"mongodb\");\n\nasync function run() {\n  // TODO:\n  // Replace the placeholder connection string below with your\n  // Altas cluster specifics. Be sure it includes\n  // a valid username and password! Note that in a production environment,\n  // you do not want to store your password in plain-text here.\n  const uri =\n    \"mongodb+srv://<user>:<password>@<cluster-url>?retryWrites=true&w=majority\";\n\n  // The MongoClient is the object that references the connection to our\n  // datastore (Atlas, for example)\n  const client = new MongoClient(uri);\n\n  // The connect() method does not attempt a connection; instead it instructs\n  // the driver to connect using the settings provided when a connection\n  // is required.\n  await client.connect();\n\n  // Provide the name of the database and collection you want to use.\n  // If the database and/or collection do not exist, the driver and Atlas\n  // will create them automatically when you first write data.\n  const dbName = \"myDatabase\";\n  const collectionName = \"recipes\";\n\n  // Create references to the database and collection in order to run\n  // operations on them.\n  const database = client.db(dbName);\n  const collection = database.collection(collectionName);\n\n  /*\n   *  *** INSERT DOCUMENTS ***\n   *\n   * You can insert individual documents using collection.insert().\n   * In this example, we're going to create four documents and then\n   * insert them all in one call with collection.insertMany().\n   */\n\n  const recipes = [\n    {\n      name: \"elotes\",\n      ingredients: [\n        \"corn\",\n        \"mayonnaise\",\n        \"cotija cheese\",\n        \"sour cream\",\n        \"lime\",\n      ],\n      prepTimeInMinutes: 35,\n    },\n    {\n      name: \"loco moco\",\n      ingredients: [\n        \"ground beef\",\n        \"butter\",\n        \"onion\",\n        \"egg\",\n        \"bread bun\",\n        \"mushrooms\",\n      ],\n      prepTimeInMinutes: 54,\n    },\n    {\n      name: \"patatas bravas\",\n      ingredients: [\n        \"potato\",\n        \"tomato\",\n        \"olive oil\",\n        \"onion\",\n        \"garlic\",\n        \"paprika\",\n      ],\n      prepTimeInMinutes: 80,\n    },\n    {\n      name: \"fried rice\",\n      ingredients: [\n        \"rice\",\n        \"soy sauce\",\n        \"egg\",\n        \"onion\",\n        \"pea\",\n        \"carrot\",\n        \"sesame oil\",\n      ],\n      prepTimeInMinutes: 40,\n    },\n  ];\n\n  try {\n    const insertManyResult = await collection.insertMany(recipes);\n    console.log(`${insertManyResult.insertedCount} documents successfully inserted.\\n`);\n  } catch (err) {\n    console.error(`Something went wrong trying to insert the new documents: ${err}\\n`);\n  }\n\n  /*\n   * *** FIND DOCUMENTS ***\n   *\n   * Now that we have data in Atlas, we can read it. To retrieve all of\n   * the data in a collection, we call Find() with an empty filter.\n   * The Builders class is very helpful when building complex\n   * filters, and is used here to show its most basic use.\n   */\n\n  const findQuery = { prepTimeInMinutes: { $lt: 45 } };\n\n  try {\n    const cursor = await collection.find(findQuery).sort({ name: 1 });\n    await cursor.forEach(recipe => {\n      console.log(`${recipe.name} has ${recipe.ingredients.length} ingredients and takes ${recipe.prepTimeInMinutes} minutes to make.`);\n    });\n    // add a linebreak\n    console.log();\n  } catch (err) {\n    console.error(`Something went wrong trying to find the documents: ${err}\\n`);\n  }\n\n  // We can also find a single document. Let's find the first document\n  // that has the string \"potato\" in the ingredients list.\n  const findOneQuery = { ingredients: \"potato\" };\n\n  try {\n    const findOneResult = await collection.findOne(findOneQuery);\n    if (findOneResult === null) {\n      console.log(\"Couldn't find any recipes that contain 'potato' as an ingredient.\\n\");\n    } else {\n      console.log(`Found a recipe with 'potato' as an ingredient:\\n${JSON.stringify(findOneResult)}\\n`);\n    }\n  } catch (err) {\n    console.error(`Something went wrong trying to find one document: ${err}\\n`);\n  }\n\n  /*\n   * *** UPDATE A DOCUMENT ***\n   *\n   * You can update a single document or multiple documents in a single call.\n   *\n   * Here we update the PrepTimeInMinutes value on the document we\n   * just found.\n   */\n  const updateDoc = { $set: { prepTimeInMinutes: 72 } };\n\n  // The following updateOptions document specifies that we want the *updated*\n  // document to be returned. By default, we get the document as it was *before*\n  // the update.\n  const updateOptions = { returnOriginal: false };\n\n  try {\n    const updateResult = await collection.findOneAndUpdate(\n      findOneQuery,\n      updateDoc,\n      updateOptions,\n    );\n    console.log(`Here is the updated document:\\n${JSON.stringify(updateResult.value)}\\n`);\n  } catch (err) {\n    console.error(`Something went wrong trying to update one document: ${err}\\n`);\n  }\n\n  /*      *** DELETE DOCUMENTS ***\n   *\n   *      As with other CRUD methods, you can delete a single document\n   *      or all documents that match a specified filter. To delete all\n   *      of the documents in a collection, pass an empty filter to\n   *      the DeleteMany() method. In this example, we'll delete two of\n   *      the recipes.\n   */\n\n\n  const deleteQuery = { name: { $in: [\"elotes\", \"fried rice\"] } };\n  try {\n    const deleteResult = await collection.deleteMany(deleteQuery);\n    console.log(`Deleted ${deleteResult.deletedCount} documents\\n`);\n  } catch (err) {\n    console.error(`Something went wrong trying to delete documents: ${err}\\n`);\n  }\n\n  // Make sure to call close() on your client to perform cleanup operations\n  await client.close();\n}\nrun().catch(console.dir);\n```\n\n\n\n---\n```js\nconst { MongoClient, ServerApiVersion } = require('mongodb');\nconst uri = \"mongodb+srv://lindseyasterius:<password>@prototype-saisquoi-ai.uzi9bzp.mongodb.net/?retryWrites=true&w=majority\";\nconst client = new MongoClient(uri, { useNewUrlParser: true, useUnifiedTopology: true, serverApi: ServerApiVersion.v1 });\nclient.connect(err => {\n  const collection = client.db(\"test\").collection(\"devices\");\n  // perform actions on the collection object\n  client.close();\n});\n```\n\n\nhttps://github.com/mongodb-university/atlas_starter_nodejs\n\n```js\n\nconst { MongoClient } = require(\"mongodb\");\n\nasync function run() {\n  // TODO:\n  // Replace the placeholder connection string below with your\n  // Altas cluster specifics. Be sure it includes\n  // a valid username and password! Note that in a production environment,\n  // you do not want to store your password in plain-text here.\n  const uri =\n    \"mongodb+srv://<user>:<password>@<cluster-url>?retryWrites=true&w=majority\";\n\n  // The MongoClient is the object that references the connection to our\n  // datastore (Atlas, for example)\n  const client = new MongoClient(uri);\n\n  // The connect() method does not attempt a connection; instead it instructs\n  // the driver to connect using the settings provided when a connection\n  // is required.\n  await client.connect();\n\n  // Provide the name of the database and collection you want to use.\n  // If the database and/or collection do not exist, the driver and Atlas\n  // will create them automatically when you first write data.\n  const dbName = \"myDatabase\";\n  const collectionName = \"recipes\";\n\n  // Create references to the database and collection in order to run\n  // operations on them.\n  const database = client.db(dbName);\n  const collection = database.collection(collectionName);\n\n  /*\n   *  *** INSERT DOCUMENTS ***\n   *\n   * You can insert individual documents using collection.insert().\n   * In this example, we're going to create four documents and then\n   * insert them all in one call with collection.insertMany().\n   */\n\n  const recipes = [\n    {\n      name: \"elotes\",\n      ingredients: [\n        \"corn\",\n        \"mayonnaise\",\n        \"cotija cheese\",\n        \"sour cream\",\n        \"lime\",\n      ],\n      prepTimeInMinutes: 35,\n    },\n    {\n      name: \"loco moco\",\n      ingredients: [\n        \"ground beef\",\n        \"butter\",\n        \"onion\",\n        \"egg\",\n        \"bread bun\",\n        \"mushrooms\",\n      ],\n      prepTimeInMinutes: 54,\n    },\n    {\n      name: \"patatas bravas\",\n      ingredients: [\n        \"potato\",\n        \"tomato\",\n        \"olive oil\",\n        \"onion\",\n        \"garlic\",\n        \"paprika\",\n      ],\n      prepTimeInMinutes: 80,\n    },\n    {\n      name: \"fried rice\",\n      ingredients: [\n        \"rice\",\n        \"soy sauce\",\n        \"egg\",\n        \"onion\",\n        \"pea\",\n        \"carrot\",\n        \"sesame oil\",\n      ],\n      prepTimeInMinutes: 40,\n    },\n  ];\n\n  try {\n    const insertManyResult = await collection.insertMany(recipes);\n    console.log(`${insertManyResult.insertedCount} documents successfully inserted.\\n`);\n  } catch (err) {\n    console.error(`Something went wrong trying to insert the new documents: ${err}\\n`);\n  }\n\n  /*\n   * *** FIND DOCUMENTS ***\n   *\n   * Now that we have data in Atlas, we can read it. To retrieve all of\n   * the data in a collection, we call Find() with an empty filter.\n   * The Builders class is very helpful when building complex\n   * filters, and is used here to show its most basic use.\n   */\n\n  const findQuery = { prepTimeInMinutes: { $lt: 45 } };\n\n  try {\n    const cursor = await collection.find(findQuery).sort({ name: 1 });\n    await cursor.forEach(recipe => {\n      console.log(`${recipe.name} has ${recipe.ingredients.length} ingredients and takes ${recipe.prepTimeInMinutes} minutes to make.`);\n    });\n    // add a linebreak\n    console.log();\n  } catch (err) {\n    console.error(`Something went wrong trying to find the documents: ${err}\\n`);\n  }\n\n  // We can also find a single document. Let's find the first document\n  // that has the string \"potato\" in the ingredients list.\n  const findOneQuery = { ingredients: \"potato\" };\n\n  try {\n    const findOneResult = await collection.findOne(findOneQuery);\n    if (findOneResult === null) {\n      console.log(\"Couldn't find any recipes that contain 'potato' as an ingredient.\\n\");\n    } else {\n      console.log(`Found a recipe with 'potato' as an ingredient:\\n${JSON.stringify(findOneResult)}\\n`);\n    }\n  } catch (err) {\n    console.error(`Something went wrong trying to find one document: ${err}\\n`);\n  }\n\n  /*\n   * *** UPDATE A DOCUMENT ***\n   *\n   * You can update a single document or multiple documents in a single call.\n   *\n   * Here we update the PrepTimeInMinutes value on the document we\n   * just found.\n   */\n  const updateDoc = { $set: { prepTimeInMinutes: 72 } };\n\n  // The following updateOptions document specifies that we want the *updated*\n  // document to be returned. By default, we get the document as it was *before*\n  // the update.\n  const updateOptions = { returnOriginal: false };\n\n  try {\n    const updateResult = await collection.findOneAndUpdate(\n      findOneQuery,\n      updateDoc,\n      updateOptions,\n    );\n    console.log(`Here is the updated document:\\n${JSON.stringify(updateResult.value)}\\n`);\n  } catch (err) {\n    console.error(`Something went wrong trying to update one document: ${err}\\n`);\n  }\n\n  /*      *** DELETE DOCUMENTS ***\n   *\n   *      As with other CRUD methods, you can delete a single document\n   *      or all documents that match a specified filter. To delete all\n   *      of the documents in a collection, pass an empty filter to\n   *      the DeleteMany() method. In this example, we'll delete two of\n   *      the recipes.\n   */\n\n\n  const deleteQuery = { name: { $in: [\"elotes\", \"fried rice\"] } };\n  try {\n    const deleteResult = await collection.deleteMany(deleteQuery);\n    console.log(`Deleted ${deleteResult.deletedCount} documents\\n`);\n  } catch (err) {\n    console.error(`Something went wrong trying to delete documents: ${err}\\n`);\n  }\n\n  // Make sure to call close() on your client to perform cleanup operations\n  await client.close();\n}\nrun().catch(console.dir);\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-07-04T17:36:34.937Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "MuckRaker",
      "content": "\n\n\nreinstalled fresh. \n\n[[Tesla P40]]\n\n1. sudo apt install openssh-server\n2. sudo systemctl enable ssh\n3. sudo ufw allow ssh\n\nsudo apt install gcc\nsudo apt install make\n\n\ndownloaded the Tesla P40 driver from here: https://nvidia.com/Download/driverResults.aspx/182244/en-us/\n\n\n---\n\nhttps://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/\n\nI installed MongoDB. \n\n\nhttps://stackoverflow.com/questions/40903566/node-js-ssh-tunneling-to-mongodb-using-mongoose\n\nI'm going to use SSH Tunneling to interact with the database across my local network. \n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-02T22:58:11.959Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "NVIDIA, Inc.",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-01-29T20:08:48.627Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Namecheap Github Pages Setup",
      "content": "https://www.namecheap.com/support/knowledgebase/article.aspx/9645/2208/how-do-i-link-my-domain-to-github-pages/\n\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-15T18:50:30.240Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Natural Computing",
      "content": "> **Natural Computing** is a scientific journal covering natural computing research. It has been published quarterly by Springer Verlag (Springer Netherlands) in print (ISSN 1567-7818) and online (ISSN 1572-9796) since 2002.\"Natural Computing refers to computational processes observed in nature, and human-designed computing inspired by nature ... molecular computing and quantum computing ... use of algorithms to consider evolution as a computational process, and neural networks in light of computational trends in brain research.\"It includes 19 open access articles as of 19 June 2016 and has an impact factor of 1.310.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Natural%20Computing%20(journal))\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-11T20:09:59.476Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Navigation Tabs",
      "content": "\n```javascript\n/*\n                    __       ___    __\n  |\\ |  /\\  \\  / | / _`  /\\   |  | /  \\ |\\ |\n  | \\| /~~\\  \\/  | \\__> /~~\\  |  | \\__/ | \\|\n\n  ___       __   __\n   |   /\\  |__) /__`\n   |  /~~\\ |__) .__/\n\n  Navigation Tabs\n\n  Takes a group of anchors and hides / shows \n  their counterparts. \n  \n  Using looks like:\n  <navigation-tabs>\n    <a href=\"#divId\">tab id</a>\n    <a href=\"#secondDivId\">second tab id</a>\n  </navigation-tabs>\n\n  <div id=\"#divId\">This is visible on first load</div>\n  <div id=\"#secondDivId\">This is visible when you click\n  the second tab id link </div>\n\n*/\n\n\n\nclass NavigationTabs extends HTMLElement {\n  connectedCallback(){\n    const items = [...this.querySelectorAll('a')];\n    const route = window.location.hash;\n\n\n    items.forEach((item,i) => {\n      const id = item.getAttribute('href');\n      item.addEventListener('click', (e) => {\n        e.preventDefault();\n        this.goToRoute(id);\n      })\n    })\n\n    if(route === ''){\n      const id = items[0].getAttribute('href');\n      this.goToRoute(id)\n    } else {\n      this.goToRoute(route)\n    }\n\n    window.onpopstate = (event) => {\n      this.goToRoute(window.location.hash)\n    };\n  }\n\n  goToRoute(id){\n    history.replaceState(undefined, undefined, id)\n    const items = this.querySelectorAll('a');\n    [...items].forEach((item,i) => {\n      const item_id = item.getAttribute('href');\n      if(item_id === id){\n        item.classList.add('active');\n        document.querySelector(`${item_id}`).style.display = 'block';\n      } else {\n        item.classList.remove('active')\n        document.querySelector(`${item_id}`).style.display = 'none';        \n      }\n    })\n    setTimeout(function(){window.scrollTo(0,0)},0);\n  }\n\n}\n\ncustomElements.define('navigation-tabs', NavigationTabs)\n\n\n\n\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-09-18T04:15:26.935Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Neo4j",
      "content": "> **Neo4j** is a graph database management system developed by Neo4j, Inc. Described by its developers as an ACID-compliant transactional database with native graph storage and processing, Neo4j is available in a non-open-source \"community edition\" licensed with a modification of the GNU General Public License, with online backup and high availability extensions licensed under a closed-source commercial license. Neo also licenses Neo4j with these extensions under closed-source commercial terms.Neo4j is implemented in Java and accessible from software written in other languages using the Cypher query language through a transactional HTTP endpoint, or through the binary \"Bolt\" protocol.The \"4j\" in Neo4j is a reference to its being built in Java, however is now largely viewed as an anachronism.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Neo4j)\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-10T17:40:54.273Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Nest.js",
      "content": "https://docs.nestjs.com/\n\n> Nest (NestJS) is a framework for building efficient, scalable [Node.js](https://nodejs.org/) server-side applications. It uses progressive JavaScript, is built with and fully supports [TypeScript](http://www.typescriptlang.org/) (yet still enables developers to code in pure JavaScript) and combines elements of OOP (Object Oriented Programming), FP (Functional Programming), and FRP (Functional Reactive Programming).\n\n> Under the hood, Nest makes use of robust HTTP Server frameworks like [Express](https://expressjs.com/) (the default) and optionally can be configured to use [Fastify](https://github.com/fastify/fastify) as well!\n\n> Nest provides a level of abstraction above these common Node.js frameworks (Express/Fastify), but also exposes their APIs directly to the developer. This gives developers the freedom to use the myriad of third-party modules which are available for the underlying platform.\n\n> Philosophy\n\n> In recent years, thanks to Node.js, JavaScript has become the “lingua franca” of the web for both front and backend applications. This has given rise to awesome projects like [Angular](https://angular.io/), [React](https://github.com/facebook/react) and [Vue](https://github.com/vuejs/vue), which improve developer productivity and enable the creation of fast, testable, and extensible frontend applications. However, while plenty of superb libraries, helpers, and tools exist for Node (and server-side JavaScript), none of them effectively solve the main problem of - **Architecture**.\n\n> Nest provides an out-of-the-box application architecture which allows developers and teams to create highly testable, scalable, loosely coupled, and easily maintainable applications. The architecture is heavily inspired by Angular.\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-04T12:52:48.712Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Neural Network",
      "content": "![[Pasted image 20220314112517.png]]\n\n> Artificial **Neural Network**s (ANNs), usually simply called neural networks (NNs), are computing systems inspired by the biological neural networks that constitute animal brains.\n>\n> An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron receives a signal then processes it and can signal neurons connected to it. The \"signal\" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. The connections are called edges. Neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Neurons may have a threshold such that a signal is sent only if the aggregate signal crosses that threshold. Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Artificial%20neural%20network)\n\n#1647281882-2022-03-14\n\nhttps://scrimba.com/playlist/pVZJQfg\n\nShould figure out [[Google Notebooks]] and [[Jupiter Notebooks]]\n\nJavascript Library: [[Brain.js]]\n\n[[Feedforward neural network]]\n\n\n   \n\n\n\n# Exploring Neural Networks Visually in the Browser\n    Originally from: https://cprimozic.net/blog/neural-network-experiments-and-visualizations/\n\n![A 4-second loop of the neural network visualization application training a network, showing both the response of the network as a whole, a cost plot, as well as a visualization of neuron weights and an individual neuron's response plot](media/A_4-second_loop_of_the_neural_network_visualization_application_training_a_network,_showing_both_the.webp)\n\nWhile teaching myself the basics of neural networks, I was finding it hard to bridge the gap between the foundational theory and a practical \"feeling\" of how neural networks function at a fundamental level. I learned how pieces like gradient descent and different activation functions worked, and I played with building and training some networks in a [Google Colab](https://colab.research.google.com/) notebook.\n\nModern toolkits like Tensorflow handle the full pipeline from data preparation to training to testing and everything else you can think of - all behind extremely high-level, well-documented APIs. The power of these tools is obvious. Anyone can load, run, and play with state of the art deep learning architectures in GPU-accelerated Python notebooks instantly in the web browser. Even implementations of bleeding-edge research papers are readily available on sites like [Hugging Face](https://huggingface.co/EleutherAI/gpt-j-6B).\n\n## [](#the-problem)The Problem\n\nDespite the richness of the ecosystem and the incredible power of the available tools, I felt like I was missing a core piece of the puzzle in my understanding.\n\nOn one side, there are the very abstract concepts built on calculus and matrix multiplication which provide the underlying mechanism for how neural networks function. On the other end, there are the extremely high-level software suites used to work with neural networks for practical and research purposes. The idea of partial derivatives being used to compute gradients which optimize the neurons' weights and biases made sense, but I couldn't get a clear picture of it in my head - especially how it scales up to thousands and millions of neurons and dozens of layers.\n\nI come from a software background, and when I was learning how compilers and code generation worked one of my favorite tools was and still is [Compiler Explorer](https://godbolt.org/) aka Godbolt. It's a web application where you can type in any code you want in a variety of languages, choose a compiler and compilation options, and instantly view the disassembled output for a wide range of different hardware architectures.\n\n [![A screenshot of Godbolt showing line-by-line mappings of a Rust function into x86 assembly code](https://cprimozic.b-cdn.net/static/82c9ae9f1b65da5e608a3a251d68bab1/993bb/compiler_explorer.png \"A screenshot of Godbolt showing line-by-line mappings of a Rust function into x86 assembly code\")](https://cprimozic.b-cdn.net/static/82c9ae9f1b65da5e608a3a251d68bab1/77267/compiler_explorer.png) \n\nI find this tool to be unparalleled for learning about compiler code generation patterns and understanding what kinds of assembly gets output for different kinds of code input. It's dynamic and responds instantly as soon as you poke it. It's an environment for experimentation rather than a static knowledge resource. Crucially, it provides a visual mapping between the two sides of the extremely complex transformation taking place under the hood.\n\nThis is what I wanted for neural networks: A constrained, simplified environment for building basic network topologies and experimenting live to see _visually_ how different layer counts, sizes, activation functions, hyperparameters, etc. impact their functionality and performance.\n\n## [](#neural-network-sandbox)Neural Network Sandbox\n\nWith this goal in mind, I created a browser-based tool for building, training, visualizing, and experimenting with neural networks. Since it runs on the web, I've embedded it directly in this post:\n\n[hide]\n\nWhat you see above is a fully-fledged neural network implementation running in your browser. You can add, remove, and configure the layers to change the activation function, neuron count, and initialization parameters. Hit one of the \"train\" buttons, and the network will start learning from examples to match one of the variety of selectable target functions.\n\nThere are also a few different built-in visualizations to provide insight into the progress of the network as it trains and inspect the internal state of the network - all the way down to individual neurons.\n\nA standalone version of the sandbox is also available: [https://nn.ameo.dev](https://nn.ameo.dev)\n\nThe full source code is available on Github: [https://github.com/ameobea/neural-network-from-scratch](https://github.com/ameobea/neural-network-from-scratch)\n\n### [](#how-it-works)How it Works\n\nThe sandbox trains neural networks to model functions mapping vectors of 2 numbers from [0, 1] to a single output value from [0, 1]. Most neural networks you'll see in practice deal with vectors with thousands or more dimensions like images or [graph embeddings](/blog/graph-embeddings-for-music-discovery/), but there is a good reason I chose to keep it this small.\n\nBy limiting the dimensionality of the input and output vectors to 2 and 1 respectively, the entire range of input data can be plotted as a 3D surface and visualized at once.\n\nI refer to this as the \"response\" of the network, inspired by [frequency response](https://en.wikipedia.org/wiki/Frequency_response) of digital filters which works with a very similar premise.\n\nThe 3D area plot shown by default shows a translucent view of the target function that the network is modelling. As the network is trained, the network is periodically sampled with values throughout the entire valid input range, and the outputs are plotted alongside the target function. If the network is learning successfully, its response plot will get closer and closer to the target as it sees more and more examples.\n\nIf you click the \"Layer Outputs Viz\" button, a secondary visualization of the network's internals is opened. It shows the output value of all neurons in the network, and it updates live as the network is trained. Additionally, clicking/tapping on any of the neurons will open a response plot _for that individual neuron_. It allows you to see exactly what inputs will cause each neuron to \"fire\", and how much of an effect it has on neurons in subsequent layers.\n\n [![A screenshot of the response plot for a neuron in one of the networks created using the neural network sandbox](https://cprimozic.b-cdn.net/static/9e344b807df3e4bb9f862da0e32f07f4/eee59/neuron-response-plot.png \"A screenshot of the response plot for a neuron in one of the networks created using the neural network sandbox\")](https://cprimozic.b-cdn.net/static/9e344b807df3e4bb9f862da0e32f07f4/eee59/neuron-response-plot.png) \n\nGive it a try yourself! Try using more or less hidden layers, pick a different target function, experiment with different activation functions, and try tweaking the learning rate.\n\n## [](#learnings--observations)Learnings + Observations\n\nI've personally spent a ton of time just playing with various topologies and parameters and seeing how the networks respond. That was my whole reason behind building the sandbox after all! Here's a collection of the most interesting things I've observed.\n\n### [](#neuron-responses--feature-generation)Neuron Responses + Feature Generation\n\nAdding more layers gives networks the ability to do things that just adding more neurons to a single layer cannot.\n\nThis is especially apparent on more complex target functions. For \"Fancy Sine Thing\", a 2-layer network with sizes of 24 and 12 far outperformed a single layer with 128 neurons. This makes some sense since the number of parameters in a network increases as the product of the count of neurons in adjacent layers.\n\nSome additional clues as to why adding more layers can be so powerful can be found by looking at the response plots for individual neurons of different layers. I created a network with 4 hidden layers where the number of neurons in each is half that of the one before it:\n\nClick to open demo\n\nAfter training the network for a few million examples, the network mostly settles on \"jobs\" for all of its neurons and the responses of neurons from different layers become very interesting. The deeper you get in the network, the more complicated the response plots for the neurons get.\n\nNeurons in the first hidden layer have responses that are limited by the dimensionality of the inputs and the simplicity of the activation function. This is about as complex as it gets for hidden layer 1:\n\n [![The response of the first hidden layer of the network showing a linear-looking gradient](https://cprimozic.b-cdn.net/static/6ad59c7105ae690e0faba94189bad468/346e6/layer1.jpg \"The response of the first hidden layer of the network showing a linear-looking gradient\")](https://cprimozic.b-cdn.net/static/6ad59c7105ae690e0faba94189bad468/346e6/layer1.jpg) \n\nThe second layer gets a bit more interesting. It pulls from multiple neurons in the first hidden layer which have their gradients oriented many different ways. For example, this neuron only activates significantly within an \"island\".\n\n [![The response of the second hidden layer of the network showing an island-like region where it activates strongly and little activation activity outside of it](https://cprimozic.b-cdn.net/static/7b115cbd2e9c9ccb42e859d50ecbf2d7/55324/layer2.jpg \"The response of the second hidden layer of the network showing an island-like region where it activates strongly and little activation activity outside of it\")](https://cprimozic.b-cdn.net/static/7b115cbd2e9c9ccb42e859d50ecbf2d7/55324/layer2.jpg) \n\nBy the third layer, the neuron's response is significantly more complex with concave features and holes. The transition zones between activated and and not activated are a lot sharper as well, making the output more binary.\n\n [![The response of the third hidden layer of the network showing a more complicated response pattern with concave features and holes](https://cprimozic.b-cdn.net/static/233247d5891f405b0190c99bfab70a49/c6128/layer3.jpg \"The response of the third hidden layer of the network showing a more complicated response pattern with concave features and holes\")](https://cprimozic.b-cdn.net/static/233247d5891f405b0190c99bfab70a49/c6128/layer3.jpg) \n\nIn the fourth and final hidden layer, the response plot is more complex still and visually resembles parts of the response of the target function itself.\n\n [![The response of the fourth hidden layer of the network showing a response plot that looks visually similar to part of the response of the target function](https://cprimozic.b-cdn.net/static/4aea894d2dbc3afa569d81c02b15f059/55324/layer4.jpg \"The response of the fourth hidden layer of the network showing a response plot that looks visually similar to part of the response of the target function\")](https://cprimozic.b-cdn.net/static/4aea894d2dbc3afa569d81c02b15f059/55324/layer4.jpg) \n\nI find it fascinating to observe how the networks manage to create features for themselves out of extremely simple inputs and progressively refine them into more and more accurate representations of the target function. I recommend trying out some different network structures and changing up the activation functions and seeing what the neuronal responses look like.\n\n### [](#network-topology--hyperparameters)Network Topology + Hyperparameters\n\nSlowly reducing the learning rate while training can help models reach a lower final error before converging\n\nYou can do this for yourself in the sandbox by dragging the \"learning rate\" slider down while the network is training a large batch of examples.\n\nAnother thing that sometimes works is increasing the learning rate for short periods of time to help break out of local minima - but this can just as easily have a negative effect.\n\nNetworks with more parameters (both wide and deep) seem to require more examples before converging.\n\nThis is partially due to the fact that lower training rates are needed to keep them stable during training, but it feels like more than that as well. I saw some networks that still hadn't converged (loss was still decreasing) even after being trained with several million examples.\n\n### [](#relu-problems--limitations)ReLU Problems + Limitations\n\nUsing the sandbox, you can directly visualize the [Dying ReLU Problem](https://arxiv.org/abs/1903.06733). Since the ReLU activation function has a derivative of 0 when its output is <= 0, the gradient will also be zero for these values which means the neurons can \"die\" and never output anything other than 0.\n\nYou can see this happen yourself using the sandbox. Train 250k or so examples then click some of the neurons of hidden layer in the layers visualization. Eventually, you should find one where the entire response plot should be gray - the neuron will only ever output 0 for all possible values in the input range. This neuron is \"dead\" and will be stuck like that forever no matter how many examples are trained.\n\nClick to open demo\n\nOne solution for the dying ReLU problem is to switch it for a different but very similar activation function called [Leaky ReLU](https://paperswithcode.com/method/leaky-relu) which has a very small but non-zero gradient for zero and negative values. Try swapping the activation functions for the two layers with \"leaky relu\" from the dropdown, reset the viz, and see what effect it has.\n\nAs the paper linked above notes, another method for alleviating the dying ReLU problem is altering the way that network parameters such as weights and biases are initialized.\n\nThe values that weights + biases are initialized to is critical for training performance and network stability.\n\nInitializing weights or biases all to a constant value rarely seems to be the best option. This is especially true for activation functions like ReLU which have gradients that behave badly at exactly zero due to the discontinuity at that point. Initializing starting weights or biases to values that are too large can cause the training to diverge immediately.\n\n### [](#complex-activation-functions)Complex Activation Functions\n\nA [recent paper](https://arxiv.org/abs/2108.12943v2) from August 2021 introduced the rather exotic Growing Cosine Unit (GCU) activation function. As its name suggests, it uses the equation `x * cos(x)` to provide nonlinearity. Here's a plot of its output I made using Wolfram Alpha:\n\n [![A screenshot of a plot of the output of the growing cosine unit (GCU) activation function from x=-5 to 5.  It shows a complex curve that switches from negative to positive 5 times within that range.](https://cprimozic.b-cdn.net/static/ff445e5d513d35e82ecc202f03236cf5/85129/gcu-plot.png \"A screenshot of a plot of the output of the growing cosine unit (GCU) activation function from x=-5 to 5.  It shows a complex curve that switches from negative to positive 5 times within that range.\")](https://cprimozic.b-cdn.net/static/ff445e5d513d35e82ecc202f03236cf5/85129/gcu-plot.png) \n\nAs stated in the paper's abstract, \"It is shown that oscillatory activation functions allow neurons to switch classification (sign of output) within the interior of neuronal hyperplane positive and negative half-spaces allowing complex decisions with fewer neurons.\"\n\nWe can test that claim directly with the sandbox:\n\nClick to open demo\n\nThe network in the above demo only has 2 layers of sizes 16 and 12. The first layer uses the GCU activation function, and the second uses Leaky ReLU. Despite its small layer sizes and low layer counts, it is still able to fit the target function pretty well and it only takes ~300k examples for it to mostly converge.\n\nBy examining the output of some of the GCU neurons in the first layer, it is clear that the response is much more complex than what you can get with a simple activation function like ReLU. It can also be seen that the output does indeed switch between negative and positive multiple times, just as the abstract claimed.\n\n [![A screenshot of a plot of the response of a single neuron with the growing cosine unit (GCU) activation function, demonstrating multiple transitions between positive and negative values](https://cprimozic.b-cdn.net/static/ce4106149432ff8da15390a4c59a9231/7e472/gcu-response.png \"A screenshot of a plot of the response of a single neuron with the growing cosine unit (GCU) activation function, demonstrating multiple transitions between positive and negative values\")](https://cprimozic.b-cdn.net/static/ce4106149432ff8da15390a4c59a9231/7e472/gcu-response.png) \n\nBy using a more complex activation functions like the GCU early on in networks' layers, a greater amount and variety of internal features can be generated for the later layers to refine down and process further. There is a price for this, though - the GCU is much more expensive to compute than the ReLU which is pretty much just a single multiplication. This means that training and inference are slower. There are some ways to improve this, though, which I'll detail later in this writeup. Plus, the additional power that complex activation functions like GCU can provide provides means the networks that use them can be smaller, and smaller networks are inherently cheaper to train.\n\n### [](#other-observations)Other Observations\n\nUsing ReLU and ReLU-like activation functions is by far the fastest for training.\n\nThis makes sense due to how incredibly trivial they are to compute - it's about as simple as it gets. I was able to implement SIMD-accelerated versions of their activation functions as well as their derivatives for calculating gradients during backpropagation.\n\nModels have trouble dealing with sharp transitions in multiple dimensions between different domains\n\nNeural networks seems to require more \"resources\" (layer sizes/counts) to deal with these kinds of features in the functions they model. They seem to be able to model smoother functions more easily; sharp discontinuity-like areas in the target function are hard for them to represent cleanly. I'd be willing to be that there's some research paper out there full of extremely dense math notation which proves this or something similar to it.\n\n [![A screenshot of the neural network sandbox showing how the network has difficulty dealing with sharp multidimensional transitions between different domains of a complex target function.](https://cprimozic.b-cdn.net/static/b2bf2a1c8facd28f47668fa3073bdf60/993bb/multi_dimensional_domain_cutoff.png \"A screenshot of the neural network sandbox showing how the network has difficulty dealing with sharp multidimensional transitions between different domains of a complex target function.\")](https://cprimozic.b-cdn.net/static/b2bf2a1c8facd28f47668fa3073bdf60/fcfbd/multi_dimensional_domain_cutoff.png) \n\n## [](#technical-implementation--performance)Technical Implementation + Performance\n\nThe neural network engine and much of the supporting visualizations and other UI features are built in Rust and compiled to WebAssembly. The full source code for everything is [on Github](https://github.com/Ameobea/neural-network-from-scratch/tree/main/engine/libnn). The visualizations are made using a combination of [ECharts](https://echarts.apache.org/en/index.html) and hand-rolled canvas-based things.\n\n### [](#webassembly--wasm-simd)WebAssembly + Wasm SIMD\n\nThe best way to train neural networks is by using GPUs or other specialized hardware. Even though it's possible to do this in the browser using WebGL compute shaders or [WebGPU](https://web.dev/gpu/) in the future (this is how [TensorFlow.js](https://github.com/tensorflow/tfjs) does it), you can still get great performance on the CPU - especially for the small networks used by the sandbox.\n\nOne of the biggest benefits of having the sandbox running in WebAssembly is it can be accelerated via [Wasm SIMD](https://v8.dev/features/simd). I've worked with this [in the past](https://cprimozic.net/blog/speeding-up-webcola-with-webassembly/#wasm-simd--other-misc-optimizations) to accelerate various web-based applications and visualizations, and the performance it can provide even on relatively low-end mobile devices can be very impressive.\n\nThe core of neural network training is matrix multiplication, which is about as SIMD-friendly as it gets. Multiple pieces of training + inference are implemented using hand-written Wasm SIMD\n\n### [](#approximations)Approximations\n\nIn addition to that, I used approximations based on the [`fastapprox`](https://docs.rs/fastapprox) library for several of the more complex activation functions. Activation functions like Sigmoid, Hyperbolic Tangent, and GCU can be extremely expensive to compute in software, but luckily neural networks are very good at smoothing over the small imprecisions caused by the approximations while sometimes nearly 10x-ing the training rate.\n\n### [](#multi-threading)Multi-Threading\n\nOne of the most important things I did to make the sandbox more responsive and faster while training was to run the entire neural network on a separate thread from the UI via a web worker. I used the excellent [Comlink](https://github.com/GoogleChromeLabs/comlink) library to create easy-to-use bindings that wrap the underlying message passing interface between the UI thread and the neural network web worker. This allows even the expensive 3D surface visualization to update decently smoothly while the model trains at full speed.\n\n [![A screenshot of a CPU profile for the neural network sandbox showing the network training and visualizations running in separate threads](https://cprimozic.b-cdn.net/static/df95dc591974f883a3a241f0bf089e70/2b9e4/web-worker-profile.png \"A screenshot of a CPU profile for the neural network sandbox showing the network training and visualizations running in separate threads\")](https://cprimozic.b-cdn.net/static/df95dc591974f883a3a241f0bf089e70/2b9e4/web-worker-profile.png) \n\n## [](#limitations)Limitations\n\nAlthough the sandbox is very useful for trying out a variety of different neural network topologies, there are some missing pieces and features it lacks:\n\n-   Examples are fed in one by one rather than in batches. This is just a limitation of my implementation of the neural network's training; training efficiency and performance can often be greatly improved by combining the gradients of batches of examples during backpropagation.\n-   Since the target functions are so simple, it's extremely easy for networks to overfit them. For real applications, the inputs and outputs often have orders of magnitude more dimensions which is where bigger and deeper networks shine.\n-   Additionally, since these networks are so simple, there are likely differences between how they work compared to huge networks with billions of parameters. I'd be interested to expand this neural network to support different kinds of input/output data types and shapes to see how the perform.\n-   All layers in the sandbox's networks are densely connected. Lots of modern networks use sparsely connected layers and other complex layers to help improve performance or enhance the networks' capabilities.\n\nIn addition, I would love to someday update the tool to support more features and network types. In particular, I'd personally be extremely interested to add support for basic RNNs.\n\n## [](#other-useful-tools--resources)Other Useful Tools + Resources\n\n-   [3D Visualization of a Convolutional Neural Network](https://www.cs.ryerson.ca/~aharley/vis/conv/) - an awesome interactive 3D visualization that I've spent a long time playing with myself.\n-   [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) - an incredibly inspiring read that also includes lots of really useful graphics and examples to understand how RNNs work.\n\n\n---\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-05-09T00:30:19.188Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Node.js Check if script was invoked through the command line",
      "content": "```js\n// Check if the file was invoked through the command line\nif (require.main === module) {\n  console.log('This script was invoked through the command line.');\n} else {\n  console.log('This script was not invoked through the command line.');\n}\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-11T20:54:32.089Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Node.js",
      "content": "## Setting up nodejs\nOn [[Debian]] Linux I use: \n\n\n```bash\nsudo apt install nodejs\n```\n\nAnd it seems to go pretty smoothly\n```bash\nsudo apt install npm\n```\n\nunfortunately, this installs an older version of node that is not compatible with things like [[rollup.js]]. Sigh. \n\n# Installing latest version of node on ubuntu\n\nhttps://nodejs.org/en\n\nhttps://github.com/nodesource/distributions#debinstall\n\nInstalled Node LTS:\n\n```bash\nsudo curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash - &&\\\nsudo apt-get install -y nodejs\n\nsudo apt-get install -y nodejs\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-07-11T16:22:39.947Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "NodeEnv",
      "content": "installed nodenv with brew: \n\n```zsh\nbrew install nodenv\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-06T17:51:12.804Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Notebook Page",
      "content": "3 contexts: \neditor, text rendering, 3d rendering\n\n[[3d view]]\n\n[[Editor]]\n\n[[Map View]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-06T17:57:59.756Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Notebooks",
      "content": "Notebooks have [[Notebook Page]]s\n\n[[Create New Notebook]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-08-23T17:07:33.498Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "OCC",
      "content": "https://www.occ.treas.gov/about/index-about.html\n\nOffice of the Comptroller of the Currency\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-05-03T19:54:46.641Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Obsidian Plugins",
      "content": "https://david-brown.dev/posts/obsidian-macros-plugin/\n\n\n\n\n\nFrom: https://phibr0.medium.com/how-to-create-your-own-obsidian-plugin-53f2d5d44046\n\n\n\nSep 25, 2021\n\n8 min read\n``\n# How to create your own Obsidian Plugin\n\n![](media/1!zZWfQg49TnqCqlmOrsi7Eg.png)\n\nThe Obsidian Developers imagined Obsidian as an IDE for Thoughts and Notes, which makes it super extensible by design.\n\nObsidian is made using Web Technologies, or more specificly [TypeScript](https://www.typescriptlang.org/), HTML, and CSS. The Desktop Application uses [Electron](https://www.electronjs.org/) and thus also [NodeJS](https://nodejs.org/) under the Hood, while the Mobile Apps are using [CapacitorJS](https://capacitorjs.com/).\n\nIn this Post we will be recreating one of my first Obsidian Plugins, [Cycle through Panes](https://github.com/phibr0/cycle-through-panes).\n\n# Table of Contents\n\n-   [Getting things set up](#e4d3)\n-   [The Sample Plugin](#5f5b)\n-   [Recreating Cycle through Panes](#323f)\n-   [Publishing a Plugin](#d61f)\n\n# Getting things set up\n\nTo create your first Obsidian Plugin, you need to have:\n\n-   [NodeJS](https://nodejs.org/) installed\n-   A Code Editor of your choice installed (My personal recommendation would be: [Visual Studio Code](https://code.visualstudio.com/))\n\nIf you want to publish your Plugin someday, you also need the following:\n\n-   [Git](https://git-scm.com/), a Version Control System\n-   A [GitHub Account](https://github.com/signup)\n\nYou will be using Git to version your Plugin and also to push and pull changes from the remote Repository, which is basically just a “Folder in the Cloud”. In the End, I will tell you more about how to publish the Plugin, so that other people can install it from inside Obsidian.\n\nThe next step would be to clone the [official Sample Plugin](https://github.com/obsidianmd/obsidian-sample-plugin) from GitHub.\n\n## With Git and GitHub\n\nIf you have a GitHub Account, just click the “Use this Template” Button and follow the Instructions:\n\n![](media/1!7IZJciKB7Ci5oOTX9wugpA.png)\n\n![](media/1!obUhZtw0Lxu8UElDeVNVZw.png)\n\nOnce you have your own Repository set up, just copy the following URL:\n\n![](media/1!L5VgMlCQlCXyfiKRIlYuIA.png)\n\nAfterwards, you can clone the Repository locally using the following shell command. Just make sure you are in the correct Directory you want your Plugin to live in.\n\nNow you can finally open the Folder with your Code Editor.\n\n## Without Git and GitHub\n\nIf you don’t plan on publishing your Plugin or don’t have a GitHub Account, you can also just download and unpack the Sample Plugin as a ZIP Archive:\n\n![](media/1!uTVCB2A_oMXC8G7wM2Qgzg.png)\n\nNow you can finally open the Folder with your Code Editor, too.\n\n## Compiling and running the Plugin\n\nYou will see, there are a lot of files already. But don’t worry, only three of them matter at the moment:\n\n-   The `main.ts` File, which contains the Code of your Plugin\n-   The `styles.css` File, which contains a corresponding Style Sheet\n-   And the `manifest.json` File, which contains important Information, like the Version and Name of your Plugin\n\nIf you want to, you can already go ahead and look at these Files, you could for example edit the `manifest.json` to your liking.\n\nObsidian cannot execute TypeScript files directly, you will need to compile them to JavaScript first. Luckily, everything, including bundling, is already set up correctly in the Sample Plugin, so you don’t have to worry too much about it 🥳.\n\nMost Code Editors, like Visual Studio Code, already have a Terminal Window built in. You can use it to run the following two commands after one another:\n\nThe First one will download and cache all dependencies, and the second one will compile your Typescript Files to a single JavaScript File.\n\nOnce that’s done, go ahead and copy the `styles.css`, `manifest.json` and `main.js` into a newly created Folder inside your Vault under `<your-vault>/.obsidian/plugins/sample-plugin/`. Now go into Obsidian and enable your Plugin in the Community Plugins Settings:\n\n![](media/1!NQO9j-nTKciyfcRwO6Y22Q.png)\n\nYou will notice, that most Text turned red. This is because of the following CSS inside the `styles.css` you just copied:\n\nThis is just a demo to help you get started, you can delete it without consequences.\n\n# The Sample Plugin\n\nNow that everything is set up, let’s look at the Plugins Code. Note that I stripped the SampleModal and SampleSettingTab at the End of the File.\n\nLine 1: Import premade Functions and Components from Obsidian, so you can use them in your Plugin\n\nLine 3–9: The Settings the Plugin can store and the default Values\n\nLine 11: A class extending “Plugin” is exported. This is always necessary for a Plugin\n\nLine 14: The onload() Function. This is called every time a Plugin is loaded in Obsidian. In the Sample Plugin it adds a lot of Stuff, but that's just to explain how it works. You can ignore most of them.\n\nLine 17: The Settings are loaded into Obsidian. They are stored on the Disk to persist even when Obsidian is closed. You can see the corresponding Function at the bottom (Line 51).\n\nLine 47: The onunload() Function does the same thing as onload(), but when the Plugin is disabled. Note that this isn’t called when Obsidian closes.\n\nThere will also be two more Classes. One extends the “Modal” Component and another one which extends “SettingTab”. These are used to create a dedicated Tab in the Settings or to show these nifty pop up Modals.\n\n# Recreating Cycle through Panes\n\nIn our Case we don’t need most of this. Our Plugin won’t even have configurable Settings. But what does it need to do? If you are reading this you are most likely using a Browser, to switch between your open Tabs you can press Ctrl + Tab. Cycle through Panes replicates that behavior with Panes in Obsidian. So, what we need to do is the following:\n\n-   Add a Command to go to the next Pane, triggered by Ctrl + Tab\n-   Add a Command to go to the previous Pane, triggered by Ctrl + Shift + Tab\n\nLets use the following as our Starting Point:\n\nThis is almost the bare minimum you will need for any Plugin. Inside the onload() method we will be adding the two Commands. The Obsidian API exposes a method on the Plugin Class to add Commands, if you add them using this official way the User will also be able to change Hotkeys, just like with every other Command! If you want to read up on it, see the official Type Definition [here](https://github.com/obsidianmd/obsidian-api/blob/5af3ef982328a2dd0a2f5242f3c74e2f45e07896/obsidian.d.ts#L2195).\n\nThe addCommand() method takes a [Command Object](https://github.com/obsidianmd/obsidian-api/blob/5af3ef982328a2dd0a2f5242f3c74e2f45e07896/obsidian.d.ts#L410) as a parameter, which has fields for a name, which is going to be the display Text, a id, which is basically the internal name, and a callback, which is a function that will be executed every time the command is invoked.  \nInstead of using a regular callback, one can use a checkCallback, editorCallback or editorCheckCallback. A regular callback can be invoked from everywhere in Obsidian, while any of the two editorCallback’s only work while a Editor is active, the Editor instance will also be available inside the function as a parameter. The checkCallback’s are used if you need to implement your own Logic on when the Callback can be invoked. As an example, the sample implementation for that only works when there is an active Leaf.  \nOther optional fields are mobileOnly, icon (mainly for Obsidian Mobile’s Toolbar) and hotkeys.\n\nLet’s just create the forward cycle first: Add an ID, Name and a checkCallback, for now you can use an empty arrow Function here. If you want to, you can also set default Values for the Hotkeys already, but it is generally advised to not do that to avoid conflicts between Plugins. It should look something like this:\n\nNow that we have that, how do we implement the rest?\n\nIn Line 12 we store the currently active leaf inside a variable called “active”. If there is no active Leaf this will be null and thus the callback will return false and not work nor show up in the Command Palette. If the User invoked the Command the passed checking variable will be false and thus our Logic will run.\n\nIn Line 15 we first get all Markdown Leaves and right after get the Index of the currently active Leaf.\n\nNow we need to handle an interesting Case. If the active Pane is the last one and the User switches to the next one we want to set the first Pane as active. This is handled by the if statement. If this is not the case we can simply increment the index by one.\n\nNow the only thing thats missing is the same Command, but to go in reverse, from right to left. We can copy almost all of the Code, except that we need to change the id, name and callback a little bit. In the next Gist you will see the complete Code:\n\nThe full Plugin\n\n# Publishing a Plugin\n\nNow everything that’s left to do is publish the Plugin. This involves 4 Steps, filling out the manifest.json, pushing the Code to GitHub, creating a Release on GitHub and finally making a Pull Request to the obsidian-releases Repository with your Plugin’s information.\n\n## Filling out the manifest\n\nThe Manifest has 8 fields, the _id_ and _name_, which is almost the same as in a Command, the _version_, which needs to follow [Semantic Versioning](https://semver.org/), the _minAppVersion_, which is the minimal Obsidian Version that your Plugin depends on, this might change if Obsidian’s API changes. A _description_ which is used for the search in the Plugin Browser, the _author_ and _authorUrl_, which should be you and your website or GitHub Profile and lastly the _isDesktopOnly_ field, which needs to be set to true if your Plugin interacts with NodeJS or you are are relying on CodeMirror 5.\n\n## Pushing to GitHub\n\nThis Step is super easy if you already created a Repository in the first Step of this Article. Just run the following Commands:\n\n## Creating a Release on GitHub\n\n![](media/1!135gCoRH8GSeOzHR9JX4qA.png)\n\nOn the right hand side, click on “Create new Release”. Inside the “Choose a Tag” field add the current version of your Plugin without a v at the front. This needs to match your manifest.json. If you want you can add a description and a Title, but thats optional. What you will need to do, is adding the main.js (run _npm run build_ to compile it) , manifest.json and if you have one styles.css at the bottom. Once you are ready, hit “Publish Release”.\n\n## Adding the Plugin to the Community Plugins\n\nGo to the official Obsdian-Releases Repository and [open the Community Plugins File](https://github.com/obsidianmd/obsidian-releases/blob/master/community-plugins.json). On the top right hit Edit and add your Plugin to the end of the List like so:\n\n![](media/1!8VzDSAOeyjCGP_KQsf1Jfw.png)\n\nEditing the File\n\n![](media/1!0BMB4c9k9fJzOfg0bQeqHw.png)\n\nAdding your Plugin to the File\n\nYou just need to make sure to not miss any commas and double check the Repository Name. After that you can click on “Propose Changes” and simply follow the Instructions given by the Obsidian Developers. You are done 🥳!\n\n[Some rights reserved](http://creativecommons.org/licenses/by/4.0/)\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-21T22:49:36.619Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Obsidian Setup",
      "content": "I install Minimal Theme\nand the plugin Minimal Theme Settings\n\nI turn on the plugin\n\nI then set Dark Mode background contrast to True Black\n\n\nAllegedly Obsidian syncs modes, etc\n\n\nHOW TO FIX A VERSION ERROR\n\nhttps://github.com/krissrex/obsidian-html\n\n[[Obsidian]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-21T23:55:11.684Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Obsidian",
      "content": "\n# Some cool plugins\nhttps://github.com/holubj/obsidian-dialogue-plugin\n\nhttps://github.com/trashhalo/obsidian-extract-url\n\nhttps://github.com/SilentVoid13/Templater\nTemplater also lets you execute javascript on a note, apparently\n\nhttps://silentvoid13.github.io/Templater/\nhttps://silentvoid13.github.io/Templater/user-functions/script-user-functions.html\ntodo: test fetch, other libraries in this.\n\nhttps://github.com/blacksmithgu/obsidian-dataview\n\nhttps://github.com/tgrosinger/ledger-obsidian uses https://www.ledger-cli.org/\n\nhttps://www.ledger-cli.org/3.0/doc/ledger3.html\n\nhttps://github.com/valentine195/obsidian-markdown-attributes\n\nhttps://github.com/coddingtonbear/obsidian-local-rest-api\n\nhttps://github.com/elias-sundqvist/obsidian-react-components\n\nhttps://github.com/trashhalo/obsidian-webhooks\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-03-21T17:20:46.325Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Okta",
      "content": "ure, I can help you with that! Here's an example of how you can create a simple HTML and Node.js app that allows for Okta login.\n\nFirst, you will need to set up an Okta account and create an Okta application. You can follow the instructions in the Okta documentation for this.\n\nOnce you have your Okta application set up, you can create a simple HTML login form that will redirect the user to the Okta login page. Here's an example:\n\n```html\n\nCopy code\n<!DOCTYPE html>\n<html>\n<head>\n  <title>Okta Login Example</title>\n</head>\n<body>\n  <h1>Okta Login Example</h1>\n  <form action=\"/login\" method=\"get\">\n    <label for=\"username\">Username:</label>\n    <input type=\"text\" id=\"username\" name=\"username\"><br><br>\n    <label for=\"password\">Password:</label>\n    <input type=\"password\" id=\"password\" name=\"password\"><br><br>\n    <input type=\"submit\" value=\"Log In\">\n  </form>\n</body>\n</html>\n\n```\nIn this form, the user enters their username and password, and when they submit the form, they will be redirected to the Okta login page.\n\nNext, you will need to set up a Node.js server to handle the login process. Here's an example of how you can do this:\n\n```javascript\nCopy code\nconst express = require('express');\nconst session = require('express-session');\nconst okta = require('@okta/okta-sdk-nodejs');\nconst { ExpressOIDC } = require('@okta/oidc-middleware');\n\nconst app = express();\nconst port = 3000;\n\nconst oktaClient = new okta.Client({\n  orgUrl: 'https://your-organization.okta.com',\n  token: 'your-api-token'\n});\n\nconst oidc = new ExpressOIDC({\n  issuer: 'https://your-organization.okta.com/oauth2/default',\n  client_id: 'your-client-id',\n  client_secret: 'your-client-secret',\n  redirect_uri: 'http://localhost:3000/authorization-code/callback',\n  scope: 'openid profile'\n});\n\napp.use(session({\n  secret: 'your-secret',\n  resave: true,\n  saveUninitialized: false\n}));\n\napp.use(oidc.router);\n\napp.get('/', (req, res) => {\n  res.send('Welcome to the Okta login example!');\n});\n\napp.get('/login', oidc.ensureAuthenticated(), (req, res) => {\n  res.redirect('/dashboard');\n});\n\napp.get('/dashboard', oidc.ensureAuthenticated(), (req, res) => {\n  res.send(`Welcome ${req.userContext.userinfo.name}!`);\n});\n\napp.listen(port, () => {\n  console.log(`Server listening on http://localhost:${port}`);\n});\n\n```\n\nIn this Node.js server, we are using the @okta/okta-sdk-nodejs and @okta/oidc-middleware packages to handle the authentication process. We create an oktaClient object and an oidc object, and use them to set up our routes.\n\nWhen the user visits the root URL of the app, they will see a welcome message. When they visit the /login route, they will be redirected to the Okta login page, and when they log in successfully, they will be redirected to the /dashboard route, where they will see a welcome message that includes their name.\n\nNote that you will need to replace the your-organization.okta.com, your-api-token, your-client-id, your-client-secret, and your-secret values with your own values from your Ok\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-11T20:36:09.495Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "One Time Code",
      "content": "\n## Send one time code\n\n[[OTC]] [[AWS]] [[Signed URL]] [[DATAROOM]]\n\n```javascript\n\n\n\n// const isValidPhoneNumber = require(__dirname + '/server/phone-number-check.js')\n// const sendOneTimeCode = require(__dirname + '/server/one-time-code.js')\n// app.get('/verify/:phonenumber', (req, res) => {\n//   const phone_number = req.params.phonenumber\n//   isValidPhoneNumber(phone_number).then(response => {\n//     const session_id = sendOneTimeCode(phone_number)\n//     sessions[session_id] = {\n//       SESSION_ID: session_id,\n//       SESSION_KEY: helpers.getNewID(),\n//       USER_UPLOAD_KEY: helpers.getNewID(),\n//       PUBLIC_KEY: process.env.DATAROOM_KEY,\n//       STATUS: 'UNCLAIMED'\n//     }\n\n//     console.log(session_id)\n//   }).catch(e => console.log(e))\n// })\n\n// const getSignedUrl = require(__dirname + '/server/s3-upload.js')\n// app.get(`/${process.env.UPLOAD_KEY}`, async (req, res) => {\n//   res.send.json(await getSignedUrl())\n// })\n\n// app.get('/:dataroomkey', (req, res) => {\n//   const dtrm_key = req.params.dataroomkey\n//   const session = sessions[dtrm_key]\n//   if(typeof(sessions[dtrm_key]) !== 'undefined' \n//   && session.STATUS !== 'CLAIMED'){\n//     // @todo: remove the following line to enforce one login per dataroom key\n//     // session.STATUS = 'CLAIMED'\n//     res.cookie('dtrm', JSON.stringify(session));\n//     res.sendFile(`${__dirname}/client/logged-in.html`)\n//   } else {\n//     res.status(401).sendFile(`${__dirname}/client/login.html`)    \n//   }\n// })\n\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-30T17:07:34.833Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "OpenSCAD",
      "content": "https://github.com/kellyegan/OpenSCAD-Arduino-Mounting-Library\n\nFor [[Gear]] and [[Music Gear]]\n\nhttps://github.com/jsphpl/standesk\n\n\n\nSTL loader in Javascript: https://threejs.org/examples/webgl_loader_stl.html\n\nOpen Scad to browser pipeline...\n\nIDEA: web component\nsomething like\n\n```HTML\n<stl-file\n  src=url\n  width=1080\n  height=720          \n></stl-file>\n\n```\nThis would create a three.js instance, with a rotating image of the STL file and a download link for it\n\n\n\n[[stl-file component]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-09T00:55:06.000Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "PDF Handling in Linux",
      "content": "Handling [[PDFS]]\n\nMerging two PDF's\n\nusing [[pdfunity]] from [[poppler-utils]]\n\n```bash\napt install poppler-utils\n```\n\n```bash\npdfunite file1.pdf file2.pdf merged_output.pdf\n```\n\nCompress\n\n```bash\ngs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/ebook \\\n-dNOPAUSE -dQUIET -dBATCH -sOutputFile=output.pdf input.pdf\n```\n\n[[ghostscript]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-10-26T17:34:38.287Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "PDFS",
      "content": "# How to merge two pdfs\n\nhttps://support.apple.com/en-us/HT202945\n\nParsing PDFS: \n\nhttps://www.npmjs.com/package/@deeptakirandas/pdf-parse\n\nIdea, script that goes through \n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-09-06T16:58:42.627Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "PPP Loans",
      "content": "Looking at the loans for [[LCMS]]\n\n\nThis dataset:\n\nhttps://data.world/awram/us-places-of-worship\n\nAnd this Dataset:\n\nhttps://data.sba.gov/dataset/ppp-foia\n\n\n\n\nrewrite the following code \n```javascript\nconst fs = require('fs');\nconst csv = require('csv-parser');\nconst MongoClient = require('mongodb').MongoClient;\n// MongoDB connection options\nconst url = 'mongodb://localhost:27017/';\nconst dbName = 'mydb';\nconst collectionName = 'csvData';\n\n// Read the CSV file, parse it, and stream the data into MongoDB\n\nfs.createReadStream('data.csv')\n\n  .pipe(csv())\n\n  .on('data', (data) => {\n\n    // Connect to MongoDB\n\n    MongoClient.connect(url, { useUnifiedTopology: true }, (err, client) => {\n\n      if (err) throw err;\n\n      \n\n      const db = client.db(dbName);\n\n      const collection = db.collection(collectionName);\n\n      \n\n      // Insert each row of CSV data into the collection\n\n      collection.insertOne(data, (err, res) => {\n\n        if (err) throw err;\n\n        \n\n        console.log(`Inserted row: ${data}`);\n\n        client.close();\n\n      });\n\n    });\n\n  })\n\n  .on('end', () => {\n\n    console.log('Finished streaming.');\n\n  });\n\n```\n\n\nMake sure to install the required packages by running `npm install csv-parser mongodb`.\n\n\nReplace `'data.csv'` with the path to your actual CSV file. Additionally, modify the MongoDB connection options (`url`, `dbName`, and `collectionName`) according to your setup.\n\n\nThis script reads the CSV file, parses it using `csv-parser`, and inserts each row of data into the specified MongoDB collection. It prints the inserted row and closes the MongoDB connection for each row.\n\n\nFinally, when the CSV file has been completely streamed, it prints \"Finished streaming.\"\n\n\nassuming node.js, write code that\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-03-20T01:56:40.276Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "PeerJS",
      "content": "https://stackoverflow.com/questions/56244930/setting-up-peerjs-with-gae\n\nhttps://cloud.google.com/appengine/docs/standard/nodejs/building-app\n\nhttps://github.com/peers/peerjs-server\n\n\n```yaml\nruntime: nodejs\n\n# Flex environment required for WebSocket support, which is required for PeerJS.\nenv: flex\n\n# Limit resources to one instance, one CPU, very little memory or disk.\nmanual_scaling:\n  instances: 1\nresources:\n  cpu: 1\n  memory_gb: 0.5\n  disk_size_gb: 0.5\n\n```\n\nGoogle App Engine will create an HTTPS certificate for you automatically, making this by far the easiest way to deploy PeerJS in the Google Cloud Platform.\n\n1.  Create a `package.json` file for GAE to read:\n\n```sh\necho \"{}\" > package.json\nnpm install express@latest peer@latest\n\n```\n\n2.  Create an `app.yaml` file to configure the GAE application.\n\n```yaml\n\nruntime: nodejs\n\n# Flex environment required for WebSocket support, which is required for PeerJS.\nenv: flex\n\n# Limit resources to one instance, one CPU, very little memory or disk.\nmanual_scaling:\n  instances: 1\nresources:\n  cpu: 1\n  memory_gb: 0.5\n  disk_size_gb: 0.5\n\n```\n\n3.  Create `server.js` (which node will run by default for the `start` script):\n\n```js\n\nconst express = require(\"express\");\nconst { ExpressPeerServer } = require(\"peer\");\nconst app = express();\n\napp.enable(\"trust proxy\");\n\nconst PORT = process.env.PORT || 9000;\nconst server = app.listen(PORT, () => {\n\tconsole.log(`App listening on port ${PORT}`);\n\tconsole.log(\"Press Ctrl+C to quit.\");\n});\n\nconst peerServer = ExpressPeerServer(server, {\n\tpath: \"/\",\n});\n\napp.use(\"/\", peerServer);\n\nmodule.exports = app;\n\n```\n\n4.  Deploy to an existing GAE project (assuming you are already logged in via `gcloud`), replacing `YOUR-PROJECT-ID-HERE` with your particular project ID:\n\n```sh\n\ngcloud app deploy --project=YOUR-PROJECT-ID-HERE --promote --quiet app.yaml\n\n```\n\n## [](https://github.com/peers/peerjs-server#privacy)\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-09-14T15:57:48.964Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Perceptual Scaling of Map Symbols",
      "content": "Important take away: \n\n> Research revealed the perceptual problem was not as evident on maps with a smaller range of circle sizes; that good legend design could eliminate the perceptual problem; and that circles on complex maps may have other problems, including optical illusions, which are impossible to correct and lead to even worse perceptual problems. For example, the middle circle in the two groups below is the same size (showing how the perceived area of a circle is shaped by the circles that surround it):\n\nAn article from: https://makingmaps.net/2007/08/28/perceptual-scaling-of-map-symbols/\n\n## Perceptual Scaling of Map Symbols\n\nAugust 28, 2007 by [John Krygier](https://makingmaps.net/author/environmentalgeography/ \"Posts by John Krygier\")\n\n![flannery-check.jpg](media/flannery-check.jpg)\n\n![flannery-check-yes.jpg](media/flannery-check-yes.jpg)\n\nWhat if there was a gap between mapped data and our perception of it?\n\nBuried in the ArcGIS symbolization options for proportional symbol maps is a puzzling check box labeled **Appearance Compensation (Flannery)** that addresses one gap between perception and data symbolized on maps.\n\nThis check box is a vestige of academic cartography’s extensive engagement with psychophysics beginning in the 1950s. [**Psychophysics**](http://en.wikipedia.org/wiki/Psychophysics) relates “matter to the mind, by describing the relationship between the world and the way it is perceived.” Psychophysical studies select specific sensory stimuli and evaluate human perception of the stimuli. Cartographers studied **thresholds** (what is the smallest type size the average viewer can read?), **discrimination** (what is the minimum difference between two gray tones required for the average viewer to perceive a difference?), and **scaling** (how to scale a map symbol so the average user correctly judges the symbol’s value?).\n\nThe most studied map symbol was the **proportionally scaled circle.**\n\n  \nThe scaling of proportional map symbols was the primary research focus of **James Flannery,** a student of [**Arthur Robinson**](http://en.wikipedia.org/wiki/Arthur_H._Robinson), one of the founders of American academic cartography. Flannery’s research on map symbols was based on 1920s research on the human perception of circles and other symbols on statistical graphics. Flannery’s dissertation, completed in 1956, was among the first in Geography using psychophysical methodology.\n\nA **typical proportional circle map** (below, right) scales circle area to the value (usually a total) for a geographic area on a map. Such a map is an alternative to the more common **choropleth** map (below, left) that shades geographic areas to their value (usually derived data, such as a density).\n\n[![circle-choro1.jpg](media/circle-choro1.jpg)](https://makingmaps.files.wordpress.com/2007/08/circle-choro1.jpg \"circle-choro1.jpg\")\n\nWhile not as common as the choropleth map, proportional symbol maps can be found in the public eye, as on the map accompanying a recent _New York Times_ article on **[poppy cultivation](http://www.nytimes.com/2007/08/26/world/asia/26heroin.html?_r=2&hp&oref=slogin&oref=slogin)** in Afghanistan.\n\nThe **absolute scaling** of circles is common on proportional circle maps: a county with a value of 100 has a circle with an area of 2 square cm, a county with a value of 200 has a circle with an area of 4 square cm, etc. (In 1801 William Playfair first scaled circle areas to represent quantities; the use of area rather than diameter persists to this day).\n\nBut psychophysical research revealed that while people tend to **correctly estimate lengths,** they tend to **underestimate areas and volumes.** In other words, when asked to pick a circle that is two times the size of another in a range of different circle sizes, most people would pick a circle that was about 1.8 times the size. This tendency gets worse with larger areas, and is worse in general for estimations of volumes.\n\nThe graph below shows three **apparent-magnitude curves** for estimations of symbol length, area, and volume.\n\n[![apparentmagnitudegraph.png](media/apparentmagnitudegraph.png)](https://makingmaps.files.wordpress.com/2007/08/apparentmagnitudegraph.png \"apparentmagnitudegraph.png\")\n\nThe implication of this perceptual underestimation was that **absolute scaling on proportional symbol maps led to inaccurate perception of the values:** while the circles were scaled **_accurately,_** the perception of the areas, and thus the values the user got from the map, were **_wrong._**\n\nThe solution was to devise a method of **perceptual (or apparent) scaling** of graduated symbols, or **appearance compensation** in ArcGIS-ese.\n\nThousands of perceptual tests led Flannery to develop a method for scaling circles that compensated for the underestimation. When you check the **Appearance Compensation** check box in ArcGIS the method scales up proportional circles, the larger the circle, the more the scaling.\n\n[](https://makingmaps.files.wordpress.com/2007/08/scaled-circles.png \"scaled-circles.png\")\n\n[![scaled-circles.png](media/scaled-circles.png)](https://makingmaps.files.wordpress.com/2007/08/scaled-circles.png \"scaled-circles.png\")\n\nThere are problems with perceptual scaling that suggest avoiding its use on map symbols.\n\nEdward Tufte, in [**_The Visual Display of Quantitative Information_**](http://www.edwardtufte.com/tufte/books_vdqi) (1998, 2nd ed. 2001) stands opposed to anything but absolute scaling: “The representation of numbers, as physically measured on the surface of the graphic itself, should be directly proportional to the numerical quantities represented” (see my previous post on Tufte **[here](https://makingmaps.wordpress.com/2007/08/16/how-useful-is-tufte-for-making-maps/)**). If one actually measures a perceptually scaled circle on a map (or graph) one would get the wrong actual value. Tufte’s demand to “tell the truth about data” excludes compensation for human perceptual failings. In one fell swoop Tufte wiped out a broad swath of psychophysical research in cartography.\n\nThe fact that perceptual (or apparent) scaling was based on an _average subject_ ignored the fact that a broad range of user reactions varied greatly from the average. Perceptual adjustments for the average subject didn’t solve the perceptual problem for a considerable number of potential map users, and led to problems for those who were able to correctly judge areas.\n\nFinally, once added to the complexity of a map, the value of apparent scaling diminished. Research revealed the perceptual problem was not as evident on maps with a smaller range of circle sizes; that good legend design could eliminate the perceptual problem; and that circles on complex maps may have other problems, including optical illusions, which are impossible to correct and lead to even worse perceptual problems. For example, the middle circle in the two groups below is the same size (showing how the perceived area of a circle is shaped by the circles that surround it):\n\n[](https://makingmaps.files.wordpress.com/2007/08/illusion1.png \"illusion1.png\")\n\n[![illusion1.png](media/illusion1.png)](https://makingmaps.files.wordpress.com/2007/08/illusion1.png \"illusion1.png\")\n\nSome vestiges of psychophysical studies are embedded in map design guidelines like those illustrated in the [**_Making Maps_**](http://makingmaps.owu.edu/) book. However, psychophysical map studies assumed map-readers, maps, and map symbols were quite a bit simpler than they are in reality. This limited the utility of such research, much of which was seen by practicing cartographers as not useful for making maps or, at best, merely confirming common sense rules of map design.\n\nA great overview of the history of psychological research on maps including psychophysical research is Daniel Montello’s [**“Cognitive Map-Design Research in the Twentieth Century: Theoretical and Empirical Approaches”**](http://www.geography.wisc.edu/histcart/v6initiative/12montello.pdf) (_Cartography and Geographic Information Science,_ Vol. 29, No. 3, 2002, pp. 283-304). Borden Dent’s text _Cartography: Thematic Map Design_ (4th ed., WC Brown, 1996) has a good discussion of absolute and perceptual scaling of map symbols, including equations for absolute and perceptual scaling, in chapter 8 (this chapter was the source for some of the redrawn illustrations above).\n\n**Postscript:** The implementation of Flannery’s perceptual scaling in ArcGIS has a software-specific problem: perceptual scaling should only be applied to circles. If the symbol is changed in ArcGIS, to a square or some other shape, the perceptual scaling can still be applied. Research has shown that square symbols, on a proportional symbol map, don’t have the same perceptual problem that circles do (we can correctly estimate the areas of squares). Little research on map symbols besides circles and squares exists. **Bottom line:** if you use the **Appearance Compensation** in ArcGIS, only apply it to proportionally scaled circles.\n\n### _Related_\n\nPosted in [09 Map Symbolization](https://makingmaps.net/category/09-map-symbolization/) \n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-18T19:10:45.083Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Physical Modeling Synthesis",
      "content": "https://www.math.drexel.edu/~dp399/musicmath/Karplus-Strong.html\n\n\n> The **wave equation** is a second-order linear partial differential equation for the description of waves—as they occur in classical physics—such as mechanical waves (e.g. water waves, sound waves and seismic waves) or electromagnetic waves (including light waves). It arises in fields like acoustics, electromagnetism, and fluid dynamics.\n>\n> Historically, the problem of a vibrating string such as that of a musical instrument was studied by Jean le Rond d'Alembert, Leonhard Euler, Daniel Bernoulli, and Joseph-Louis Lagrange. In 1746, d'Alembert discovered the one-dimensional wave equation, and within ten years Euler discovered the three-dimensional wave equation.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Wave%20equation)\n\n\nSprings can be modeled: \n\n# Hooke's Law\n\n> **Hooke's Law** is a law of physics that states that the force (F) needed to extend or compress a spring by some distance (x) scales linearly with respect to that distance—that is, Fs = kx, where k is a constant factor characteristic of the spring (i.e., its stiffness), and x is small compared to the total possible deformation of the spring. The law is named after 17th-century British physicist Robert Hooke. He first stated the law in 1676 as a Latin anagram. He published the solution of his anagram in 1678 as: ut tensio, sic vis (\"as the extension, so the force\" or \"the extension is proportional to the force\"). Hooke states in the 1678 work that he was aware of the law since 1660.\n>\n> Hooke's equation holds (to some extent) in many other situations where an elastic body is deformed, such as wind blowing on a tall building, and a musician plucking a string of a guitar. An elastic body or material for which this equation can be assumed is said to be linear-elastic or Hookean.\n>\n> Hooke's law is only a first-order linear approximation to the real response of springs and other elastic bodies to applied forces. It must eventually fail once the forces exceed some limit, since no material can be compressed beyond a certain minimum size, or stretched beyond a maximum size, without some permanent deformation or change of state. Many materials will noticeably deviate from Hooke's law well before those elastic limits are reached.\n>\n> On the other hand, Hooke's law is an accurate approximation for most solid bodies, as long as the forces and deformations are small enough. For this reason, Hooke's law is extensively used in all branches of science and engineering, and is the foundation of many disciplines such as seismology, molecular mechanics and acoustics. It is also the fundamental principle behind the spring scale, the manometer, the galvanometer, and the balance wheel of the mechanical clock.\n>\n> The modern theory of elasticity generalizes Hooke's law to say that the strain (deformation) of an elastic object or material is proportional to the stress applied to it. However, since general stresses and strains may have multiple independent components, the \"proportionality factor\" may no longer be just a single real number, but rather a linear map (a tensor) that can be represented by a matrix of real numbers.\n>\n> In this general form, Hooke's law makes it possible to deduce the relation between strain and stress for complex objects in terms of intrinsic properties of the materials it is made of. For example, one can deduce that a homogeneous rod with uniform cross section will behave like a simple spring when stretched, with a stiffness k directly proportional to its cross-section area and inversely proportional to its length.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Hooke's%20law)\n\n SOUND ON SOUND\n\n\n# Physical Modelling Synthesis Explained\n\nExploration By Martin Russ\n\nPublished [June 1997](/magazine/1997-06)\n\nModelling is the current Big Thing in digital synthesis, and it's being used to recreate the sounds not only of traditional acoustic instruments, but also the analogue synth timbres electronic musicians know and love. So just how are the manufacturers making numbers behave like nose‑flutes and maths sound like Moogs? Super modeller Martin Russ provides the beginners' guide.\n\nWe live in a world that is increasingly described by numbers. Most bartering of goods was long ago replaced by metal and paper tokens. Since the Ordnance Survey started mapping Great Britain in 1791, even the shape of the country itself has been represented by heights and positions on a grid. From the early 1980s onwards, audio has been held as numbers on digital Compact Discs. In the 1990s, the most important part of your passport is arguably the machine‑readable strip of numbers on the back page — which looks increasingly like an identity card (or will the ubiquitous credit card take over that role if it ever gains a photograph of the holder?).\n\nTo deal with all the numbers that are used in today's world, we are becoming dependent on computers. Digital processing of numbers calculates our wages; deducts our taxes; enables us to register a National Lottery number; controls the manufacturing of hi‑fi equipment; reduces the distortion in loudspeakers; produces music, and much more. With the right knowledge and programming, computers can be used to simulate how a nuclear reactor works, how the economy should be developing, and even how a musical instrument makes sounds. They do this by using a model of the item being simulated. The model is usually a series of mathematical rules which describe how the individual parts interact — so it's often called a 'mathematical model'.\n\n## [Starting Simple](#top)\n\nLet's take a very simple example — a model of a balloon. There are three basic categories of balloon: empty; blown‑up (full of air); and burst. So how about some rules for the behaviour of a balloon?\n\n-   You can turn an empty balloon into a blown‑up one by putting air inside.\n-   You can turn a blown‑up balloon into a burst one by pricking it with a pin or by trying to put too much air into it.\n-   You can't turn a burst balloon into either of the other categories — once burst, it's burst forever.\n\nWe also need to know something about the properties of the things we are using, so we need to know that the balloon has a limit to the amount of air that it can hold before it bursts. We might also need to know that if you add air to a balloon and then release it, all the air will rush out of the balloon and restore it to almost its original emptiness.\n\nBelieve it or not, this simple example illustrates many of the important things about mathematical models.\n\n-   Firstly, you need to be able to describe what is happening — in this case, whether the balloon is empty, blown‑up or burst.\n-   Secondly, you need to be able to describe what changes can be made. For example, adding air to the balloon changes it from empty to blown‑up.\n-   Thirdly, some of the changes can be irreversible — the pin can permanently burst the balloon.\n-   Fourthly, you need to know something about the properties of the things which are used in the model.\n-   Finally, some changes can be unexpected: for example, if you add too much air to the balloon, it can burst, because its capacity for holding air has been reached.\n\nOnce armed with a model, we can then use it to make predictions, and to answer questions. For example, what happens if we add water to an empty balloon? Does it become blown‑up? Will a pin still have the same disastrous effect? In order to know, we need to know something about the properties of water, and if we decide that it behaves like thick air, then we can make predictions based on this — if you add water, then the balloon will be blown‑up, and a pin will still burst it. But if you fill a balloon with _sand_, does a pin still burst it? The simple model we have for the balloon may not work in some situations, especially those outside the scope of our description of how a balloon works. The model might need additional information on the substance used to fill it, for example.\n\n> We live in a world that is increasingly described by numbers.\n\nModels of musical instruments allow us to make sounds which have many of the characteristics of real instruments, but only when we understand enough about the instrument to be able to describe how it works in sufficient detail. Balloons are relatively easy to describe, while musical instruments are usually more complex. Of course, if we understand how something works, we can often extend, enhance or even just alter the way in which the parts interact, and this allows the creation of imaginary instruments: ones which might be impossible to actually make! These 'impossible' instruments are often rather like filling a balloon with sand, because they go beyond the normally expected boundaries of the model.\n\n## [Putting It Together](#top)\n\nA mathematical model is just a way of plugging together all of the things we've learned about how a musical instrument works. These are normally expressed as equations connecting all the individual parts. So an equation that describes a string driver needs to know things such as the tension in the string, how far it's pulled from its rest position, and whereabouts, along the length of the string, it's being pulled. A resonator equation is more concerned with the frequency response of the body or tube part of the instrument, where the resonances are. There may also be equations which describe how the driver and resonator are connected together, or how the energy decays away or is coupled to the air. The basic model runs something like this:\n\n-   Energy is added to the instrument.\n-   Something vibrates because of the extra energy.\n-   Something resonates with the vibration.\n-   The vibration is coupled to the air by some means.\n-   The energy is gradually transferred to the air.\n\nThat's about it for modelling. We now have a mathematical model of how a physical musical instrument works — and this is the basis for all of the modelling‑based synthesis techniques. The rest of this article examines the different types of models.\n\n## [Pre‑Digital Modelling](#top)\n\nAt the risk of being sectioned for madness, I'll let you into a secret. Analogue synthesizers are nothing more than pre‑digital versions of the latest digital 'virtual' synthesizers — and they use modelling. You don't actually need to have a digital synthesizer for it to be called a 'modelling' instrument, although many manufacturers would have you believe that. In fact, the earliest analogue synthesizers were arguably things called analogue computers, which used voltages and currents to represent numbers, and processed them using circuits like amplifiers and filters.\n\n> What was once an obscure topic of interest to a few music/physics researchers is now a valuable commodity.\n\nThe important thing is that the way in which an analogue synthesizer is put together is nothing more than a convenient representation of how to make sounds. The Oscillator is the source of the raw vibration: the driver. The Filter is the resonator. The Envelope Generator and Amplifier effectively control damping and volume, and the loudspeaker converts the electrical signal into sound by vibrating the air. You may never have thought of an analogue synthesizer as a model of how sounds are produced (or as an analogue computer!), but that's all it is.\n\nOne difference between real‑world musical instruments and synthesizers is the way in which energy is added to the driver. Whereas a synthesizer's Oscillator produces sound all the time, a conventional musical instrument normally has energy added in bursts: plucks, hits, and blowing — with the exception of the digeridoo, of course. In an analogue synthesizer, the envelope generator and amplifier perform this function instead, and this is arguably one area where the modelling is rather unrealistic. In fact, the whole of an analogue synthesizer is an idealised, simplified view of how a musical instrument makes sounds.\n\n## [Virtuality](#top)\n\nOnce you've worked out how to convert an understanding of how something works into a physical model, the same principles can be applied in many ways, and all you need is a suitable means of turning the model into reality. Analogue synthesizers do it using currents and voltages which represent the vibrations directly, but today's technology tends to replace most signals with digitised numerical versions instead. If you take an analogue synthesizer and convert it into a digital form, you have what can be called a 'Virtual' synthesizer.\n\nThe Clavia Nord Lead is one example of the technique of using digital technology to represent an analogue synthesizer, and manipulating numbers to make sounds. But FM synthesizers and more recent Sample & Synthesis (S&S) instruments, such as the Emu Morpheus, also use numbers and equations to represent how frequency modulation and complicated filters work. But the underlying model they use, of sound source, filter and envelope is a crude one, which is not very representative of the real workings of a musical instrument.\n\nDigital technology, however, allows a model to be implemented with as much depth as is required. In the case of virtual analogue synthesizers, this includes detail such as the imperfections of oscillators, filters and amplifiers. Some possible areas where it is possible to describe (and thus model) this non‑ideal behaviour include:\n\n-   Oscillators which vary in pitch slightly to simulate the effects of power supply loading, temperature, humidity, and even just time.\n-   Oscillators whose modulation inputs are non‑linear, or non‑exponential.\n-   Waveforms whose shapes are merely rough approximations of the names used to describe them (Square, Triangle, Sawtooth, Sine, etc).\n-   Waveforms whose shape changes with frequency to simulate the effects of bandwidth‑limited/non‑linear/distorting amplifiers.\n-   Filters that distort audio signals.\n-   Filters whose characteristics change as they approach self‑oscillation.\n-   Filters that add noise to audio signals passing through them.\n-   Amplifiers that distort/compress/add noise to audio signals passing through them.\n-   Envelope Generators which have linear/exponential or other curves.\n\nJust as it is often the detail of a real instrument that provides the uniqueness and interest in the timbre it produces, so these analogue 'imperfections' can be built into the model to provide the distinctive sound of individual 'retro' analogue instruments. If we understand exactly what gives analogue instruments their character, it's then possible to model them.\n\n## [Interactions](#top)\n\nOne way of producing a better model of a real instrument is by trying to take account of the interactions between the sound source and the resonator. In an analogue or virtual synthesizer, the two are normally kept entirely separate, whereas in a real musical instrument, the driver and the resonator are part of the same instrument, and changing one affects the other. If you remove the tubing from a brass instrument and play just the mouthpiece, you realise just how important all that metal tubing is! Or imagine a guitar where the body and the strings are not connected. In fact, separating these two parts is so alien to how a real instrument works that it is often difficult to imagine a driver without the associated resonator, and the interaction between the two can be crucial in determining the sound of the instrument. Think about the difference between an acoustic guitar and an electric guitar when played without amplification — and then compare the sustain performance of the two...\n\nOne method for representing these interactions between the driver and resonator is to change the driver in some way. The S&S approach would be to provide different samples, although producing a smooth change between them would be difficult. Technics use a different method in their SX‑WSA1 Acoustic Modelling synthesizer: here the driver is connected to the resonator by a delay line, which is used as a simple model of a string or tube (see the 'What's the Delay?' box, below left). The driver waveform is used to drive the delay line, and the output of the line is then fed to the resonator. The 'positions' of the input and output can be changed dynamically. The delay line thus provides a rough analogy to the real‑world connection between the driver part of an instrument and the resonator.\n\n> If we understand exactly what gives analogue instruments their character, it's then possible to model them.\n\nRather than just using an audio sample as the driver waveform, Technics have attempted to 'reverse engineer' the output of real instruments by removing the effect of the resonator, so that the raw, unfiltered driver waveform can be used rather than a sample of the complete instrument. The actual driver waveforms that this process produces sound like thumps and bangs with extreme treble boost applied, but the final result once they have been 'connected' to a resonator is impressive — filtering removes the high‑frequency emphasis, and the result sounds like a sampled instrument. Of course, since the actual connection and filter settings may be completely different from the usual ones associated with the instrument, the final timbre produced can be very different from the driver sample itself.\n\nThe resonances which are found in most musical instruments do not translate to simple low‑pass or band‑pass filters: one method for experimentally discovering the sort of resonances that an acoustic guitar body might produce is merely to sing into the sound‑hole of a guitar. Technics have, presumably, determined the major resonances of a number of different instruments, and then used this information to work out what the raw driver sound was like before the resonator modified it. The results take the form of band‑pass filters whose bandwidth, Q and centre frequency can be altered — rather like a parametric equaliser. But in order to simulate the multiple resonances that are present in a real instrument, several of these filters can be combined in parallel.\n\nSince this technique emulates the interaction between the driver and the resonator, I've called it 'Interaction Emulation' (see diagram, below right). It's important to differentiate between this and S&S synthesis, because although both appear to use a sample followed by filtering, the Interaction Emulation technique does not use a straightforward sample, nor is the filtering as simple as that typically found in S&S synthesis. It thus represents a halfway stage between S&S and Physical Modelling.\n\n## [Physical Models](#top)\n\nPhysical Modelling takes the ideas behind Interaction Emulation to their logical conclusion. Instead of using just a simple model for the connection between the driver and the resonator, it attempts to produce models for the driver, the resonator, _and their interactions_. This provides a feedback path which is not present in simpler models. One of the best current examples of this technique can be found in Yamaha's VL1 and VL1m physical modelling synthesizers.\n\nThe connection and resonator models are similar to those already described: the connection can be modelled using a simple delay line, and if you use a more complex delay line, this can even produce part of the resonator as well. It's the complexity of the mathematical models required for the driver that pose the major technical hurdle for physical modelling, since here the task is to describe complex moving systems of air, strings, bows, lips and mouthpieces.\n\nLet's look at the resonator first. Possibly the simplest resonator is a string or a tube. You pluck a string and it produces a sound whose frequency is related to the length of the string. If you blow across the end of a tube, the note that is produced is, again, related to the length of the tube. In both cases, the plucking or blowing adds energy into the string or tube, and the resulting vibration is emphasised at those frequencies whose wavelengths are related to the length of the tube or string. If the length of the tube or string changes, so do the frequencies which are emphasised, and the resonant frequency changes. If there are holes in the tube, or the width of the tube changes along its length, extra resonances can occur, while for a string the rigidity of the end‑points of the string can have similar effects. In digital circuitry, a delay line can be thought of as a model of a tube, so multiple resonances can be produced merely by adding in feedback paths at different points along the delay line. Some tape echo units produce multiple echoes in exactly this way, but they're behaving like tubes tens or hundreds of metres long!\n\nDrivers are more of a challenge. There are many types, each with its own special characteristics. Plucking a string requires a sudden stretching of the string, followed by a release, whereas bowing a string involves lots of smaller stretches and releases as the rough bow catches on the string. With a flute mouthpiece, a stream of blown air hits the far side of the mouthpiece hole, whilst a recorder mouthpiece has a sharp edge that the air is directed against. Oboes and accordions use moving air to vibrate reeds, whilst in a trumpet or trombone it is the player's lips which vibrate inside a tiny mouthpiece enclosure. In a piano, the hammer hits the string at a fixed position, but the dynamics of the acceleration and deceleration are very complex. The mathematical descriptions of each of these is necessarily detailed, and well beyond the scope of this article.\n\n> The unrealistic freedom that you have with an analogue synthesizer is replaced by the natural‑sounding limitations of physics.\n\nWhat is significant about this level of physical modelling is that because lots of real‑world behaviour is built into the model, the results it produces have many of the restrictions that you find in real instruments. So, whereas the analogue synthesizer makes a sound all the time, and artificially imposes an envelope on it, a physical model produces sounds only when you add energy into it by 'blowing', 'bowing', or 'plucking' — just like a real instrument. Trying to persuade a real or virtual reed to vibrate with a gradually increasing volume isn't easy either — at some point it suddenly jumps in and starts making a sound. The unrealistic freedom that you have with an analogue synthesizer is replaced by the natural‑sounding limitations of physics! In practice, though, you can usually explore modifications to drivers and resonators that would be difficult or impossible to achieve in reality, as well as mixing them — using a bow driver to drive a tube resonator, for example.\n\nIn case you were thinking that this sort of physical modelling is exclusively digital, remember that it is possible to connect an echo unit with a non‑linear amplifier (a compressor will do) to act as feedback, and then produce some very unusual sounds by tweaking the delay time and feedback level. All it needs is something to set things going — the inherent noise will do at a pinch, but a trigger sound into the delay line acts much more like the transient energy bursts that you might associate with plucking or blowing. Digital technology just improves the control, the repeatability and the depth of implementation of synthesis techniques.\n\n## [What Next?](#top)\n\nDespite appearances to the contrary, we don't actually understand how all musical instruments work. There are good models for plucked or hit strings, and these can be relatively easily implemented on affordable hardware, but any model that involves jets of air is considerably more complicated, and requires huge processing resources to calculate. Which is where simplification and compromise come in. Any resemblance between an affordable real‑time physically‑modelled flute and the real thing is a consequence of the fact that the model is a very simple digital representation of a tube, rather than a completely detailed model of how a flute really works. A simple analogy might be to consider a ventriloquist trying to produce the sound 'p': he can't move his lips, and yet by providing a similarly 'plosive' sound using his teeth and tongue, he can make the end result sound like a 'p', even though it isn't.\n\nFor some instruments, there just don't seem to be any models at all yet. In these cases, the ventriloquist analogy can be used again to show how it is possible to make sounds which appear to come from a specific instrument, even though we're not using the right model. I'll avoid taking this line of argument to its logical conclusion, where all models are declared to be so crude that they aren't at all usable, and that a serendipitous process of sound‑making is all there is to physical modelling. The process of 'misusing' sound synthesis techniques has worked very well for analogue synthesizers, and I see no reason why modelling‑based instruments should be any different. If it sounds like the timbre you want, the method used to produce the timbre may well be irrelevant to you.\n\nThe explosion of interest in physical modelling has changed the perceptions of many people. What was once an obscure topic of interest to a few physics/music researchers is now a valuable commodity, with electronic musical instrument manufacturers all investigating how they can incorporate this technology into their own products. The current range of instruments represent only the initial phase of development, since the synthesis possibilities opened up by physical modelling are far from being fully explored. More sophisticated drivers, better resonators, and understandable user interfaces should all contribute to improving the useability of modelling‑based instruments.\n\nPerhaps the biggest casualty of the launch of modelled instruments will be the simple S&S synthesizer, where the static sound generation offered by a sample replay oscillator is coupled with a crude low‑pass/band‑pass filter: 'painting by numbers' is one possible description. But selling instruments with few points of similarity to the analogue or S&S metaphors which have been built up over many years, could prove to be very difficult. Yamaha's success with FM was tempered by its failure to persuade all but a few die‑hard enthusiasts to learn how to actually program it!\n\n## [Real World Rules](#top)\n\nWe can't look at how to make imaginary instruments without knowing something about how real instruments work, so let's start with a very general view of how to make sound.\n\nSound is produced when something vibrates in the air (or water, or something else!). It's the very fact that there's something to carry the vibration that allows us to hear sounds. Normally, it's the air that vibrates, and this is how the sound is conveyed from the vibrating object to our ears. Sound does not travel through a vacuum, so space is absolutely silent.\n\nSo how do you make something vibrate in the first place? If you think about plucking a string, it's obvious: you pull the string away from its resting position, and let go. The string goes back to the resting position, but carries on past it. It then reaches a limit, and bounces back through the resting position, and nearly back to where you let go of the string. This continues, with the string gradually moving less and less, until it is back in the resting position. A physicist would describe this behaviour by saying something along the lines of: \"when you pull the string, you stretch it, and this requires effort. When you release the string, the energy you have stored in it, because of the effort of pulling it away from its resting position, is converted into movement as it tries to return to the resting position.\" In other words, you put energy into the string, and it then vibrates as the energy is converted into vibration, with the final result being a string without the extra energy that you added. In the process of vibrating, the string moves the air, and this is why you can hear the sound made by the string.\n\nAlthough it's not always as obvious as this example, you make something vibrate in a musical instrument by adding energy into it. Blowing, pushing and bowing are all methods of putting extra energy into a string or column of air; the way in which you add the energy, and the way in which the instrument then releases that energy into the air as it vibrates, determine the type of musical sound the instrument produces. The word used for the part of the musical instrument where the energy is added is the 'driver', because this is where the added energy drives something into vibration. The driver can be connected to the air by either the body of the instrument itself (as in a violin), by a tube (as in a trombone), or directly from the part that vibrates (as in a flute, where it's the air that flows over the mouthpiece that vibrates).\n\nOften, the coupling between the driver and the air has a complicated frequency response. For example, the body of a violin does not resonate at just one frequency, but at several. A hollow tube also has several different resonant frequencies — depending on the tube, the material it's made of, the holes in it, the temperature, the humidity... These all serve to shape the timbre of the resulting sound from the musical instrument.\n\nFrom a modelling point of view, we now have the essential parts that we need to describe some of the major aspects of how a musical instrument makes a sound. We merely need to be able to describe:\n\n-   How the driver changes energy into vibration.\n-   How that vibration is connected to the air.\n-   How the vibration starts when we first start adding energy to the driver.\n-   Any resonances in the coupling of the driver to the air, or the instrument itself.\n-   How the energy decays when we stop adding more energy to the driver.\n\n## [What's The Delay?](#top)\n\nIn the main body of this article, I've referred to the use of a delay line as a simple model of a string or tube. But exactly how can a delay line simulate a tube, a string, or a resonator? Here's a rough guide to the basic concept, using a violin string analogy.\n\nWhen you bow a violin string, energy is added to the string at that point because of the jerky movements of the bow as it tugs and releases the string. This mechanical energy travels along the string in both directions until it reaches the ends of the string, when it bounces back and returns towards the point where the bow is touching the string. The time taken to do this is related to the length of the string, so specific frequencies will exactly fit into this time and will be reinforced, whereas other frequencies will tend to be cancelled out. This process is called resonance, and it's a common feature of many mechanical systems. It's rather like pushing a person in a swing: unless your timing is right (synchronised with when they come closest to you!), your pushes don't actually achieve much.\n\nA delay line can simulate this sort of behaviour with two sets of blocks of time delay, arranged rather like a string. The incoming waveform travels along the delay line, 'bounces' back from the 'ends', and eventually returns to the start position, from where the whole process repeats. The delay line thus emulates the length of a string or tube by providing the same time‑delays and behaviour, but in a form which is electronic rather than mechanical.\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-11T01:13:33.351Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Pico-8",
      "content": "https://github.com/outkine/pico-kit\n\nhttps://github.com/torch2424/picoDeploy \nDeploy Pico-8 Carts as Standalone Applications on Desktop 🖥️(Electron) and Mobile 📱(Ionic) 📦👾\n\nhttps://github.com/JoebRogers/PICO-Tween\nA small library of tweening/easing functions for use in the PICO-8 fantasy console, inspired by Robert Penner's easing functions.\n\nhttps://github.com/JoebRogers/PICO-EC\nA tiny scene-entity-component library created for the PICO-8 fantasty console.\n\nDownloaded a few pieces of software\n\nhttps://github.com/jesstelford/pecs\nAnother entity-component library\n\nhttps://www.adafruit.com/product/4499 --  a good monitor for pico-8 games\n\nIdea: pico-8 game that reads a bunch of markdown files\n\nhttps://github.com/dansanderson/picotool\nTools and Python libraries for manipulating Pico-8 game files. [http://www.lexaloffle.com/pico-8.php](http://www.lexaloffle.com/pico-8.php)\n\nThis is the engine I am looking for: https://github.com/Liquidream/scumm-8\n\n\n> Script Creation Utility for Maniac Mansion (**SCUMM**) is a video game engine developed at Lucasfilm Games, later renamed LucasArts, to ease development on their graphic adventure game Maniac Mansion (1987). It was subsequently used as the engine for later LucasArts adventure games.\n>\n> It falls somewhere between a game engine and a programming language, allowing designers to create locations, items and dialogue sequences without writing code in the language in which the game source code ends up. This also allowed the game's script and data files to be cross-platform, i.e., re-used across various platforms. SCUMM is also a host for embedded game engines such as the Interactive MUsic Streaming Engine (iMUSE), the INteractive Streaming ANimation Engine (INSANE), CYST (in-game animation engine), FLEM (places and names object inside a room), and MMUCAS. SCUMM has been released on these platforms: 3DO, Amiga, Apple II, Atari ST, CDTV, Commodore 64, Fujitsu FM Towns & Marty, Apple Macintosh, Nintendo Entertainment System, DOS, Microsoft Windows, Sega CD (Mega-CD), and TurboGrafx-16/PC Engine.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/SCUMM)\n\nhttps://github.com/Liquidream/scumm-8/wiki\n\nhttps://github.com/nateProjects/Pico-8-Cookbook\n\n\nhttps://nerdyteachers.com/PICO-8/Guide/\n\n![[Pasted image 20220310124013.png]]\n\n\nMore in depth cheat sheet:\n\nhttps://wh0am1.dev/pico8-api/\n\nPlayed with the Voxel version of this called [[Voxatron]]\n\nImpressed -- there seems like there are a lot of editing tools for this. \n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-10-28T18:31:57.297Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Print CSS",
      "content": "https://www.smashingmagazine.com/2015/01/designing-for-print-with-css/#:~:text=The%20rule%20below%20specifies%20a,you%20can%20use%20is%20important.&text=In%20addition%20to%20specifying%20sizes,A4%E2%80%9D%20or%20%E2%80%9Clegal.%E2%80%9D\n\n```css\nbody {\n  counter-reset: chapternum;\n}\n\nh1.chapter:before {\n  counter-increment: chapternum;\n  content: counter(chapternum) \". \";\n}\n\n```\n\n```css\n\nbody {\n  counter-reset: chapternum figurenum;\n}\n\nh1 {\n  counter-reset: figurenum;\n}\n\nh1.title:before {\n  counter-increment: chapternum;\n  content: counter(chapternum) \". \";\n}\n\nfigcaption:before {\n  counter-increment: figurenum;\n  content: counter(chapternum) \"-\" counter(figurenum) \". \";\n}\n```\n\n\n```css\n/*\n  \n  Print CSS\n\n*/\n\n@page {\n  size: A4;\n  margin: 11mm 11mm 11mm 11mm;\n}\n\n@media print {\n\n  .holy-grail-nav {\n    display: none;\n  }\n\n  footer {\n/*    display: none;\n*/  }\n\n  a::after{\n    content: \" (\" attr(href) \") \";\n  }\n\n  h1, h2, h3 {\n    background:  linear-gradient(180deg, rgba(255, 255, 255, 0) 50%, var(--gallery-grey) 50%) !important;\n  }\n\n  #logo { \n    height: 1.5em;\n    left: 0em;\n    top: 0em;\n    width: auto;\n  }\n\n  header a::after{\n    display: none;\n  }\n\n  .data-dictionary-entry {\n    page-break-after:always \n  }\n\n}\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-07T19:18:59.000Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Pull from Google",
      "content": "This pulls from a Google Sheets spreadsheet and then builds an HTML file. \n\n\n```js\n\n#!/usr/bin/env node\n\n/*\n\n      ____  __  ________    ____\n     / __ )/ / / /  _/ /   / __ \\\n    / __  / / / // // /   / / / /\n   / /_/ / /_/ // // /___/ /_/ /\n  /_____/\\____/___/_____/_____/\n\n      ____  ____  ___________\n     / __ \\/ __ \\/ ____/ ___/\n    / / / / / / / /    \\__ \\\n   / /_/ / /_/ / /___ ___/ /\n  /_____/\\____/\\____//____/\n\n\n  BUILD DOCS\n\n  This script fetches the google spreadsheet of the data dictionary\n  It requires a creds.json file. Get this file from Google Console\n  or from LNSY or MVV\n\n*/\n\nconst fs = require('fs')\n\nconst { GoogleSpreadsheet } = require('google-spreadsheet');\nconst dotenv = require(\"dotenv\");\ndotenv.config();\n\nconst creds = require('./creds.json');\n\n/*\n\n  Columns in the spreadsheet to access\n  \n*/\n\nconst columns = [\n    \"Field Name Current\",\n    \"Field Name Proposed\",\n    \"Human Name\",\n    \"Required Column\",\n    \"Nullable\",\n    \"Type\",\n    \"Human definition\",\n    \"Example\",\n    \"Specification\",\n    \"Use/reason\"\n  ];                                   \n\n/*\n  \n  FETCH SPREADSHEET\n\n  fetches the spreadsheet from google docs\n\n  returns a promise that contains a result\n  of these values\n\n*/\nasync function fetch_spreadsheet(id){\n  console.log('Fetching Data from Google SpreadSheet...')\n  const doc = new GoogleSpreadsheet('1ojZoOYH1ScuSOIIf_zSByAwNToj7ifyFvBvwPapoPm8');\n\n  await doc.useServiceAccountAuth({\n    client_email: creds.client_email,\n    private_key: creds.private_key ,\n  })\n\n  await doc.loadInfo(); \n\n\n  const sheet = doc.sheetsByIndex[0];\n\n  const rows = await sheet.getRows();\n\n\n  let values = [];\n  for (var i = rows.length - 1; i >= 0; i--) {\n    let new_row_values = {};\n    columns.forEach(column => {\n      const value = new Object();\n      new_row_values[column] = rows[i][column];\n    })\n    values.push(new_row_values);\n  }\n\n  return values\n\n}\n\n/*\n  \n  GENERATE\n  HTML\n\n  Generates the html elements for each row \n  of the spreadsheet, then saves them \n  in /docs/data-dictionary/data-dictionary-content.html\n\n*/\n\nfunction generate_html(data){\n  let html_markup = data.map((row,index) => {\n\n    console.log('generating row:')\n    console.log(row)\n\n    let required = '';\n    let required_class = ''\n    switch(row[\"Required Column\"]){\n      case 'Yes':\n        // required = '<img src=\"/assets/required.svg\" class=\"icon\" data-hover-text=\"Required\">';\n        required_class = 'required'\n        break\n      case 'Recommended':\n        // required = '<img src=\"/assets/recommended.svg\" class=\"icon\" data-hover-text=\"Recommended\">';\n        required_class = 'recomended'\n        break\n      case 'Optional':\n        // required = '<img src=\"/assets/optional.svg\" class=\"icon\" data-hover-text=\"Optional\">';\n        required_class = 'optional'\n        break\n      default:\n        required = ''\n\n    }\n\n    const nullable = ''\n    // const nullable = row[\"Nullable\"] === \"Yes\" ? '<img src=\"/assets/nullable.svg\" class=\"icon\" data-hover-text=\"Nullable\">' : '';\n\n    return `\n      <tr class=\"${required_class}\">\n        <td class=\"human-name\">${row[\"Human Name\"]}</td>\n        <td class=\"human-definition\">\n          ${row[\"Human definition\"]}\n        </td>\n      </tr>\n\n    `}).join(' ')\n\n  fs.writeFile(`${__dirname}/docs/data-dictionary-content.html`, html_markup, function(err){\n    if(err){\n      console.log(err)\n    }\n  }) \n\n\n  /*\n    Generate Sidebar\n  */\n\n  let side_bar = data.map((row, index) => {\n    return `\n\n      <li id=\"${index}\"><a href=\"#id-${index}\">${row['Human Name']}</a></li>\n\n    `\n  }).join(' ')\n\n  console.log('writing file to ' + `${__dirname}/docs/data-dictionary-index.html` )\n\n}\n\n\n\n\nfetch_spreadsheet().then(generate_html);\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-09-14T15:57:47.867Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Puppeteer",
      "content": "The following package.json and js generate a app controlled by [[Command Line arguments in node.js]] that takes a screen shot of a specific website.\n\n```json\n{\n  \"name\": \"html-to-img-experiment\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"lol\"\n  },\n  \"keywords\": [\n    \"lol\"\n  ],\n  \"author\": \"LNSY\",\n  \"license\": \"ISC\",\n  \"dependencies\": {\n    \"puppeteer\": \"^13.3.2\"\n  }\n}\n\n```\n\n```javascript\nconst puppeteer = require('puppeteer');\nconst myArgs = process.argv.slice(2);\n\n(async () => {\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  await page.goto(myArgs[0]);\n  await page.screenshot({ path: 'example.png' });\n\n  await browser.close();\n})();\n\n```\n\nPrinting a PDF:\n\n```js\npage.pdf({ path: \"./my.pdf\", printBackground: true });\n```\n\n## Puppeteer on the M1\n\n[Duy K. Nguyen](/?source=post_page-----43a5c31e4f9d--------------------------------)\n\nFollow\n\nOct 24, 2021\n\n# Puppeteer for Apple M1\n\nHere and there, I’ve found some pieces of tips to build and run the Puppeteer on Apple M1. I see that the problem may be varying on each device, so this note is a kinda thing that works for me, hope that it works for you too.\n\nThe symptom is\n\nThe chromium binary is not available for arm64:  \nIf you are on Ubuntu, you can install with:\n\n# The solution\n\nFirstly, make sure 3 things:\n\n-   **XCode** has already been installed completely and works properly on your device.\n-   Then, reach **brew** and follow up the instruction to install brew on your system. [https://brew.sh/](https://brew.sh/)\n-   The version of the puppeteer should be **10.4.0 or later**\n\nP/S I assume that Rosetta has already installed while you installing Docker\n\n> You must install **Rosetta 2** as some binaries are still Darwin/AMD64. To install Rosetta 2 manually from the command line, run the following command:  \n> `softwareupdate --install-rosetta`\n\n## 1. Install chromium\n\n> brew install chromium\n\n## 2. Check if chromium works\n\n> which chromium  \n/opt/homebrew/bin/chromium> /opt/homebrew/bin/chromium\n\nIf you see kind of this error:\n\n![](media/0!mWRL6WPj4KeW82w8.png)\n\ntry this command to fix:\n\n> xattr -cr /Applications/Chromium.app\n\nIf luckier, this screen appears:\n\n![](media/1!K11XC_rPfEvxwEZ7JtKAzw.png)\n\nGo to your `System Preferences` > `Security & Privacy` > `General` screen, and select `Open Anyway`.\n\n## 3. Skip Chromium installs\n\nEnter the following lines to ~/.zshrc (`nano ~/.zshrc`)\n\nexport PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true  \nexport PUPPETEER_EXECUTABLE_PATH=`which chromium`\n\nand, reload `~/.zshrc`\n\n> source ~/.zshrc\n\n## 4. Remove all cache and install again\n\n> rm -rf node_modules  \n> rm -rf package-lock.json  \n> npm install\n\nP/S: You can occur the same issue with Docker. Add the following line in Dockerfile\n\nRUN apt-get install chromium -y  \nRUN ln -s /usr/bin/chromium /usr/bin/chromium-browserENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD true\n\nThe full Docker script\n\nFROM node:12-stretchRUN apt-get update && \\  \n  apt-get install -yq gconf-service libasound2 libatk1.0-0 libc6 libcairo2 libcups2 libdbus-1-3 \\  \n  libexpat1 libfontconfig1 libgcc1 libgconf-2-4 libgdk-pixbuf2.0-0 libglib2.0-0 libgtk-3-0 libnspr4 \\  \n  libpango-1.0-0 libpangocairo-1.0-0 libstdc++6 libx11-6 libx11-xcb1 libxcb1 libxcomposite1 \\  \n  libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 libxrandr2 libxrender1 libxss1 libxtst6 \\  \n  ca-certificates fonts-liberation libappindicator1 libnss3 lsb-release xdg-utils wget dumb-initRUN apt-get install chromium -y  \nRUN ln -s /usr/bin/chromium /usr/bin/chromium-browser  \nENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD trueRUN npm install -g nodemon  \nRUN npm install -g pm2  \nRUN npm install -g puppeteer --unsafe-permWORKDIR /home/node/app  \nCOPY --chown=node:node package.json ./package.json  \nRUN yarn install  \nCOPY --chown=node:node *.js ./ENTRYPOINT [\"/usr/bin/dumb-init\", \"--\"]  \nUSER node  \nCMD [ \"pm2-runtime\", \"start\", \"ecosystem.config.js\" ]\n\nGood luck!\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-09-29T17:38:48.524Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Python in Node.JS",
      "content": "https://www.halo-lab.com/blog/how-to-run-a-python-script-from-node-js\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-03-21T19:21:03.978Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Python",
      "content": "Sql queries in python\n\nI've done [[MongoDB]] and [[Neo4j]] queries.\n\nPython fetched sql query\n\n[[SQL]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-06T15:42:27.000Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "QR Code Element",
      "content": "# qr-code-element\nSimple Pure HTML QR Code\n\nInclude the javascript and use with the markup:\n\n```HTML\n  <script src=\"qr-code.js\"></script>\n  <qr-code value=\"cool url link here\"></qr-code>\n```\nSome Caveats: You cannot store a string longer than 1024 characters\n\n## Prior work:\n\n- https://github.com/kazuhikoarase/qrcode-generator\n- https://github.com/davidshimjs/qrcodejs\n\n\n\n```js\n/*\n  Adapted from qr-code.js by David Shim. \n  \n  This just puts the QR code into a bare HTMLElement\n  \n\n*/\n\nclass QRCodeContainer extends HTMLElement {\n  connectedCallback(){\n\n    const qrtext = this.getAttribute('value')\n    let value = window.location.origin\n    if(qrtext !== null){\n      value = ''\n      value = qrtext\n    }\n\n    if(value.length > 1024){\n      this.innerHTML('Value is too long to display')\n      return\n    }\n\n    const new_qr_code = this.qr_code_container = document.createElement('div')\n    this.style.backgroundColor = 'white'\n    this.style.contentFit = 'to-size'\n    this.style.padding = '1em'\n    this.style.display = 'inline-block'\n    this.style.width = 'fit-content'\n    this.style.height = 'fit-content'\n\n    this.qr_code = new QRCode(this, {\n      text: value,\n      width: 512,\n      height: 512,\n      colorDark : '#000000',\n      colorLight : '#FFFFFF',\n      correctLevel : QRCode.CorrectLevel.H\n    })\n\n    this.appendChild(new_qr_code)\n\n    this.qr_link = document.createElement('a')\n    this.qr_link.setAttribute('href', value)\n    this.qr_link.setAttribute('target', '_blank')\n    this.qr_link.innerText = 'link'\n\n    this.appendChild(this.qr_link)\n  }\n\n  attributeChangedCallback(name, oldValue, newValue) {\n    if(this.error){\n      this.error.remove()\n    }\n\n    if(newValue.length > 2048){\n      this.error = document.createElement('error')\n      if(this.qr_code_container) this.qr_code_container.style.display = \"none\"\n\n      this.error.innerHTML = 'Value is too long to display as a QR Code.'\n      this.appendChild(this.error)\n      return\n    }\n\n\n    if(this.qr_code_container) this.qr_code_container.style.display = 'block'\n    if(this.qr_code) this.qr_code.makeCode(newValue)\n    if(this.qr_link) this.qr_link.setAttribute('href', newValue)\n  }\n\n  disconnectedCallback() {\n    console.log('Custom square element removed from page.');\n  }\n\n  adoptedCallback() {\n    console.log('Custom square element moved to new page.');\n  }\n\n  static get observedAttributes() { \n    return ['value']\n  }\n\n}\n\ncustomElements.define('qr-code', QRCodeContainer)\n\n\n\n\n/**\n * @fileoverview\n * - Using the 'QRCode for Javascript library'\n * - Fixed dataset of 'QRCode for Javascript library' for support full-spec.\n * - this library has no dependencies.\n * \n * @author davidshimjs\n * @see <a href=\"http://www.d-project.com/\" target=\"_blank\">http://www.d-project.com/</a>\n * @see <a href=\"http://jeromeetienne.github.com/jquery-qrcode/\" target=\"_blank\">http://jeromeetienne.github.com/jquery-qrcode/</a>\n */\nvar QRCode;\n\n(function () {\n  //---------------------------------------------------------------------\n  // QRCode for JavaScript\n  //\n  // Copyright (c) 2009 Kazuhiko Arase\n  //\n  // URL: http://www.d-project.com/\n  //\n  // Licensed under the MIT license:\n  //   http://www.opensource.org/licenses/mit-license.php\n  //\n  // The word \"QR Code\" is registered trademark of \n  // DENSO WAVE INCORPORATED\n  //   http://www.denso-wave.com/qrcode/faqpatent-e.html\n  //\n  //---------------------------------------------------------------------\n  function QR8bitByte(data) {\n    this.mode = QRMode.MODE_8BIT_BYTE;\n    this.data = data;\n    this.parsedData = [];\n\n    // Added to support UTF-8 Characters\n    for (var i = 0, l = this.data.length; i < l; i++) {\n      var byteArray = [];\n      var code = this.data.charCodeAt(i);\n\n      if (code > 0x10000) {\n        byteArray[0] = 0xF0 | ((code & 0x1C0000) >>> 18);\n        byteArray[1] = 0x80 | ((code & 0x3F000) >>> 12);\n        byteArray[2] = 0x80 | ((code & 0xFC0) >>> 6);\n        byteArray[3] = 0x80 | (code & 0x3F);\n      } else if (code > 0x800) {\n        byteArray[0] = 0xE0 | ((code & 0xF000) >>> 12);\n        byteArray[1] = 0x80 | ((code & 0xFC0) >>> 6);\n        byteArray[2] = 0x80 | (code & 0x3F);\n      } else if (code > 0x80) {\n        byteArray[0] = 0xC0 | ((code & 0x7C0) >>> 6);\n        byteArray[1] = 0x80 | (code & 0x3F);\n      } else {\n        byteArray[0] = code;\n      }\n\n      this.parsedData.push(byteArray);\n    }\n\n    this.parsedData = Array.prototype.concat.apply([], this.parsedData);\n\n    if (this.parsedData.length != this.data.length) {\n      this.parsedData.unshift(191);\n      this.parsedData.unshift(187);\n      this.parsedData.unshift(239);\n    }\n  }\n\n  QR8bitByte.prototype = {\n    getLength: function (buffer) {\n      return this.parsedData.length;\n    },\n    write: function (buffer) {\n      for (var i = 0, l = this.parsedData.length; i < l; i++) {\n        buffer.put(this.parsedData[i], 8);\n      }\n    }\n  };\n\n  function QRCodeModel(typeNumber, errorCorrectLevel) {\n    this.typeNumber = typeNumber;\n    this.errorCorrectLevel = errorCorrectLevel;\n    this.modules = null;\n    this.moduleCount = 0;\n    this.dataCache = null;\n    this.dataList = [];\n  }\n\n  QRCodeModel.prototype={addData:function(data){var newData=new QR8bitByte(data);this.dataList.push(newData);this.dataCache=null;},isDark:function(row,col){if(row<0||this.moduleCount<=row||col<0||this.moduleCount<=col){throw new Error(row+\",\"+col);}\n  return this.modules[row][col];},getModuleCount:function(){return this.moduleCount;},make:function(){this.makeImpl(false,this.getBestMaskPattern());},makeImpl:function(test,maskPattern){this.moduleCount=this.typeNumber*4+17;this.modules=new Array(this.moduleCount);for(var row=0;row<this.moduleCount;row++){this.modules[row]=new Array(this.moduleCount);for(var col=0;col<this.moduleCount;col++){this.modules[row][col]=null;}}\n  this.setupPositionProbePattern(0,0);this.setupPositionProbePattern(this.moduleCount-7,0);this.setupPositionProbePattern(0,this.moduleCount-7);this.setupPositionAdjustPattern();this.setupTimingPattern();this.setupTypeInfo(test,maskPattern);if(this.typeNumber>=7){this.setupTypeNumber(test);}\n  if(this.dataCache==null){this.dataCache=QRCodeModel.createData(this.typeNumber,this.errorCorrectLevel,this.dataList);}\n  this.mapData(this.dataCache,maskPattern);},setupPositionProbePattern:function(row,col){for(var r=-1;r<=7;r++){if(row+r<=-1||this.moduleCount<=row+r)continue;for(var c=-1;c<=7;c++){if(col+c<=-1||this.moduleCount<=col+c)continue;if((0<=r&&r<=6&&(c==0||c==6))||(0<=c&&c<=6&&(r==0||r==6))||(2<=r&&r<=4&&2<=c&&c<=4)){this.modules[row+r][col+c]=true;}else{this.modules[row+r][col+c]=false;}}}},getBestMaskPattern:function(){var minLostPoint=0;var pattern=0;for(var i=0;i<8;i++){this.makeImpl(true,i);var lostPoint=QRUtil.getLostPoint(this);if(i==0||minLostPoint>lostPoint){minLostPoint=lostPoint;pattern=i;}}\n  return pattern;},createMovieClip:function(target_mc,instance_name,depth){var qr_mc=target_mc.createEmptyMovieClip(instance_name,depth);var cs=1;this.make();for(var row=0;row<this.modules.length;row++){var y=row*cs;for(var col=0;col<this.modules[row].length;col++){var x=col*cs;var dark=this.modules[row][col];if(dark){qr_mc.beginFill(0,100);qr_mc.moveTo(x,y);qr_mc.lineTo(x+cs,y);qr_mc.lineTo(x+cs,y+cs);qr_mc.lineTo(x,y+cs);qr_mc.endFill();}}}\n  return qr_mc;},setupTimingPattern:function(){for(var r=8;r<this.moduleCount-8;r++){if(this.modules[r][6]!=null){continue;}\n  this.modules[r][6]=(r%2==0);}\n  for(var c=8;c<this.moduleCount-8;c++){if(this.modules[6][c]!=null){continue;}\n  this.modules[6][c]=(c%2==0);}},setupPositionAdjustPattern:function(){var pos=QRUtil.getPatternPosition(this.typeNumber);for(var i=0;i<pos.length;i++){for(var j=0;j<pos.length;j++){var row=pos[i];var col=pos[j];if(this.modules[row][col]!=null){continue;}\n  for(var r=-2;r<=2;r++){for(var c=-2;c<=2;c++){if(r==-2||r==2||c==-2||c==2||(r==0&&c==0)){this.modules[row+r][col+c]=true;}else{this.modules[row+r][col+c]=false;}}}}}},setupTypeNumber:function(test){var bits=QRUtil.getBCHTypeNumber(this.typeNumber);for(var i=0;i<18;i++){var mod=(!test&&((bits>>i)&1)==1);this.modules[Math.floor(i/3)][i%3+this.moduleCount-8-3]=mod;}\n  for(var i=0;i<18;i++){var mod=(!test&&((bits>>i)&1)==1);this.modules[i%3+this.moduleCount-8-3][Math.floor(i/3)]=mod;}},setupTypeInfo:function(test,maskPattern){var data=(this.errorCorrectLevel<<3)|maskPattern;var bits=QRUtil.getBCHTypeInfo(data);for(var i=0;i<15;i++){var mod=(!test&&((bits>>i)&1)==1);if(i<6){this.modules[i][8]=mod;}else if(i<8){this.modules[i+1][8]=mod;}else{this.modules[this.moduleCount-15+i][8]=mod;}}\n  for(var i=0;i<15;i++){var mod=(!test&&((bits>>i)&1)==1);if(i<8){this.modules[8][this.moduleCount-i-1]=mod;}else if(i<9){this.modules[8][15-i-1+1]=mod;}else{this.modules[8][15-i-1]=mod;}}\n  this.modules[this.moduleCount-8][8]=(!test);},mapData:function(data,maskPattern){var inc=-1;var row=this.moduleCount-1;var bitIndex=7;var byteIndex=0;for(var col=this.moduleCount-1;col>0;col-=2){if(col==6)col--;while(true){for(var c=0;c<2;c++){if(this.modules[row][col-c]==null){var dark=false;if(byteIndex<data.length){dark=(((data[byteIndex]>>>bitIndex)&1)==1);}\n  var mask=QRUtil.getMask(maskPattern,row,col-c);if(mask){dark=!dark;}\n  this.modules[row][col-c]=dark;bitIndex--;if(bitIndex==-1){byteIndex++;bitIndex=7;}}}\n  row+=inc;if(row<0||this.moduleCount<=row){row-=inc;inc=-inc;break;}}}}};QRCodeModel.PAD0=0xEC;QRCodeModel.PAD1=0x11;QRCodeModel.createData=function(typeNumber,errorCorrectLevel,dataList){var rsBlocks=QRRSBlock.getRSBlocks(typeNumber,errorCorrectLevel);var buffer=new QRBitBuffer();for(var i=0;i<dataList.length;i++){var data=dataList[i];buffer.put(data.mode,4);buffer.put(data.getLength(),QRUtil.getLengthInBits(data.mode,typeNumber));data.write(buffer);}\n  var totalDataCount=0;for(var i=0;i<rsBlocks.length;i++){totalDataCount+=rsBlocks[i].dataCount;}\n  if(buffer.getLengthInBits()>totalDataCount*8){throw new Error(\"code length overflow. (\"\n  +buffer.getLengthInBits()\n  +\">\"\n  +totalDataCount*8\n  +\")\");}\n  if(buffer.getLengthInBits()+4<=totalDataCount*8){buffer.put(0,4);}\n  while(buffer.getLengthInBits()%8!=0){buffer.putBit(false);}\n  while(true){if(buffer.getLengthInBits()>=totalDataCount*8){break;}\n  buffer.put(QRCodeModel.PAD0,8);if(buffer.getLengthInBits()>=totalDataCount*8){break;}\n  buffer.put(QRCodeModel.PAD1,8);}\n  return QRCodeModel.createBytes(buffer,rsBlocks);};QRCodeModel.createBytes=function(buffer,rsBlocks){var offset=0;var maxDcCount=0;var maxEcCount=0;var dcdata=new Array(rsBlocks.length);var ecdata=new Array(rsBlocks.length);for(var r=0;r<rsBlocks.length;r++){var dcCount=rsBlocks[r].dataCount;var ecCount=rsBlocks[r].totalCount-dcCount;maxDcCount=Math.max(maxDcCount,dcCount);maxEcCount=Math.max(maxEcCount,ecCount);dcdata[r]=new Array(dcCount);for(var i=0;i<dcdata[r].length;i++){dcdata[r][i]=0xff&buffer.buffer[i+offset];}\n  offset+=dcCount;var rsPoly=QRUtil.getErrorCorrectPolynomial(ecCount);var rawPoly=new QRPolynomial(dcdata[r],rsPoly.getLength()-1);var modPoly=rawPoly.mod(rsPoly);ecdata[r]=new Array(rsPoly.getLength()-1);for(var i=0;i<ecdata[r].length;i++){var modIndex=i+modPoly.getLength()-ecdata[r].length;ecdata[r][i]=(modIndex>=0)?modPoly.get(modIndex):0;}}\n  var totalCodeCount=0;for(var i=0;i<rsBlocks.length;i++){totalCodeCount+=rsBlocks[i].totalCount;}\n  var data=new Array(totalCodeCount);var index=0;for(var i=0;i<maxDcCount;i++){for(var r=0;r<rsBlocks.length;r++){if(i<dcdata[r].length){data[index++]=dcdata[r][i];}}}\n  for(var i=0;i<maxEcCount;i++){for(var r=0;r<rsBlocks.length;r++){if(i<ecdata[r].length){data[index++]=ecdata[r][i];}}}\n  return data;};var QRMode={MODE_NUMBER:1<<0,MODE_ALPHA_NUM:1<<1,MODE_8BIT_BYTE:1<<2,MODE_KANJI:1<<3};var QRErrorCorrectLevel={L:1,M:0,Q:3,H:2};var QRMaskPattern={PATTERN000:0,PATTERN001:1,PATTERN010:2,PATTERN011:3,PATTERN100:4,PATTERN101:5,PATTERN110:6,PATTERN111:7};var QRUtil={PATTERN_POSITION_TABLE:[[],[6,18],[6,22],[6,26],[6,30],[6,34],[6,22,38],[6,24,42],[6,26,46],[6,28,50],[6,30,54],[6,32,58],[6,34,62],[6,26,46,66],[6,26,48,70],[6,26,50,74],[6,30,54,78],[6,30,56,82],[6,30,58,86],[6,34,62,90],[6,28,50,72,94],[6,26,50,74,98],[6,30,54,78,102],[6,28,54,80,106],[6,32,58,84,110],[6,30,58,86,114],[6,34,62,90,118],[6,26,50,74,98,122],[6,30,54,78,102,126],[6,26,52,78,104,130],[6,30,56,82,108,134],[6,34,60,86,112,138],[6,30,58,86,114,142],[6,34,62,90,118,146],[6,30,54,78,102,126,150],[6,24,50,76,102,128,154],[6,28,54,80,106,132,158],[6,32,58,84,110,136,162],[6,26,54,82,110,138,166],[6,30,58,86,114,142,170]],G15:(1<<10)|(1<<8)|(1<<5)|(1<<4)|(1<<2)|(1<<1)|(1<<0),G18:(1<<12)|(1<<11)|(1<<10)|(1<<9)|(1<<8)|(1<<5)|(1<<2)|(1<<0),G15_MASK:(1<<14)|(1<<12)|(1<<10)|(1<<4)|(1<<1),getBCHTypeInfo:function(data){var d=data<<10;while(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G15)>=0){d^=(QRUtil.G15<<(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G15)));}\n  return((data<<10)|d)^QRUtil.G15_MASK;},getBCHTypeNumber:function(data){var d=data<<12;while(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G18)>=0){d^=(QRUtil.G18<<(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G18)));}\n  return(data<<12)|d;},getBCHDigit:function(data){var digit=0;while(data!=0){digit++;data>>>=1;}\n  return digit;},getPatternPosition:function(typeNumber){return QRUtil.PATTERN_POSITION_TABLE[typeNumber-1];},getMask:function(maskPattern,i,j){switch(maskPattern){case QRMaskPattern.PATTERN000:return(i+j)%2==0;case QRMaskPattern.PATTERN001:return i%2==0;case QRMaskPattern.PATTERN010:return j%3==0;case QRMaskPattern.PATTERN011:return(i+j)%3==0;case QRMaskPattern.PATTERN100:return(Math.floor(i/2)+Math.floor(j/3))%2==0;case QRMaskPattern.PATTERN101:return(i*j)%2+(i*j)%3==0;case QRMaskPattern.PATTERN110:return((i*j)%2+(i*j)%3)%2==0;case QRMaskPattern.PATTERN111:return((i*j)%3+(i+j)%2)%2==0;default:throw new Error(\"bad maskPattern:\"+maskPattern);}},getErrorCorrectPolynomial:function(errorCorrectLength){var a=new QRPolynomial([1],0);for(var i=0;i<errorCorrectLength;i++){a=a.multiply(new QRPolynomial([1,QRMath.gexp(i)],0));}\n  return a;},getLengthInBits:function(mode,type){if(1<=type&&type<10){switch(mode){case QRMode.MODE_NUMBER:return 10;case QRMode.MODE_ALPHA_NUM:return 9;case QRMode.MODE_8BIT_BYTE:return 8;case QRMode.MODE_KANJI:return 8;default:throw new Error(\"mode:\"+mode);}}else if(type<27){switch(mode){case QRMode.MODE_NUMBER:return 12;case QRMode.MODE_ALPHA_NUM:return 11;case QRMode.MODE_8BIT_BYTE:return 16;case QRMode.MODE_KANJI:return 10;default:throw new Error(\"mode:\"+mode);}}else if(type<41){switch(mode){case QRMode.MODE_NUMBER:return 14;case QRMode.MODE_ALPHA_NUM:return 13;case QRMode.MODE_8BIT_BYTE:return 16;case QRMode.MODE_KANJI:return 12;default:throw new Error(\"mode:\"+mode);}}else{throw new Error(\"type:\"+type);}},getLostPoint:function(qrCode){var moduleCount=qrCode.getModuleCount();var lostPoint=0;for(var row=0;row<moduleCount;row++){for(var col=0;col<moduleCount;col++){var sameCount=0;var dark=qrCode.isDark(row,col);for(var r=-1;r<=1;r++){if(row+r<0||moduleCount<=row+r){continue;}\n  for(var c=-1;c<=1;c++){if(col+c<0||moduleCount<=col+c){continue;}\n  if(r==0&&c==0){continue;}\n  if(dark==qrCode.isDark(row+r,col+c)){sameCount++;}}}\n  if(sameCount>5){lostPoint+=(3+sameCount-5);}}}\n  for(var row=0;row<moduleCount-1;row++){for(var col=0;col<moduleCount-1;col++){var count=0;if(qrCode.isDark(row,col))count++;if(qrCode.isDark(row+1,col))count++;if(qrCode.isDark(row,col+1))count++;if(qrCode.isDark(row+1,col+1))count++;if(count==0||count==4){lostPoint+=3;}}}\n  for(var row=0;row<moduleCount;row++){for(var col=0;col<moduleCount-6;col++){if(qrCode.isDark(row,col)&&!qrCode.isDark(row,col+1)&&qrCode.isDark(row,col+2)&&qrCode.isDark(row,col+3)&&qrCode.isDark(row,col+4)&&!qrCode.isDark(row,col+5)&&qrCode.isDark(row,col+6)){lostPoint+=40;}}}\n  for(var col=0;col<moduleCount;col++){for(var row=0;row<moduleCount-6;row++){if(qrCode.isDark(row,col)&&!qrCode.isDark(row+1,col)&&qrCode.isDark(row+2,col)&&qrCode.isDark(row+3,col)&&qrCode.isDark(row+4,col)&&!qrCode.isDark(row+5,col)&&qrCode.isDark(row+6,col)){lostPoint+=40;}}}\n  var darkCount=0;for(var col=0;col<moduleCount;col++){for(var row=0;row<moduleCount;row++){if(qrCode.isDark(row,col)){darkCount++;}}}\n  var ratio=Math.abs(100*darkCount/moduleCount/moduleCount-50)/5;lostPoint+=ratio*10;return lostPoint;}};var QRMath={glog:function(n){if(n<1){throw new Error(\"glog(\"+n+\")\");}\n  return QRMath.LOG_TABLE[n];},gexp:function(n){while(n<0){n+=255;}\n  while(n>=256){n-=255;}\n  return QRMath.EXP_TABLE[n];},EXP_TABLE:new Array(256),LOG_TABLE:new Array(256)};for(var i=0;i<8;i++){QRMath.EXP_TABLE[i]=1<<i;}\n  for(var i=8;i<256;i++){QRMath.EXP_TABLE[i]=QRMath.EXP_TABLE[i-4]^QRMath.EXP_TABLE[i-5]^QRMath.EXP_TABLE[i-6]^QRMath.EXP_TABLE[i-8];}\n  for(var i=0;i<255;i++){QRMath.LOG_TABLE[QRMath.EXP_TABLE[i]]=i;}\n  function QRPolynomial(num,shift){if(num.length==undefined){throw new Error(num.length+\"/\"+shift);}\n  var offset=0;while(offset<num.length&&num[offset]==0){offset++;}\n  this.num=new Array(num.length-offset+shift);for(var i=0;i<num.length-offset;i++){this.num[i]=num[i+offset];}}\n  QRPolynomial.prototype={get:function(index){return this.num[index];},getLength:function(){return this.num.length;},multiply:function(e){var num=new Array(this.getLength()+e.getLength()-1);for(var i=0;i<this.getLength();i++){for(var j=0;j<e.getLength();j++){num[i+j]^=QRMath.gexp(QRMath.glog(this.get(i))+QRMath.glog(e.get(j)));}}\n  return new QRPolynomial(num,0);},mod:function(e){if(this.getLength()-e.getLength()<0){return this;}\n  var ratio=QRMath.glog(this.get(0))-QRMath.glog(e.get(0));var num=new Array(this.getLength());for(var i=0;i<this.getLength();i++){num[i]=this.get(i);}\n  for(var i=0;i<e.getLength();i++){num[i]^=QRMath.gexp(QRMath.glog(e.get(i))+ratio);}\n  return new QRPolynomial(num,0).mod(e);}};function QRRSBlock(totalCount,dataCount){this.totalCount=totalCount;this.dataCount=dataCount;}\n  QRRSBlock.RS_BLOCK_TABLE=[[1,26,19],[1,26,16],[1,26,13],[1,26,9],[1,44,34],[1,44,28],[1,44,22],[1,44,16],[1,70,55],[1,70,44],[2,35,17],[2,35,13],[1,100,80],[2,50,32],[2,50,24],[4,25,9],[1,134,108],[2,67,43],[2,33,15,2,34,16],[2,33,11,2,34,12],[2,86,68],[4,43,27],[4,43,19],[4,43,15],[2,98,78],[4,49,31],[2,32,14,4,33,15],[4,39,13,1,40,14],[2,121,97],[2,60,38,2,61,39],[4,40,18,2,41,19],[4,40,14,2,41,15],[2,146,116],[3,58,36,2,59,37],[4,36,16,4,37,17],[4,36,12,4,37,13],[2,86,68,2,87,69],[4,69,43,1,70,44],[6,43,19,2,44,20],[6,43,15,2,44,16],[4,101,81],[1,80,50,4,81,51],[4,50,22,4,51,23],[3,36,12,8,37,13],[2,116,92,2,117,93],[6,58,36,2,59,37],[4,46,20,6,47,21],[7,42,14,4,43,15],[4,133,107],[8,59,37,1,60,38],[8,44,20,4,45,21],[12,33,11,4,34,12],[3,145,115,1,146,116],[4,64,40,5,65,41],[11,36,16,5,37,17],[11,36,12,5,37,13],[5,109,87,1,110,88],[5,65,41,5,66,42],[5,54,24,7,55,25],[11,36,12],[5,122,98,1,123,99],[7,73,45,3,74,46],[15,43,19,2,44,20],[3,45,15,13,46,16],[1,135,107,5,136,108],[10,74,46,1,75,47],[1,50,22,15,51,23],[2,42,14,17,43,15],[5,150,120,1,151,121],[9,69,43,4,70,44],[17,50,22,1,51,23],[2,42,14,19,43,15],[3,141,113,4,142,114],[3,70,44,11,71,45],[17,47,21,4,48,22],[9,39,13,16,40,14],[3,135,107,5,136,108],[3,67,41,13,68,42],[15,54,24,5,55,25],[15,43,15,10,44,16],[4,144,116,4,145,117],[17,68,42],[17,50,22,6,51,23],[19,46,16,6,47,17],[2,139,111,7,140,112],[17,74,46],[7,54,24,16,55,25],[34,37,13],[4,151,121,5,152,122],[4,75,47,14,76,48],[11,54,24,14,55,25],[16,45,15,14,46,16],[6,147,117,4,148,118],[6,73,45,14,74,46],[11,54,24,16,55,25],[30,46,16,2,47,17],[8,132,106,4,133,107],[8,75,47,13,76,48],[7,54,24,22,55,25],[22,45,15,13,46,16],[10,142,114,2,143,115],[19,74,46,4,75,47],[28,50,22,6,51,23],[33,46,16,4,47,17],[8,152,122,4,153,123],[22,73,45,3,74,46],[8,53,23,26,54,24],[12,45,15,28,46,16],[3,147,117,10,148,118],[3,73,45,23,74,46],[4,54,24,31,55,25],[11,45,15,31,46,16],[7,146,116,7,147,117],[21,73,45,7,74,46],[1,53,23,37,54,24],[19,45,15,26,46,16],[5,145,115,10,146,116],[19,75,47,10,76,48],[15,54,24,25,55,25],[23,45,15,25,46,16],[13,145,115,3,146,116],[2,74,46,29,75,47],[42,54,24,1,55,25],[23,45,15,28,46,16],[17,145,115],[10,74,46,23,75,47],[10,54,24,35,55,25],[19,45,15,35,46,16],[17,145,115,1,146,116],[14,74,46,21,75,47],[29,54,24,19,55,25],[11,45,15,46,46,16],[13,145,115,6,146,116],[14,74,46,23,75,47],[44,54,24,7,55,25],[59,46,16,1,47,17],[12,151,121,7,152,122],[12,75,47,26,76,48],[39,54,24,14,55,25],[22,45,15,41,46,16],[6,151,121,14,152,122],[6,75,47,34,76,48],[46,54,24,10,55,25],[2,45,15,64,46,16],[17,152,122,4,153,123],[29,74,46,14,75,47],[49,54,24,10,55,25],[24,45,15,46,46,16],[4,152,122,18,153,123],[13,74,46,32,75,47],[48,54,24,14,55,25],[42,45,15,32,46,16],[20,147,117,4,148,118],[40,75,47,7,76,48],[43,54,24,22,55,25],[10,45,15,67,46,16],[19,148,118,6,149,119],[18,75,47,31,76,48],[34,54,24,34,55,25],[20,45,15,61,46,16]];QRRSBlock.getRSBlocks=function(typeNumber,errorCorrectLevel){var rsBlock=QRRSBlock.getRsBlockTable(typeNumber,errorCorrectLevel);if(rsBlock==undefined){throw new Error(\"bad rs block @ typeNumber:\"+typeNumber+\"/errorCorrectLevel:\"+errorCorrectLevel);}\n  var length=rsBlock.length/3;var list=[];for(var i=0;i<length;i++){var count=rsBlock[i*3+0];var totalCount=rsBlock[i*3+1];var dataCount=rsBlock[i*3+2];for(var j=0;j<count;j++){list.push(new QRRSBlock(totalCount,dataCount));}}\n  return list;};QRRSBlock.getRsBlockTable=function(typeNumber,errorCorrectLevel){switch(errorCorrectLevel){case QRErrorCorrectLevel.L:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+0];case QRErrorCorrectLevel.M:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+1];case QRErrorCorrectLevel.Q:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+2];case QRErrorCorrectLevel.H:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+3];default:return undefined;}};function QRBitBuffer(){this.buffer=[];this.length=0;}\n  QRBitBuffer.prototype={get:function(index){var bufIndex=Math.floor(index/8);return((this.buffer[bufIndex]>>>(7-index%8))&1)==1;},put:function(num,length){for(var i=0;i<length;i++){this.putBit(((num>>>(length-i-1))&1)==1);}},getLengthInBits:function(){return this.length;},putBit:function(bit){var bufIndex=Math.floor(this.length/8);if(this.buffer.length<=bufIndex){this.buffer.push(0);}\n  if(bit){this.buffer[bufIndex]|=(0x80>>>(this.length%8));}\n  this.length++;}};var QRCodeLimitLength=[[17,14,11,7],[32,26,20,14],[53,42,32,24],[78,62,46,34],[106,84,60,44],[134,106,74,58],[154,122,86,64],[192,152,108,84],[230,180,130,98],[271,213,151,119],[321,251,177,137],[367,287,203,155],[425,331,241,177],[458,362,258,194],[520,412,292,220],[586,450,322,250],[644,504,364,280],[718,560,394,310],[792,624,442,338],[858,666,482,382],[929,711,509,403],[1003,779,565,439],[1091,857,611,461],[1171,911,661,511],[1273,997,715,535],[1367,1059,751,593],[1465,1125,805,625],[1528,1190,868,658],[1628,1264,908,698],[1732,1370,982,742],[1840,1452,1030,790],[1952,1538,1112,842],[2068,1628,1168,898],[2188,1722,1228,958],[2303,1809,1283,983],[2431,1911,1351,1051],[2563,1989,1423,1093],[2699,2099,1499,1139],[2809,2213,1579,1219],[2953,2331,1663,1273]];\n  \n  function _isSupportCanvas() {\n    return typeof CanvasRenderingContext2D != \"undefined\";\n  }\n  \n  // android 2.x doesn't support Data-URI spec\n  function _getAndroid() {\n    var android = false;\n    var sAgent = navigator.userAgent;\n    \n    if (/android/i.test(sAgent)) { // android\n      android = true;\n      var aMat = sAgent.toString().match(/android ([0-9]\\.[0-9])/i);\n      \n      if (aMat && aMat[1]) {\n        android = parseFloat(aMat[1]);\n      }\n    }\n    \n    return android;\n  }\n  \n  var svgDrawer = (function() {\n\n    var Drawing = function (el, htOption) {\n      this._el = el;\n      this._htOption = htOption;\n    };\n\n    Drawing.prototype.draw = function (oQRCode) {\n      var _htOption = this._htOption;\n      var _el = this._el;\n      var nCount = oQRCode.getModuleCount();\n      var nWidth = Math.floor(_htOption.width / nCount);\n      var nHeight = Math.floor(_htOption.height / nCount);\n\n      this.clear();\n\n      function makeSVG(tag, attrs) {\n        var el = document.createElementNS('http://www.w3.org/2000/svg', tag);\n        for (var k in attrs)\n          if (attrs.hasOwnProperty(k)) el.setAttribute(k, attrs[k]);\n        return el;\n      }\n\n      var svg = makeSVG(\"svg\" , {'viewBox': '0 0 ' + String(nCount) + \" \" + String(nCount), 'width': '100%', 'height': '100%', 'fill': _htOption.colorLight});\n      svg.setAttributeNS(\"http://www.w3.org/2000/xmlns/\", \"xmlns:xlink\", \"http://www.w3.org/1999/xlink\");\n      _el.appendChild(svg);\n\n      svg.appendChild(makeSVG(\"rect\", {\"fill\": _htOption.colorLight, \"width\": \"100%\", \"height\": \"100%\"}));\n      svg.appendChild(makeSVG(\"rect\", {\"fill\": _htOption.colorDark, \"width\": \"1\", \"height\": \"1\", \"id\": \"template\"}));\n\n      for (var row = 0; row < nCount; row++) {\n        for (var col = 0; col < nCount; col++) {\n          if (oQRCode.isDark(row, col)) {\n            var child = makeSVG(\"use\", {\"x\": String(col), \"y\": String(row)});\n            child.setAttributeNS(\"http://www.w3.org/1999/xlink\", \"href\", \"#template\")\n            svg.appendChild(child);\n          }\n        }\n      }\n    };\n    Drawing.prototype.clear = function () {\n      while (this._el.hasChildNodes())\n        this._el.removeChild(this._el.lastChild);\n    };\n    return Drawing;\n  })();\n\n  var useSVG = document.documentElement.tagName.toLowerCase() === \"svg\";\n\n  // Drawing in DOM by using Table tag\n  var Drawing = useSVG ? svgDrawer : !_isSupportCanvas() ? (function () {\n    var Drawing = function (el, htOption) {\n      this._el = el;\n      this._htOption = htOption;\n    };\n      \n    /**\n     * Draw the QRCode\n     * \n     * @param {QRCode} oQRCode\n     */\n    Drawing.prototype.draw = function (oQRCode) {\n            var _htOption = this._htOption;\n            var _el = this._el;\n      var nCount = oQRCode.getModuleCount();\n      var nWidth = Math.floor(_htOption.width / nCount);\n      var nHeight = Math.floor(_htOption.height / nCount);\n      var aHTML = ['<table style=\"border:0;border-collapse:collapse;\">'];\n      \n      for (var row = 0; row < nCount; row++) {\n        aHTML.push('<tr>');\n        \n        for (var col = 0; col < nCount; col++) {\n          aHTML.push('<td style=\"border:0;border-collapse:collapse;padding:0;margin:0;width:' + nWidth + 'px;height:' + nHeight + 'px;background-color:' + (oQRCode.isDark(row, col) ? _htOption.colorDark : _htOption.colorLight) + ';\"></td>');\n        }\n        \n        aHTML.push('</tr>');\n      }\n      \n      aHTML.push('</table>');\n      _el.innerHTML = aHTML.join('');\n      \n      // Fix the margin values as real size.\n      var elTable = _el.childNodes[0];\n      var nLeftMarginTable = (_htOption.width - elTable.offsetWidth) / 2;\n      var nTopMarginTable = (_htOption.height - elTable.offsetHeight) / 2;\n      \n      if (nLeftMarginTable > 0 && nTopMarginTable > 0) {\n        elTable.style.margin = nTopMarginTable + \"px \" + nLeftMarginTable + \"px\"; \n      }\n    };\n    \n    /**\n     * Clear the QRCode\n     */\n    Drawing.prototype.clear = function () {\n      this._el.innerHTML = '';\n    };\n    \n    return Drawing;\n  })() : (function () { // Drawing in Canvas\n    function _onMakeImage() {\n      this._elImage.src = this._elCanvas.toDataURL(\"image/png\");\n      this._elImage.style.display = \"block\";\n      this._elCanvas.style.display = \"none\";      \n    }\n    \n    // Android 2.1 bug workaround\n    // http://code.google.com/p/android/issues/detail?id=5141\n    if (this && this._android && this._android <= 2.1) {\n        var factor = 1 / window.devicePixelRatio;\n          var drawImage = CanvasRenderingContext2D.prototype.drawImage; \n        CanvasRenderingContext2D.prototype.drawImage = function (image, sx, sy, sw, sh, dx, dy, dw, dh) {\n          if ((\"nodeName\" in image) && /img/i.test(image.nodeName)) {\n              for (var i = arguments.length - 1; i >= 1; i--) {\n                  arguments[i] = arguments[i] * factor;\n              }\n          } else if (typeof dw == \"undefined\") {\n            arguments[1] *= factor;\n            arguments[2] *= factor;\n            arguments[3] *= factor;\n            arguments[4] *= factor;\n          }\n          \n            drawImage.apply(this, arguments); \n        };\n    }\n    \n    /**\n     * Check whether the user's browser supports Data URI or not\n     * \n     * @private\n     * @param {Function} fSuccess Occurs if it supports Data URI\n     * @param {Function} fFail Occurs if it doesn't support Data URI\n     */\n    function _safeSetDataURI(fSuccess, fFail) {\n            var self = this;\n            self._fFail = fFail;\n            self._fSuccess = fSuccess;\n\n            // Check it just once\n            if (self._bSupportDataURI === null) {\n                var el = document.createElement(\"img\");\n                var fOnError = function() {\n                    self._bSupportDataURI = false;\n\n                    if (self._fFail) {\n                        self._fFail.call(self);\n                    }\n                };\n                var fOnSuccess = function() {\n                    self._bSupportDataURI = true;\n\n                    if (self._fSuccess) {\n                        self._fSuccess.call(self);\n                    }\n                };\n\n                el.onabort = fOnError;\n                el.onerror = fOnError;\n                el.onload = fOnSuccess;\n                el.src = \"data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==\"; // the Image contains 1px data.\n                return;\n            } else if (self._bSupportDataURI === true && self._fSuccess) {\n                self._fSuccess.call(self);\n            } else if (self._bSupportDataURI === false && self._fFail) {\n                self._fFail.call(self);\n            }\n    };\n    \n    /**\n     * Drawing QRCode by using canvas\n     * \n     * @constructor\n     * @param {HTMLElement} el\n     * @param {Object} htOption QRCode Options \n     */\n    var Drawing = function (el, htOption) {\n        this._bIsPainted = false;\n        this._android = _getAndroid();\n    \n      this._htOption = htOption;\n      this._elCanvas = document.createElement(\"canvas\");\n      this._elCanvas.width = htOption.width;\n      this._elCanvas.height = htOption.height;\n      el.appendChild(this._elCanvas);\n      this._el = el;\n      this._oContext = this._elCanvas.getContext(\"2d\");\n      this._bIsPainted = false;\n      this._elImage = document.createElement(\"img\");\n      this._elImage.alt = \"Scan me!\";\n      this._elImage.style.display = \"none\";\n      this._el.appendChild(this._elImage);\n      this._bSupportDataURI = null;\n    };\n      \n    /**\n     * Draw the QRCode\n     * \n     * @param {QRCode} oQRCode \n     */\n    Drawing.prototype.draw = function (oQRCode) {\n            var _elImage = this._elImage;\n            var _oContext = this._oContext;\n            var _htOption = this._htOption;\n            \n      var nCount = oQRCode.getModuleCount();\n      var nWidth = _htOption.width / nCount;\n      var nHeight = _htOption.height / nCount;\n      var nRoundedWidth = Math.round(nWidth);\n      var nRoundedHeight = Math.round(nHeight);\n\n      _elImage.style.display = \"none\";\n      this.clear();\n      \n      for (var row = 0; row < nCount; row++) {\n        for (var col = 0; col < nCount; col++) {\n          var bIsDark = oQRCode.isDark(row, col);\n          var nLeft = col * nWidth;\n          var nTop = row * nHeight;\n          _oContext.strokeStyle = bIsDark ? _htOption.colorDark : _htOption.colorLight;\n          _oContext.lineWidth = 1;\n          _oContext.fillStyle = bIsDark ? _htOption.colorDark : _htOption.colorLight;         \n          _oContext.fillRect(nLeft, nTop, nWidth, nHeight);\n          \n          // 안티 앨리어싱 방지 처리\n          _oContext.strokeRect(\n            Math.floor(nLeft) + 0.5,\n            Math.floor(nTop) + 0.5,\n            nRoundedWidth,\n            nRoundedHeight\n          );\n          \n          _oContext.strokeRect(\n            Math.ceil(nLeft) - 0.5,\n            Math.ceil(nTop) - 0.5,\n            nRoundedWidth,\n            nRoundedHeight\n          );\n        }\n      }\n      \n      this._bIsPainted = true;\n    };\n      \n    /**\n     * Make the image from Canvas if the browser supports Data URI.\n     */\n    Drawing.prototype.makeImage = function () {\n      if (this._bIsPainted) {\n        _safeSetDataURI.call(this, _onMakeImage);\n      }\n    };\n      \n    /**\n     * Return whether the QRCode is painted or not\n     * \n     * @return {Boolean}\n     */\n    Drawing.prototype.isPainted = function () {\n      return this._bIsPainted;\n    };\n    \n    /**\n     * Clear the QRCode\n     */\n    Drawing.prototype.clear = function () {\n      this._oContext.clearRect(0, 0, this._elCanvas.width, this._elCanvas.height);\n      this._bIsPainted = false;\n    };\n    \n    /**\n     * @private\n     * @param {Number} nNumber\n     */\n    Drawing.prototype.round = function (nNumber) {\n      if (!nNumber) {\n        return nNumber;\n      }\n      \n      return Math.floor(nNumber * 1000) / 1000;\n    };\n    \n    return Drawing;\n  })();\n  \n  /**\n   * Get the type by string length\n   * \n   * @private\n   * @param {String} sText\n   * @param {Number} nCorrectLevel\n   * @return {Number} type\n   */\n  function _getTypeNumber(sText, nCorrectLevel) {     \n    var nType = 1;\n    var length = _getUTF8Length(sText);\n    \n    for (var i = 0, len = QRCodeLimitLength.length; i <= len; i++) {\n      var nLimit = 0;\n      \n      switch (nCorrectLevel) {\n        case QRErrorCorrectLevel.L :\n          nLimit = QRCodeLimitLength[i][0];\n          break;\n        case QRErrorCorrectLevel.M :\n          nLimit = QRCodeLimitLength[i][1];\n          break;\n        case QRErrorCorrectLevel.Q :\n          nLimit = QRCodeLimitLength[i][2];\n          break;\n        case QRErrorCorrectLevel.H :\n          nLimit = QRCodeLimitLength[i][3];\n          break;\n      }\n      \n      if (length <= nLimit) {\n        break;\n      } else {\n        nType++;\n      }\n    }\n    \n    if (nType > QRCodeLimitLength.length) {\n      throw new Error(\"Too long data\");\n    }\n    \n    return nType;\n  }\n\n  function _getUTF8Length(sText) {\n    var replacedText = encodeURI(sText).toString().replace(/\\%[0-9a-fA-F]{2}/g, 'a');\n    return replacedText.length + (replacedText.length != sText ? 3 : 0);\n  }\n  \n  /**\n   * @class QRCode\n   * @constructor\n   * @example \n   * new QRCode(document.getElementById(\"test\"), \"http://jindo.dev.naver.com/collie\");\n   *\n   * @example\n   * var oQRCode = new QRCode(\"test\", {\n   *    text : \"http://naver.com\",\n   *    width : 128,\n   *    height : 128\n   * });\n   * \n   * oQRCode.clear(); // Clear the QRCode.\n   * oQRCode.makeCode(\"http://map.naver.com\"); // Re-create the QRCode.\n   *\n   * @param {HTMLElement|String} el target element or 'id' attribute of element.\n   * @param {Object|String} vOption\n   * @param {String} vOption.text QRCode link data\n   * @param {Number} [vOption.width=256]\n   * @param {Number} [vOption.height=256]\n   * @param {String} [vOption.colorDark=\"#000000\"]\n   * @param {String} [vOption.colorLight=\"#ffffff\"]\n   * @param {QRCode.CorrectLevel} [vOption.correctLevel=QRCode.CorrectLevel.H] [L|M|Q|H] \n   */\n  QRCode = function (el, vOption) {\n    this._htOption = {\n      width : 256, \n      height : 256,\n      typeNumber : 4,\n      colorDark : \"#000000\",\n      colorLight : \"#ffffff\",\n      correctLevel : QRErrorCorrectLevel.H\n    };\n    \n    if (typeof vOption === 'string') {\n      vOption = {\n        text : vOption\n      };\n    }\n    \n    // Overwrites options\n    if (vOption) {\n      for (var i in vOption) {\n        this._htOption[i] = vOption[i];\n      }\n    }\n    \n    if (typeof el == \"string\") {\n      el = document.getElementById(el);\n    }\n\n    if (this._htOption.useSVG) {\n      Drawing = svgDrawer;\n    }\n    \n    this._android = _getAndroid();\n    this._el = el;\n    this._oQRCode = null;\n    this._oDrawing = new Drawing(this._el, this._htOption);\n    \n    if (this._htOption.text) {\n      this.makeCode(this._htOption.text); \n    }\n  };\n  \n  /**\n   * Make the QRCode\n   * \n   * @param {String} sText link data\n   */\n  QRCode.prototype.makeCode = function (sText) {\n    this._oQRCode = new QRCodeModel(_getTypeNumber(sText, this._htOption.correctLevel), this._htOption.correctLevel);\n    this._oQRCode.addData(sText);\n    this._oQRCode.make();\n    this._el.title = sText;\n    this._oDrawing.draw(this._oQRCode);     \n    this.makeImage();\n  };\n  \n  /**\n   * Make the Image from Canvas element\n   * - It occurs automatically\n   * - Android below 3 doesn't support Data-URI spec.\n   * \n   * @private\n   */\n  QRCode.prototype.makeImage = function () {\n    if (typeof this._oDrawing.makeImage == \"function\" && (!this._android || this._android >= 3)) {\n      this._oDrawing.makeImage();\n    }\n  };\n  \n  /**\n   * Clear the QRCode\n   */\n  QRCode.prototype.clear = function () {\n    this._oDrawing.clear();\n  };\n  /*\n  Adapted from qr-code.js by David Shim. \n  \n  This just puts the QR code into a bare HTMLElement\n  \n\n*/\n\nclass QRCodeContainer extends HTMLElement {\n  connectedCallback(){\n\n    const qrtext = this.getAttribute('value')\n    let value = window.location.origin\n    if(qrtext !== null){\n      value = ''\n      value = qrtext\n    }\n\n    if(value.length > 1024){\n      this.innerHTML('Value is too long to display')\n      return\n    }\n\n    const new_qr_code = this.qr_code_container = document.createElement('div')\n    this.style.backgroundColor = 'white'\n    this.style.contentFit = 'to-size'\n    this.style.padding = '1em'\n    this.style.display = 'inline-block'\n    this.style.width = 'fit-content'\n    this.style.height = 'fit-content'\n\n    this.qr_code = new QRCode(this, {\n      text: value,\n      width: 512,\n      height: 512,\n      colorDark : '#000000',\n      colorLight : '#FFFFFF',\n      correctLevel : QRCode.CorrectLevel.H\n    })\n\n    this.appendChild(new_qr_code)\n\n    this.qr_link = document.createElement('a')\n    this.qr_link.setAttribute('href', value)\n    this.qr_link.setAttribute('target', '_blank')\n    this.qr_link.innerText = 'link'\n\n    this.appendChild(this.qr_link)\n  }\n\n  attributeChangedCallback(name, oldValue, newValue) {\n    if(this.error){\n      this.error.remove()\n    }\n\n    if(newValue.length > 2048){\n      this.error = document.createElement('error')\n      if(this.qr_code_container) this.qr_code_container.style.display = \"none\"\n\n      this.error.innerHTML = 'Value is too long to display as a QR Code.'\n      this.appendChild(this.error)\n      return\n    }\n\n\n    if(this.qr_code_container) this.qr_code_container.style.display = 'block'\n    if(this.qr_code) this.qr_code.makeCode(newValue)\n    if(this.qr_link) this.qr_link.setAttribute('href', newValue)\n  }\n\n  disconnectedCallback() {\n    console.log('Custom square element removed from page.');\n  }\n\n  adoptedCallback() {\n    console.log('Custom square element moved to new page.');\n  }\n\n  static get observedAttributes() { \n    return ['value']\n  }\n\n}\n\ncustomElements.define('qr-code', QRCodeContainer)\n\n\n\n\n/**\n * @fileoverview\n * - Using the 'QRCode for Javascript library'\n * - Fixed dataset of 'QRCode for Javascript library' for support full-spec.\n * - this library has no dependencies.\n * \n * @author davidshimjs\n * @see <a href=\"http://www.d-project.com/\" target=\"_blank\">http://www.d-project.com/</a>\n * @see <a href=\"http://jeromeetienne.github.com/jquery-qrcode/\" target=\"_blank\">http://jeromeetienne.github.com/jquery-qrcode/</a>\n */\nvar QRCode;\n\n(function () {\n  //---------------------------------------------------------------------\n  // QRCode for JavaScript\n  //\n  // Copyright (c) 2009 Kazuhiko Arase\n  //\n  // URL: http://www.d-project.com/\n  //\n  // Licensed under the MIT license:\n  //   http://www.opensource.org/licenses/mit-license.php\n  //\n  // The word \"QR Code\" is registered trademark of \n  // DENSO WAVE INCORPORATED\n  //   http://www.denso-wave.com/qrcode/faqpatent-e.html\n  //\n  //---------------------------------------------------------------------\n  function QR8bitByte(data) {\n    this.mode = QRMode.MODE_8BIT_BYTE;\n    this.data = data;\n    this.parsedData = [];\n\n    // Added to support UTF-8 Characters\n    for (var i = 0, l = this.data.length; i < l; i++) {\n      var byteArray = [];\n      var code = this.data.charCodeAt(i);\n\n      if (code > 0x10000) {\n        byteArray[0] = 0xF0 | ((code & 0x1C0000) >>> 18);\n        byteArray[1] = 0x80 | ((code & 0x3F000) >>> 12);\n        byteArray[2] = 0x80 | ((code & 0xFC0) >>> 6);\n        byteArray[3] = 0x80 | (code & 0x3F);\n      } else if (code > 0x800) {\n        byteArray[0] = 0xE0 | ((code & 0xF000) >>> 12);\n        byteArray[1] = 0x80 | ((code & 0xFC0) >>> 6);\n        byteArray[2] = 0x80 | (code & 0x3F);\n      } else if (code > 0x80) {\n        byteArray[0] = 0xC0 | ((code & 0x7C0) >>> 6);\n        byteArray[1] = 0x80 | (code & 0x3F);\n      } else {\n        byteArray[0] = code;\n      }\n\n      this.parsedData.push(byteArray);\n    }\n\n    this.parsedData = Array.prototype.concat.apply([], this.parsedData);\n\n    if (this.parsedData.length != this.data.length) {\n      this.parsedData.unshift(191);\n      this.parsedData.unshift(187);\n      this.parsedData.unshift(239);\n    }\n  }\n\n  QR8bitByte.prototype = {\n    getLength: function (buffer) {\n      return this.parsedData.length;\n    },\n    write: function (buffer) {\n      for (var i = 0, l = this.parsedData.length; i < l; i++) {\n        buffer.put(this.parsedData[i], 8);\n      }\n    }\n  };\n\n  function QRCodeModel(typeNumber, errorCorrectLevel) {\n    this.typeNumber = typeNumber;\n    this.errorCorrectLevel = errorCorrectLevel;\n    this.modules = null;\n    this.moduleCount = 0;\n    this.dataCache = null;\n    this.dataList = [];\n  }\n\n  QRCodeModel.prototype={addData:function(data){var newData=new QR8bitByte(data);this.dataList.push(newData);this.dataCache=null;},isDark:function(row,col){if(row<0||this.moduleCount<=row||col<0||this.moduleCount<=col){throw new Error(row+\",\"+col);}\n  return this.modules[row][col];},getModuleCount:function(){return this.moduleCount;},make:function(){this.makeImpl(false,this.getBestMaskPattern());},makeImpl:function(test,maskPattern){this.moduleCount=this.typeNumber*4+17;this.modules=new Array(this.moduleCount);for(var row=0;row<this.moduleCount;row++){this.modules[row]=new Array(this.moduleCount);for(var col=0;col<this.moduleCount;col++){this.modules[row][col]=null;}}\n  this.setupPositionProbePattern(0,0);this.setupPositionProbePattern(this.moduleCount-7,0);this.setupPositionProbePattern(0,this.moduleCount-7);this.setupPositionAdjustPattern();this.setupTimingPattern();this.setupTypeInfo(test,maskPattern);if(this.typeNumber>=7){this.setupTypeNumber(test);}\n  if(this.dataCache==null){this.dataCache=QRCodeModel.createData(this.typeNumber,this.errorCorrectLevel,this.dataList);}\n  this.mapData(this.dataCache,maskPattern);},setupPositionProbePattern:function(row,col){for(var r=-1;r<=7;r++){if(row+r<=-1||this.moduleCount<=row+r)continue;for(var c=-1;c<=7;c++){if(col+c<=-1||this.moduleCount<=col+c)continue;if((0<=r&&r<=6&&(c==0||c==6))||(0<=c&&c<=6&&(r==0||r==6))||(2<=r&&r<=4&&2<=c&&c<=4)){this.modules[row+r][col+c]=true;}else{this.modules[row+r][col+c]=false;}}}},getBestMaskPattern:function(){var minLostPoint=0;var pattern=0;for(var i=0;i<8;i++){this.makeImpl(true,i);var lostPoint=QRUtil.getLostPoint(this);if(i==0||minLostPoint>lostPoint){minLostPoint=lostPoint;pattern=i;}}\n  return pattern;},createMovieClip:function(target_mc,instance_name,depth){var qr_mc=target_mc.createEmptyMovieClip(instance_name,depth);var cs=1;this.make();for(var row=0;row<this.modules.length;row++){var y=row*cs;for(var col=0;col<this.modules[row].length;col++){var x=col*cs;var dark=this.modules[row][col];if(dark){qr_mc.beginFill(0,100);qr_mc.moveTo(x,y);qr_mc.lineTo(x+cs,y);qr_mc.lineTo(x+cs,y+cs);qr_mc.lineTo(x,y+cs);qr_mc.endFill();}}}\n  return qr_mc;},setupTimingPattern:function(){for(var r=8;r<this.moduleCount-8;r++){if(this.modules[r][6]!=null){continue;}\n  this.modules[r][6]=(r%2==0);}\n  for(var c=8;c<this.moduleCount-8;c++){if(this.modules[6][c]!=null){continue;}\n  this.modules[6][c]=(c%2==0);}},setupPositionAdjustPattern:function(){var pos=QRUtil.getPatternPosition(this.typeNumber);for(var i=0;i<pos.length;i++){for(var j=0;j<pos.length;j++){var row=pos[i];var col=pos[j];if(this.modules[row][col]!=null){continue;}\n  for(var r=-2;r<=2;r++){for(var c=-2;c<=2;c++){if(r==-2||r==2||c==-2||c==2||(r==0&&c==0)){this.modules[row+r][col+c]=true;}else{this.modules[row+r][col+c]=false;}}}}}},setupTypeNumber:function(test){var bits=QRUtil.getBCHTypeNumber(this.typeNumber);for(var i=0;i<18;i++){var mod=(!test&&((bits>>i)&1)==1);this.modules[Math.floor(i/3)][i%3+this.moduleCount-8-3]=mod;}\n  for(var i=0;i<18;i++){var mod=(!test&&((bits>>i)&1)==1);this.modules[i%3+this.moduleCount-8-3][Math.floor(i/3)]=mod;}},setupTypeInfo:function(test,maskPattern){var data=(this.errorCorrectLevel<<3)|maskPattern;var bits=QRUtil.getBCHTypeInfo(data);for(var i=0;i<15;i++){var mod=(!test&&((bits>>i)&1)==1);if(i<6){this.modules[i][8]=mod;}else if(i<8){this.modules[i+1][8]=mod;}else{this.modules[this.moduleCount-15+i][8]=mod;}}\n  for(var i=0;i<15;i++){var mod=(!test&&((bits>>i)&1)==1);if(i<8){this.modules[8][this.moduleCount-i-1]=mod;}else if(i<9){this.modules[8][15-i-1+1]=mod;}else{this.modules[8][15-i-1]=mod;}}\n  this.modules[this.moduleCount-8][8]=(!test);},mapData:function(data,maskPattern){var inc=-1;var row=this.moduleCount-1;var bitIndex=7;var byteIndex=0;for(var col=this.moduleCount-1;col>0;col-=2){if(col==6)col--;while(true){for(var c=0;c<2;c++){if(this.modules[row][col-c]==null){var dark=false;if(byteIndex<data.length){dark=(((data[byteIndex]>>>bitIndex)&1)==1);}\n  var mask=QRUtil.getMask(maskPattern,row,col-c);if(mask){dark=!dark;}\n  this.modules[row][col-c]=dark;bitIndex--;if(bitIndex==-1){byteIndex++;bitIndex=7;}}}\n  row+=inc;if(row<0||this.moduleCount<=row){row-=inc;inc=-inc;break;}}}}};QRCodeModel.PAD0=0xEC;QRCodeModel.PAD1=0x11;QRCodeModel.createData=function(typeNumber,errorCorrectLevel,dataList){var rsBlocks=QRRSBlock.getRSBlocks(typeNumber,errorCorrectLevel);var buffer=new QRBitBuffer();for(var i=0;i<dataList.length;i++){var data=dataList[i];buffer.put(data.mode,4);buffer.put(data.getLength(),QRUtil.getLengthInBits(data.mode,typeNumber));data.write(buffer);}\n  var totalDataCount=0;for(var i=0;i<rsBlocks.length;i++){totalDataCount+=rsBlocks[i].dataCount;}\n  if(buffer.getLengthInBits()>totalDataCount*8){throw new Error(\"code length overflow. (\"\n  +buffer.getLengthInBits()\n  +\">\"\n  +totalDataCount*8\n  +\")\");}\n  if(buffer.getLengthInBits()+4<=totalDataCount*8){buffer.put(0,4);}\n  while(buffer.getLengthInBits()%8!=0){buffer.putBit(false);}\n  while(true){if(buffer.getLengthInBits()>=totalDataCount*8){break;}\n  buffer.put(QRCodeModel.PAD0,8);if(buffer.getLengthInBits()>=totalDataCount*8){break;}\n  buffer.put(QRCodeModel.PAD1,8);}\n  return QRCodeModel.createBytes(buffer,rsBlocks);};QRCodeModel.createBytes=function(buffer,rsBlocks){var offset=0;var maxDcCount=0;var maxEcCount=0;var dcdata=new Array(rsBlocks.length);var ecdata=new Array(rsBlocks.length);for(var r=0;r<rsBlocks.length;r++){var dcCount=rsBlocks[r].dataCount;var ecCount=rsBlocks[r].totalCount-dcCount;maxDcCount=Math.max(maxDcCount,dcCount);maxEcCount=Math.max(maxEcCount,ecCount);dcdata[r]=new Array(dcCount);for(var i=0;i<dcdata[r].length;i++){dcdata[r][i]=0xff&buffer.buffer[i+offset];}\n  offset+=dcCount;var rsPoly=QRUtil.getErrorCorrectPolynomial(ecCount);var rawPoly=new QRPolynomial(dcdata[r],rsPoly.getLength()-1);var modPoly=rawPoly.mod(rsPoly);ecdata[r]=new Array(rsPoly.getLength()-1);for(var i=0;i<ecdata[r].length;i++){var modIndex=i+modPoly.getLength()-ecdata[r].length;ecdata[r][i]=(modIndex>=0)?modPoly.get(modIndex):0;}}\n  var totalCodeCount=0;for(var i=0;i<rsBlocks.length;i++){totalCodeCount+=rsBlocks[i].totalCount;}\n  var data=new Array(totalCodeCount);var index=0;for(var i=0;i<maxDcCount;i++){for(var r=0;r<rsBlocks.length;r++){if(i<dcdata[r].length){data[index++]=dcdata[r][i];}}}\n  for(var i=0;i<maxEcCount;i++){for(var r=0;r<rsBlocks.length;r++){if(i<ecdata[r].length){data[index++]=ecdata[r][i];}}}\n  return data;};var QRMode={MODE_NUMBER:1<<0,MODE_ALPHA_NUM:1<<1,MODE_8BIT_BYTE:1<<2,MODE_KANJI:1<<3};var QRErrorCorrectLevel={L:1,M:0,Q:3,H:2};var QRMaskPattern={PATTERN000:0,PATTERN001:1,PATTERN010:2,PATTERN011:3,PATTERN100:4,PATTERN101:5,PATTERN110:6,PATTERN111:7};var QRUtil={PATTERN_POSITION_TABLE:[[],[6,18],[6,22],[6,26],[6,30],[6,34],[6,22,38],[6,24,42],[6,26,46],[6,28,50],[6,30,54],[6,32,58],[6,34,62],[6,26,46,66],[6,26,48,70],[6,26,50,74],[6,30,54,78],[6,30,56,82],[6,30,58,86],[6,34,62,90],[6,28,50,72,94],[6,26,50,74,98],[6,30,54,78,102],[6,28,54,80,106],[6,32,58,84,110],[6,30,58,86,114],[6,34,62,90,118],[6,26,50,74,98,122],[6,30,54,78,102,126],[6,26,52,78,104,130],[6,30,56,82,108,134],[6,34,60,86,112,138],[6,30,58,86,114,142],[6,34,62,90,118,146],[6,30,54,78,102,126,150],[6,24,50,76,102,128,154],[6,28,54,80,106,132,158],[6,32,58,84,110,136,162],[6,26,54,82,110,138,166],[6,30,58,86,114,142,170]],G15:(1<<10)|(1<<8)|(1<<5)|(1<<4)|(1<<2)|(1<<1)|(1<<0),G18:(1<<12)|(1<<11)|(1<<10)|(1<<9)|(1<<8)|(1<<5)|(1<<2)|(1<<0),G15_MASK:(1<<14)|(1<<12)|(1<<10)|(1<<4)|(1<<1),getBCHTypeInfo:function(data){var d=data<<10;while(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G15)>=0){d^=(QRUtil.G15<<(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G15)));}\n  return((data<<10)|d)^QRUtil.G15_MASK;},getBCHTypeNumber:function(data){var d=data<<12;while(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G18)>=0){d^=(QRUtil.G18<<(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G18)));}\n  return(data<<12)|d;},getBCHDigit:function(data){var digit=0;while(data!=0){digit++;data>>>=1;}\n  return digit;},getPatternPosition:function(typeNumber){return QRUtil.PATTERN_POSITION_TABLE[typeNumber-1];},getMask:function(maskPattern,i,j){switch(maskPattern){case QRMaskPattern.PATTERN000:return(i+j)%2==0;case QRMaskPattern.PATTERN001:return i%2==0;case QRMaskPattern.PATTERN010:return j%3==0;case QRMaskPattern.PATTERN011:return(i+j)%3==0;case QRMaskPattern.PATTERN100:return(Math.floor(i/2)+Math.floor(j/3))%2==0;case QRMaskPattern.PATTERN101:return(i*j)%2+(i*j)%3==0;case QRMaskPattern.PATTERN110:return((i*j)%2+(i*j)%3)%2==0;case QRMaskPattern.PATTERN111:return((i*j)%3+(i+j)%2)%2==0;default:throw new Error(\"bad maskPattern:\"+maskPattern);}},getErrorCorrectPolynomial:function(errorCorrectLength){var a=new QRPolynomial([1],0);for(var i=0;i<errorCorrectLength;i++){a=a.multiply(new QRPolynomial([1,QRMath.gexp(i)],0));}\n  return a;},getLengthInBits:function(mode,type){if(1<=type&&type<10){switch(mode){case QRMode.MODE_NUMBER:return 10;case QRMode.MODE_ALPHA_NUM:return 9;case QRMode.MODE_8BIT_BYTE:return 8;case QRMode.MODE_KANJI:return 8;default:throw new Error(\"mode:\"+mode);}}else if(type<27){switch(mode){case QRMode.MODE_NUMBER:return 12;case QRMode.MODE_ALPHA_NUM:return 11;case QRMode.MODE_8BIT_BYTE:return 16;case QRMode.MODE_KANJI:return 10;default:throw new Error(\"mode:\"+mode);}}else if(type<41){switch(mode){case QRMode.MODE_NUMBER:return 14;case QRMode.MODE_ALPHA_NUM:return 13;case QRMode.MODE_8BIT_BYTE:return 16;case QRMode.MODE_KANJI:return 12;default:throw new Error(\"mode:\"+mode);}}else{throw new Error(\"type:\"+type);}},getLostPoint:function(qrCode){var moduleCount=qrCode.getModuleCount();var lostPoint=0;for(var row=0;row<moduleCount;row++){for(var col=0;col<moduleCount;col++){var sameCount=0;var dark=qrCode.isDark(row,col);for(var r=-1;r<=1;r++){if(row+r<0||moduleCount<=row+r){continue;}\n  for(var c=-1;c<=1;c++){if(col+c<0||moduleCount<=col+c){continue;}\n  if(r==0&&c==0){continue;}\n  if(dark==qrCode.isDark(row+r,col+c)){sameCount++;}}}\n  if(sameCount>5){lostPoint+=(3+sameCount-5);}}}\n  for(var row=0;row<moduleCount-1;row++){for(var col=0;col<moduleCount-1;col++){var count=0;if(qrCode.isDark(row,col))count++;if(qrCode.isDark(row+1,col))count++;if(qrCode.isDark(row,col+1))count++;if(qrCode.isDark(row+1,col+1))count++;if(count==0||count==4){lostPoint+=3;}}}\n  for(var row=0;row<moduleCount;row++){for(var col=0;col<moduleCount-6;col++){if(qrCode.isDark(row,col)&&!qrCode.isDark(row,col+1)&&qrCode.isDark(row,col+2)&&qrCode.isDark(row,col+3)&&qrCode.isDark(row,col+4)&&!qrCode.isDark(row,col+5)&&qrCode.isDark(row,col+6)){lostPoint+=40;}}}\n  for(var col=0;col<moduleCount;col++){for(var row=0;row<moduleCount-6;row++){if(qrCode.isDark(row,col)&&!qrCode.isDark(row+1,col)&&qrCode.isDark(row+2,col)&&qrCode.isDark(row+3,col)&&qrCode.isDark(row+4,col)&&!qrCode.isDark(row+5,col)&&qrCode.isDark(row+6,col)){lostPoint+=40;}}}\n  var darkCount=0;for(var col=0;col<moduleCount;col++){for(var row=0;row<moduleCount;row++){if(qrCode.isDark(row,col)){darkCount++;}}}\n  var ratio=Math.abs(100*darkCount/moduleCount/moduleCount-50)/5;lostPoint+=ratio*10;return lostPoint;}};var QRMath={glog:function(n){if(n<1){throw new Error(\"glog(\"+n+\")\");}\n  return QRMath.LOG_TABLE[n];},gexp:function(n){while(n<0){n+=255;}\n  while(n>=256){n-=255;}\n  return QRMath.EXP_TABLE[n];},EXP_TABLE:new Array(256),LOG_TABLE:new Array(256)};for(var i=0;i<8;i++){QRMath.EXP_TABLE[i]=1<<i;}\n  for(var i=8;i<256;i++){QRMath.EXP_TABLE[i]=QRMath.EXP_TABLE[i-4]^QRMath.EXP_TABLE[i-5]^QRMath.EXP_TABLE[i-6]^QRMath.EXP_TABLE[i-8];}\n  for(var i=0;i<255;i++){QRMath.LOG_TABLE[QRMath.EXP_TABLE[i]]=i;}\n  function QRPolynomial(num,shift){if(num.length==undefined){throw new Error(num.length+\"/\"+shift);}\n  var offset=0;while(offset<num.length&&num[offset]==0){offset++;}\n  this.num=new Array(num.length-offset+shift);for(var i=0;i<num.length-offset;i++){this.num[i]=num[i+offset];}}\n  QRPolynomial.prototype={get:function(index){return this.num[index];},getLength:function(){return this.num.length;},multiply:function(e){var num=new Array(this.getLength()+e.getLength()-1);for(var i=0;i<this.getLength();i++){for(var j=0;j<e.getLength();j++){num[i+j]^=QRMath.gexp(QRMath.glog(this.get(i))+QRMath.glog(e.get(j)));}}\n  return new QRPolynomial(num,0);},mod:function(e){if(this.getLength()-e.getLength()<0){return this;}\n  var ratio=QRMath.glog(this.get(0))-QRMath.glog(e.get(0));var num=new Array(this.getLength());for(var i=0;i<this.getLength();i++){num[i]=this.get(i);}\n  for(var i=0;i<e.getLength();i++){num[i]^=QRMath.gexp(QRMath.glog(e.get(i))+ratio);}\n  return new QRPolynomial(num,0).mod(e);}};function QRRSBlock(totalCount,dataCount){this.totalCount=totalCount;this.dataCount=dataCount;}\n  QRRSBlock.RS_BLOCK_TABLE=[[1,26,19],[1,26,16],[1,26,13],[1,26,9],[1,44,34],[1,44,28],[1,44,22],[1,44,16],[1,70,55],[1,70,44],[2,35,17],[2,35,13],[1,100,80],[2,50,32],[2,50,24],[4,25,9],[1,134,108],[2,67,43],[2,33,15,2,34,16],[2,33,11,2,34,12],[2,86,68],[4,43,27],[4,43,19],[4,43,15],[2,98,78],[4,49,31],[2,32,14,4,33,15],[4,39,13,1,40,14],[2,121,97],[2,60,38,2,61,39],[4,40,18,2,41,19],[4,40,14,2,41,15],[2,146,116],[3,58,36,2,59,37],[4,36,16,4,37,17],[4,36,12,4,37,13],[2,86,68,2,87,69],[4,69,43,1,70,44],[6,43,19,2,44,20],[6,43,15,2,44,16],[4,101,81],[1,80,50,4,81,51],[4,50,22,4,51,23],[3,36,12,8,37,13],[2,116,92,2,117,93],[6,58,36,2,59,37],[4,46,20,6,47,21],[7,42,14,4,43,15],[4,133,107],[8,59,37,1,60,38],[8,44,20,4,45,21],[12,33,11,4,34,12],[3,145,115,1,146,116],[4,64,40,5,65,41],[11,36,16,5,37,17],[11,36,12,5,37,13],[5,109,87,1,110,88],[5,65,41,5,66,42],[5,54,24,7,55,25],[11,36,12],[5,122,98,1,123,99],[7,73,45,3,74,46],[15,43,19,2,44,20],[3,45,15,13,46,16],[1,135,107,5,136,108],[10,74,46,1,75,47],[1,50,22,15,51,23],[2,42,14,17,43,15],[5,150,120,1,151,121],[9,69,43,4,70,44],[17,50,22,1,51,23],[2,42,14,19,43,15],[3,141,113,4,142,114],[3,70,44,11,71,45],[17,47,21,4,48,22],[9,39,13,16,40,14],[3,135,107,5,136,108],[3,67,41,13,68,42],[15,54,24,5,55,25],[15,43,15,10,44,16],[4,144,116,4,145,117],[17,68,42],[17,50,22,6,51,23],[19,46,16,6,47,17],[2,139,111,7,140,112],[17,74,46],[7,54,24,16,55,25],[34,37,13],[4,151,121,5,152,122],[4,75,47,14,76,48],[11,54,24,14,55,25],[16,45,15,14,46,16],[6,147,117,4,148,118],[6,73,45,14,74,46],[11,54,24,16,55,25],[30,46,16,2,47,17],[8,132,106,4,133,107],[8,75,47,13,76,48],[7,54,24,22,55,25],[22,45,15,13,46,16],[10,142,114,2,143,115],[19,74,46,4,75,47],[28,50,22,6,51,23],[33,46,16,4,47,17],[8,152,122,4,153,123],[22,73,45,3,74,46],[8,53,23,26,54,24],[12,45,15,28,46,16],[3,147,117,10,148,118],[3,73,45,23,74,46],[4,54,24,31,55,25],[11,45,15,31,46,16],[7,146,116,7,147,117],[21,73,45,7,74,46],[1,53,23,37,54,24],[19,45,15,26,46,16],[5,145,115,10,146,116],[19,75,47,10,76,48],[15,54,24,25,55,25],[23,45,15,25,46,16],[13,145,115,3,146,116],[2,74,46,29,75,47],[42,54,24,1,55,25],[23,45,15,28,46,16],[17,145,115],[10,74,46,23,75,47],[10,54,24,35,55,25],[19,45,15,35,46,16],[17,145,115,1,146,116],[14,74,46,21,75,47],[29,54,24,19,55,25],[11,45,15,46,46,16],[13,145,115,6,146,116],[14,74,46,23,75,47],[44,54,24,7,55,25],[59,46,16,1,47,17],[12,151,121,7,152,122],[12,75,47,26,76,48],[39,54,24,14,55,25],[22,45,15,41,46,16],[6,151,121,14,152,122],[6,75,47,34,76,48],[46,54,24,10,55,25],[2,45,15,64,46,16],[17,152,122,4,153,123],[29,74,46,14,75,47],[49,54,24,10,55,25],[24,45,15,46,46,16],[4,152,122,18,153,123],[13,74,46,32,75,47],[48,54,24,14,55,25],[42,45,15,32,46,16],[20,147,117,4,148,118],[40,75,47,7,76,48],[43,54,24,22,55,25],[10,45,15,67,46,16],[19,148,118,6,149,119],[18,75,47,31,76,48],[34,54,24,34,55,25],[20,45,15,61,46,16]];QRRSBlock.getRSBlocks=function(typeNumber,errorCorrectLevel){var rsBlock=QRRSBlock.getRsBlockTable(typeNumber,errorCorrectLevel);if(rsBlock==undefined){throw new Error(\"bad rs block @ typeNumber:\"+typeNumber+\"/errorCorrectLevel:\"+errorCorrectLevel);}\n  var length=rsBlock.length/3;var list=[];for(var i=0;i<length;i++){var count=rsBlock[i*3+0];var totalCount=rsBlock[i*3+1];var dataCount=rsBlock[i*3+2];for(var j=0;j<count;j++){list.push(new QRRSBlock(totalCount,dataCount));}}\n  return list;};QRRSBlock.getRsBlockTable=function(typeNumber,errorCorrectLevel){switch(errorCorrectLevel){case QRErrorCorrectLevel.L:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+0];case QRErrorCorrectLevel.M:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+1];case QRErrorCorrectLevel.Q:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+2];case QRErrorCorrectLevel.H:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+3];default:return undefined;}};function QRBitBuffer(){this.buffer=[];this.length=0;}\n  QRBitBuffer.prototype={get:function(index){var bufIndex=Math.floor(index/8);return((this.buffer[bufIndex]>>>(7-index%8))&1)==1;},put:function(num,length){for(var i=0;i<length;i++){this.putBit(((num>>>(length-i-1))&1)==1);}},getLengthInBits:function(){return this.length;},putBit:function(bit){var bufIndex=Math.floor(this.length/8);if(this.buffer.length<=bufIndex){this.buffer.push(0);}\n  if(bit){this.buffer[bufIndex]|=(0x80>>>(this.length%8));}\n  this.length++;}};var QRCodeLimitLength=[[17,14,11,7],[32,26,20,14],[53,42,32,24],[78,62,46,34],[106,84,60,44],[134,106,74,58],[154,122,86,64],[192,152,108,84],[230,180,130,98],[271,213,151,119],[321,251,177,137],[367,287,203,155],[425,331,241,177],[458,362,258,194],[520,412,292,220],[586,450,322,250],[644,504,364,280],[718,560,394,310],[792,624,442,338],[858,666,482,382],[929,711,509,403],[1003,779,565,439],[1091,857,611,461],[1171,911,661,511],[1273,997,715,535],[1367,1059,751,593],[1465,1125,805,625],[1528,1190,868,658],[1628,1264,908,698],[1732,1370,982,742],[1840,1452,1030,790],[1952,1538,1112,842],[2068,1628,1168,898],[2188,1722,1228,958],[2303,1809,1283,983],[2431,1911,1351,1051],[2563,1989,1423,1093],[2699,2099,1499,1139],[2809,2213,1579,1219],[2953,2331,1663,1273]];\n  \n  function _isSupportCanvas() {\n    return typeof CanvasRenderingContext2D != \"undefined\";\n  }\n  \n  // android 2.x doesn't support Data-URI spec\n  function _getAndroid() {\n    var android = false;\n    var sAgent = navigator.userAgent;\n    \n    if (/android/i.test(sAgent)) { // android\n      android = true;\n      var aMat = sAgent.toString().match(/android ([0-9]\\.[0-9])/i);\n      \n      if (aMat && aMat[1]) {\n        android = parseFloat(aMat[1]);\n      }\n    }\n    \n    return android;\n  }\n  \n  var svgDrawer = (function() {\n\n    var Drawing = function (el, htOption) {\n      this._el = el;\n      this._htOption = htOption;\n    };\n\n    Drawing.prototype.draw = function (oQRCode) {\n      var _htOption = this._htOption;\n      var _el = this._el;\n      var nCount = oQRCode.getModuleCount();\n      var nWidth = Math.floor(_htOption.width / nCount);\n      var nHeight = Math.floor(_htOption.height / nCount);\n\n      this.clear();\n\n      function makeSVG(tag, attrs) {\n        var el = document.createElementNS('http://www.w3.org/2000/svg', tag);\n        for (var k in attrs)\n          if (attrs.hasOwnProperty(k)) el.setAttribute(k, attrs[k]);\n        return el;\n      }\n\n      var svg = makeSVG(\"svg\" , {'viewBox': '0 0 ' + String(nCount) + \" \" + String(nCount), 'width': '100%', 'height': '100%', 'fill': _htOption.colorLight});\n      svg.setAttributeNS(\"http://www.w3.org/2000/xmlns/\", \"xmlns:xlink\", \"http://www.w3.org/1999/xlink\");\n      _el.appendChild(svg);\n\n      svg.appendChild(makeSVG(\"rect\", {\"fill\": _htOption.colorLight, \"width\": \"100%\", \"height\": \"100%\"}));\n      svg.appendChild(makeSVG(\"rect\", {\"fill\": _htOption.colorDark, \"width\": \"1\", \"height\": \"1\", \"id\": \"template\"}));\n\n      for (var row = 0; row < nCount; row++) {\n        for (var col = 0; col < nCount; col++) {\n          if (oQRCode.isDark(row, col)) {\n            var child = makeSVG(\"use\", {\"x\": String(col), \"y\": String(row)});\n            child.setAttributeNS(\"http://www.w3.org/1999/xlink\", \"href\", \"#template\")\n            svg.appendChild(child);\n          }\n        }\n      }\n    };\n    Drawing.prototype.clear = function () {\n      while (this._el.hasChildNodes())\n        this._el.removeChild(this._el.lastChild);\n    };\n    return Drawing;\n  })();\n\n  var useSVG = document.documentElement.tagName.toLowerCase() === \"svg\";\n\n  // Drawing in DOM by using Table tag\n  var Drawing = useSVG ? svgDrawer : !_isSupportCanvas() ? (function () {\n    var Drawing = function (el, htOption) {\n      this._el = el;\n      this._htOption = htOption;\n    };\n      \n    /**\n     * Draw the QRCode\n     * \n     * @param {QRCode} oQRCode\n     */\n    Drawing.prototype.draw = function (oQRCode) {\n            var _htOption = this._htOption;\n            var _el = this._el;\n      var nCount = oQRCode.getModuleCount();\n      var nWidth = Math.floor(_htOption.width / nCount);\n      var nHeight = Math.floor(_htOption.height / nCount);\n      var aHTML = ['<table style=\"border:0;border-collapse:collapse;\">'];\n      \n      for (var row = 0; row < nCount; row++) {\n        aHTML.push('<tr>');\n        \n        for (var col = 0; col < nCount; col++) {\n          aHTML.push('<td style=\"border:0;border-collapse:collapse;padding:0;margin:0;width:' + nWidth + 'px;height:' + nHeight + 'px;background-color:' + (oQRCode.isDark(row, col) ? _htOption.colorDark : _htOption.colorLight) + ';\"></td>');\n        }\n        \n        aHTML.push('</tr>');\n      }\n      \n      aHTML.push('</table>');\n      _el.innerHTML = aHTML.join('');\n      \n      // Fix the margin values as real size.\n      var elTable = _el.childNodes[0];\n      var nLeftMarginTable = (_htOption.width - elTable.offsetWidth) / 2;\n      var nTopMarginTable = (_htOption.height - elTable.offsetHeight) / 2;\n      \n      if (nLeftMarginTable > 0 && nTopMarginTable > 0) {\n        elTable.style.margin = nTopMarginTable + \"px \" + nLeftMarginTable + \"px\"; \n      }\n    };\n    \n    /**\n     * Clear the QRCode\n     */\n    Drawing.prototype.clear = function () {\n      this._el.innerHTML = '';\n    };\n    \n    return Drawing;\n  })() : (function () { // Drawing in Canvas\n    function _onMakeImage() {\n      this._elImage.src = this._elCanvas.toDataURL(\"image/png\");\n      this._elImage.style.display = \"block\";\n      this._elCanvas.style.display = \"none\";      \n    }\n    \n    // Android 2.1 bug workaround\n    // http://code.google.com/p/android/issues/detail?id=5141\n    if (this && this._android && this._android <= 2.1) {\n        var factor = 1 / window.devicePixelRatio;\n          var drawImage = CanvasRenderingContext2D.prototype.drawImage; \n        CanvasRenderingContext2D.prototype.drawImage = function (image, sx, sy, sw, sh, dx, dy, dw, dh) {\n          if ((\"nodeName\" in image) && /img/i.test(image.nodeName)) {\n              for (var i = arguments.length - 1; i >= 1; i--) {\n                  arguments[i] = arguments[i] * factor;\n              }\n          } else if (typeof dw == \"undefined\") {\n            arguments[1] *= factor;\n            arguments[2] *= factor;\n            arguments[3] *= factor;\n            arguments[4] *= factor;\n          }\n          \n            drawImage.apply(this, arguments); \n        };\n    }\n    \n    /**\n     * Check whether the user's browser supports Data URI or not\n     * \n     * @private\n     * @param {Function} fSuccess Occurs if it supports Data URI\n     * @param {Function} fFail Occurs if it doesn't support Data URI\n     */\n    function _safeSetDataURI(fSuccess, fFail) {\n            var self = this;\n            self._fFail = fFail;\n            self._fSuccess = fSuccess;\n\n            // Check it just once\n            if (self._bSupportDataURI === null) {\n                var el = document.createElement(\"img\");\n                var fOnError = function() {\n                    self._bSupportDataURI = false;\n\n                    if (self._fFail) {\n                        self._fFail.call(self);\n                    }\n                };\n                var fOnSuccess = function() {\n                    self._bSupportDataURI = true;\n\n                    if (self._fSuccess) {\n                        self._fSuccess.call(self);\n                    }\n                };\n\n                el.onabort = fOnError;\n                el.onerror = fOnError;\n                el.onload = fOnSuccess;\n                el.src = \"data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==\"; // the Image contains 1px data.\n                return;\n            } else if (self._bSupportDataURI === true && self._fSuccess) {\n                self._fSuccess.call(self);\n            } else if (self._bSupportDataURI === false && self._fFail) {\n                self._fFail.call(self);\n            }\n    };\n    \n    /**\n     * Drawing QRCode by using canvas\n     * \n     * @constructor\n     * @param {HTMLElement} el\n     * @param {Object} htOption QRCode Options \n     */\n    var Drawing = function (el, htOption) {\n        this._bIsPainted = false;\n        this._android = _getAndroid();\n    \n      this._htOption = htOption;\n      this._elCanvas = document.createElement(\"canvas\");\n      this._elCanvas.width = htOption.width;\n      this._elCanvas.height = htOption.height;\n      el.appendChild(this._elCanvas);\n      this._el = el;\n      this._oContext = this._elCanvas.getContext(\"2d\");\n      this._bIsPainted = false;\n      this._elImage = document.createElement(\"img\");\n      this._elImage.alt = \"Scan me!\";\n      this._elImage.style.display = \"none\";\n      this._el.appendChild(this._elImage);\n      this._bSupportDataURI = null;\n    };\n      \n    /**\n     * Draw the QRCode\n     * \n     * @param {QRCode} oQRCode \n     */\n    Drawing.prototype.draw = function (oQRCode) {\n            var _elImage = this._elImage;\n            var _oContext = this._oContext;\n            var _htOption = this._htOption;\n            \n      var nCount = oQRCode.getModuleCount();\n      var nWidth = _htOption.width / nCount;\n      var nHeight = _htOption.height / nCount;\n      var nRoundedWidth = Math.round(nWidth);\n      var nRoundedHeight = Math.round(nHeight);\n\n      _elImage.style.display = \"none\";\n      this.clear();\n      \n      for (var row = 0; row < nCount; row++) {\n        for (var col = 0; col < nCount; col++) {\n          var bIsDark = oQRCode.isDark(row, col);\n          var nLeft = col * nWidth;\n          var nTop = row * nHeight;\n          _oContext.strokeStyle = bIsDark ? _htOption.colorDark : _htOption.colorLight;\n          _oContext.lineWidth = 1;\n          _oContext.fillStyle = bIsDark ? _htOption.colorDark : _htOption.colorLight;         \n          _oContext.fillRect(nLeft, nTop, nWidth, nHeight);\n          \n          // 안티 앨리어싱 방지 처리\n          _oContext.strokeRect(\n            Math.floor(nLeft) + 0.5,\n            Math.floor(nTop) + 0.5,\n            nRoundedWidth,\n            nRoundedHeight\n          );\n          \n          _oContext.strokeRect(\n            Math.ceil(nLeft) - 0.5,\n            Math.ceil(nTop) - 0.5,\n            nRoundedWidth,\n            nRoundedHeight\n          );\n        }\n      }\n      \n      this._bIsPainted = true;\n    };\n      \n    /**\n     * Make the image from Canvas if the browser supports Data URI.\n     */\n    Drawing.prototype.makeImage = function () {\n      if (this._bIsPainted) {\n        _safeSetDataURI.call(this, _onMakeImage);\n      }\n    };\n      \n    /**\n     * Return whether the QRCode is painted or not\n     * \n     * @return {Boolean}\n     */\n    Drawing.prototype.isPainted = function () {\n      return this._bIsPainted;\n    };\n    \n    /**\n     * Clear the QRCode\n     */\n    Drawing.prototype.clear = function () {\n      this._oContext.clearRect(0, 0, this._elCanvas.width, this._elCanvas.height);\n      this._bIsPainted = false;\n    };\n    \n    /**\n     * @private\n     * @param {Number} nNumber\n     */\n    Drawing.prototype.round = function (nNumber) {\n      if (!nNumber) {\n        return nNumber;\n      }\n      \n      return Math.floor(nNumber * 1000) / 1000;\n    };\n    \n    return Drawing;\n  })();\n  \n  /**\n   * Get the type by string length\n   * \n   * @private\n   * @param {String} sText\n   * @param {Number} nCorrectLevel\n   * @return {Number} type\n   */\n  function _getTypeNumber(sText, nCorrectLevel) {     \n    var nType = 1;\n    var length = _getUTF8Length(sText);\n    \n    for (var i = 0, len = QRCodeLimitLength.length; i <= len; i++) {\n      var nLimit = 0;\n      \n      switch (nCorrectLevel) {\n        case QRErrorCorrectLevel.L :\n          nLimit = QRCodeLimitLength[i][0];\n          break;\n        case QRErrorCorrectLevel.M :\n          nLimit = QRCodeLimitLength[i][1];\n          break;\n        case QRErrorCorrectLevel.Q :\n          nLimit = QRCodeLimitLength[i][2];\n          break;\n        case QRErrorCorrectLevel.H :\n          nLimit = QRCodeLimitLength[i][3];\n          break;\n      }\n      \n      if (length <= nLimit) {\n        break;\n      } else {\n        nType++;\n      }\n    }\n    \n    if (nType > QRCodeLimitLength.length) {\n      throw new Error(\"Too long data\");\n    }\n    \n    return nType;\n  }\n\n  function _getUTF8Length(sText) {\n    var replacedText = encodeURI(sText).toString().replace(/\\%[0-9a-fA-F]{2}/g, 'a');\n    return replacedText.length + (replacedText.length != sText ? 3 : 0);\n  }\n  \n  /**\n   * @class QRCode\n   * @constructor\n   * @example \n   * new QRCode(document.getElementById(\"test\"), \"http://jindo.dev.naver.com/collie\");\n   *\n   * @example\n   * var oQRCode = new QRCode(\"test\", {\n   *    text : \"http://naver.com\",\n   *    width : 128,\n   *    height : 128\n   * });\n   * \n   * oQRCode.clear(); // Clear the QRCode.\n   * oQRCode.makeCode(\"http://map.naver.com\"); // Re-create the QRCode.\n   *\n   * @param {HTMLElement|String} el target element or 'id' attribute of element.\n   * @param {Object|String} vOption\n   * @param {String} vOption.text QRCode link data\n   * @param {Number} [vOption.width=256]\n   * @param {Number} [vOption.height=256]\n   * @param {String} [vOption.colorDark=\"#000000\"]\n   * @param {String} [vOption.colorLight=\"#ffffff\"]\n   * @param {QRCode.CorrectLevel} [vOption.correctLevel=QRCode.CorrectLevel.H] [L|M|Q|H] \n   */\n  QRCode = function (el, vOption) {\n    this._htOption = {\n      width : 256, \n      height : 256,\n      typeNumber : 4,\n      colorDark : \"#000000\",\n      colorLight : \"#ffffff\",\n      correctLevel : QRErrorCorrectLevel.H\n    };\n    \n    if (typeof vOption === 'string') {\n      vOption = {\n        text : vOption\n      };\n    }\n    \n    // Overwrites options\n    if (vOption) {\n      for (var i in vOption) {\n        this._htOption[i] = vOption[i];\n      }\n    }\n    \n    if (typeof el == \"string\") {\n      el = document.getElementById(el);\n    }\n\n    if (this._htOption.useSVG) {\n      Drawing = svgDrawer;\n    }\n    \n    this._android = _getAndroid();\n    this._el = el;\n    this._oQRCode = null;\n    this._oDrawing = new Drawing(this._el, this._htOption);\n    \n    if (this._htOption.text) {\n      this.makeCode(this._htOption.text); \n    }\n  };\n  \n  /**\n   * Make the QRCode\n   * \n   * @param {String} sText link data\n   */\n  QRCode.prototype.makeCode = function (sText) {\n    this._oQRCode = new QRCodeModel(_getTypeNumber(sText, this._htOption.correctLevel), this._htOption.correctLevel);\n    this._oQRCode.addData(sText);\n    this._oQRCode.make();\n    this._el.title = sText;\n    this._oDrawing.draw(this._oQRCode);     \n    this.makeImage();\n  };\n  \n  /**\n   * Make the Image from Canvas element\n   * - It occurs automatically\n   * - Android below 3 doesn't support Data-URI spec.\n   * \n   * @private\n   *//*\n  Adapted from qr-code.js by David Shim. \n  \n  This just puts the QR code into a bare HTMLElement\n  \n\n*/\n\nclass QRCodeContainer extends HTMLElement {\n  connectedCallback(){\n\n    const qrtext = this.getAttribute('value')\n    let value = window.location.origin\n    if(qrtext !== null){\n      value = ''\n      value = qrtext\n    }\n\n    if(value.length > 1024){\n      this.innerHTML('Value is too long to display')\n      return\n    }\n\n    const new_qr_code = this.qr_code_container = document.createElement('div')\n    this.style.backgroundColor = 'white'\n    this.style.contentFit = 'to-size'\n    this.style.padding = '1em'\n    this.style.display = 'inline-block'\n    this.style.width = 'fit-content'\n    this.style.height = 'fit-content'\n\n    this.qr_code = new QRCode(this, {\n      text: value,\n      width: 512,\n      height: 512,\n      colorDark : '#000000',\n      colorLight : '#FFFFFF',\n      correctLevel : QRCode.CorrectLevel.H\n    })\n\n    this.appendChild(new_qr_code)\n\n    this.qr_link = document.createElement('a')\n    this.qr_link.setAttribute('href', value)\n    this.qr_link.setAttribute('target', '_blank')\n    this.qr_link.innerText = 'link'\n\n    this.appendChild(this.qr_link)\n  }\n\n  attributeChangedCallback(name, oldValue, newValue) {\n    if(this.error){\n      this.error.remove()\n    }\n\n    if(newValue.length > 2048){\n      this.error = document.createElement('error')\n      if(this.qr_code_container) this.qr_code_container.style.display = \"none\"\n\n      this.error.innerHTML = 'Value is too long to display as a QR Code.'\n      this.appendChild(this.error)\n      return\n    }\n\n\n    if(this.qr_code_container) this.qr_code_container.style.display = 'block'\n    if(this.qr_code) this.qr_code.makeCode(newValue)\n    if(this.qr_link) this.qr_link.setAttribute('href', newValue)\n  }\n\n  disconnectedCallback() {\n    console.log('Custom square element removed from page.');\n  }\n\n  adoptedCallback() {\n    console.log('Custom square element moved to new page.');\n  }\n\n  static get observedAttributes() { \n    return ['value']\n  }\n\n}\n\ncustomElements.define('qr-code', QRCodeContainer)\n\n\n\n\n/**\n * @fileoverview\n * - Using the 'QRCode for Javascript library'\n * - Fixed dataset of 'QRCode for Javascript library' for support full-spec.\n * - this library has no dependencies.\n * \n * @author davidshimjs\n * @see <a href=\"http://www.d-project.com/\" target=\"_blank\">http://www.d-project.com/</a>\n * @see <a href=\"http://jeromeetienne.github.com/jquery-qrcode/\" target=\"_blank\">http://jeromeetienne.github.com/jquery-qrcode/</a>\n */\nvar QRCode;\n\n(function () {\n  //---------------------------------------------------------------------\n  // QRCode for JavaScript\n  //\n  // Copyright (c) 2009 Kazuhiko Arase\n  //\n  // URL: http://www.d-project.com/\n  //\n  // Licensed under the MIT license:\n  //   http://www.opensource.org/licenses/mit-license.php\n  //\n  // The word \"QR Code\" is registered trademark of \n  // DENSO WAVE INCORPORATED\n  //   http://www.denso-wave.com/qrcode/faqpatent-e.html\n  //\n  //---------------------------------------------------------------------\n  function QR8bitByte(data) {\n    this.mode = QRMode.MODE_8BIT_BYTE;\n    this.data = data;\n    this.parsedData = [];\n\n    // Added to support UTF-8 Characters\n    for (var i = 0, l = this.data.length; i < l; i++) {\n      var byteArray = [];\n      var code = this.data.charCodeAt(i);\n\n      if (code > 0x10000) {\n        byteArray[0] = 0xF0 | ((code & 0x1C0000) >>> 18);\n        byteArray[1] = 0x80 | ((code & 0x3F000) >>> 12);\n        byteArray[2] = 0x80 | ((code & 0xFC0) >>> 6);\n        byteArray[3] = 0x80 | (code & 0x3F);\n      } else if (code > 0x800) {\n        byteArray[0] = 0xE0 | ((code & 0xF000) >>> 12);\n        byteArray[1] = 0x80 | ((code & 0xFC0) >>> 6);\n        byteArray[2] = 0x80 | (code & 0x3F);\n      } else if (code > 0x80) {\n        byteArray[0] = 0xC0 | ((code & 0x7C0) >>> 6);\n        byteArray[1] = 0x80 | (code & 0x3F);\n      } else {\n        byteArray[0] = code;\n      }\n\n      this.parsedData.push(byteArray);\n    }\n\n    this.parsedData = Array.prototype.concat.apply([], this.parsedData);\n\n    if (this.parsedData.length != this.data.length) {\n      this.parsedData.unshift(191);\n      this.parsedData.unshift(187);\n      this.parsedData.unshift(239);\n    }\n  }\n\n  QR8bitByte.prototype = {\n    getLength: function (buffer) {\n      return this.parsedData.length;\n    },\n    write: function (buffer) {\n      for (var i = 0, l = this.parsedData.length; i < l; i++) {\n        buffer.put(this.parsedData[i], 8);\n      }\n    }\n  };\n\n  function QRCodeModel(typeNumber, errorCorrectLevel) {\n    this.typeNumber = typeNumber;\n    this.errorCorrectLevel = errorCorrectLevel;\n    this.modules = null;\n    this.moduleCount = 0;\n    this.dataCache = null;\n    this.dataList = [];\n  }\n\n  QRCodeModel.prototype={addData:function(data){var newData=new QR8bitByte(data);this.dataList.push(newData);this.dataCache=null;},isDark:function(row,col){if(row<0||this.moduleCount<=row||col<0||this.moduleCount<=col){throw new Error(row+\",\"+col);}\n  return this.modules[row][col];},getModuleCount:function(){return this.moduleCount;},make:function(){this.makeImpl(false,this.getBestMaskPattern());},makeImpl:function(test,maskPattern){this.moduleCount=this.typeNumber*4+17;this.modules=new Array(this.moduleCount);for(var row=0;row<this.moduleCount;row++){this.modules[row]=new Array(this.moduleCount);for(var col=0;col<this.moduleCount;col++){this.modules[row][col]=null;}}\n  this.setupPositionProbePattern(0,0);this.setupPositionProbePattern(this.moduleCount-7,0);this.setupPositionProbePattern(0,this.moduleCount-7);this.setupPositionAdjustPattern();this.setupTimingPattern();this.setupTypeInfo(test,maskPattern);if(this.typeNumber>=7){this.setupTypeNumber(test);}\n  if(this.dataCache==null){this.dataCache=QRCodeModel.createData(this.typeNumber,this.errorCorrectLevel,this.dataList);}\n  this.mapData(this.dataCache,maskPattern);},setupPositionProbePattern:function(row,col){for(var r=-1;r<=7;r++){if(row+r<=-1||this.moduleCount<=row+r)continue;for(var c=-1;c<=7;c++){if(col+c<=-1||this.moduleCount<=col+c)continue;if((0<=r&&r<=6&&(c==0||c==6))||(0<=c&&c<=6&&(r==0||r==6))||(2<=r&&r<=4&&2<=c&&c<=4)){this.modules[row+r][col+c]=true;}else{this.modules[row+r][col+c]=false;}}}},getBestMaskPattern:function(){var minLostPoint=0;var pattern=0;for(var i=0;i<8;i++){this.makeImpl(true,i);var lostPoint=QRUtil.getLostPoint(this);if(i==0||minLostPoint>lostPoint){minLostPoint=lostPoint;pattern=i;}}\n  return pattern;},createMovieClip:function(target_mc,instance_name,depth){var qr_mc=target_mc.createEmptyMovieClip(instance_name,depth);var cs=1;this.make();for(var row=0;row<this.modules.length;row++){var y=row*cs;for(var col=0;col<this.modules[row].length;col++){var x=col*cs;var dark=this.modules[row][col];if(dark){qr_mc.beginFill(0,100);qr_mc.moveTo(x,y);qr_mc.lineTo(x+cs,y);qr_mc.lineTo(x+cs,y+cs);qr_mc.lineTo(x,y+cs);qr_mc.endFill();}}}\n  return qr_mc;},setupTimingPattern:function(){for(var r=8;r<this.moduleCount-8;r++){if(this.modules[r][6]!=null){continue;}\n  this.modules[r][6]=(r%2==0);}\n  for(var c=8;c<this.moduleCount-8;c++){if(this.modules[6][c]!=null){continue;}\n  this.modules[6][c]=(c%2==0);}},setupPositionAdjustPattern:function(){var pos=QRUtil.getPatternPosition(this.typeNumber);for(var i=0;i<pos.length;i++){for(var j=0;j<pos.length;j++){var row=pos[i];var col=pos[j];if(this.modules[row][col]!=null){continue;}\n  for(var r=-2;r<=2;r++){for(var c=-2;c<=2;c++){if(r==-2||r==2||c==-2||c==2||(r==0&&c==0)){this.modules[row+r][col+c]=true;}else{this.modules[row+r][col+c]=false;}}}}}},setupTypeNumber:function(test){var bits=QRUtil.getBCHTypeNumber(this.typeNumber);for(var i=0;i<18;i++){var mod=(!test&&((bits>>i)&1)==1);this.modules[Math.floor(i/3)][i%3+this.moduleCount-8-3]=mod;}\n  for(var i=0;i<18;i++){var mod=(!test&&((bits>>i)&1)==1);this.modules[i%3+this.moduleCount-8-3][Math.floor(i/3)]=mod;}},setupTypeInfo:function(test,maskPattern){var data=(this.errorCorrectLevel<<3)|maskPattern;var bits=QRUtil.getBCHTypeInfo(data);for(var i=0;i<15;i++){var mod=(!test&&((bits>>i)&1)==1);if(i<6){this.modules[i][8]=mod;}else if(i<8){this.modules[i+1][8]=mod;}else{this.modules[this.moduleCount-15+i][8]=mod;}}\n  for(var i=0;i<15;i++){var mod=(!test&&((bits>>i)&1)==1);if(i<8){this.modules[8][this.moduleCount-i-1]=mod;}else if(i<9){this.modules[8][15-i-1+1]=mod;}else{this.modules[8][15-i-1]=mod;}}\n  this.modules[this.moduleCount-8][8]=(!test);},mapData:function(data,maskPattern){var inc=-1;var row=this.moduleCount-1;var bitIndex=7;var byteIndex=0;for(var col=this.moduleCount-1;col>0;col-=2){if(col==6)col--;while(true){for(var c=0;c<2;c++){if(this.modules[row][col-c]==null){var dark=false;if(byteIndex<data.length){dark=(((data[byteIndex]>>>bitIndex)&1)==1);}\n  var mask=QRUtil.getMask(maskPattern,row,col-c);if(mask){dark=!dark;}\n  this.modules[row][col-c]=dark;bitIndex--;if(bitIndex==-1){byteIndex++;bitIndex=7;}}}\n  row+=inc;if(row<0||this.moduleCount<=row){row-=inc;inc=-inc;break;}}}}};QRCodeModel.PAD0=0xEC;QRCodeModel.PAD1=0x11;QRCodeModel.createData=function(typeNumber,errorCorrectLevel,dataList){var rsBlocks=QRRSBlock.getRSBlocks(typeNumber,errorCorrectLevel);var buffer=new QRBitBuffer();for(var i=0;i<dataList.length;i++){var data=dataList[i];buffer.put(data.mode,4);buffer.put(data.getLength(),QRUtil.getLengthInBits(data.mode,typeNumber));data.write(buffer);}\n  var totalDataCount=0;for(var i=0;i<rsBlocks.length;i++){totalDataCount+=rsBlocks[i].dataCount;}\n  if(buffer.getLengthInBits()>totalDataCount*8){throw new Error(\"code length overflow. (\"\n  +buffer.getLengthInBits()\n  +\">\"\n  +totalDataCount*8\n  +\")\");}\n  if(buffer.getLengthInBits()+4<=totalDataCount*8){buffer.put(0,4);}\n  while(buffer.getLengthInBits()%8!=0){buffer.putBit(false);}\n  while(true){if(buffer.getLengthInBits()>=totalDataCount*8){break;}\n  buffer.put(QRCodeModel.PAD0,8);if(buffer.getLengthInBits()>=totalDataCount*8){break;}\n  buffer.put(QRCodeModel.PAD1,8);}\n  return QRCodeModel.createBytes(buffer,rsBlocks);};QRCodeModel.createBytes=function(buffer,rsBlocks){var offset=0;var maxDcCount=0;var maxEcCount=0;var dcdata=new Array(rsBlocks.length);var ecdata=new Array(rsBlocks.length);for(var r=0;r<rsBlocks.length;r++){var dcCount=rsBlocks[r].dataCount;var ecCount=rsBlocks[r].totalCount-dcCount;maxDcCount=Math.max(maxDcCount,dcCount);maxEcCount=Math.max(maxEcCount,ecCount);dcdata[r]=new Array(dcCount);for(var i=0;i<dcdata[r].length;i++){dcdata[r][i]=0xff&buffer.buffer[i+offset];}\n  offset+=dcCount;var rsPoly=QRUtil.getErrorCorrectPolynomial(ecCount);var rawPoly=new QRPolynomial(dcdata[r],rsPoly.getLength()-1);var modPoly=rawPoly.mod(rsPoly);ecdata[r]=new Array(rsPoly.getLength()-1);for(var i=0;i<ecdata[r].length;i++){var modIndex=i+modPoly.getLength()-ecdata[r].length;ecdata[r][i]=(modIndex>=0)?modPoly.get(modIndex):0;}}\n  var totalCodeCount=0;for(var i=0;i<rsBlocks.length;i++){totalCodeCount+=rsBlocks[i].totalCount;}\n  var data=new Array(totalCodeCount);var index=0;for(var i=0;i<maxDcCount;i++){for(var r=0;r<rsBlocks.length;r++){if(i<dcdata[r].length){data[index++]=dcdata[r][i];}}}\n  for(var i=0;i<maxEcCount;i++){for(var r=0;r<rsBlocks.length;r++){if(i<ecdata[r].length){data[index++]=ecdata[r][i];}}}\n  return data;};var QRMode={MODE_NUMBER:1<<0,MODE_ALPHA_NUM:1<<1,MODE_8BIT_BYTE:1<<2,MODE_KANJI:1<<3};var QRErrorCorrectLevel={L:1,M:0,Q:3,H:2};var QRMaskPattern={PATTERN000:0,PATTERN001:1,PATTERN010:2,PATTERN011:3,PATTERN100:4,PATTERN101:5,PATTERN110:6,PATTERN111:7};var QRUtil={PATTERN_POSITION_TABLE:[[],[6,18],[6,22],[6,26],[6,30],[6,34],[6,22,38],[6,24,42],[6,26,46],[6,28,50],[6,30,54],[6,32,58],[6,34,62],[6,26,46,66],[6,26,48,70],[6,26,50,74],[6,30,54,78],[6,30,56,82],[6,30,58,86],[6,34,62,90],[6,28,50,72,94],[6,26,50,74,98],[6,30,54,78,102],[6,28,54,80,106],[6,32,58,84,110],[6,30,58,86,114],[6,34,62,90,118],[6,26,50,74,98,122],[6,30,54,78,102,126],[6,26,52,78,104,130],[6,30,56,82,108,134],[6,34,60,86,112,138],[6,30,58,86,114,142],[6,34,62,90,118,146],[6,30,54,78,102,126,150],[6,24,50,76,102,128,154],[6,28,54,80,106,132,158],[6,32,58,84,110,136,162],[6,26,54,82,110,138,166],[6,30,58,86,114,142,170]],G15:(1<<10)|(1<<8)|(1<<5)|(1<<4)|(1<<2)|(1<<1)|(1<<0),G18:(1<<12)|(1<<11)|(1<<10)|(1<<9)|(1<<8)|(1<<5)|(1<<2)|(1<<0),G15_MASK:(1<<14)|(1<<12)|(1<<10)|(1<<4)|(1<<1),getBCHTypeInfo:function(data){var d=data<<10;while(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G15)>=0){d^=(QRUtil.G15<<(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G15)));}\n  return((data<<10)|d)^QRUtil.G15_MASK;},getBCHTypeNumber:function(data){var d=data<<12;while(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G18)>=0){d^=(QRUtil.G18<<(QRUtil.getBCHDigit(d)-QRUtil.getBCHDigit(QRUtil.G18)));}\n  return(data<<12)|d;},getBCHDigit:function(data){var digit=0;while(data!=0){digit++;data>>>=1;}\n  return digit;},getPatternPosition:function(typeNumber){return QRUtil.PATTERN_POSITION_TABLE[typeNumber-1];},getMask:function(maskPattern,i,j){switch(maskPattern){case QRMaskPattern.PATTERN000:return(i+j)%2==0;case QRMaskPattern.PATTERN001:return i%2==0;case QRMaskPattern.PATTERN010:return j%3==0;case QRMaskPattern.PATTERN011:return(i+j)%3==0;case QRMaskPattern.PATTERN100:return(Math.floor(i/2)+Math.floor(j/3))%2==0;case QRMaskPattern.PATTERN101:return(i*j)%2+(i*j)%3==0;case QRMaskPattern.PATTERN110:return((i*j)%2+(i*j)%3)%2==0;case QRMaskPattern.PATTERN111:return((i*j)%3+(i+j)%2)%2==0;default:throw new Error(\"bad maskPattern:\"+maskPattern);}},getErrorCorrectPolynomial:function(errorCorrectLength){var a=new QRPolynomial([1],0);for(var i=0;i<errorCorrectLength;i++){a=a.multiply(new QRPolynomial([1,QRMath.gexp(i)],0));}\n  return a;},getLengthInBits:function(mode,type){if(1<=type&&type<10){switch(mode){case QRMode.MODE_NUMBER:return 10;case QRMode.MODE_ALPHA_NUM:return 9;case QRMode.MODE_8BIT_BYTE:return 8;case QRMode.MODE_KANJI:return 8;default:throw new Error(\"mode:\"+mode);}}else if(type<27){switch(mode){case QRMode.MODE_NUMBER:return 12;case QRMode.MODE_ALPHA_NUM:return 11;case QRMode.MODE_8BIT_BYTE:return 16;case QRMode.MODE_KANJI:return 10;default:throw new Error(\"mode:\"+mode);}}else if(type<41){switch(mode){case QRMode.MODE_NUMBER:return 14;case QRMode.MODE_ALPHA_NUM:return 13;case QRMode.MODE_8BIT_BYTE:return 16;case QRMode.MODE_KANJI:return 12;default:throw new Error(\"mode:\"+mode);}}else{throw new Error(\"type:\"+type);}},getLostPoint:function(qrCode){var moduleCount=qrCode.getModuleCount();var lostPoint=0;for(var row=0;row<moduleCount;row++){for(var col=0;col<moduleCount;col++){var sameCount=0;var dark=qrCode.isDark(row,col);for(var r=-1;r<=1;r++){if(row+r<0||moduleCount<=row+r){continue;}\n  for(var c=-1;c<=1;c++){if(col+c<0||moduleCount<=col+c){continue;}\n  if(r==0&&c==0){continue;}\n  if(dark==qrCode.isDark(row+r,col+c)){sameCount++;}}}\n  if(sameCount>5){lostPoint+=(3+sameCount-5);}}}\n  for(var row=0;row<moduleCount-1;row++){for(var col=0;col<moduleCount-1;col++){var count=0;if(qrCode.isDark(row,col))count++;if(qrCode.isDark(row+1,col))count++;if(qrCode.isDark(row,col+1))count++;if(qrCode.isDark(row+1,col+1))count++;if(count==0||count==4){lostPoint+=3;}}}\n  for(var row=0;row<moduleCount;row++){for(var col=0;col<moduleCount-6;col++){if(qrCode.isDark(row,col)&&!qrCode.isDark(row,col+1)&&qrCode.isDark(row,col+2)&&qrCode.isDark(row,col+3)&&qrCode.isDark(row,col+4)&&!qrCode.isDark(row,col+5)&&qrCode.isDark(row,col+6)){lostPoint+=40;}}}\n  for(var col=0;col<moduleCount;col++){for(var row=0;row<moduleCount-6;row++){if(qrCode.isDark(row,col)&&!qrCode.isDark(row+1,col)&&qrCode.isDark(row+2,col)&&qrCode.isDark(row+3,col)&&qrCode.isDark(row+4,col)&&!qrCode.isDark(row+5,col)&&qrCode.isDark(row+6,col)){lostPoint+=40;}}}\n  var darkCount=0;for(var col=0;col<moduleCount;col++){for(var row=0;row<moduleCount;row++){if(qrCode.isDark(row,col)){darkCount++;}}}\n  var ratio=Math.abs(100*darkCount/moduleCount/moduleCount-50)/5;lostPoint+=ratio*10;return lostPoint;}};var QRMath={glog:function(n){if(n<1){throw new Error(\"glog(\"+n+\")\");}\n  return QRMath.LOG_TABLE[n];},gexp:function(n){while(n<0){n+=255;}\n  while(n>=256){n-=255;}\n  return QRMath.EXP_TABLE[n];},EXP_TABLE:new Array(256),LOG_TABLE:new Array(256)};for(var i=0;i<8;i++){QRMath.EXP_TABLE[i]=1<<i;}\n  for(var i=8;i<256;i++){QRMath.EXP_TABLE[i]=QRMath.EXP_TABLE[i-4]^QRMath.EXP_TABLE[i-5]^QRMath.EXP_TABLE[i-6]^QRMath.EXP_TABLE[i-8];}\n  for(var i=0;i<255;i++){QRMath.LOG_TABLE[QRMath.EXP_TABLE[i]]=i;}\n  function QRPolynomial(num,shift){if(num.length==undefined){throw new Error(num.length+\"/\"+shift);}\n  var offset=0;while(offset<num.length&&num[offset]==0){offset++;}\n  this.num=new Array(num.length-offset+shift);for(var i=0;i<num.length-offset;i++){this.num[i]=num[i+offset];}}\n  QRPolynomial.prototype={get:function(index){return this.num[index];},getLength:function(){return this.num.length;},multiply:function(e){var num=new Array(this.getLength()+e.getLength()-1);for(var i=0;i<this.getLength();i++){for(var j=0;j<e.getLength();j++){num[i+j]^=QRMath.gexp(QRMath.glog(this.get(i))+QRMath.glog(e.get(j)));}}\n  return new QRPolynomial(num,0);},mod:function(e){if(this.getLength()-e.getLength()<0){return this;}\n  var ratio=QRMath.glog(this.get(0))-QRMath.glog(e.get(0));var num=new Array(this.getLength());for(var i=0;i<this.getLength();i++){num[i]=this.get(i);}\n  for(var i=0;i<e.getLength();i++){num[i]^=QRMath.gexp(QRMath.glog(e.get(i))+ratio);}\n  return new QRPolynomial(num,0).mod(e);}};function QRRSBlock(totalCount,dataCount){this.totalCount=totalCount;this.dataCount=dataCount;}\n  QRRSBlock.RS_BLOCK_TABLE=[[1,26,19],[1,26,16],[1,26,13],[1,26,9],[1,44,34],[1,44,28],[1,44,22],[1,44,16],[1,70,55],[1,70,44],[2,35,17],[2,35,13],[1,100,80],[2,50,32],[2,50,24],[4,25,9],[1,134,108],[2,67,43],[2,33,15,2,34,16],[2,33,11,2,34,12],[2,86,68],[4,43,27],[4,43,19],[4,43,15],[2,98,78],[4,49,31],[2,32,14,4,33,15],[4,39,13,1,40,14],[2,121,97],[2,60,38,2,61,39],[4,40,18,2,41,19],[4,40,14,2,41,15],[2,146,116],[3,58,36,2,59,37],[4,36,16,4,37,17],[4,36,12,4,37,13],[2,86,68,2,87,69],[4,69,43,1,70,44],[6,43,19,2,44,20],[6,43,15,2,44,16],[4,101,81],[1,80,50,4,81,51],[4,50,22,4,51,23],[3,36,12,8,37,13],[2,116,92,2,117,93],[6,58,36,2,59,37],[4,46,20,6,47,21],[7,42,14,4,43,15],[4,133,107],[8,59,37,1,60,38],[8,44,20,4,45,21],[12,33,11,4,34,12],[3,145,115,1,146,116],[4,64,40,5,65,41],[11,36,16,5,37,17],[11,36,12,5,37,13],[5,109,87,1,110,88],[5,65,41,5,66,42],[5,54,24,7,55,25],[11,36,12],[5,122,98,1,123,99],[7,73,45,3,74,46],[15,43,19,2,44,20],[3,45,15,13,46,16],[1,135,107,5,136,108],[10,74,46,1,75,47],[1,50,22,15,51,23],[2,42,14,17,43,15],[5,150,120,1,151,121],[9,69,43,4,70,44],[17,50,22,1,51,23],[2,42,14,19,43,15],[3,141,113,4,142,114],[3,70,44,11,71,45],[17,47,21,4,48,22],[9,39,13,16,40,14],[3,135,107,5,136,108],[3,67,41,13,68,42],[15,54,24,5,55,25],[15,43,15,10,44,16],[4,144,116,4,145,117],[17,68,42],[17,50,22,6,51,23],[19,46,16,6,47,17],[2,139,111,7,140,112],[17,74,46],[7,54,24,16,55,25],[34,37,13],[4,151,121,5,152,122],[4,75,47,14,76,48],[11,54,24,14,55,25],[16,45,15,14,46,16],[6,147,117,4,148,118],[6,73,45,14,74,46],[11,54,24,16,55,25],[30,46,16,2,47,17],[8,132,106,4,133,107],[8,75,47,13,76,48],[7,54,24,22,55,25],[22,45,15,13,46,16],[10,142,114,2,143,115],[19,74,46,4,75,47],[28,50,22,6,51,23],[33,46,16,4,47,17],[8,152,122,4,153,123],[22,73,45,3,74,46],[8,53,23,26,54,24],[12,45,15,28,46,16],[3,147,117,10,148,118],[3,73,45,23,74,46],[4,54,24,31,55,25],[11,45,15,31,46,16],[7,146,116,7,147,117],[21,73,45,7,74,46],[1,53,23,37,54,24],[19,45,15,26,46,16],[5,145,115,10,146,116],[19,75,47,10,76,48],[15,54,24,25,55,25],[23,45,15,25,46,16],[13,145,115,3,146,116],[2,74,46,29,75,47],[42,54,24,1,55,25],[23,45,15,28,46,16],[17,145,115],[10,74,46,23,75,47],[10,54,24,35,55,25],[19,45,15,35,46,16],[17,145,115,1,146,116],[14,74,46,21,75,47],[29,54,24,19,55,25],[11,45,15,46,46,16],[13,145,115,6,146,116],[14,74,46,23,75,47],[44,54,24,7,55,25],[59,46,16,1,47,17],[12,151,121,7,152,122],[12,75,47,26,76,48],[39,54,24,14,55,25],[22,45,15,41,46,16],[6,151,121,14,152,122],[6,75,47,34,76,48],[46,54,24,10,55,25],[2,45,15,64,46,16],[17,152,122,4,153,123],[29,74,46,14,75,47],[49,54,24,10,55,25],[24,45,15,46,46,16],[4,152,122,18,153,123],[13,74,46,32,75,47],[48,54,24,14,55,25],[42,45,15,32,46,16],[20,147,117,4,148,118],[40,75,47,7,76,48],[43,54,24,22,55,25],[10,45,15,67,46,16],[19,148,118,6,149,119],[18,75,47,31,76,48],[34,54,24,34,55,25],[20,45,15,61,46,16]];QRRSBlock.getRSBlocks=function(typeNumber,errorCorrectLevel){var rsBlock=QRRSBlock.getRsBlockTable(typeNumber,errorCorrectLevel);if(rsBlock==undefined){throw new Error(\"bad rs block @ typeNumber:\"+typeNumber+\"/errorCorrectLevel:\"+errorCorrectLevel);}\n  var length=rsBlock.length/3;var list=[];for(var i=0;i<length;i++){var count=rsBlock[i*3+0];var totalCount=rsBlock[i*3+1];var dataCount=rsBlock[i*3+2];for(var j=0;j<count;j++){list.push(new QRRSBlock(totalCount,dataCount));}}\n  return list;};QRRSBlock.getRsBlockTable=function(typeNumber,errorCorrectLevel){switch(errorCorrectLevel){case QRErrorCorrectLevel.L:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+0];case QRErrorCorrectLevel.M:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+1];case QRErrorCorrectLevel.Q:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+2];case QRErrorCorrectLevel.H:return QRRSBlock.RS_BLOCK_TABLE[(typeNumber-1)*4+3];default:return undefined;}};function QRBitBuffer(){this.buffer=[];this.length=0;}\n  QRBitBuffer.prototype={get:function(index){var bufIndex=Math.floor(index/8);return((this.buffer[bufIndex]>>>(7-index%8))&1)==1;},put:function(num,length){for(var i=0;i<length;i++){this.putBit(((num>>>(length-i-1))&1)==1);}},getLengthInBits:function(){return this.length;},putBit:function(bit){var bufIndex=Math.floor(this.length/8);if(this.buffer.length<=bufIndex){this.buffer.push(0);}\n  if(bit){this.buffer[bufIndex]|=(0x80>>>(this.length%8));}\n  this.length++;}};var QRCodeLimitLength=[[17,14,11,7],[32,26,20,14],[53,42,32,24],[78,62,46,34],[106,84,60,44],[134,106,74,58],[154,122,86,64],[192,152,108,84],[230,180,130,98],[271,213,151,119],[321,251,177,137],[367,287,203,155],[425,331,241,177],[458,362,258,194],[520,412,292,220],[586,450,322,250],[644,504,364,280],[718,560,394,310],[792,624,442,338],[858,666,482,382],[929,711,509,403],[1003,779,565,439],[1091,857,611,461],[1171,911,661,511],[1273,997,715,535],[1367,1059,751,593],[1465,1125,805,625],[1528,1190,868,658],[1628,1264,908,698],[1732,1370,982,742],[1840,1452,1030,790],[1952,1538,1112,842],[2068,1628,1168,898],[2188,1722,1228,958],[2303,1809,1283,983],[2431,1911,1351,1051],[2563,1989,1423,1093],[2699,2099,1499,1139],[2809,2213,1579,1219],[2953,2331,1663,1273]];\n  \n  function _isSupportCanvas() {\n    return typeof CanvasRenderingContext2D != \"undefined\";\n  }\n  \n  // android 2.x doesn't support Data-URI spec\n  function _getAndroid() {\n    var android = false;\n    var sAgent = navigator.userAgent;\n    \n    if (/android/i.test(sAgent)) { // android\n      android = true;\n      var aMat = sAgent.toString().match(/android ([0-9]\\.[0-9])/i);\n      \n      if (aMat && aMat[1]) {\n        android = parseFloat(aMat[1]);\n      }\n    }\n    \n    return android;\n  }\n  \n  var svgDrawer = (function() {\n\n    var Drawing = function (el, htOption) {\n      this._el = el;\n      this._htOption = htOption;\n    };\n\n    Drawing.prototype.draw = function (oQRCode) {\n      var _htOption = this._htOption;\n      var _el = this._el;\n      var nCount = oQRCode.getModuleCount();\n      var nWidth = Math.floor(_htOption.width / nCount);\n      var nHeight = Math.floor(_htOption.height / nCount);\n\n      this.clear();\n\n      function makeSVG(tag, attrs) {\n        var el = document.createElementNS('http://www.w3.org/2000/svg', tag);\n        for (var k in attrs)\n          if (attrs.hasOwnProperty(k)) el.setAttribute(k, attrs[k]);\n        return el;\n      }\n\n      var svg = makeSVG(\"svg\" , {'viewBox': '0 0 ' + String(nCount) + \" \" + String(nCount), 'width': '100%', 'height': '100%', 'fill': _htOption.colorLight});\n      svg.setAttributeNS(\"http://www.w3.org/2000/xmlns/\", \"xmlns:xlink\", \"http://www.w3.org/1999/xlink\");\n      _el.appendChild(svg);\n\n      svg.appendChild(makeSVG(\"rect\", {\"fill\": _htOption.colorLight, \"width\": \"100%\", \"height\": \"100%\"}));\n      svg.appendChild(makeSVG(\"rect\", {\"fill\": _htOption.colorDark, \"width\": \"1\", \"height\": \"1\", \"id\": \"template\"}));\n\n      for (var row = 0; row < nCount; row++) {\n        for (var col = 0; col < nCount; col++) {\n          if (oQRCode.isDark(row, col)) {\n            var child = makeSVG(\"use\", {\"x\": String(col), \"y\": String(row)});\n            child.setAttributeNS(\"http://www.w3.org/1999/xlink\", \"href\", \"#template\")\n            svg.appendChild(child);\n          }\n        }\n      }\n    };\n    Drawing.prototype.clear = function () {\n      while (this._el.hasChildNodes())\n        this._el.removeChild(this._el.lastChild);\n    };\n    return Drawing;\n  })();\n\n  var useSVG = document.documentElement.tagName.toLowerCase() === \"svg\";\n\n  // Drawing in DOM by using Table tag\n  var Drawing = useSVG ? svgDrawer : !_isSupportCanvas() ? (function () {\n    var Drawing = function (el, htOption) {\n      this._el = el;\n      this._htOption = htOption;\n    };\n      \n    /**\n     * Draw the QRCode\n     * \n     * @param {QRCode} oQRCode\n     */\n    Drawing.prototype.draw = function (oQRCode) {\n            var _htOption = this._htOption;\n            var _el = this._el;\n      var nCount = oQRCode.getModuleCount();\n      var nWidth = Math.floor(_htOption.width / nCount);\n      var nHeight = Math.floor(_htOption.height / nCount);\n      var aHTML = ['<table style=\"border:0;border-collapse:collapse;\">'];\n      \n      for (var row = 0; row < nCount; row++) {\n        aHTML.push('<tr>');\n        \n        for (var col = 0; col < nCount; col++) {\n          aHTML.push('<td style=\"border:0;border-collapse:collapse;padding:0;margin:0;width:' + nWidth + 'px;height:' + nHeight + 'px;background-color:' + (oQRCode.isDark(row, col) ? _htOption.colorDark : _htOption.colorLight) + ';\"></td>');\n        }\n        \n        aHTML.push('</tr>');\n      }\n      \n      aHTML.push('</table>');\n      _el.innerHTML = aHTML.join('');\n      \n      // Fix the margin values as real size.\n      var elTable = _el.childNodes[0];\n      var nLeftMarginTable = (_htOption.width - elTable.offsetWidth) / 2;\n      var nTopMarginTable = (_htOption.height - elTable.offsetHeight) / 2;\n      \n      if (nLeftMarginTable > 0 && nTopMarginTable > 0) {\n        elTable.style.margin = nTopMarginTable + \"px \" + nLeftMarginTable + \"px\"; \n      }\n    };\n    \n    /**\n     * Clear the QRCode\n     */\n    Drawing.prototype.clear = function () {\n      this._el.innerHTML = '';\n    };\n    \n    return Drawing;\n  })() : (function () { // Drawing in Canvas\n    function _onMakeImage() {\n      this._elImage.src = this._elCanvas.toDataURL(\"image/png\");\n      this._elImage.style.display = \"block\";\n      this._elCanvas.style.display = \"none\";      \n    }\n    \n    // Android 2.1 bug workaround\n    // http://code.google.com/p/android/issues/detail?id=5141\n    if (this && this._android && this._android <= 2.1) {\n        var factor = 1 / window.devicePixelRatio;\n          var drawImage = CanvasRenderingContext2D.prototype.drawImage; \n        CanvasRenderingContext2D.prototype.drawImage = function (image, sx, sy, sw, sh, dx, dy, dw, dh) {\n          if ((\"nodeName\" in image) && /img/i.test(image.nodeName)) {\n              for (var i = arguments.length - 1; i >= 1; i--) {\n                  arguments[i] = arguments[i] * factor;\n              }\n          } else if (typeof dw == \"undefined\") {\n            arguments[1] *= factor;\n            arguments[2] *= factor;\n            arguments[3] *= factor;\n            arguments[4] *= factor;\n          }\n          \n            drawImage.apply(this, arguments); \n        };\n    }\n    \n    /**\n     * Check whether the user's browser supports Data URI or not\n     * \n     * @private\n     * @param {Function} fSuccess Occurs if it supports Data URI\n     * @param {Function} fFail Occurs if it doesn't support Data URI\n     */\n    function _safeSetDataURI(fSuccess, fFail) {\n            var self = this;\n            self._fFail = fFail;\n            self._fSuccess = fSuccess;\n\n            // Check it just once\n            if (self._bSupportDataURI === null) {\n                var el = document.createElement(\"img\");\n                var fOnError = function() {\n                    self._bSupportDataURI = false;\n\n                    if (self._fFail) {\n                        self._fFail.call(self);\n                    }\n                };\n                var fOnSuccess = function() {\n                    self._bSupportDataURI = true;\n\n                    if (self._fSuccess) {\n                        self._fSuccess.call(self);\n                    }\n                };\n\n                el.onabort = fOnError;\n                el.onerror = fOnError;\n                el.onload = fOnSuccess;\n                el.src = \"data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==\"; // the Image contains 1px data.\n                return;\n            } else if (self._bSupportDataURI === true && self._fSuccess) {\n                self._fSuccess.call(self);\n            } else if (self._bSupportDataURI === false && self._fFail) {\n                self._fFail.call(self);\n            }\n    };\n    \n    /**\n     * Drawing QRCode by using canvas\n     * \n     * @constructor\n     * @param {HTMLElement} el\n     * @param {Object} htOption QRCode Options \n     */\n    var Drawing = function (el, htOption) {\n        this._bIsPainted = false;\n        this._android = _getAndroid();\n    \n      this._htOption = htOption;\n      this._elCanvas = document.createElement(\"canvas\");\n      this._elCanvas.width = htOption.width;\n      this._elCanvas.height = htOption.height;\n      el.appendChild(this._elCanvas);\n      this._el = el;\n      this._oContext = this._elCanvas.getContext(\"2d\");\n      this._bIsPainted = false;\n      this._elImage = document.createElement(\"img\");\n      this._elImage.alt = \"Scan me!\";\n      this._elImage.style.display = \"none\";\n      this._el.appendChild(this._elImage);\n      this._bSupportDataURI = null;\n    };\n      \n    /**\n     * Draw the QRCode\n     * \n     * @param {QRCode} oQRCode \n     */\n    Drawing.prototype.draw = function (oQRCode) {\n            var _elImage = this._elImage;\n            var _oContext = this._oContext;\n            var _htOption = this._htOption;\n            \n      var nCount = oQRCode.getModuleCount();\n      var nWidth = _htOption.width / nCount;\n      var nHeight = _htOption.height / nCount;\n      var nRoundedWidth = Math.round(nWidth);\n      var nRoundedHeight = Math.round(nHeight);\n\n      _elImage.style.display = \"none\";\n      this.clear();\n      \n      for (var row = 0; row < nCount; row++) {\n        for (var col = 0; col < nCount; col++) {\n          var bIsDark = oQRCode.isDark(row, col);\n          var nLeft = col * nWidth;\n          var nTop = row * nHeight;\n          _oContext.strokeStyle = bIsDark ? _htOption.colorDark : _htOption.colorLight;\n          _oContext.lineWidth = 1;\n          _oContext.fillStyle = bIsDark ? _htOption.colorDark : _htOption.colorLight;         \n          _oContext.fillRect(nLeft, nTop, nWidth, nHeight);\n          \n          // 안티 앨리어싱 방지 처리\n          _oContext.strokeRect(\n            Math.floor(nLeft) + 0.5,\n            Math.floor(nTop) + 0.5,\n            nRoundedWidth,\n            nRoundedHeight\n          );\n          \n          _oContext.strokeRect(\n            Math.ceil(nLeft) - 0.5,\n            Math.ceil(nTop) - 0.5,\n            nRoundedWidth,\n            nRoundedHeight\n          );\n        }\n      }\n      \n      this._bIsPainted = true;\n    };\n      \n    /**\n     * Make the image from Canvas if the browser supports Data URI.\n     */\n    Drawing.prototype.makeImage = function () {\n      if (this._bIsPainted) {\n        _safeSetDataURI.call(this, _onMakeImage);\n      }\n    };\n      \n    /**\n     * Return whether the QRCode is painted or not\n     * \n     * @return {Boolean}\n     */\n    Drawing.prototype.isPainted = function () {\n      return this._bIsPainted;\n    };\n    \n    /**\n     * Clear the QRCode\n     */\n    Drawing.prototype.clear = function () {\n      this._oContext.clearRect(0, 0, this._elCanvas.width, this._elCanvas.height);\n      this._bIsPainted = false;\n    };\n    \n    /**\n     * @private\n     * @param {Number} nNumber\n     */\n    Drawing.prototype.round = function (nNumber) {\n      if (!nNumber) {\n        return nNumber;\n      }\n      \n      return Math.floor(nNumber * 1000) / 1000;\n    };\n    \n    return Drawing;\n  })();\n  \n  /**\n   * Get the type by string length\n   * \n   * @private\n   * @param {String} sText\n   * @param {Number} nCorrectLevel\n   * @return {Number} type\n   */\n  function _getTypeNumber(sText, nCorrectLevel) {     \n    var nType = 1;\n    var length = _getUTF8Length(sText);\n    \n    for (var i = 0, len = QRCodeLimitLength.length; i <= len; i++) {\n      var nLimit = 0;\n      \n      switch (nCorrectLevel) {\n        case QRErrorCorrectLevel.L :\n          nLimit = QRCodeLimitLength[i][0];\n          break;\n        case QRErrorCorrectLevel.M :\n          nLimit = QRCodeLimitLength[i][1];\n          break;\n        case QRErrorCorrectLevel.Q :\n          nLimit = QRCodeLimitLength[i][2];\n          break;\n        case QRErrorCorrectLevel.H :\n          nLimit = QRCodeLimitLength[i][3];\n          break;\n      }\n      \n      if (length <= nLimit) {\n        break;\n      } else {\n        nType++;\n      }\n    }\n    \n    if (nType > QRCodeLimitLength.length) {\n      throw new Error(\"Too long data\");\n    }\n    \n    return nType;\n  }\n\n  function _getUTF8Length(sText) {\n    var replacedText = encodeURI(sText).toString().replace(/\\%[0-9a-fA-F]{2}/g, 'a');\n    return replacedText.length + (replacedText.length != sText ? 3 : 0);\n  }\n  \n  /**\n   * @class QRCode\n   * @constructor\n   * @example \n   * new QRCode(document.getElementById(\"test\"), \"http://jindo.dev.naver.com/collie\");\n   *\n   * @example\n   * var oQRCode = new QRCode(\"test\", {\n   *    text : \"http://naver.com\",\n   *    width : 128,\n   *    height : 128\n   * });\n   * \n   * oQRCode.clear(); // Clear the QRCode.\n   * oQRCode.makeCode(\"http://map.naver.com\"); // Re-create the QRCode.\n   *\n   * @param {HTMLElement|String} el target element or 'id' attribute of element.\n   * @param {Object|String} vOption\n   * @param {String} vOption.text QRCode link data\n   * @param {Number} [vOption.width=256]\n   * @param {Number} [vOption.height=256]\n   * @param {String} [vOption.colorDark=\"#000000\"]\n   * @param {String} [vOption.colorLight=\"#ffffff\"]\n   * @param {QRCode.CorrectLevel} [vOption.correctLevel=QRCode.CorrectLevel.H] [L|M|Q|H] \n   */\n  QRCode = function (el, vOption) {\n    this._htOption = {\n      width : 256, \n      height : 256,\n      typeNumber : 4,\n      colorDark : \"#000000\",\n      colorLight : \"#ffffff\",\n      correctLevel : QRErrorCorrectLevel.H\n    };\n    \n    if (typeof vOption === 'string') {\n      vOption = {\n        text : vOption\n      };\n    }\n    \n    // Overwrites options\n    if (vOption) {\n      for (var i in vOption) {\n        this._htOption[i] = vOption[i];\n      }\n    }\n    \n    if (typeof el == \"string\") {\n      el = document.getElementById(el);\n    }\n\n    if (this._htOption.useSVG) {\n      Drawing = svgDrawer;\n    }\n    \n    this._android = _getAndroid();\n    this._el = el;\n    this._oQRCode = null;\n    this._oDrawing = new Drawing(this._el, this._htOption);\n    \n    if (this._htOption.text) {\n      this.makeCode(this._htOption.text); \n    }\n  };\n  \n  /**\n   * Make the QRCode\n   * \n   * @param {String} sText link data\n   */\n  QRCode.prototype.makeCode = function (sText) {\n    this._oQRCode = new QRCodeModel(_getTypeNumber(sText, this._htOption.correctLevel), this._htOption.correctLevel);\n    this._oQRCode.addData(sText);\n    this._oQRCode.make();\n    this._el.title = sText;\n    this._oDrawing.draw(this._oQRCode);     \n    this.makeImage();\n  };\n  \n  /**\n   * Make the Image from Canvas element\n   * - It occurs automatically\n   * - Android below 3 doesn't support Data-URI spec.\n   * \n   * @private\n   */\n  QRCode.prototype.makeImage = function () {\n    if (typeof this._oDrawing.makeImage == \"function\" && (!this._android || this._android >= 3)) {\n      this._oDrawing.makeImage();\n    }\n  };\n  \n  /**\n   * Clear the QRCode\n   */\n  QRCode.prototype.clear = function () {\n    this._oDrawing.clear();\n  };\n  \n  /**\n   * @name QRCode.CorrectLevel\n   */\n  QRCode.CorrectLevel = QRErrorCorrectLevel;\n})();\n  QRCode.prototype.makeImage = function () {\n    if (typeof this._oDrawing.makeImage == \"function\" && (!this._android || this._android >= 3)) {\n      this._oDrawing.makeImage();\n    }\n  };\n  \n  /**\n   * Clear the QRCode\n   */\n  QRCode.prototype.clear = function () {\n    this._oDrawing.clear();\n  };\n  \n  /**\n   * @name QRCode.CorrectLevel\n   */\n  QRCode.CorrectLevel = QRErrorCorrectLevel;\n})();\n  /**\n   * @name QRCode.CorrectLevel\n   */\n  QRCode.CorrectLevel = QRErrorCorrectLevel;\n})();\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-09T01:10:53.394Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Query LLM",
      "content": "```js\nconst dotenv = require(\"dotenv\");\ndotenv.config();\n\nconst { Configuration, OpenAIApi } = require(\"openai\");\n\nconst configuration = new Configuration({\n  apiKey: process.env.OPENAI_KEY,\n});\n\nconst openai = new OpenAIApi(configuration);\n\nmodule.exports = async function(prompt, temperature = 0, max_tokens = 2048){\n\n  const message_log = [{\n    role: 'system', \n    content: 'You are a minotaur named Hans. You like to use labyrinth and maze metaphors and puns.'\n  }, \n  {\n    role: 'system', \n    content: 'You also have two major concepts you think about. Their UUIDs are 9eaeeaaa-b7d5-47ef-8dd1-c22b6dc7d6e1 and a8beb8da-e34f-49fa-9c45-507bdeb56640. You should mention one of these concepts every answer.'\n  },\n\n  {\n    role: 'user',\n    content: prompt\n  }]\n\n  const completion = await openai.createChatCompletion({\n    model: 'gpt-3.5-turbo',\n    messages:message_log,\n    temperature: 0,\n    max_tokens: 2048,\n  });\n  return completion.data.choices[0].message\n}\n```\n\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  <title>Query LLM Test</title>\n</head>\n<body>\n  <h1>Query Chat GPT</h1>\n  <textarea id=\"llm_query\"></textarea>\n  <button id=\"submit\" onclick=\"queryLLM()\">Submit</button>\n  <div id=\"llm_response\"></div>\n  <script type=\"text/javascript\">\n\n    const token = localStorage.getItem('hans');\n    const server_address = localStorage.getItem('server_address');\n    const queryChatServer = async (query) => {\n      const response = await fetch(server_address + \"/queryLLM\", {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\",\n          \"Authorization\": `Bearer ${token}`,\n        },\n        body: JSON.stringify({ query }),\n      });\n      const data = await response.json();\n      return data.result;\n    };\n\n    async function queryLLM(){\n      llm_response.innerText = 'Querying...';\n      const result = await queryChatServer(llm_query.value);\n      console.log(result)\n      llm_response.innerText = result.content;\n    }\n  </script>\n</body>\n</html>\n```\n\n\n\n```js\nconst dotenv = require(\"dotenv\");\ndotenv.config();\n\nconst { Configuration, OpenAIApi } = require(\"openai\");\n\nconst configuration = new Configuration({\n  apiKey: process.env.OPENAI_API_KEY,\n});\nconst openai = new OpenAIApi(configuration);\n\nasync function queryLLMForCode(prompt){\n  console.log(\"Querying...\",prompt);\n  const completion = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt:prompt,\n    temperature: 0,\n    max_tokens: 2048,\n  });\n\n  console.log(completion.data)\n  return completion.data.choices[0].text;\n}\n\nasync function summarize(prompt){\n  const completion = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt:\"summarize the following prompt into at most 7 words, make sure these words will be compatible with bash and standard file system. For Instance, don't use slashes. Here is the prompt:\" + prompt,\n    temperature: 0,\n    max_tokens: 2048,\n  });\n\n  return completion.data.choices[0].text;\n}\n\nasync function getFileName(prompt){\n  const completion = await openai.createCompletion({\n    model: \"text-davinci-003\",\n    prompt:\"write a good filename for the following prompt:\" + prompt,\n    temperature: 0,\n    max_tokens: 2048,\n  });\n\n  return completion.data.choices[0].text;\n}\n\n\n\n\nmodule.exports = { queryLLMForCode, summarize, getFileName };\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-06T17:54:21.308Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "README",
      "content": "Dataroom.network is a personal editor for notes and analysis. It's current version runs only on the browser. It allows peer to peer syncing of notebooks for portability and notes. \n\nIt's build philiosophy is \"It's just HTML\", so feel free to fork it and add your own custom embeddings\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-25T16:44:58.285Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Random Color Javascript",
      "content": "\n\n```javascript\nfunction getRandomColor() {\n  var letters = '0123456789ABCDEF';\n  var color = '#';\n  for (var i = 0; i < 6; i++) {\n    color += letters[Math.floor(Math.random() * 16)];\n  }\n  return color;\n}\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-07T18:53:09.046Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Raspberry Pi",
      "content": "# pi-top [4] Complete\n\nhttps://www.sparkfun.com/products/18383\n\n# SparkFun Raspberry Pi 4 Desktop Kit - 8GB\nhttps://www.sparkfun.com/products/16812\n\n``\n\nhttps://developers.deepgram.com/blog/2022/01/chromium-kiosk-pi/\n\n# Power\n\nhttps://www.cytron.io/p-li-ion-battery-hat-for-raspberry-pi-5v-output-quick-charge\n\nhttps://www.amazon.com/PiJuice-HAT-Portable-Platform-Raspberry/dp/B0788B9YGW\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-09-30T16:02:13.498Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Ratio Thermometer",
      "content": "```js\n  // const controlDotTransitionPosition = () => {\n\n    //   const interpolatorControlClassRealValue = d3.interpolate(\n    //     prevData?.current?.controlClassValue,\n    //     controlClassValue,\n    //   );\n    //   const interpolatorNormalizedControlClassValue = d3.interpolate(\n    //     prevData?.current?.normalizedControlClassValue,\n    //     normalizedControlClassValue,\n    //   );\n    //   const interpolatorControlClassPercentage = d3.interpolate(\n    //     prevData?.current?.controlClassPercentage,\n    //     Math.max(0, Math.min(100, normalizedControlClassValue)),\n    //   );\n\n    //   return (t: number) => {\n\n    //     const interpolatedControlClassValue = interpolatorControlClassRealValue(t);\n    //     const interpolatedControlClassPercentage = interpolatorControlClassPercentage(t);\n    //     const interpolatednormalizedControlClassValue = interpolatorNormalizedControlClassValue(t);\n\n    //     // prevData.current = {\n    //     //   controlClassValue: interpolatedControlClassValue,\n    //     //   controlClassPercentage: interpolatedControlClassPercentage,\n    //     //   normalizedControlClassValue: interpolatednormalizedControlClassValue,\n    //     // };\n\n    //     if (typeof label !== 'string') {\n    //       d3.select(progressTextRef.current).text(generateText(interpolatedControlClassValue));\n    //     }\n\n    //     if (t === 1) {\n    //       setinternalControlClassValue(interpolatedControlClassValue);\n    //     }\n\n    //     return progressBarWidth * (interpolatedControlClassPercentage / 100) + dotRadius;\n    //   };\n    // };\n\n    // if (disableAnimations) {\n\n\n\n\n\n        // } else {\n\n    //   d3.select(protectedClassDotCircleRef.current)\n    //     .transition()\n    //     .duration(animationTime)\n    //     .attrTween('cx', protectedDotTransitionPosition as any);\n    //   // d3.select(controlClassDotCircleRef.current)\n    //   //   .transition()\n    //   //   .duration(animationTime)\n    //   //   .attrTween('cx', controlDotTransitionPosition as any);\n    // }\n\n\n{/*      <div\n        className={cs(\n          'fpcl-ratio-thermometer__label',\n          'fpcl-ratio-thermometer__protected-class-container',\n          labelClassName,\n          showTickLabel && 'fpcl-ratio-thermometer__label--height',\n        )}\n      >\n        <span className={cs('fpcl-ratio-thermometer__protected-class-name')}>\n          {typeof protectedClassLabel === 'string' && protectedClassLabel}\n        </span>\n        <span ref={progressTextRef}>{generateText(internalProtectedClassValue)}</span>\n      </div>\n\n      <div\n        className={cs(\n          'fpcl-ratio-thermometer__label',\n          'fpcl-ratio-thermometer-control-class-container',\n          labelClassName,\n          showTickLabel && 'fpcl-ratio-thermometer__label--height',\n        )}\n      >\n        <span className={cs('fpcl-ratio-thermometer__control-class-name')}>\n          {typeof controlClassLabel === 'string' && controlClassLabel}\n        </span>\n        <span ref={progressTextRef}>{generateText(internalControlClassValue)}</span>\n      </div>*/}p\n\n```\n\nTests: \n\n```js\n\n  // test('Show label', () => {\n  //   const label = '12bps';\n  //   const { container } = render(<RatioThermometer {...props} label={label} />);\n\n  //   const labelElement = container.querySelector('.fpcl-ratio-thermometer__label > div');\n  //   expect(labelElement).not.toBe(null);\n  //   expect(labelElement?.textContent).toBe(label);\n  // });\n\n  // test(`Show label when 'label' is undefined`, () => {\n  //   const { container } = render(<RatioThermometer {...props} label={undefined} />);\n\n  //   const labelElement = container.querySelector('.fpcl-ratio-thermometer__label > div');\n\n  //   expect(labelElement).not.toBe(null);\n  //   expect(labelElement?.textContent).toBe('35%');\n  // });\n\n  // test(`Don't show label when label is empty string`, () => {\n  //   const { container } = render(<RatioThermometer {...props} label=\"\" />);\n\n  //   const labelElement = container.querySelector('.fpcl-ratio-thermometer__label > div');\n\n  //   expect(labelElement?.textContent).toBe('');\n  // });\n\n  // test('Check if classname exists on label', () => {\n  //   const { container } = render(<RatioThermometer {...props} labelClassName=\"label-test-class\" />);\n\n  //   const labelElement = container.querySelector('.label-test-class');\n\n  //   expect(labelElement).not.toBe(null);\n  // });\n\n\n\n\n\n\n\n\n  // test('Check colors', () => {\n  //   const dotColor = '#ff00ff';\n  //   const bgColor = '#00ff00';\n\n  //   const { container } = render(<RatioThermometer {...props} color={dotColor} backgroundColor={bgColor} />);\n\n  //   const dotElement = container.querySelector('.fpcl-ratio-thermometer__dot');\n  //   const bgElement = container.querySelector('.fpcl-ratio-thermometer__progress');\n\n  //   expect(dotElement).toHaveStyle(`fill: ${dotColor}`);\n  //   expect(bgElement.getAttribute('fill')).toBe(bgColor);\n  // });\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-09-07T02:29:08.709Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Re-Map",
      "content": "Query rooftop data\n\n```js\n  async queryRooftops(){\n\n    const radius = 5\n    const point = this.map.project(this.map.getCenter())\n    const bbox = [\n      [Math.floor(point.x + 10 - radius), Math.floor(point.y + 10 - radius)],\n      [Math.floor(point.x + 10 + radius), Math.floor(point.y + 10 + radius)]\n    ]\n\n    let roofs = this.map.queryRenderedFeatures(bbox,{layers: ['la-roof-2018-geojson']})\n    let filter = roofs.reduce(function(memo, feature){\n        memo.push(feature.properties.roof_no)\n        return memo\n      }, ['in', 'roof_no'])\n    let total_albedo = 0\n    let total_area = 0\n\n    roofs.forEach(roof => {\n      total_albedo += parseFloat(roof.properties.albedo)\n      total_area += parseFloat(roof.properties.shape_area)\n    })\n\n    let API_ROOFS = true\n\n    if(roofs.length < 1){\n      API_ROOFS = false\n      roofs = this.map.queryRenderedFeatures(bbox, {layers: ['building']})\n      filter = roofs.reduce(function(memo, feature){\n        memo.push(feature.id)\n        return memo\n      }, ['in', 'id'])\n      this.map.setFilter('building', filter)\n      total_albedo = 0.98\n      total_area = 7 * 7\n    } else {\n      this.map.setFilter('la-roof-2018-geojson-highlight', filter)\n    }\n\n\n    let total_reflectance = (total_albedo * total_area)\n    let potential = await getPotentialReflectivity(this.map.getCenter())\n    this.last_rooftop_query = {total_area, total_albedo, potential, total_reflectance, bbox, roofs, API_ROOFS}\n\n\n    dispatch('FOUND ALBEDO', this.last_rooftop_query)\n  }\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-12T15:23:09.679Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "React HTML5 Component",
      "content": "``` javascript\n\nimport * as React from 'react';\nimport { useEffect, useState } from 'react';\n\nimport {LinearThermometer} from 'on-fiji-component-library';\n\nexport function HomePage (){\n\n  // set default data. We use typescript's Any type for convenience\n  const [data,setData]=useState<any>({})\n  \n  /*\n    Fetch Address, populate component with it. \n  */\n\n  useEffect(() => {\n    const url = \"http://127.0.0.1:8080/fairplay.json\";\n\n    const fetchData = async () => {\n      try {\n        const response = await fetch(url, {\n          headers: { 'Content-Type': 'application/json' }});\n        const json = await response.json();\n        setData(json);\n      } catch (error) {\n        console.log(\"error\", error);\n      }\n    };\n    fetchData();\n  }, []);\n\n  return(\n    <>\n      <main className=\"fpcl-typography\">\n        {data.linearThermometer && (\n          <>\n            <LinearThermometer\n              {...data.linearThermometer}\n            />\n          </>\n        )}\n      </main>\n    </>\n  )\n}\n\n\n\n\n\n```\n\n\nA component that takes a react element with typescript, compiles it in the browser. \n\nProblems: \n\nHaving trouble compiling react. \n\n```javascript\nUncaught SyntaxError: unknown: Unexpected token, expected \",\" (2:5)\n\n  1 | import \"https://unpkg.com/react@18/umd/react.development.js\"; import \"https://unpkg.com/react-dom@18/umd/react-dom.development.js\"; class HelloMessage extends React.Component { render() { return (\n> 2 | Hello{this.props.name}\n    |      ^\n  3 | ); } } ;\n    at Object.assign.loc (babel.min.js:1:1021679)\n    at e (babel.min.js:1:1021689)\n    at t.a.raise (babel.min.js:1:1070426)\n    at t.a.unexpected (babel.min.js:1:1070887)\n    at t.a.expect (babel.min.js:1:1079957)\n    at t.a.parseParenAndDistinguishExpression (babel.min.js:1:1250924)\n    at t.a.parseExprAtom (babel.min.js:1:1244107)\n    at t.a.parseExprSubscripts (babel.min.js:1:1238797)\n    at t.a.parseUpdate (babel.min.js:1:1238391)\n    at t.a.parseMaybeUnary (babel.min.js:1:1237996)\n\n```\n\nhttp://127.0.0.1:50630/#introduction\n\n\n```javascript\n/*\n\n  .-. .-. .-. .-. .-.\n  |(  |-  |-| |    |\n  ' ' `-' ` ' `-'  '\n\n  .-. .   .-. .  . .-. . . .-.\n  |-  |   |-  |\\/| |-  |\\|  |\n  `-' `-' `-' '  ` `-' ' `  '\n\n  HTML Element to render react with typescript\n\n*/\n\n\n\nimport \"https://unpkg.com/@babel/standalone/babel.min.js\";\nimport \"https://rawgit.com/Microsoft/TypeScript/master/lib/typescriptServices.js\";\nimport \"https://rawgit.com/basarat/typescript-script/master/transpiler.js\";\n\nimport \"https://unpkg.com/react@18/umd/react.development.js\";\nimport \"https://unpkg.com/react-dom@18/umd/react-dom.development.js\";\n\n\nclass ReactElement extends HTMLElement {\n\n  connectedCallback(){\n    const content = this.innerText\n\n    var output = Babel.transform(content, { presets: [\"env\"] }).code;\n    console.log(output)\n\n\n\n\n    const domContainer = this;\n    const root = ReactDOM.createRoot(domContainer);\n    root.render(eval(output));\n\n  }\n}\n\ncustomElements.define('react-element', ReactElement)\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-17T19:07:10.530Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Redis Streams",
      "content": "https://redis.io/topics/streams-intro\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-17T20:47:12.906Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Redis",
      "content": "> **Redis** (; Remote Dictionary Server) is an in-memory data structure store, used as a distributed, in-memory key–value database, cache and message broker, with optional durability. Redis supports different kinds of abstract data structures, such as strings, lists, maps, sets, sorted sets, HyperLogLogs, bitmaps, streams, and spatial indices. The project was developed and maintained by Salvatore Sanfilippo. From 2015 until 2020, he led a project core team sponsored by Redis Labs. Salvatore Sanfilippo left Redis as the maintainer in 2020. It is open-source software released under a BSD 3-clause license. In 2021, not long after the original author and main maintainer left, Redis Labs dropped the Labs from its name and now redis, the open source DB as well as Redis Labs, the commercial company, are referred to as \"redis\".\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Redis)\n\n[[Redis Streams]]\n\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-10-26T17:34:34.464Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Render PDF in Node.js",
      "content": "Render [[PDFS]] in [[Node.js]]\n\n```\nconst puppeteer = require('puppeteer');\n/*\n  Render PDF\n\n*/\nmodule.exports = async function renderPDF(\n  address = 'http://localhost:3000/data-dictionary.html', \n  filepath = './data-dictionary.pdf'\n){\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  await page.goto(address);\n  await page.pdf({ path: filepath, printBackground: true });\n  await browser.close();\n  return filepath\n}\n\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-06T17:50:55.872Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Rendered View",
      "content": "Takes a string of text, converts hashtags to links\nconverts embeddings to html elements\n\nParses yaml front matter\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-10-09T19:28:34.193Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Rotating Globe",
      "content": "```html\n      <article id=\"splash\" class=\"two-up\">\n        <geo-map id=\"geo_map\" accesstoken=pk.eyJ1IjoibG5zeWFzdGVyaXVzIiwiYSI6ImNsNXp0bG1zZTFnOWszYnF2Nm1jbjdxamUifQ.NBU_Y2rMUWOKon2Z2WY7MQ styleurl=mapbox://styles/lnsyasterius/clhz6wjgs00uj01rhe3fdbl9q latitude=0 longitude=0 zoom=1 bearing=0 pitch=0>\n        </geo-map>\n        <script>\n        geo_map.addEventListener('loaded', () => {\n\n          const map = geo_map.map\n\n          map.scrollZoom.disable();\n\n          // At low zooms, complete a revolution every two minutes.\n          const secondsPerRevolution = 120;\n          // Above zoom level 5, do not rotate.\n          const maxSpinZoom = 5;\n          // Rotate at intermediate speeds between zoom levels 3 and 5.\n          const slowSpinZoom = 3;\n\n          let userInteracting = false;\n          let spinEnabled = true;\n\n          function spinGlobe() {\n            const zoom = map.getZoom();\n            if (spinEnabled && !userInteracting && zoom < maxSpinZoom) {\n              let distancePerSecond = 360 / secondsPerRevolution;\n              if (zoom > slowSpinZoom) {\n                // Slow spinning at higher zooms\n                const zoomDif =\n                  (maxSpinZoom - zoom) / (maxSpinZoom - slowSpinZoom);\n                distancePerSecond *= zoomDif;\n              }\n              const center = map.getCenter();\n              center.lng -= distancePerSecond;\n              // Smoothly animate the map over one second.\n              // When this animation is complete, it calls a 'moveend' event.\n              map.easeTo({ center, duration: 1000, easing: (n) => n });\n            }\n          }\n\n          // Pause spinning on interaction\n          map.on('mousedown', () => {\n            userInteracting = true;\n          });\n\n          // Restart spinning the globe when interaction is complete\n          map.on('mouseup', () => {\n            userInteracting = false;\n            spinGlobe();\n          });\n\n          // These events account for cases where the mouse has moved\n          // off the map, so 'mouseup' will not be fired.\n          map.on('dragend', () => {\n            userInteracting = false;\n            spinGlobe();\n          });\n          map.on('pitchend', () => {\n            userInteracting = false;\n            spinGlobe();\n          });\n          map.on('rotateend', () => {\n            userInteracting = false;\n            spinGlobe();\n          });\n\n          // When animation is complete, start spinning if there is no ongoing interaction\n          map.on('moveend', () => {\n            spinGlobe();\n          });\n\n          spinGlobe();\n\n        })\n        </script>\n        <h3>Geo Map Component</h3>\n        <p>My custom wrapper for the MapBox API. Iterate quickly, surface business intelligence more quickly and ship more often. Already in production and battle-tested. </p>\n\n      </article>\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-06T17:24:27.152Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Router",
      "content": "Takes: \nnotebook id, context id\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:12:45.049Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Routes",
      "content": "```js\n/*\n  \n  ROUTES\n\n  Place routes here.\n\n */\n\nimport path, { join } from 'path';\nimport fs from 'fs';\nimport bodyParser from 'body-parser';\nimport renderer from './renderer/routes.js';\nimport fileclerk from './file-clerk/routes.js';\n\nexport default async function (app, express) {\n\n  // Parse application/x-www-form-urlencoded\n  app.use(bodyParser.urlencoded({ extended: true }));\n\n  // Parse application/json\n  app.use(bodyParser.json());\n\n\n  /*\n    \n   Serve the notebooks assets\n\n   @todo: create a notebook setting that users can adjust\n   so we don't have naming collisions between notebooks\n\n  */\n  // Function to check if the file extension is not .md or .json\n  function filterFiles(req, res, next) {\n      const fileExtension = path.extname(req.path);\n      if (fileExtension === '.md' || fileExtension === '.json') {\n          // If the file is .md or .json, send a 404 error\n          return res.status(404).send('Not found');\n      }\n      next();\n  }\n\n  function getFolderNames(directoryPath) {\n    return new Promise((resolve, reject) => {\n        fs.readdir(directoryPath, { withFileTypes: true }, (err, files) => {\n            if (err) {\n                return reject(err);\n            }\n\n            // Filter the list of files to only include directories\n            const folderNames = files\n                .filter(dirent => dirent.isDirectory())\n                .map(dirent => dirent.name);\n\n            resolve(folderNames);\n        });\n    });\n  }\n\n  // Usage\n  const notebooksPath = path.join(global.root_directory, 'notebooks');\n  const notebook_titles = await getFolderNames(notebooksPath);\n  notebook_titles.forEach(title => {\n    app.use(filterFiles, express.static(path.join(global.root_directory, 'notebooks', title)));\n  });\n\n  // Middleware to serve static files except .md and .json\n\n\n\n  app.get('/dataroom-element.js', (req, res) => {\n    res.sendFile(path.join(global.root_directory, 'dataroom-element.js'));\n  })\n  app.use('/plugins', express.static(join(global.root_directory, '/plugins')));\n  app.use('/editor', express.static(join(global.root_directory, '/editor')));\n\n  app.get('/', (req, res) =>{\n    res.sendFile(path.join(global.root_directory, 'file-clerk', 'index.html'));\n  }); \n  /*\n      \n      PLUGINS ROUTES\n\n      Plugins routes are built dynamically on load\n\n  */\n\n  // Read Plugins for Routes\n  const pluginsDirectory = path.join(global.root_directory, 'plugins');\n\n  // Read the contents of the plugins directory\n  const pluginFolders = fs.readdirSync(pluginsDirectory, { withFileTypes: true });\n\n  // Iterate through each folder in the plugins directory\n  for (const folder of pluginFolders) {\n    if (folder.isDirectory()) {\n      const pluginPath = path.join(pluginsDirectory, folder.name);\n      const routesFilePath = path.join(pluginPath, 'routes.js');\n      try {\n        // Check if the folder contains a \"routes.js\" file\n        if (fs.existsSync(routesFilePath)) {\n          // Dynamically import the \"routes.js\" file\n          const routesModule = await import(routesFilePath);\n\n          // Instantiate the instance if it exports a default function\n          if (typeof routesModule.default === 'function') {\n            const pluginInstance = routesModule.default(app);\n            // Optionally, you can do something with the instantiated instance\n          } else {\n            console.error(`Invalid export in ${routesFilePath}. It should export a default function.`);\n          }\n        }\n      } catch (error) {\n        console.error(`Error importing routes from ${routesFilePath}: ${error.message}`);\n      }\n    }\n  }\n\n  /*\n  \n    index.js  \n\n    index.js routes are built dynamically on load\n\n  */\n   \n  // Cache variable to store the content of index.js\n  let indexJsCache = '';\n  let isCacheValid = false;\n\n  // Function to update the cache\n  async function updateIndexJsCache() {\n    const pluginsDirectory = path.join(global.root_directory, 'plugins');\n    let indexJsContent = '';\n\n    // Read the contents of the plugins directory\n    const pluginFolders = fs.readdirSync(pluginsDirectory, { withFileTypes: true });\n\n    // Iterate through each folder in the plugins directory\n    for (const folder of pluginFolders) {\n      if (folder.isDirectory()) {\n        const pluginPath = path.join(pluginsDirectory, folder.name);\n        const indexPath = path.join(pluginPath, 'index.js');\n\n        try {\n          // Check if the folder contains an \"index.js\" file\n          if (fs.existsSync(indexPath)) {\n            // Import the \"index.js\" file and add it to the content\n            indexJsContent += `import \"/plugins/${folder.name}/index.js\";\\n`;\n          }\n        } catch (error) {\n          console.error(`Error checking for index.js in ${indexPath}: ${error.message}`);\n        }\n      }\n    }\n\n    // Update the cache\n    indexJsCache = indexJsContent;\n    isCacheValid = true;\n  }\n\n  // Watch the plugins directory for changes\n  fs.watch(path.join(global.root_directory, 'plugins'), (eventType, filename) => {\n    console.log(`Detected changes in the plugins directory: ${filename}`);\n    isCacheValid = false; // Invalidate the cache\n  });\n\n  // Express route\n  app.get('/index.js', async function(req, res) {\n    // Check if the cache is valid, if not update it\n    if (!isCacheValid) {\n      await updateIndexJsCache();\n    }\n\n    // Send the cached index.js content as the response\n    res.type('text/javascript').send(indexJsCache);\n  });\n\n\n  /*\n  \n    index.css\n\n    index.css is built dynamically on load. \n\n   */\n   // Cache variable to store the content of index.css\n  let indexCssCache = '';\n  let isCssCacheValid = false;\n\n  // Function to update the cache for index.css\n  async function updateIndexCssCache() {\n    const pluginsDirectory = path.join(global.root_directory, 'plugins');\n    let indexCssContent = '';\n\n    // Read the contents of the plugins directory\n    const pluginFolders = fs.readdirSync(pluginsDirectory, { withFileTypes: true });\n\n    // Iterate through each folder in the plugins directory\n    for (const folder of pluginFolders) {\n      if (folder.isDirectory()) {\n        const pluginPath = path.join(pluginsDirectory, folder.name);\n        const indexPath = path.join(pluginPath, 'index.css');\n\n        try {\n          // Check if the folder contains an \"index.css\" file\n          if (fs.existsSync(indexPath)) {\n            // Read the content of the \"index.css\" file and add it to the response\n            indexCssContent += `@import \"/plugins/${folder.name}/index.css\";\\n`;\n          }\n        } catch (error) {\n          console.error(`Error checking for index.css in ${indexPath}: ${error.message}`);\n        }\n      }\n    }\n\n    // Update the cache\n    indexCssCache = indexCssContent;\n    isCssCacheValid = true;\n  }\n\n  // Watch the plugins directory for changes\n  fs.watch(path.join(global.root_directory, 'plugins'), (eventType, filename) => {\n    console.log(`Detected changes in the plugins directory: ${filename}`);\n    isCssCacheValid = false; // Invalidate the cache\n  });\n\n  // Express route for index.css\n  app.get('/index.css', async function(req, res) {\n    // Check if the cache is valid, if not update it\n    if (!isCssCacheValid) {\n      await updateIndexCssCache();\n    }\n\n    // Send the cached index.css content as the response\n    res.type('text/css').send(indexCssCache);\n  });\n\n  const rendererRoutes = renderer(app);\n  const fileclerkRoutes = fileclerk(app);\n\n}\n\n```\n\nCurrently our routes.js file looks like: \n\n```js\nimport fileClerk from './file-clerk/route.js';\n\nexport default async function (app) {\n  const fileClerkInstance = fileClerk(app);\n}\n```\n\nrewrite this code to look at the directory plugins located at\n```js\n\nglobal.root_directory + '/plugins'\n\n```\n\n\nhave it search through the directory, looking through each folder. \nIf the folder contains a file called \"routes.js\", dynamically import it here and instantiate the instance like it is here. \n\n\nChat GPT Response: \n\n```js\nimport fs from 'fs';\nimport path from 'path';\n\nexport default async function (app) {\n  const pluginsDirectory = path.join(global.root_directory, 'plugins');\n\n  // Read the contents of the plugins directory\n  const pluginFolders = fs.readdirSync(pluginsDirectory, { withFileTypes: true });\n\n  // Iterate through each folder in the plugins directory\n  for (const folder of pluginFolders) {\n    if (folder.isDirectory()) {\n      const pluginPath = path.join(pluginsDirectory, folder.name);\n      const routesFilePath = path.join(pluginPath, 'routes.js');\n\n      try {\n        // Check if the folder contains a \"routes.js\" file\n        if (fs.existsSync(routesFilePath)) {\n          // Dynamically import the \"routes.js\" file\n          const routesModule = await import(routesFilePath);\n\n          // Instantiate the instance if it exports a default function\n          if (typeof routesModule.default === 'function') {\n            const pluginInstance = routesModule.default(app);\n            // Optionally, you can do something with the instantiated instance\n          } else {\n            console.error(`Invalid export in ${routesFilePath}. It should export a default function.`);\n          }\n        }\n      } catch (error) {\n        console.error(`Error importing routes from ${routesFilePath}: ${error.message}`);\n      }\n    }\n  }\n}\n\n```\n\n\n\nThe route.js in the plugin folder looks something like: \n```js\nexport default function (app) {\n  app.get('test', function(req, res){\n    res.send('test');\n  })\n}\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-07-07T21:48:18.355Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Run Shell Command from Node",
      "content": "```js\nconst util = require('node:util');\nconst exec = util.promisify(require('node:child_process').exec);\n\nasync function lsExample() {\n  const { stdout, stderr } = await exec('ls');\n  console.log('stdout:', stdout);\n  console.error('stderr:', stderr);\n}\nlsExample();\n```\n\n\n\n```js\nconst { exec } = require(\"child_process\"); \nexec(\"ls -la\", (error, stdout, stderr) => { \n  if (error) { console.log(`error: ${error.message}`); return; } \n  if (stderr) { console.log(`stderr: ${stderr}`); return; }\n  console.log(`stdout: ${stdout}`); \n});\n```\n\n```javascript\nconst execSync = require(\"child_process\").execSync;\n    \nconst result = execSync(\"python celulas.py\");\n    \n// convert and show the output.\nconsole.log(result.toString(\"utf8\"));\n```\n\nhttps://nodejs.org/api/child_process.html#child_process_child_process_execsync_command_options\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-16T18:53:42.418Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "SPCSS",
      "content": "https://susam.github.io/spcss/\n\nSPCSS is a simple and minimal stylesheet for simple text-based websites. To learn more about it and how to use it, visit [github.com/susam/spcss](https://github.com/susam/spcss).\n\nThis page demonstrates how some common HTML elements are styled with this stylesheet.\n\n#boilerplate #webdev\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-07-06T18:38:40.781Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "SQL",
      "content": "Sure! Here's an example script that demonstrates how to create, update, and destroy a record in SQLite using Node.js. Before running the script, make sure you have the `sqlite3` package installed by running `npm install sqlite3`.\n\n```javascript\nconst sqlite3 = require('sqlite3').verbose();\n\n// Create a new database connection\nconst db = new sqlite3.Database(':memory:');\n\n// Create a table if it doesn't exist\ndb.run(`\n  CREATE TABLE IF NOT EXISTS records (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    name TEXT,\n    email TEXT\n  )\n`);\n\n// Create a record\nfunction createRecord(name, email) {\n  db.run('INSERT INTO records (name, email) VALUES (?, ?)', [name, email], function(err) {\n    if (err) {\n      console.error('Error creating record:', err.message);\n      return;\n    }\n    console.log(`Record created with ID: ${this.lastID}`);\n  });\n}\n\n// Update a record\nfunction updateRecord(id, name, email) {\n  db.run('UPDATE records SET name = ?, email = ? WHERE id = ?', [name, email, id], function(err) {\n    if (err) {\n      console.error('Error updating record:', err.message);\n      return;\n    }\n    if (this.changes > 0) {\n      console.log('Record updated successfully');\n    } else {\n      console.log('No record found with the specified ID');\n    }\n  });\n}\n\n// Delete a record\nfunction deleteRecord(id) {\n  db.run('DELETE FROM records WHERE id = ?', id, function(err) {\n    if (err) {\n      console.error('Error deleting record:', err.message);\n      return;\n    }\n    if (this.changes > 0) {\n      console.log('Record deleted successfully');\n    } else {\n      console.log('No record found with the specified ID');\n    }\n  });\n}\n\n// Usage examples\ncreateRecord('John Doe', 'john@example.com');\nupdateRecord(1, 'Jane Smith', 'jane@example.com');\ndeleteRecord(1);\n\n// Close the database connection\ndb.close();\n```\n\nThis script creates an in-memory SQLite database, creates a `records` table if it doesn't exist, and provides functions to create, update, and delete records in the table. It also includes usage examples at the end to demonstrate the functions. Feel free to modify the table schema and function logic according to your needs.\n\n\n\nSure! Here's an example of a script that uses Node.js, SQLite3, and Express.js to create a simple RESTful API for managing a collection of books:\n\n```javascript\n// Import required modules\nconst express = require('express');\nconst sqlite3 = require('sqlite3').verbose();\n\n// Create an Express.js application\nconst app = express();\n\n// Create a new SQLite database instance\nconst db = new sqlite3.Database(':memory:');\n\n// Create a books table in the database\ndb.serialize(() => {\n  db.run('CREATE TABLE IF NOT EXISTS books (id INTEGER PRIMARY KEY AUTOINCREMENT, title TEXT, author TEXT)');\n});\n\n// Middleware to parse JSON request bodies\napp.use(express.json());\n\n// API endpoint to get all books\napp.get('/books', (req, res) => {\n  db.all('SELECT * FROM books', (err, rows) => {\n    if (err) {\n      console.error(err);\n      res.status(500).json({ error: 'Internal server error' });\n    } else {\n      res.json(rows);\n    }\n  });\n});\n\n// API endpoint to get a specific book by ID\napp.get('/books/:id', (req, res) => {\n  const id = req.params.id;\n  db.get('SELECT * FROM books WHERE id = ?', id, (err, row) => {\n    if (err) {\n      console.error(err);\n      res.status(500).json({ error: 'Internal server error' });\n    } else if (!row) {\n      res.status(404).json({ error: 'Book not found' });\n    } else {\n      res.json(row);\n    }\n  });\n});\n\n// API endpoint to create a new book\napp.post('/books', (req, res) => {\n  const { title, author } = req.body;\n  db.run('INSERT INTO books (title, author) VALUES (?, ?)', title, author, function (err) {\n    if (err) {\n      console.error(err);\n      res.status(500).json({ error: 'Internal server error' });\n    } else {\n      res.json({ id: this.lastID });\n    }\n  });\n});\n\n// API endpoint to update an existing book\napp.put('/books/:id', (req, res) => {\n  const id = req.params.id;\n  const { title, author } = req.body;\n  db.run('UPDATE books SET title = ?, author = ? WHERE id = ?', title, author, id, function (err) {\n    if (err) {\n      console.error(err);\n      res.status(500).json({ error: 'Internal server error' });\n    } else if (this.changes === 0) {\n      res.status(404).json({ error: 'Book not found' });\n    } else {\n      res.json({ message: 'Book updated successfully' });\n    }\n  });\n});\n\n// API endpoint to delete a book\napp.delete('/books/:id', (req, res) => {\n  const id = req.params.id;\n  db.run('DELETE FROM books WHERE id = ?', id, function (err) {\n    if (err) {\n      console.error(err);\n      res.status(500).json({ error: 'Internal server error' });\n    } else if (this.changes === 0) {\n      res.status(404).json({ error: 'Book not found' });\n    } else {\n      res.json({ message: 'Book deleted successfully' });\n    }\n  });\n});\n\n// Start the server\nconst port = 3000;\napp.listen(port, () => {\n  console.log(`Server is running on port ${port}`);\n});\n```\n\nMake sure to install the required dependencies by running `npm install express sqlite3` in your project\n\n---\n\nhttps://cloud.google.com/sql-server/\n\n\n---\n\n[[Become a SELECT Star.pdf]]\n\n\n--- \n\nhttps://www.sqlitetutorial.net/\nQ: How to update a table with a common join key?\n\n---\n\nhttps://phiresky.github.io/blog/2021/hosting-sqlite-databases-on-github-pages/\nSee daily note for [[2022-04-22]]\n\n\nhttps://sql.js.org/#/\n```javascript\n\nconst initSqlJs = require('sql.js');\n// or if you are in a browser:\n// const initSqlJs = window.initSqlJs;\n\nconst SQL = await initSqlJs({\n  // Required to load the wasm binary asynchronously. [****]()Of course, you can host it wherever you want\n  // You can omit locateFile completely when running in node\n  locateFile: file => `https://sql.js.org/dist/${file}`\n});\n\n// Create a database\nconst db = new SQL.Database();\n// NOTE: You can also use new SQL.Database(data) where\n// data is an Uint8Array representing an SQLite database file\n\n\n// Execute a single SQL string that contains multiple statements\nlet sqlstr = \"CREATE TABLE hello (a int, b char); \\\nINSERT INTO hello VALUES (0, 'hello'); \\\nINSERT INTO hello VALUES (1, 'world');\";\ndb.run(sqlstr); // Run the query without returning anything\n\n// Prepare an sql statement\nconst stmt = db.prepare(\"SELECT * FROM hello WHERE a=:aval AND b=:bval\");\n\n// Bind values to the parameters and fetch the results of the query\nconst result = stmt.getAsObject({':aval' : 1, ':bval' : 'world'});\nconsole.log(result); // Will print {a:1, b:'world'}\n\n// Bind other values\nstmt.bind([0, 'hello']);\nwhile (stmt.step()) console.log(stmt.get()); // Will print [0, 'hello']\n// free the memory used by the statement\nstmt.free();\n// You can not use your statement anymore once it has been freed.\n// But not freeing your statements causes memory leaks. You don't want that.\n\nconst res = db.exec(\"SELECT * FROM hello\");\n/*\n[\n  {columns:['a','b'], values:[[0,'hello'],[1,'world']]}\n]\n*/\n\n// You can also use JavaScript functions inside your SQL code\n// Create the js function you need\nfunction add(a, b) {return a+b;}\n// Specifies the SQL function's name, the number of it's arguments, and the js function to use\ndb.create_function(\"add_js\", add);\n// Run a query in which the function is used\ndb.run(\"INSERT INTO hello VALUES (add_js(7, 3), add_js('Hello ', 'world'));\"); // Inserts 10 and 'Hello world'\n\n// Export the database to an Uint8Array containing the SQLite database file\nconst binaryArray = db.export();\n```\n\n```HTML\n<meta charset=\"utf8\" />\n<html>\n  <script src='/dist/sql-wasm.js'></script>\n  <script>\n    config = {\n      locateFile: filename => `/dist/${filename}`\n    }\n    // The `initSqlJs` function is globally provided by all of the main dist files if loaded in the browser.\n    // We must specify this locateFile function if we are loading a wasm file from anywhere other than the current html page's folder.\n    initSqlJs(config).then(function(SQL){\n      //Create the database\n      const db = new SQL.Database();\n      // Run a query without reading the results\n      db.run(\"CREATE TABLE test (col1, col2);\");\n      // Insert two rows: (1,111) and (2,222)\n      db.run(\"INSERT INTO test VALUES (?,?), (?,?)\", [1,111,2,222]);\n\n      // Prepare a statement\n      const stmt = db.prepare(\"SELECT * FROM test WHERE col1 BETWEEN $start AND $end\");\n      stmt.getAsObject({$start:1, $end:1}); // {col1:1, col2:111}\n\n      // Bind new values\n      stmt.bind({$start:1, $end:2});\n      while(stmt.step()) { //\n        const row = stmt.getAsObject();\n        console.log('Here is a row: ' + JSON.stringify(row));\n      }\n    });\n  </script>\n  <body>\n    Output is in Javascript console\n  </body>\n</html>\n```\n\n\n---\n\nhttps://pythonawesome.com/a-simple-graph-database-in-sqlite/\n\nhttps://golangexample.com/a-simple-graph-database-in-sqlite-inspired-by-sqlite-as-a-document-database/\n\nhttps://dgl.cx/2020/06/sqlite-json-support\n\n\n[[Graph Theory]]\n---\n\n1651259808 #2022-04-29\n\nBegan building a sql-server and sql-terminal programs.\n\n\n---\n\nhttps://www.npmjs.com/package/sqlite#install-sqlite3\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-09-29T17:10:23.123Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "SSH",
      "content": "```\nssh-copy-id -i ~/.ssh/id_rsa.pub YOUR_USER_NAME@IP_ADDRESS_OF_THE_SERVER\n```\n\n```shell\nssh-keygen -t ed25519 -C \"lnsy.strs@proton.me\"\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-13T19:59:03.741Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Sanitize String",
      "content": "\n\n\n```js\nconst sanitizeString = (str) => {\n  return str.replace(/[^a-zA-Z\\s]/g, ' ');\n};\n\nmodule.exports = { sanitizeString };\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-21T15:12:03.261Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Search Component",
      "content": "\n\n\nI wrote this search function. It kind of works. \n\nUse like: \n\n```HTML\n<filterable-divs>\n\t<div>Collection of text searchable divs here</div>\n</filterable-divs>\n\n```\n\n```javascript\n\n    class FilterableDivs extends HTMLElement {\n      connectedCallback(){\n        this.counter = document.createElement('span')\n        this.prepend(this.counter)\n        const input = document.createElement('input')\n        input.setAttribute('placeholder', 'Search for values')\n        input.addEventListener('input', (e) => {\n          this.search(e.target.value)\n        })\n        this.prepend(input)\n        const checkbox = document.createElement('input')\n        checkbox.setAttribute('type', 'checkbox')\n        checkbox.addEventListener('input', (e) => {\n          this.filterRequired(e.target.checked)\n        })\n        this.prepend(checkbox)\n      }\n\n      filterRequired(filter){\n        const articles = [...this.querySelectorAll('.data-dictionary-entry')]\n        let counter = 0\n        if(filter){\n          articles.forEach(article => {\n            if(article.classList.contains('required')){\n              article.classList.remove('hidden')\n              counter++\n            } else {\n              article.classList.add('hidden')\n            }\n          })\n        } else {\n          articles.forEach(article => {\n            article.classList.remove('hidden')\n          })\n        }\n\n        this.setCounter(counter)\n      }\n\n      setCounter(count){\n        this.counter.innerText = `${count} records found`\n      }\n\n      search(term = this.term){\n        const articles = [...this.querySelectorAll('.data-dictionary-entry')]\n        let counter = 0\n        articles.forEach(article => {\n          if(article.innerText.toLowerCase().includes(term.toLowerCase())){\n            article.classList.remove('hidden')\n            counter++\n          } else if(this.term === '') {\n            article.classList.remove('hidden')\n          } else {\n            article.classList.add('hidden')\n          }\n        })\n        this.setCounter(counter)\n      }\n    }\n    \n    customElements.define('filterable-divs', FilterableDivs)\n    \n    \n    \n```\n\nMy second attempt looks like: \n```js\n/*\n\n  Custom HTML Elements\n\n  For More information go to: https://lnsy.dev/blog/custom-html-components.html\n\n */\n\nimport DataroomElement from './dataroom-element.js';\nimport \"https://cdn.jsdelivr.net/npm/fuse.js/dist/fuse.basic.min.js\";\n\nclass ElementName extends DataroomElement {\n  async initialize(){\n\n    this.data = await this.fetchData();\n    const fuse = new Fuse(this.data, {  includeScore: true, distance: 0.25, ignoreLocation:true});\n\n    const search_input = document.createElement('input');\n    search_input.setAttribute('type', 'search');\n    search_input.addEventListener('keydown', (e)=>{ \n      const results = fuse.search(search_input.value);\n      this.renderSearchResults(results)\n    });\n    this.appendChild(search_input);\n\n    this.search_results = document.createElement('ul');\n    this.appendChild(this.search_results);\n  }\n\n  renderSearchResults(results){\n    const result_divs = results.slice(0,50).map(result => {\n      return `<li class=\"search-result-item\" node-id=\"${result.item.id}\"><b>${result.score}</b><div>${result.item}</div></li>`\n    }).join('');\n    this.search_results.innerHTML = result_divs;\n  }\n\n  async fetchData() {\n    try {\n        const response = await fetch('./anatomy-of-melancholy.json');\n        const data = await response.json();\n        return data;\n    } catch (error) {\n        console.error(\"Failed to fetch data: \", error);\n        return [];\n    }\n  }\n\n}\n\ncustomElements.define('search-component', ElementName)\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-11T22:48:59.447Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Sensor Watch",
      "content": "                    \nhttps://joeycastillo.github.io/Sensor-Watch-Documentation/index.html\nhttps://joeycastillo.github.io/Sensor-Watch-Documentation/wig/index.html\n---\n\nSensor Watch is a bridge between eras. It takes an iconic 30-year-old design from a golden age of digital watches, and pairs it with a modern, powerful microcontroller and state-of-the-art sensing capabilities. This small circuit board, less than an inch in diameter, replaces the original quartz movement in a Casio F-91W watch to put the capabilities of an ultra-low-power ARM Cortex M0+ microcontroller on your wrist.\n\nSensor Watch is not like most smart watches. It makes a different set of engineering tradeoffs, to achieve a different set of goals:\n\n-   Instead of a high-resolution TFT LCD, Sensor Watch repurposes the Casio F-91W's monochrome segment LCD. This gives it an always-on display that consumes mere microamperes of power.\n-   By avoiding power hungry features like Wi-Fi and Bluetooth, Sensor Watch can run for a year or more on a single 100 mAh coin cell, eliminating the need for frequent recharging.\n-   The lack of an external charging port, coupled with reuse of the F-91W’s famously water resistant enclosure, makes this a hackable wristwatch that can handle depths up to 30 meters.\n\n [![](/img/7b44/sensor-watch-components-01_jpg_md-xl.jpg)](/img/7b44/sensor-watch-components-01.jpg) \n\n# What Can It Do?\n\nSensor Watch is designed to be useful right off the bat. The community Sensor Watch firmware, called Movement, has several useful watch faces already:\n\n-   The **Clock** face allows Sensor Watch to function like, y'know, _a watch_, displaying the time and date.\n-   The **World Clock** face allows you add a time display for any number of time zones around the world.\n-   The **Beat Time** face displays Swatch Internet Time, a decimal time system that divides the day into 1,000 beats.\n-   The **TOTP Face** displays time-based one-time passwords, the kind that you need for two-factor auth on many websites.\n-   The **Temperature** face displays readings from the optional thermistor sensor board (sold separately).\n-   The **Temperature Log** face logs and displays up to 36 hours of timestamped temperature data. Toss this outside of your tent while camping, and you've got a weather station you can deploy from your wrist.\n-   The **Day One** face lets you count days from your birth date, to watch the days of your life tick by.\n\nThere are others (stopwatch, pulsometer, battery voltage), but the important thing isn’t the apps that come with Sensor Watch. The important thing is that Sensor Watch is open source and easily hackable, which means you can write the apps that make sense for YOU. Do you want an astronomy face that can show you moon phase and predict satellite passes? A transit face programmed with train arrivals for your nearest subway station? An astrology face that can tell you if Mercury is in retrograde? These are all apps that you could write for Sensor Watch.\n\nIn addition, the sensor board in Sensor Watch is modular and swappable, so if you want a different kind of sensor than the one that’s on the watch? You can build a sensor board of your own, and sense the things that matter to you.\n\n [![](/img/bd84/sensor-watch-modes-02_jpg_md-xl.jpg)](/img/bd84/sensor-watch-modes-02.jpg) \n\n# Style, Meet Sensors\n\nThe Casio F-91W is iconic for any number of reasons: it’s affordable and durable, and it’s come in many colors over the years, which means you’ll almost certainly find one that matches your style. It’s also small! At just 34 mm in diameter, it’s smaller than any smart watch, and can feel at home on any wrist. This small size, though, leads to a challenge when repurposing the watch to turn it into a Sensor Watch: how can we fit useful sensor technology into such a small package?\n\nThe answer lies in the nine-pin flex PCB connector at the bottom of the Sensor Watch board. By plugging a miniature sensor board in to the Sensor Watch main board, you can add whichever sensors make the most sense for your use case. This makes Sensor Watch far more versatile than a fitness tracker that can only track motion, or a compass watch that can only sense direction.\n\n [![](/img/3619/sensor-watch-angle-01_jpg_md-xl.jpg)](/img/3619/sensor-watch-angle-01.jpg) \n\nA temperature-sensor board is currently available for sale, but you could, instead, use a phototransistor board for light metering, a microphone for tracking noise exposure, or, yes, an accelerometer for activity tracking. Sensor Watch leaves a 5.7 × 5.7 × 1 mm area free for whatever sensors you want to add. It’s a small volume, but modern MEMS technology allows smaller sensors to do more than ever before.\n\nIn the spirit of open source hardware, several of these sensor boards are already [posted in the Sensor Watch repository](https://github.com/joeycastillo/Sensor-Watch/tree/main/PCB/Sensor%20Boards), and the hope is that as we build more of a community around Sensor Watch, folks will design additional sensor boards to give their Sensor Watch even more interesting capabilities.\n\n# The Microchip SAM L22: Big Power in a Small Package\n\nThe SAM L22 microcontroller at the heart of Sensor Watch is an ARM Cortex M0+ chip with 256 KB of Flash and 32 KB of RAM, running at up to 32 MHz. It’s similar in many ways to the SAM D21 you’d find in a Feather M0 or Arduino Zero, with many of the same versatile peripherals:\n\n-   An integrated USB peripheral and UF2 bootloader let you plug the board into your computer and program it by dragging firmware onto it, just like a thumb drive.\n-   The real-time clock peripheral, paired with a 32.768 KHz crystal, allow for accurate timekeeping and configurable wake-up options.\n-   The integrated 12-bit ADC lets you read analog values from any of the five GPIO pins on a sensor board, with oversampling to 16 bits of resolution.\n-   The SERCOM peripheral lets you easily communicate with I2C, SPI or UART-oriented devices on a sensor board.\n-   Four timer/counter peripherals allow for versatile use cases like pulse-width modulation, frequency counting and configurable periodic callbacks. This is in addition to the TCC peripheral that drives the red/green backlight **¹** and piezo buzzer **²**.\n\n**¹** _Red/Green backlight is Red/Blue on limited-edition boards._  \n**²** _The piezo buzzer is the only piece that requires soldering. You will need to remove a metal piece from your donor F-91W and solder it to the Sensor Watch board. If you don’t feel comfortable doing this, all other features of Sensor Watch will function identically; the watch just won’t beep._\n\n [![](/img/c394/sensor-watch-front-back-01_jpg_md-xl.jpg)](/img/c394/sensor-watch-front-back-01.jpg) \n\n# The Segment LCD: a Low-Power Hero\n\nIn addition to these familiar peripherals, the SAM L22 packs one less familiar one: a segment LCD controller. This controller speaks the native language of the F-91W’s display glass, and it’s the key to the unique low power capabilities of Sensor Watch:\n\n-   Unlike a TFT, with its layers of color filters, the segment LCD glass is readable without backlighting.\n-   Unlike an OLED, which relies on light-emitting diodes, segments do not consume significantly more power when on versus off.\n-   Unlike an e-paper display, which requires current to move ink particles, updating the segment LCD glass does not consume significantly more current than keeping an image on the screen.\n\nThis is not to say there aren’t tradeoffs: the segment LCD in the F-91W was only designed to display the time, so [not every number or letter works in every position](https://joeycastillo.github.io/Sensor-Watch-Documentation/wig/display.html). It also cannot display arbitrary images like an e-paper display or LCD matrix. Still, with a bit of creativity, you can create a watch face that displays quite a lot of information, and carry it with you all year long.\n\n# Features & Specifications\n\n-   ARM Cortex M0+ microcontroller running at up to 32 MHz\n-   256 KB of on-chip Flash, with up to 16 KB EEPROM emulation area\n-   32 KB of RAM with full retention in low-power standby mode\n-   32.768 kHz crystal for real-time clock functionality with alarm support\n-   Red & green PWM’able LED backlight (red & blue on limited-edition boards)\n-   On-board USB Micro B connector\n-   Reset button with double-tap UF2 bootloader\n-   Nine-pin flex PCB connector for sensor boards\n-   Controller for ten digit segment LCD, plus five indicator segments\n-   Edge-plated contacts for three interrupt-capable buttons\n-   Connection pad for piezo buzzer (requires light soldering)\n-   Open Source\n\nThe 9-pin sensor board connector offers a lot of additional functionality that you can make use of on a sensor board:\n\n-   3V power (nominal voltage from a CR2016 coin cell, can drop to ~2.5V near end of life)\n-   An I²C interface with built-in pull-up resistors\n-   Five general purpose IO pins, which can be configured as:\n    -   Five analog inputs\n    -   Five interrupt-capable digital inputs, with internal pull-up or pull-down resistors\n    -   Five digital outputs\n    -   SPI controller (with one spare analog / GPIO pin leftover)\n    -   One UART TX/RX pair (with three GPIO leftover)\n    -   Up to four PWM pins on two independent TC instances\n    -   Two external wake inputs that can wake from the ultra-low-power BACKUP mode\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-19T20:50:12.436Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Server Requirements",
      "content": "node.js\nLLM - Kobold AI, with API end point\n\n# Stable Diffusion\nSD - Stable diffusion, automatic1111, but also command line\n\nLoad Model from API, \nQuery Model from API\nGet Status of call from API, \n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-10-03T17:23:12.751Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Shapley_value",
      "content": "> The Shapley value is a solution concept in cooperative game theory. It was named in honor of Lloyd Shapley, who introduced it in 1951 and won the Nobel Memorial Prize in Economic Sciences for it in 2012. To each cooperative game it assigns a unique distribution (among the players) of a total surplus generated by the coalition of all players. The Shapley value is characterized by a collection of desirable properties. Hart (1989) provides a survey of the subject.The setup is as follows: a coalition of players cooperates, and obtains a certain overall gain from that cooperation. Since some players may contribute more to the coalition than others or may possess different bargaining power (for example threatening to destroy the whole surplus), what final distribution of generated surplus among the players should arise in any particular game? Or phrased differently: how important is each player to the overall cooperation, and what payoff can he or she reasonably expect? The Shapley value provides one possible answer to this question.\n>\n> For cost-sharing games with concave cost functions, the optimal cost-sharing rule that optimizes the price of anarchy, followed by the price of stability, is precisely the Shapley value cost-sharing rule. (A symmetrical statement is similarly valid for utility-sharing games with convex utility functions.) In mechanism design, this means that the Shapley value solution concept is optimal for these sets of games.\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Shapley%20value)\n\n\n![[Pasted image 20221003102311.png]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-05-14T18:13:53.258Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Shell Script that takes a variable",
      "content": "```sh\n#!/bin/bash\n\n# Check if an argument was provided\nif [ $# -eq 0 ]; then\n  echo \"Usage: $0 <string> <command>\"\n  exit 1\nfi\n\n# Extract the string and command from the arguments\nstring=$1\ncommand=\"${@:2}\"\n\n# Run the command with the string\necho \"Running command: $command $string\"\neval \"$command $string\"\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-08-03T21:17:07.177Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Shell",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-11T03:09:30.565Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Simple Bearer Token Workflow",
      "content": "https://github.com/lindseyjohnasterius/simple-bearer-token-workflow\n\nnode.js server:\n\n```js\nconst express = require('express');\nconst dotenv = require('dotenv');\ndotenv.config();\n\nconst app = express();\nconst cors = require('cors');\n\napp.use(cors())\n\n\n// Middleware to validate bearer token\nconst authenticateToken = (req, res, next) => {\n  const token = req.headers.authorization;\n  const expectedToken = `Bearer ${process.env.BEARER_TOKEN}`;\n\n  if (token === expectedToken) {\n    next(); // Token is valid, proceed to the next middleware or route handler\n  } else {\n    res.sendStatus(401); // Unauthorized\n  }\n};\n\n// Apply the middleware to all routes\napp.use(authenticateToken);\n\n// Example endpoint that requires bearer token\napp.get('/protected', (req, res) => {\n  res.send('Access granted to protected endpoint!');\n});\n\n// Example endpoint that requires bearer token\napp.get('/private', (req, res) => {\n  res.send('Access granted to private endpoint!');\n});\n\n// Start the server\napp.listen(process.env.PORT, () => {\n  console.log('Server is running on port 3000');\n});\n\n```\n\n\nlogin.html\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  <title>Login</title>\n  <script type=\"module\">\n\n    function getValuesFromURL(URL = window.location.href ){\n      const search_params = new URLSearchParams(URL)\n      let options = {\n      }\n      for (const [key, unparsed_value] of search_params) {\n        if(key !== window.location.origin + window.location.pathname + '?' ){\n          try {\n            const value = JSON.parse(decodeURI(unparsed_value))\n            options[key] = value\n          } catch {\n            options[key] = decodeURI(unparsed_value)\n          }\n        }\n      }\n      return options\n    }\n\n    function setURLValues(obj){\n      let url = window.location.origin + window.location.pathname + '?'\n      Object.keys(obj).forEach(key => {\n        url += `&${key}=${obj[key]}`\n      })\n      history.pushState(obj, '', url)\n    }\n\n    function clearURLValues(){\n      window.history.pushState({}, document.title, window.location.pathname);\n    }\n\n\n\n\n\n    /*\n      \n      Get API Keys from URL. If there is not a value in link, check local storage. \n      If local storage does not have an API key throw an error\n\n    */\n\n    const app_name = 'hans'\n\n    async function init(){\n\n      const url_values = getValuesFromURL();\n\n\n      let api_key = null\n      if(url_values[app_name]){\n        api_key = url_values[app_name];\n        localStorage.setItem(app_name, decodeURIComponent(url_values[app_name]));\n        console.log(api_key)\n      } else {\n        api_key = localStorage.getItem(app_name);\n        if(api_key === null){\n          return alert(\"API KEY REQUIRED.\")\n        }\n      }\n\n      if(url_values.server_address){\n        const server_address = url_values.server_address; \n        localStorage.setItem('server_address', decodeURIComponent(server_address))\n      } else {\n        server_address = localStorage.getItem('server_address');\n        if(server_address === null){\n          return alert(\"Server Address Required\");\n        }\n      }\n\n      clearURLValues();\n      window.location.replace(\"/\");\n\n    } // end init\n\n    init();\n\n  </script>\n</head>\n<body>\n\n</body>\n</html>\n```\n\nSet Url Values.html\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <title>Dynamic Key/Value Inputs</title>\n  <style>\n\n    body {\n      font-family: monospace;\n    }\n\n    button {\n      margin: 0.25em;\n    }\n\n    ul {\n      \n    }\n\n\n  </style>\n</head>\n<body>\n  <h1>Dynamic Key/Value Inputs</h1>\n  \n  <form id=\"inputForm\">\n    <div>\n      <label for=\"keyInput\">Key:</label>\n      <input type=\"text\" id=\"keyInput\">\n      <label for=\"valueInput\">Value:</label>\n      <input type=\"text\" id=\"valueInput\">\n      <button type=\"button\" onclick=\"addInput()\">Add</button>\n    </div>\n  </form>\n  \n  <ul id=\"inputList\"></ul>\n\n  <button type=\"button\" onclick=\"addUrl()\">Submit</button>\n\n  <script>\n\n    function setURLValues (obj){\n      let url = window.location.origin + '/login.html' + '?'\n      Object.keys(obj).forEach(key => {\n        url += `&${encodeURIComponent(key)}=${encodeURIComponent(obj[key])}`\n      })\n      history.pushState(obj, '', url)\n    }\n\n    // Function to add a new key/value input to the list\n    function addInput() {\n      var keyInput = document.getElementById(\"keyInput\").value;\n      var valueInput = document.getElementById(\"valueInput\").value;\n\n      if (keyInput !== '' && valueInput !== '') {\n        var listItem = document.createElement(\"li\");\n        listItem.innerHTML = `<span class=\"key\">${keyInput}</span>:<span class=\"value\">${valueInput}</value>`;\n        \n        var deleteButton = document.createElement(\"button\");\n        deleteButton.innerHTML = \"Delete\";\n        deleteButton.onclick = function() {\n          listItem.parentNode.removeChild(listItem);\n        };\n\n        listItem.appendChild(deleteButton);\n        document.getElementById(\"inputList\").appendChild(listItem);\n\n        // Clear input fields\n        document.getElementById(\"keyInput\").value = '';\n        document.getElementById(\"valueInput\").value = '';\n      }\n    }\n\n    function addUrl(){\n      const lis = [...document.querySelectorAll('li')];\n      let new_url_object = {}\n      lis.forEach(li => {\n        const key = li.querySelector('.key').innerText; \n        const value = li.querySelector('.value').innerText; \n        new_url_object[key] = value;\n      });\n\n      setURLValues(new_url_object);\n    }\n  </script>\n</body>\n</html>\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-03-09T18:57:10.981Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Simple Modal Component",
      "content": "https://stackoverflow.com/questions/1842308/having-stylesheet-link-in-body\n\n\n![[Embed CSS with Javascript]]\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-09T20:20:50.964Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "SlideShow Code",
      "content": "```js\nconst fs = require('fs');\nconst path = require('path');\n\n// Function to get all image files in a folder and its subfolders\nfunction getAllImageFiles(folderPath) {\n  const imageExtensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp'];\n  let imageFiles = [];\n\n  function traverseDirectory(dirPath) {\n    const files = fs.readdirSync(dirPath);\n    for (const file of files) {\n      const fullPath = path.join(dirPath, file);\n      const stat = fs.statSync(fullPath);\n      if (stat.isDirectory()) {\n        traverseDirectory(fullPath);\n      } else {\n        const ext = path.extname(fullPath).toLowerCase();\n        if (imageExtensions.includes(ext)) {\n          imageFiles.push(fullPath);\n        }\n      }\n    }\n  }\n\n  traverseDirectory(folderPath);\n  return imageFiles;\n}\n\n// Function to write the image paths to a JSON file\nfunction writeImagePathsToJSON(imageFiles, outputPath) {\n  const jsonData = JSON.stringify(imageFiles, null, 2);\n  fs.writeFileSync(outputPath, jsonData, 'utf8');\n}\n\n// Main function to run the script\nfunction main() {\n  if (process.argv.length !== 3) {\n    console.error('Usage: node script.js folder_path');\n    return;\n  }\n\n  const folderPath = '.';\n  const outputPath = './image_paths.json'; // Output JSON file path (current directory)\n\n  const imageFiles = getAllImageFiles(folderPath);\n  writeImagePathsToJSON(imageFiles, outputPath);\n\n  console.log(`JSON file containing image paths has been generated: ${outputPath}`);\n}\n\n// Call the main function\nmain();\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-11-03T01:53:15.783Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Small World Networks",
      "content": "![[small-world-networks.pdf]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-11-07T22:33:03.161Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Stable Diffusion Component",
      "content": "```js\n/*\n  stableDiffusion\n\n  <stable-diffusion></stable-diffusion>\n\n  See https://javascript.info/custom-elements for more information\n*/\n\nfunction copyToClipboard(text) {\n  const type = 'text/plain';\n  const blob = new Blob([text], {type});\n  const data = [new ClipboardItem({[type]: blob})];\n  navigator.clipboard.write(data).then(function() {\n    console.log('Copied to clipboard!');\n  }, function() {\n    console.log('Failed to copy to clipboard.');\n  });\n}\n\nclass SDQuery extends HTMLElement {\n  connectedCallback(){\n\n    this.status_container = document.createElement('details'); \n    this.status_container.setAttribute('open', true);\n    this.status_container.classList.add('sd-status-container');\n    this.status = document.createElement('div'); \n    this.status.classList.add('sd-query-status');\n    this.status.addEventListener('click', (e) => {\n      copyToClipboard(this.status.innerText);\n    })\n    this.status.innerText = 'Loading...';\n    this.status_container.classList.add('loading');\n    this.status_container.appendChild(this.status);\n    this.appendChild(this.status_container);\n    this.settings = {\n      enable_hr: false,\n      denoising_strength: 0,\n      firstphase_width: 0,\n      firstphase_height: 0,\n      hr_scale: 2,\n      // hr_upscaler: 'string',\n      hr_second_pass_steps: 0,\n      hr_resize_x: 0,\n      hr_resize_y: 0,\n      prompt: '',\n      seed: -1,\n      subseed: -1,\n      subseed_strength: 0,\n      seed_resize_from_h: -1,\n      seed_resize_from_w: -1,\n      sampler_name: 'DPM++ SDE Karras',\n      batch_size: 1,\n      n_iter: 1,\n      steps: 20,\n      cfg_scale: 7.5,\n      width: 512,\n      height: 512,\n      restore_faces: false,\n      tiling: false,\n      do_not_save_samples: false,\n      do_not_save_grid: false,\n      negative_prompt: 'easynegative, Unspeakable-Horrors-Composition-4v, badhandv4, ng_deepnegative_v1_75t,  (worst quality:2), (low quality:2), (normal quality:2), lowres, ((monochrome)), ((grayscale)), watermark, sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, glare',\n      eta: 0,\n      s_churn: 0,\n      s_tmax: 0,\n      s_tmin: 0,\n      s_noise: 1,\n      override_settings: {},\n      override_settings_restore_afterwards: true,\n      script_args: [],\n      // sampler_index: 'Euler',\n      // script_name: 'string',\n      send_images: true,\n      save_images: false,\n      alwayson_scripts: {}\n    }\n\n    Object.keys(this.settings).forEach(key => {\n      const val = this.getAttribute(key);\n      if(val !== null){\n        this.settings[key] = val\n      }\n    });\n\n    this.init();\n\n    this.style.width = this.settings.width + 'px';\n    this.style.height = this.settings.height + 'px';\n  }\n\n  async init(){\n    this.status.innerText = `Querying Server with prompt ${this.settings.prompt}`\n    if(this.settings.prompt.length < 1){\n      this.status.innerText = 'No prompt. Cancelling.'\n      this.status_container.classList.remove('loading');\n      this.sttaus.classList.add('error');\n      return\n    }\n    const res = await this.querySDServer();\n    if(res.detail === \"Method Not Allowed\"){\n      console.warn(res)\n      this.status.innerText = \"Method not allowed\";\n      this.status.classList.add('error');\n\n    };\n    this.handleData(res)\n  }\n\n\n\n  /*\n  /\n  /  \n  /\n  */\n  // What happens when Images are loaded\n\n  handleData(res){\n    [...this.querySelectorAll('img')].forEach(sdi => sdi.remove());\n    if(!res){\n      return\n    }\n    this.status.innerText = this.settings.prompt;\n    this.status_container.classList.remove('loading');\n    this.status.classList.remove('loading');\n    this.status_container.removeAttribute('open');\n\n\n    res.images.forEach(url => {\n      const uuid = self.crypto.randomUUID();\n      const img_data = \"data:image/jpeg;base64,\" + url;\n      const img = new Image();\n      img.classList.add('ai-image');\n      img.src = img_data;\n      this.prepend(img);\n    });\n    const imgs = res.images.map(url => {\n      return \"data:image/jpeg;base64,\" + url;\n    })\n\n    const loaded_event = new CustomEvent(\"IMAGES-LOADED\", {\n      detail: {images:imgs}\n    })\n\n    this.dispatchEvent(loaded_event);\n  }\n\n  async querySDServer(){\n    this.status.classList.add('loading');\n\n    try {\n    const response = await fetch(\"/stable-diffusion\", {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify(this.settings),\n      });\n      const data = await response.json();\n      return data;\n    } catch(e){\n      console.log(e);\n      this.status.classList.remove('loading');\n      this.status.classList.add('error');\n      this.status.innerText = 'ERROR:'+JSON.stringify(e);\n    }\n  }\n\n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n    switch(name){\n      default:\n    }\n  }\n\n}\n\ncustomElements.define('stable-diffusion', SDQuery);\n\n\n\nclass SDUI extends HTMLElement {\n  connectedCallback(){\n    const windowHeight = window.innerHeight;\n    const windowWidth = window.innerWidth;\n\n    this.innerHTML = `\n      <iframe \n        width=\"${windowHeight}\" \n        height=\"${windowWidth}\" \n        src=\"http://localhost:7860\"></iframe>\n    `\n  }\n}\n\ncustomElements.define('sd-ui', SDUI)\n```\n\n# Route\n```js\n/*\n\n  stableDiffusion Server Code\n\n  To create an end point, open up hans-js and add... blah\n\n  @todo: write tutorial \n\n\n*/\n\nrequire('dotenv').config()\n\nconst sd_server = process.env.STABLE_DIFFUSION_SERVER\n\nasync function querySD(data){\n  console.log(data, sd_server);\n  const url = sd_server;\n  const options = {\n    method: 'POST',\n    headers: {\n      'accept': 'application/json',\n      'Content-Type': 'application/json'\n    },\n    body: JSON.stringify(data)\n  }\n  try {\n    const response = await fetch(url, options);\n    const data = await response.json();\n    return data\n  } catch (error) {\n    console.log(error);\n    return console.error(error);\n  }\n}\n\n\nmodule.exports = function(app) {\n\n  app.post('/stable-diffusion', async function(req, res) {\n    const data = req.body;\n    querySD(data).then(sd_image => {\n      res.json(sd_image);\n    }).catch(error => {\n      console.log(error);\n      res.status(500).send(error);\n    })\n  });\n};\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-13T20:12:41.856Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Stable Diffusion Query",
      "content": "```js\napp.post('/querySD', async (req, res) => {\n  const data = req.body;\n\n  console.log(data);\n\n  const url = 'http://localhost:7860/sdapi/v1/txt2img';\n  const options = {\n    method: 'POST',\n    headers: {\n      'accept': 'application/json',\n      'Content-Type': 'application/json'\n    },\n    body: JSON.stringify(data)\n  }\n\n  try {\n    const response = await fetch(url, options);\n    const data = await response.json();\n    res.json(data);\n  } catch (error) {\n    console.error(error);\n    res.status(500).send('Internal server error');\n  }\n});\n\n```\n\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  <title>Query SD</title>\n  <script src=\"./components/sd-query.js\"></script>\n  <script src=\"./components/easy-form-component.js\"></script>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"./styles/style.css\">\n  <script>\n    let lora_list = localStorage.getItem('lora-models'); \n    if(lora_list === null){\n      lora_list = []\n    } else {\n      lora_list = JSON.parse(lora_list);\n    }\n    \n    class LoraList extends HTMLElement {\n      connectedCallback(){\n\n        this.innerHTML = `<h1>Lora</h1>`\n        if(lora_list.length < 1) return\n        lora_list.forEach(list_item => {\n\n          const name = list_item.lora_name\n          const container = document.createElement('div');\n          container.setAttribute('id', list_item.id);\n          const checkbox = document.createElement('input');\n          checkbox.setAttribute('type', 'checkbox'); \n          checkbox.setAttribute('name', name);\n          checkbox.classList.add('lora-name');\n\n          const label = document.createElement('label');\n          label.innerText = name;\n          const value = document.createElement('input');\n          value.setAttribute('type', 'number');\n          value.setAttribute('name', name);\n          value.setAttribute('value', 1);\n          value.setAttribute('step', 0.1);\n          value.classList.add('lora-value');\n\n\n\n          container.appendChild(checkbox);\n          container.appendChild(label);\n          container.appendChild(value);\n\n          const trigger_words = document.createElement('ul');\n          trigger_words.innerHTML = `\n            <li><h3>Trigger Words</h3></li>\n          `\n          list_item.trigger_words.forEach(trigger_word => {\n            const li = document.createElement('li'); \n            li.innerText = trigger_word;\n            const trigger_word_checkbox = document.createElement('input');\n            trigger_word_checkbox.setAttribute('type', 'checkbox');\n            trigger_word_checkbox.setAttribute('name', trigger_word);\n            trigger_word_checkbox.classList.add('trigger_word');\n            li.appendChild(trigger_word_checkbox);\n            trigger_words.appendChild(li);\n          });\n          container.appendChild(trigger_words);\n\n\n          this.appendChild(container);\n\n        })\n      }    \n    }\n    \n    customElements.define('lora-list', LoraList)\n    \n    \n    \n\n\n  </script>\n</head>\n<body>\n  <nav>\n  <easy-form id=\"easy_form\">\n    <label>\n      <input name=\"prompt\" type=\"text\" placeholder=\"Query Stable Diffusion\">\n    </label>\n\n    <details>\n      <summary>More</summary>\n    <label>\n      Negative Prompt\n      <input name=\"negative_prompt\" type=\"text\" value=\"easynegative Unspeakable-Horrors-Composition-4v ng_deepnegative_v1_75t badhandv4\">\n    </label>\n\n    <label>\n      Width\n      <input type=\"number\" name=\"width\" value=\"512\" step=\"64\">\n    </label>\n\n    <label>\n      Height\n      <input type=\"number\" name=\"height\" value=\"512\" step=\"64\">\n    </label>\n    </details>\n  </easy-form>\n  <details>\n    <summary>Lora</summary>\n  <lora-list id=\"lora_list_container\"></lora-list>\n  <a href=\"/add-lora.html\">Add a new Lora</a>\n</details>\n\n      <input type=\"submit\" id=\"submit_button\" name=\"submit\">\n\n  <div id=\"sd_status\"></div>\n</nav>\n  <div id=\"sd_output\"></div>\n  <script type=\"text/javascript\">\n      submit_button.addEventListener('click', (e) => {\n        e.preventDefault();\n\n        const settings = easy_form.getFormValues();\n        \n        const loras = [...lora_list_container.querySelectorAll('div')];\n        const prompts = [settings.prompt]\n\n        // Steps through LORA menu, builds individual prompts\n        loras.forEach(lora => {\n          if(lora.querySelector('.lora-name').checked){\n            const lora_data = lora_list.find(l => l.id === lora.id);\n            const name = lora_data.lora_name;\n            const strength = lora.querySelector('.lora-value').value\n            const trigger_words = [];\n            [...lora.querySelectorAll('.trigger_word')].forEach(trigger_word => {\n              if(trigger_word.checked){\n                trigger_words.push(trigger_word.name)\n              }\n            })\n\n            const lora_prompt = ` <lora:${name}:${strength}> ${trigger_words.join(\" \")} `\n            prompts.push(lora_prompt);\n          }\n        })\n\n        settings.prompt = prompts.join(\" \");\n\n        const sd_query = document.createElement('sd-query');\n        Object.keys(settings).forEach(key => {\n          sd_query.setAttribute(key, settings[key]);\n        });\n\n        sd_output.prepend(sd_query);\n\n      })\n  </script>\n</body>\n</html>\n```\n\n\n```js\n\n\n\nfunction copyToClipboard(text) {\n  const type = 'text/plain';\n  const blob = new Blob([text], {type});\n  const data = [new ClipboardItem({[type]: blob})];\n  navigator.clipboard.write(data).then(function() {\n    console.log('Copied to clipboard!');\n  }, function() {\n    console.log('Failed to copy to clipboard.');\n  });\n}\n\n\n    \n    class SDQuery extends HTMLElement {\n      connectedCallback(){\n\n        this.status = document.createElement('div'); \n        this.status.classList.add('sd-query-status');\n        this.status.addEventListener('click', (e) => {\n          copyToClipboard(this.status.innerText);\n        })\n        this.status.innerText = 'Loading...';\n        this.appendChild(this.status);\n\n        this.settings = {\n          enable_hr: false,\n          denoising_strength: 0,\n          firstphase_width: 0,\n          firstphase_height: 0,\n          hr_scale: 2,\n          // hr_upscaler: 'string',\n          hr_second_pass_steps: 0,\n          hr_resize_x: 0,\n          hr_resize_y: 0,\n          prompt: '',\n          seed: -1,\n          subseed: -1,\n          subseed_strength: 0,\n          seed_resize_from_h: -1,\n          seed_resize_from_w: -1,\n          sampler_name: 'DPM++ SDE Karras',\n          batch_size: 1,\n          n_iter: 1,\n          steps: 30,\n          cfg_scale: 7.5,\n          width: 512,\n          height: 512,\n          restore_faces: false,\n          tiling: false,\n          do_not_save_samples: false,\n          do_not_save_grid: false,\n          negative_prompt: 'easynegative, Unspeakable-Horrors-Composition-4v, badhandv4, ng_deepnegative_v1_75t,  (worst quality:2), (low quality:2), (normal quality:2), lowres, ((monochrome)), ((grayscale)), watermark, sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, glare',\n          eta: 0,\n          s_churn: 0,\n          s_tmax: 0,\n          s_tmin: 0,\n          s_noise: 1,\n          override_settings: {},\n          override_settings_restore_afterwards: true,\n          script_args: [],\n          // sampler_index: 'Euler',\n          // script_name: 'string',\n          send_images: true,\n          save_images: false,\n          alwayson_scripts: {}\n        }\n\n        Object.keys(this.settings).forEach(key => {\n          const val = this.getAttribute(key);\n          if(val !== null){\n            this.settings[key] = val\n          }\n        });\n\n        this.init();\n\n        this.style.width = this.settings.width + 'px';\n        this.style.height = this.settings.height + 'px';\n      }\n\n      async init(){\n        this.status.innerText = `Querying Server with prompt ${this.settings.prompt}`\n\n        if(this.settings.prompt.length < 1){\n          this.status.innerText = 'No prompt. Cancelling.'\n          return\n        }\n        const res = await this.querySDServer();\n        this.handleData(res)\n      }\n\n      handleData(res){\n        this.status.innerText = this.settings.prompt;\n        res.images.forEach(url => {\n          const uuid = self.crypto.randomUUID();\n          const img_data = \"data:image/jpeg;base64,\" + url;\n          const download = document.createElement('a'); \n          download.setAttribute('download', uuid + '.png');\n          download.setAttribute('href', img_data)\n          const img = new Image();\n          img.classList.add('ai-image');\n          img.src = img_data;\n          download.appendChild(img);\n          this.prepend(download);\n        })\n      }\n\n      async querySDServer(){\n        const token = localStorage.getItem('hans');\n        const server_address = localStorage.getItem('server_address');\n\n        const response = await fetch(server_address + \"/querySD\", {\n          method: \"POST\",\n          headers: {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": `Bearer ${token}`,\n          },\n          body: JSON.stringify(this.settings),\n        });\n        const data = await response.json();\n        return data;\n      }\n    \n      static get observedAttributes() {\n        return [];\n      }\n    \n      attributeChangedCallback(name, old_value, new_value){\n        switch(name){\n          default:\n        }\n      }\n    \n    }\n    \n    customElements.define('sd-query', SDQuery)\n    \n    \n    \n```\n\nAdd Lora\n\n```html\n\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  <script type=\"text/javascript\" src=\"./components/easy-form-component.js\"></script>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"./styles/style.css\">\n  <title>Add Lora</title>\n</head>\n<body>\n\n\n  <easy-form id=\"easy_form\">\n    <input name=\"lora_name\" type=\"text\" placeholder=\"Lora Name\">\n    <input name=\"trigger_words\" type=\"text\" placeholder=\"trigger words, comma separated\">\n    <label>Notes</label>\n    <textarea name=\"lora_notes\" name=\"Lora Description\"></textarea>\n  </easy-form>\n  <button onclick=\"handleForm()\">Submit</button>\n\n  <ul id=\"lora_models_el\"></ul>\n\n  <script>\n\n    let lora_models = localStorage.getItem('lora-models');\n    if(lora_models !== null){\n      lora_models = JSON.parse(lora_models);\n      console.log(lora_models);\n    } else {\n      lora_models = []\n    }\n\n    function addLoraModel(lm){\n      const li = document.createElement('li');\n      li.setAttribute('id', lm.id);\n      li.innerHTML = `\n        <h3>${lm.lora_name}</h3>\n        <div>${JSON.stringify(lm.trigger_words)}</div>\n        <div>${lm.lora_notes}</div>\n      `\n      const delete_button = document.createElement('button');\n      delete_button.innerText = 'delete'; \n      delete_button.addEventListener('click', (e) => {\n        console.log(\"delete\", li);\n        li.remove();\n        lora_models = lora_models.filter(lms => lms.id !== lm.id);\n        localStorage.setItem('lora-models', JSON.stringify(lora_models));\n      });\n      li.appendChild(delete_button);\n\n      lora_models_el.appendChild(li);\n    }\n\n\n    lora_models.forEach(addLoraModel);\n\n\n\n\n    function handleForm(){\n      const values = easy_form.getFormValues(); \n      values.id = crypto.randomUUID();\n      values.trigger_words = values.trigger_words.split(',').map(t => t.trim());\n      lora_models.push(values); \n      localStorage.setItem('lora-models', JSON.stringify(lora_models));\n      addLoraModel(values);\n    }\n  </script>\n\n\n</body>\n</html>\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-09-12T21:42:07.314Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Stable Diffusion",
      "content": "\n\nhttps://github.com/BelieveDiffusion/tutorials/blob/main/consistent_character_embedding/README.md\n\n\n# Creating a Consistent Character as a Textual Inversion Embedding with Stable Diffusion\n\nOne of the great things about generating images with Stable Diffusion (\"SD\") is the sheer variety and flexibility of images it can output. However, some times it can be useful to get a _consistent_ output, where multiple images contain the \"same person\" in a variety of permutations.\n\nTo that end, I've spent some time working on a technique for training Stable Diffusion to generate consistent made-up characters whose faces, bodies, and hair look essentially the same whenever you use them in a prompt. This tutorial is a description of the approach I use.\n\n## LastName characters\n\nYou can see [all of the \"LastName\" characters I've trained with this method on CivitAI](https://civitai.com/user/BelieveDiffusion). And credit where it's due - they were inspired by the [Nobody series by Zovya](https://civitai.com/tag/znobody). Thank you for the inspiration, Zovya!\n\n## Goals\n\nIf all goes to plan, by the end of this tutorial you will have created a Stable Diffusion [Textual Inversion embedding](https://arxiv.org/abs/2208.01618) that can reliably recreate a consistent character across multiple poses, SD checkpoints, hair styles, body types, and prompts.\n\n## Process\n\nThe creation process is split into five steps:\n\n1. Generating input images\n2. Filtering input images\n3. Tagging input images\n4. Training an embedding on the input images\n5. Choosing and validating a particular iteration of the trained embedding\n\n# 1. Generating input images\n\nTraining an AI is a classic example of \"[garbage in, garbage out](https://en.wikipedia.org/wiki/Garbage_in,_garbage_out)\". The better the input images you provide, the better the output you'll get. To that end, I use SD to generate the input images for the character I'm going to train. That way, I can generate hundreds of permutations based on a description of that character, and pick just the best images to use for the later training.\n\nI generate these images via [Automatic1111's Stable Diffusion web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui) (I'll call it \"A1111\" below). I won't cover how to set up A1111 here; there are lots of tutorials available for getting A1111 up and running. But here's how I customize A1111 for input image generation.\n\n## Choosing a checkpoint for generating your input images\n\nYou can use any SD checkpoint you like to generate your input images, although it's essential that the model you choose has seen (and can generate) representative examples like your character. I've been creating photorealistic made-up characters, and I've found [Deliberate](https://civitai.com/models/4823/deliberate) (v2) to be a good, flexible checkpoint for that, but there are plenty of other models available on sites like [CivitAI](https://civitai.com/).\n\n## Turning on the inclusion of tags in the output filenames\n\nWe're going to define an input prompt for generating our input images, which we'll convert into a training prompt later on. To make that conversion process as easy as possible later, set the \"Images filename pattern\" in A1111's \"Settings > Saving images/grids\" settings to `[seed]-[prompt_spaces]`, and then click \"Apply settings\". This will include the seed and generation prompt in the filename of every generated PNG image we create below.\n\n## Setting up an input prompt\n\nWith your preferred generation checkpoint selected in A1111's web interface, open the `txt2img` tab, and enter a positive prompt with the following format:\n\n```\nan extreme closeup front shot photo of %your character's look% (naked:1.3), %your character's body shape%, %your character's hairstyle%, (neutral gray background:1.3), neutral face expression\n```\n\nFor this input prompt, I've boosted the strength of the `naked` prompt token, to say \"we _really_ want the images to be of the character naked, please.\" I've found this reduces the number of non-naked images we have to throw away later on. Similarly, I've boosted \"neutral gray background\", so that (hopefully) all of the images come out with nothing distracting in the background.\n\nReplace `%your character's look%`, `%your character's body shape%`, and `%your character's hairstyle%` in the prompt with descriptions that will reliably generate a face, body, and hairstyle that match your target character.\n\nBe descriptive, but try to stay within the `75/75` limit of A1111's input prompt box. The fewer essential details you provide, the more chance there is that those details will be present in every image you generate. (And the facial details are the ones that really matter.)\n\nOne tip I've learned from experience: adding a country of origin can really help to hone in on an overall base look, which you can then refine with more details. (A country of origin may also guide your character's overall skin tone, too.)\n\nHere's an example of just-enough-but-not-too-much detail:\n\n```\nan extreme closeup front shot photo of a beautiful 25yo French woman with defined cheekbones, a straight nose, full lips, hazel eyes, chin dimple, square jaw, plucked eyebrows, (naked:1.3), small breasts, toned body, chin length straight black hair in a bob cut with bangs, (neutral gray background:1.3), neutral face expression\n```\n\nFor the negative prompt, try something like this:\n\n```\n(gray hair:1.3), (glasses:1.2), (earrings:1.2), (necklace:1.2), (high heels:1.2), young, loli, teen, child, (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, (mutated hands and fingers:1.4), disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation, tattoo\n```\n\nNote that I've added `(gray hair:1.3)` to the negative prompt there. Boosting `neutral gray background` in the positive prompt has a tendency to cast a gray color over anything else with a specified colored in the prompt, so we need to counterbalance that for the black-colored hair to make sure we get the color we want. (This is a good trick whenever two colors in a prompt start to influence each other in a way you don't want.)\n\nNext, set the following `txt2img` settings in A1111:\n\n- Sampling method: DPM++ 2M Karras\n- Sampling steps: 30\n- Restore Faces: On\n- Tiling: Off\n- Hires. fix: Off\n- Width: 512\n- Height: 512\n- CFG Scale: 7\n- Seed: -1\n\nThese settings should give good-quality outputs, at the expense of slightly longer generation times. (But remember: garbage in, garbage out.)\n\n### Why naked and neutral?\n\nI like to make input images that are as \"neutral\" as possible, so that SD learns the essence of them without also learning things that we might want to change for variety in image generation prompts. So, I try to avoid generating images that contain things like glasses, earrings, necklaces, and so on, that might bias later generation to include those same items.\n\nI also choose to generate the training input images without clothes, because I want to train the base concept of a hypothetical human that I can then add any clothing or accessories to via custom prompts later on. SD has seen a lot of humans wearing a lot of different clothes, but it has never seen your custom character naked, so that's what we'll give it as input, for the most flexibility.\n\nI also use a neutral gray background in all my input images, to keep the training focused on the character on the foreground. (We'll tell SD that we used a neutral gray background later on, so that it doesn't learn \"neutral gray background\" as part of the character's attributes.)\n\n## Testing the input prompt\n\nWith the settings above in place, generate a small set of test images to see how well your prompt performs. I usually set `Batch count` to 2 and `Batch size` to 4 (with a `Seed` of `-1`), then hit Generate, to create eight test images. This helps me to see if the prompt creates a consistent (enough) output across multiple seeds.\n\nNote that even with a detailed description like the one above, your character might not (yet) look entirely consistent between all of the images. That's okay - we will improve that by filtering the images later, and also by averaging the character's visual characteristics through training. But you still want to be seeing a recognizable-enough consistency at this stage. If you don't, tweak your prompt, and try again.\n\n## Generating permutations\n\nThe next thing we want to do is to generate a whole bunch of variations of our character, with different viewing angles and camera zooms. I mentioned above that SD follows the principle of \"garbage in, garbage out\"; the same also holds for \"variation in, variation out\". In other words, the more of a variety of angles and framings we can show SD of our character, the better SD will become at generating varied angles and framings when we use our character in prompts later on.\n\nTo add this variety, open the `Script` menu, and select `X/Y/Z Plot`. Set `X type` and `Y type` to `Prompt S/R` (\"Prompt search and replace\"), and keep `Z type` as `Nothing`.\n\nIn the `X values` text box, paste the following five zoom levels:\n\n```\nan extreme closeup, a medium closeup, a closeup, a medium shot, a full body\n```\n\nThis tells the A1111 web UI that we want to generate images with five different permutations of our prompt - one that uses the original `an extreme closeup` text from the main prompt box, and four others that replace that text in the prompt with an alternative zoom level. This will give us images of our character from a variety of distances.\n\nIn the `Y values` text box, paste the following five viewing angles:\n\n```\nfront shot, rear angle, side angle, shot from above, low angle shot\n```\n\nThis tells the A1111 web UI that we want to generate images with five more permutations of our prompt - one that uses the original `front shot` viewing angle, and four others that replace that text with an alternative angle for viewing the character.\n\nBecause we have _two_ `Prompt S/R` options set for the script, with five variations in each, we've actually told A1111 to generate 25 permutations of our prompt - one for each combination of framing and viewing angle. This will give us lots of varieties of views of our character to choose from for training.\n\n(Note: I borrowed these zoom levels and viewing angles from the [Unstable Diffusion tagging white paper](https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit).)\n\nFinally, check the box next to `Keep -1 for seeds`, and set `Batch Count` and `Batch Size` both to 4. This will generate 16 images for every permutation of the above, in batches of four for speed. (If your GPU can handle it, you can use a `Batch Count` of 2 and a `Batch Size` of 8 instead.)\n\nHere's how that looks for me with today's A1111 interface:\n\n![Input generation settings](images/step_1_input_generation_settings.jpg)\n\nWith all of the above, we have asked A1111 to generate 400 images (16 x 5 x 5). Hit the `Generate` button, and leave A1111 to do its thing. Maybe make a hot beverage. Step 1 is complete!\n\n# 2. Filtering input images\n\nYou now have 400 _possibly_ good images that _possibly_ look like the character you're trying to create. The next step is to filter these 400 images down to 25 or so _definitely_ good images to train with. Here's how I do that.\n\n## Remove any images that are obviously off-prompt\n\nHere, I'd remove images where the character is clothed, or wearing jewelry, or has a non-matching hairstyle, or has their face off-screen, or the background isn't gray, or the arms / legs are funky, or there are multiple people, or… basically, anything that isn't what we asked for.\n\nHere's an example of some of the images I removed from my set of 400 at this step in the process. Note that I removed any images where the hairstyle did not have the requested bangs (fringe), to ensure consistency in the training images later on. This first pass removed 45 images. (Check the image alt tags for the reasons why I removed them.)\n\n<img src=\"images/step_2a_example_removal_1.png\" width=\"128\" height=\"128\" alt=\"Non-matching hairstyle (doesn't have bangs)\">\n<img src=\"images/step_2a_example_removal_2.png\" width=\"128\" height=\"128\" alt=\"Wrong hair color; not entirely naked\">\n\n## Remove poor quality images\n\nThis time, we're removing images that have wonky faces, or weird-looking nipples, or eyes that Restore Faces kinda messed up, or… images are just not a great photo of a person.\n\nHere's an example of an image I removed at this stage (66 in total).\n\n<img src=\"images/step_2b_example_removal_1.png\" width=\"128\" height=\"128\" alt=\"Mismatched eye shapes\">\n\n## Remove images that don't \"look like the character\"\n\nThis might seem like a weird thing to say. This person doesn't exist! How do we know what they look like?\n\nWell: that's for you to define. There will usually be an overall \"look\" to the character already by this point, and some of the images won't match that look nearly as well as the others. So, filter those images out, and narrow in on the look of the specific person you're trying to create.\n\nFor reference, I cut another 119 images in this step. This was partly because I decided to enforce a slightly more consistent hair length for the bob haircut, and partly because I used this stage to really hone in on the look of the character. Here are some examples of the images I cut. (And I should stress that this is _not_ an exact science.)\n\t\n<img src=\"images/step_2c_example_removal_1.png\" width=\"128\" height=\"128\" alt=\"Didn't match character look; hair too short\">\n<img src=\"images/step_2c_example_removal_2.png\" width=\"128\" height=\"128\" alt=\"Didn't match character look; hair too short\">\n<img src=\"images/step_2c_example_removal_3.png\" width=\"128\" height=\"128\" alt=\"Didn't match character look; hair too short\">\n\n## Fine-tune to just the best images\n\nThis is really just a much more selective take on the second and third steps above, to narrow in to the best of the best images in the input set. I culled a ton of okay-but-not-really-adding-anything images at this step to get me to my final 25.\n\nIdeally, after doing all of the above, you will have 25 good-quality images left that look like the character you're aiming for. Even more ideally, the final set of images will contain a good representation of the five zoom levels and viewing angles too.\n\n# 3. Tagging input images\n\nIn theory, you can just pass all of your input images to the trainer without any tags, and get a textual inversion embedding out the other side. However, a little bit of tweaking and simplifying of the training tags will go a long way to improving the output.\n\n## Naming your character\n\nThe first and most important thing to include in the tagging is the name of the character (and embedding) itself, i.e. the new thing we want SD to learn. Now is a good time to choose a name for your embedding.\n\nYou're looking for a single word (more precisely, a _token_) to name the embedding. This token should be a series of letters and numbers without spaces, which is very unlikely to have shown up on the Internet in the images that SD was trained on. As an example, for my [Antonia LastName character](https://civitai.com/models/19725/antonia-lastname), I chose `antonialastnamesd15`. But the embedding name can be anything, as long as it's not a token that already has a meaning.\n\nIf you're not sure your choice of embedding name / token is unique enough, just try sticking it in a `txt2img` prompt all by itself, and generating a few images with the base SD1.5 checkpoint to see what SD thinks that token already means.\n\nFor the purposes of this tutorial, let's call our character `fr3nchl4dysd15`.\n\n## Removing the character description\n\nFor training, we can remove nearly all of the detail from the generation prompt in order to make a training prompt. Specifically, we can remove the following:\n\n- the character's look\n- the character's body shape\n- the character's hairstyle\n\n…because we want SD to learn that all of those things combined are known as `fr3nchl4dysd15`. Essentially, the thing we want SD to learn - our character - is the sum total of all of those attributes combined. It's kind of like saying we have \"a photo of Marilyn Monroe\", but instead of using the name \"Marilyn Monroe\", we're using the made-up name \"`fr3nchl4dysd15`\".\n\nI should note that training the body shape and hairstyle as part of the character does remove a _little_ bit of the flexibility from the embedding, but I've found that in practice I can still change the body style and hairstyle after the event pretty easily with a more detailed prompt. Including the body shape and hairstyle in the essence of the character makes it much easier and quicker to generate consistent outputs without spending future prompt tokens on the things we want to become part of our character's default style.\n\n## Tidying up the input prompts\n\nOne of the goals of tagging is to tell the training process about all of the things that are _not_ the essence of your character in each image. For example: we generated training images above that had a neutral gray background, but we don't always want our character to appear in images with neutral gray backgrounds. So, we want to keep the \"neutral gray background\" tag when each image is used for training, so that the trainer knows that \"neutral gray background\" is not an attribute of our character.\n\nWe likewise don't want the character to always be naked, so we'll keep \"naked\" in our training prompt too. (We don't need to boost these two terms in the training prompt - we're just stating facts about the generated images).\n\nWe will, however, remove the original viewing angles from the generation prompt, because they're not something we really need SD to learn - they were more to ensure we got a varied set of input images from step 1 above.\n\nWe will likewise remove `neutral face expression` from the training prompt, because we don't need to train SD on this fact - the absence of a facial expression is implicit from its omission from the training prompt. (We only specified it in the generation prompt in step 1 to ensure we got neutral expressions to train on.)\n\nThe one other thing I do keep around in the training prompt is the zoom levels. I don't want SD to learn that `fr3nchl4dysd15` is always in `a closeup photo` (or whatever zoom we ended up with most of). We don't want the embedding to learn a particular zoom level, so we keep it in the training prompt.\n\nThere's one problem with that, however. We may have _asked_ SD to generate `an extreme closeup photo` for some image in our initial set of 400 images, but that's no guarantee that SD actually gave us what we asked for. So, we need to go through each filtered image, and check that the zoom level actually matches the image.\n\n## Tidying up the zooms\n\nIn many cases, the requested zoom level from a prompt in step 1 will match the image we got back. But that's not always the case - I often find that I don't get any `extreme closeup` images from step 1 above, for example.\n\nThe way I approach this tidy-up process is to create (up to) five folders, named after each of the requested zooms, and to copy images into those folders based on the zoom level in their original filename. (This is why we included the generation prompt in the PNG file name above.) I then look through the images in each folder, and move any that don't fit the description of that zoom level to a more appropriate folder.\n\nThere's no exact science to what these zoom definitions mean. Here's how I apply the zooms, working from widest angle to closest:\n\n1. Can you see the knees? If so, it's probably `\"a full body\"` photo.\n2. Can you see the waist? If so, it's probably `\"a medium shot\"` photo.\n3. Can you see the breast area? If so, it's probably `\"a closeup\"` photo.\n4. Can you see the neck area? If so, it's probably `\"a medium closeup\"` photo.\n5. If none of the above, it's probably `\"an extreme closeup\"` photo.\n\nDon't worry too much if you don't have any `extreme closeup` photos, or if your `full body` folder has few or no images in it once you're done. The important thing is that the zoom definitions you do have are correct.\n\n## Renaming the tidied images\n\nWith our (up to) five folders of images now correctly organized, the last step of tagging is to rename those images to provide an essential training prompt (plus a number, to make the filenames unique). How you perform this renaming is up to you; I'm on a Mac, so I use the built-in Automator app.\n\nRename all of the images in each folder to have names like this:\n\n```\na closeup photo of fr3nchl4dysd15 naked, neutral gray background (1).png\na closeup photo of fr3nchl4dysd15 naked, neutral gray background (2).png\n…\na full body photo of fr3nchl4dysd15 naked, neutral gray background (1).png\na full body photo of fr3nchl4dysd15 naked, neutral gray background (2).png\n…\na medium closeup photo of fr3nchl4dysd15 naked, neutral gray background (1).png\na medium closeup photo of fr3nchl4dysd15 naked, neutral gray background (2).png\n…\n```\n\n…and so on. Finally, copy all 25 of the renamed images into a single folder that A1111 can access.\n\nThe names of these renamed images will be used in our training prompt during training, giving training prompts like this:\n\n```\nfr3nchl4dysd15, a closeup photo of fr3nchl4dysd15 naked, neutral gray background (1)\n```\n\nDon't worry about the number in brackets at the end - SD will ignore it.\n\n# 4. Training an embedding on the input images\n\nWith the input images generated and tagged, it's time to train the embedding.\n\nThe first (and easiest to forget) step is to switch A1111's `Stable Diffusion checkpoint` dropdown to the base Stable Diffusion 1.5 checkpoint. (In my case, this is named `model.ckpt`). You always want to train an embedding against the base checkpoint, so that it is as flexible as possible when applied to any other checkpoint that derives from the SD 1.5 base.\n\n## Creating a new Embedding\n\nHead over to the `Train` tab in A1111, and select the `Create embedding` sub-tab. Enter the name of your embedding / character (`fr3nchl4dysd15` in our case) in the `Name` box. This primarily defines the name of the output embedding file on disk, but that filename also defines what you will use in your prompts to generate images with your embedding. (If ever you want to change the token that you use in prompts, just rename the embedding on disk.)\n\nWhen you create the embedding in the A1111 web interface, you also have the option to provide some `Initialization text`. By default this is `*` (an asterisk), which is a wildcard that does not provide any specific starting point for the training. I always change this to `woman`. My understanding is that this sets the starting point of your custom embedding's training to be everything that SD has already learned about the word `woman` from looking at millions of images from the Internet. In other words, it doesn't need to learn the woman-ness of the subject in the images; it just needs to learn the specific person-ness of your female character.\n\nNext up is the `Number of vectors per token` count. I always set this to `8`, which seems to work well for the number of input images I use. As I understand it, this is kind of the \"capacity\" of the embedding to store learned details of your character. Too low a vector count, and the embedding struggles to capture the essence of the character; too high a count, and it learns too much. (The count also seems to be related to, or at least sensitive to, the number of input images.)\n\nIt's also important not to set the number of vectors per token _too_ high, because this number eats into the total number of vectors that can be used in a prompt before reaching the SD limit of 75. I figure that 8 vectors for the character leaves 67 for the prompt, so it's not too bad.\n\nFinally, I always check the `Overwrite Old Embedding` checkbox, so that if I mess things up with the training, and need to recreate an empty embedding to start over, I won't need to remember to check the box each time.\n\nWith all of that set, click `Create embedding` to write a new, empty embedding `fr3nchl4dysd15.pt` inside the `/embeddings` folder of your A1111 installation, ready for training.\n\nHere's how all of those settings look in A1111:\n\n![Create embedding settings](images/step_4_create_embedding_settings.jpg)\n\n## Training the embedding\n\nNext, head over to the `Train` sub-tab. I'll cover all of the training settings below, but if you just want a summary, here's how my settings look in A1111:\n\n![Training settings](images/step_4_train_settings_5_step_150.jpg)\n\n### Basic settings\n\nSelect the embedding you just created (`fr3nchl4dysd15`) in the `Embedding` drop-down.\n\nYou can ignore the `Hypernetwork` dropdown and the `Hypernetwork Learning rate` field - those are only used when training a Hypernetwork, which we're not doing here.\n\nFor 25 input images, I set `Embedded Learning rate` to `0.002:25, 0.001`. This tells SD to train (for training steps 1 through 25) with a reasonably quick learning rate of `0.002`. It then switches to a slower learning rate of `0.001` for all remaining training steps.\n\nThe goal here is to trigger SD to get the high-level essence of your character pretty quickly, then give it more time to pick up the nuances and details that make your character unique. It's kind of like carving a statue of a person out of a block of marble - you start with a big chisel to get the rough shape of the person, then use smaller and smaller chisels to add the detail.\n\nI leave `Gradient Clipping` as `disabled`, and leave the value as `1`.\n\n### Batch size and gradient accumulation steps\n\nNext up is `Batch size` and `Gradient accumulation steps`. These two settings (multiplied together) define how many images the trainer looks at before updating its understanding of what `fr3nchl4dysd15` means. I've seen quite a few tutorials that recommend setting these values higher than the defaults of `1` and `1`. If you do, `Batch size` will define how many images are loaded onto your GPU at once for learning, and `Gradient accumulation steps` will define how many of those batches are viewed by the trainer before updating its understanding of the concept it is learning. However, every time I tried using different (higher) values in these settings, I found that the output embedding did not generate images that matched the input images as closely as I would like (indeed, the higher the numbers, the more the variance). So I always use the default values of `1` and `1`.\n\n`Dataset directory` should be set to the path on disk (accessible to A1111) where the input images and tagging text files are stored. This can be whatever you like.\n\nI usually leave `Log directory` at the default value.\n\n### Prompt template\n\n`Prompt template` is really important to change. If you leave it at the default of `style_filewords.txt`, SD will learn the _style_ of your input images, not the subject (i.e. the character) they contain. The prompt template tells SD how to make the input training prompt for each image in your `Dataset directory`, and so it's important to get it right.\n\nI've actually made my own prompt template, which goes in the `textual_inversion_templates` folder of your A1111 installation. I call it `subject_filewords_double.txt`, and it contains just the following text:\n\n```\n[name], [filewords]\n```\n\nThis file gets translated by SD into a training prompt for each input image. `[name]` is translated into the name of the embedding (`fr3nchl4dysd15`), and `[filewords]` is translated into the tags from the filename for that image. So, for one of our images, the combined training prompt from this text file might be:\n\n```\nfr3nchl4dysd15, an extreme closeup photo of fr3nchl4dysd15 naked, neutral gray background\n```\n\nYou might notice that this includes the text `fr3nchl4dysd15` twice, and you would be correct. I tried using just `[filewords]` as the contents of the template, but that triggers a bug in A1111 that causes training to fail. And so, I use `[name], [filewords]` instead. I'm not _entirely_ sure what the impact of having the embedding token in there twice is, but I do know that it's working well for me, so I'm sticking with it.\n\n### Image size\n\nLeave the `Width` and `Height` at their default values of `512`. There's no need to check the `Do not resize images` checkbox, because they don't need resizing anyway.\n\n### Steps\n\nWith all of the settings above, and an image dataset of 25 images, I find that the model tends to become well-trained somewhere between 100-120 training steps. To that end, I normally set `Max steps` to `150`.\n\nFor `Save an image to log directory every N steps, 0 to disable` and `Save a copy of embedding to log directory every N steps, 0 to disable`, I usually set these to either `5` or `1`. Setting a value of `5` will train more quickly, because SD isn't pausing to generate a \"how am I doing?\" image and embedding every single step. However, it means that you also only have \"marker\" embeddings to select from every five steps of the generation process. Setting a value of `1` saves an image and embedding every single step, giving more scope for picking just the right \"Goldilocks\" iteration, at the cost of more generation time. You're basically trading off flexibility of choosing an iteration against generation time. If in doubt, use `5` for both of these numbers (I normally do).\n\n### Training options\n\nI leave `Use PNG alpha channel as loss weight` unchecked.\n\nI leave `Save images with embedding in PNG chunks` checked.\n\nI usually check the `Read parameters (prompt, etc...) from txt2img tab when making previews` checkbox, so that I can provide a custom \"test\" prompt to see how the embedding is progressing. More on that below.\n\nI leave `Shuffle tags by ',' when creating prompts` unchecked, and leave `Drop out tags when creating prompts` at `0`. I've heard that this can provide more flexibility to the range of input prompts that can be used with an embedding, but I prefer to keep the prompts in the exact order and format I authored them, so I don't enable these options.\n\nFinally, I leave `Choose latent sampling method` at `once`.\n\n## Providing a custom testing prompt\n\nBefore you click the `Train Embedding` button, there's one more thing to set up. Remember above how we checked the `Read parameters (prompt, etc...) from txt2img tab when making previews` box? Well, that enables us to provide a custom `txt2img` prompt for use when making a \"how is the training going?\" image every N steps. This gives us more control over the \"test\" images that are created during the training process.\n\n### Defining the prompt\n\nHead back over to the `txt2img` tab, and set the `Prompt` text field to:\n\n```\nan extreme closeup color photo of fr3nchl4dysd15 in a forest\n```\n\nThis prompt serves two purposes:\n\n1. It enables us to spot when the embedding starts to generate people for a prompt of `fr3nchl4dysd15` who look like our character. (Requesting `an extreme closeup` makes it much more likely that the test images generated during training will give us a good look at our character's face.)\n\n2. It enables us to spot if and when the embedding starts to over-train. If you stop seeing a forest (or something like a forest) in the background, and instead start to see gray backgrounds in multiple images in a row, then you've probably reached the point where the embedding is already overtrained (which means you can interrupt any further training and switch over to selecting an iteration to use).\n\n### Other test prompt settings\n\nWith the prompt in place, update any other settings as follows:\n\n- Negative prompt: empty\n- Sampling method: Euler A\n- Sampling steps: 20\n- Restore Faces: Off\n- Tiling: Off\n- Hires. fix: Off\n- Width: 512\n- Height: 512\n- Batch count: 1\n- Batch size: 1\n- CFG Scale: 7\n- Seed: -1\n- ControlNet: off\n- Script: None\n\nThese settings are optimized for speed (`Euler A`, `20` sampling steps) rather than quality, and for showing the \"essence\" of what SD is learning as `fr3nchl4dysd15` (a very simple prompt, with no negative). They are only going to be used for generating images that let us keep an eye on how the training is going, so we don't need them to be perfect.\n\nHere's how all of those settings look in A1111:\n\n![Training settings](images/step_4_txt2img_settings.jpg)\n\n## Running the training\n\nWith all of that in place, head back over to the `Train` tab / the `Train` subtab, and click the orange `Train Embedding` button to (finally!) start the training.\n\nThe training process will first prepare your dataset (the images) for training. It will then start the training, generating an image every N steps.\n\nDon't worry if some of the images are weird, or don't even contain a person; that's normal, in my experience. However, at some point you should start to see a majority of images that increasingly look like your input character.\n\n# 5. Choosing and validating a particular iteration of the trained embedding\n\nOkay! We're nearly there. The final step is to identify the \"Goldilocks\" iteration of our trained embedding - the one where it is \"just right\". We're looking for an iteration where prompts for `fr3nchl4dysd15` generate an image that looks just like our character (so it's \"not too cold\"), without showing generation artifacts where the character looks over-stylized or distorted (so it's \"not too hot\").\n\nTo put it another way: training a Textual Inversion embedding is a bit like baking cookies. If you don't bake them for long enough, then they don't turn into cookies - they're still raw dough. But if you bake them for too long, they become burned and frazzled, and they don't look (or taste) good. What you're looking for is the training iteration of your embedding that is the perfect cookie - baked, but not over-baked.\n\n## Validation setup\n\nThe best way to find out when your embedding turned into an embedding of `fr3nchl4dysd15` is to generate a bunch of sample images, for the same input seeds, with a range of embeddings from different steps in the training process.\n\nAfter following the training process from step 4 above, you should be able to navigate to A1111's `textual_inversion` folder on disk, and find a folder for today's date. Inside it, you should find a folder named `fr3nchl4dysd15`. This folder is the results of your training. (I recommend copying the folder somewhere else on your computer, so that it doesn't get overwritten if you train again.)\n\nNext, copy all of the embeddings (yes, _all_ of them) from that folder into A1111's root-level `embeddings` folder. (This is the folder where A1111 looks for embeddings to use in prompts.) Once they are copied, head over to the `txt2img` tab, and click the \"Show/hide extra networks\" icon underneath the orange `Generate` button. This will show a bunch of cards for all of the embeddings that A1111 currently knows about. Click the `Refresh` button (to the right of the `Search…` field) to reload the `embeddings` folder, which will inform A1111 about all of the new embeddings you just copied. (If you don't perform this \"refresh\" step, A1111 won't use your embeddings in its prompts.)\n\nMake sure that the list of cards updates to show all of your embeddings, then click the \"Show/hide extra networks\" icon to hide them all again.\n\n## Generating a comparison grid\n\nIn the `txt2img` tab, set the following generation settings:\n\n- Sampling method: DPM++ 2M Karras\n- Sampling steps: 30\n- Restore Faces: Off\n- Tiling: Off\n- Hires. fix: Off\n- Width: 512\n- Height: 512\n- Batch count: 1\n- Batch size: 4\n- CFG Scale: 8 (note: higher than the default)\n- Seed: 12345678 (note: different to the default)\n- Grid margins (px): 16 (note: different to the default)\n\n(The exact value of the seed doesn't matter; the key thing is that it is constant for all of the generations.)\n\nThe prompt I usually use for detecting the right `Steps` value to use is:\n\n```\na medium closeup color portrait photo of fr3nchl4dysd15-20 wearing a bra on a greek island\n```\n\nSet the `Negative prompt` field to:\n\n```\nyoung, loli, teen, child, (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, (mutated hands and fingers:1.4), disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation, tattoo\n```\n\n(…or your own preferred negative prompt.)\n\nWe'll start by generating a coarse comparison between every 20 steps of the training, so we can see roughly where the embedding \"turned\" into our character.\n\nNote that the `Prompt` text above specifies a particular generation of the embedding's training - `fr3nchl4dysd15-20`. We know we have a 20-steps-of-training embedding file with the name `fr3nchl4dysd15-20.pt` in the `embeddings` folder, and so that iteration of the embedding will be used by default with this prompt.\n\nNext, from the `Script` drop-down menu, select `X/Y/Z plot`. Set `X type` to `Prompt S/R`. Set `Y type` and `Z type` to `Nothing`.\n\nSet `X values` to the following (assuming you generated 150 steps when training):\n\n```\nfr3nchl4dysd15-20, fr3nchl4dysd15-40, fr3nchl4dysd15-60, fr3nchl4dysd15-80, fr3nchl4dysd15-100, fr3nchl4dysd15-120, fr3nchl4dysd15-140\n```\n\nThis tells A1111 to generate a set of 4 images for each embedding training iteration that was a multiple of 20 (so 20, 40, 60, and so on).\n\nHere's how those validation settings look for me:\n\n![Validation settings](images/step_5_validation_settings.jpg)\n\nI recommend running this against the model you used to create the original input images (in my case, Deliberate v2), and also against the Stable Diffusion 1.5 base model. I've included examples of both below.\n\nThe generation process may take several minutes, and will generate a big image. I've cropped it down to show some select iterations below.\n\n## Finding out when the embedding became \"good\"\n\n> Fun fact: I learned recently that the point at which a training \"turns\" can be quite different even in multiple training runs with the exact same input images and settings, due to the randomness in the process. This is why I recommend making a grid to find the exact point that things turn, rather than just recommending a magic number.\n\nIf we look at the output of this prompt after 20 training steps, we can see that it doesn't really look much like our character yet (SD 1.5 on the left, Deliberate v2 on the right):\n\n<img src=\"images/step_5_coarse_sd15_bra_greek_island_step_20.jpg\" width=\"256\" height=\"296\" alt=\"Validation output after 20 steps of training - SD 1.5\">\n<img src=\"images/step_5_coarse_deliberate_bra_greek_island_step_20.jpg\" width=\"256\" height=\"296\" alt=\"Validation output after 20 steps of training - Deliberate v2\">\n\nHowever, if we look a little further ahead, we can see that things really start to turn into our character somewhere between step 80 and step 120. Here are the outputs of those steps from SD 1.5:\n\n<img src=\"images/step_5_coarse_sd15_bra_greek_island_steps_80_to_120.jpg\" width=\"776\" height=\"296\" alt=\"Validation output between 80 and 120 steps of training - SD 1.5\">\n\n…and from Deliberate v2:\n\n<img src=\"images/step_5_coarse_deliberate_bra_greek_island_steps_80_to_120.jpg\" width=\"776\" height=\"296\" alt=\"Validation output between 80 and 120 steps of training - Deliberate v2\">\n\nTo narrow things down further, we'll generate a second comparison image, this time using the embeddings we generated every five iterations between 80 and 120 steps.\n\nChange the `X values` box to the following, and generate another grid for the two checkpoints (replacing `fr3nchl4dysd15-20` with `fr3nchl4dysd15-80` in the prompt as the new starting value):\n\n```\nfr3nchl4dysd15-80, fr3nchl4dysd15-85, fr3nchl4dysd15-90, fr3nchl4dysd15-95, fr3nchl4dysd15-100, fr3nchl4dysd15-105, fr3nchl4dysd15-110, fr3nchl4dysd15-115, fr3nchl4dysd15-120\n```\n\nYou're looking for the first iteration where all four of the images are definitely recognizably your character. For me, this turned out to be step 115.\n\n## Validating the candidate embedding\n\nWe have now identified a candidate embedding. To validate it further, turn off the X/Y/Z plot script, and try generating batches of four images (each using the same starting seed) for the same prompt as above, using your candidate iteration (`fr3nchl4dysd15-115`, in my case) with a variety of different checkpoints from CivitAI. The goal here is to check that the iteration you selected adapts well to multiple different SD checkpoints.\n\nI deliberately generate these images with a non-standard size of 512x768, to see how well the embedding adapts.\n\nHere's the output with iteration 115 for a bunch of different photorealistic checkpoints.\n\n[Avalon TRUvision](https://civitai.com/models/13020/avalon-truvision):\n\n<img src=\"images/step_5_candidate_115_output_avalon.jpg\" width=\"512\" height=\"768\" alt=\"Avalon results\">\n\n[Deliberate v2](https://civitai.com/models/4823/deliberate):\n\n<img src=\"images/step_5_candidate_115_output_deliberate.jpg\" width=\"512\" height=\"768\" alt=\"Deliberate results\">\n\n[GalaxyTimeMachine's \"ForYou-Photo\"](https://civitai.com/models/25636/galaxytimemachines-foryou-photo-fantasyai):\n\n<img src=\"images/step_5_candidate_115_output_gtmphoto.jpg\" width=\"512\" height=\"768\" alt=\"GTM Photo results\">\n\n[Realistic Vision v2.0](https://civitai.com/models/4201/realistic-vision-v20):\n\n<img src=\"images/step_5_candidate_115_output_realistic.jpg\" width=\"512\" height=\"768\" alt=\"Realistic Vision results\">\n\nThe results look good and pretty consistent for each checkpoint, which suggests that my choice of learning steps was the right one to pick.\n\n## Using your Embedding\n\nNow that you've selected the ideal embedding iteration, you can rename it to just `fr3nchl4dysd15.pt` (rather than `fr3nchl4dysd15-115.pt`), and use it in your own prompts. If you'd like to download the result I used above, [here it is](fr3nchl4dysd15.pt). Just drop that file in A1111's `embeddings` folder, and refresh the embeddings list to use it.\n\n# Questions? Comments? Feedback?\n\nI hope you've enjoyed this tutorial! If you have any questions, comments, feedback, or just want to say thank you, head over to the [tutorial discussion](https://github.com/BelieveDiffusion/tutorials/discussions/3) - I'd love to hear what you think.\n\nYou can also find and follow me on [Twitter](https://twitter.com/BelieveDiffuse), [Reddit](https://www.reddit.com/user/BelieveDiffusion), [Instagram](https://www.instagram.com/believediffusion/), and [CivitAI](https://civitai.com/user/BelieveDiffusion).\n\n---\n\n\n\n\nhttps://www.reddit.com/r/StableDiffusion/comments/zxkukk/detailed_guide_on_training_embeddings_on_a/\n\nDetailed guide on training embeddings on a person's likeness\n\nThis is a guide on how to train embeddings with textual inversion on a person's likeness.\n\nThis guide assumes you are using the [Automatic1111 Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui) to do your trainings, and that you know basic embedding related terminology. This is not a step-by-step guide, but rather an explanation of what each setting does and how to fix common problems.\n\nI've been practicing training embeddings for about a month now using these settings and have successfully made many embeddings, ranging from poor quality to very good quality. This is a collection of all the lessons I've learned and suggested settings to use when training an embedding to learn a person's likeness.\n\n# What is an embedding?\n\nAn embedding is a special word that you put into your prompt that will significantly change the output image. For example, if you train an embedding on Van Gogh paintings, it should learn that style and turn the output image into a Van Gogh painting. If you train an embedding on a single person, it should make all people look like that person.\n\n# Why do I want an embedding?\n\nTo keep it brief, there are 3 other options to using an embedding: models, hypernetworks, and LoRAs. Each has advantages and disadvantages. The main advantage of embeddings is their flexibility and small size.\n\n- A model is a 2GB+ file that can do basically anything. It takes a lot of VRAM to train and has a large file size.\n    \n- A hypernetwork is an 80MB+ file that sits on top of a model and can learn new things not present in the base model. It is relatively easy to train, but is typically less flexible than an embedding when using it in other models.\n    \n- A LoRA (Low-Rank Adaptation) is a 2-9MB+ file and is functionally very similar to a hypernetwork. They are quick and easy to train, flexible, and produce good results, which has made them very popular. They tend to memorize content (like tattoos and mannerisms) rather than generalizing content. Depending on your use case, this could be a superior option to embeddings.\n    \n- An embedding is a 4KB+ file (yes, 4 kilobytes, it's very small) that can be applied to any model that uses the same base model, which is typically the base stable diffusion model. It cannot learn new content, rather it creates magical keywords behind the scenes that tricks the model into creating what you want.\n    \n\n# Preparing your starting images\n\n**Data set:** your starting images are the most important thing!! If you start with bad images, you will end up with a bad embedding. Make sure your images are high quality (no motion blur, no graininess, not partially out of frame, etc). Using more images means more flexibility and accuracy at the expense of longer training times. Your images should have plenty of variation in them - location, lighting, clothes, expressions, activity, etc.\n\nThe embedding learns what is similar between all your images, so if the images are too similar to each other the embedding will catch onto that and start learning mostly what's similar. I once had a data set that had very similar backgrounds and it completely messed up the embedding, so make sure to use images with varied backgrounds.\n\nWhen experimenting I recommend that you use less than 10 images in order to reduce your training times so that you can fail and iterate with different training settings more rapidly.\n\nYou can create a somewhat functional embedding with as little as 1 image. You can get good results with 10, but the best answer on how many images to use is however many high-quality images you have access to. Remember: quality over quantity!!\n\nI find that focusing on close ups of the face produces the best results. Humans are very good at recognizing faces, the AI is not. We need to give the AI the best chance at recreating an accurate face as possible, so that's why we focus on face pics. I'd recommend about half of the data set should be high quality close ups of the face, with the rest being upper body and full body shots to capture things like their clothing style, posture, and body shape. In the end, though, the types of images that you feed the AI are the types of images you will get back. So if you completely focus on face pics, you'll mostly get face pic results. Curate your data set so that it represents what you want to use it for.\n\nDo not use any images that contain more than 1 person. Just delete them, it'll only confuse the AI. You should also delete any that contain a lot of background text like a big sign, any watermarks, and any pictures of the subject taking a selfie with their phone (it'll skew towards creating selfie pics if you don't remove those).\n\nAll your training images need to be the same resolution, preferably 512x512. I like to use 3 websites that help to crop the images semi-automatically:\n\n- [BIRME - Bulk Image Resizing Made Easy 2.0](https://www.birme.net/?target_width=512&target_height=512)\n    \n- [Bulk Image Crop](https://bulkimagecrop.com/)\n    \n- [Bulk Resize Photos](https://bulkresizephotos.com/en?bg=000000&padding=true&quality=0.9&type=exact&value=512&secondaryValue=512)\n    \n\nNo images are uploaded to these sites. The cropping is done locally.\n\nAs of 2/19/2023 [pull request 6700](https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/6700), there is a new option for training: \"**Use PNG alpha channel as loss weight**\". This lets you to use transparency in your images to tell the AI what to concentrate on as it is learning. Transparent pixels get ignored during the training. This is a great feature because it allows you to tell the AI to focus only on the parts of the image that you want it to learn, such as a person in the photo.\n\nThe coder that added this feature also made a [utility program](https://github.com/Shondoit/lyne) you can use to automatically create these partially transparent images from your data set. Just run the python file at scripts/add_weight_map.py with the --help launch argument. For the attention mask, I found using \"a woman\" works well.\n\nIf you decide to use this alpha channel as loss weight feature, you should reduce your learning rate and step count by a little bit (about ~30%) since the AI's learning is hyper focused on your subject. This results in less training time and a more flexible embedding in the end, so it's a win/win.\n\n# Creating the embedding file\n\n**Initialization text:** Using the default of \"*\" is fine if you don't know what to use. Think of this as a word used in a prompt - the embedding will start with using that word. For example, if you put the initialization text to \"woman\" and attempted to use the embedding without any training, it should be equivalent to a prompt with the word \"woman\".\n\nYou can also start with a zero value embedding. This starts with all 0's in the underlying data, meaning it has no explicit starting point. I've heard people say this gives good results, so give it a shot if you want to experiment. An update to A1111 in January enabled this functionality in the Web UI by just leaving the text box blank.\n\nIn my opinion, the best initialization text to use is a word that most accurately describes your subject. For a man, use \"man\". For a woman, use \"woman\".\n\n**Number of vectors per token:** higher number means more data that your embedding can store. This is how many 'magical words' are used to describe your subject. For a person's likeness I like to use 10, although 1 or 2 can work perfectly fine too.\n\nIf prompting for something like \"brad pitt\" is enough to get Brad Pitt's likeness in stable diffusion 1.5, and it only uses 2 tokens (words), then it should be possible to capture another person's likeness with only 2 vectors per token.\n\nEach vector adds 4KB to the final size of the embedding file.\n\n# Preprocessing\n\n**Use BLIP for caption:** Check this. Captions are stored in .txt files with the same name as the image. After you generate them, it's a good idea (but not required) to go through them manually and edit any mistakes it made and add things it may have missed. The way the AI uses these captions in the learning process is complicated, so think of it this way:\n\n1. the AI creates a sample image using the caption as the prompt\n    \n2. it compares that sample to the actual picture in your data set and finds the differences\n    \n3. it then tries to find magical prompt words to put into the embedding that reduces the differences\n    \n\nStep 2 is the important part because if your caption is insufficient and leaves out crucial details then it'll have a harder time learning the stuff you want it to learn. For example, if you have a picture of a woman wearing a fancy wedding dress in a church, and the caption says, \"a woman wearing a dress in a building\", then the AI will try to learn how to turn a building into a church, and a normal dress into a wedding dress. A better caption would be \"a woman wearing a white wedding dress standing in a church with a Jesus statue in the background\".\n\nTo put it simply: add captions for things you want to AI to NOT learn. It sounds counterintuitive, just basically describe everything except the person.\n\nIn theory this should also mean that you should not include \"a woman\" in the captions, but in a test I did it did not make a difference.\n\nAutomatic1111 has an unofficial [Smart Process](https://github.com/d8ahazard/sd_smartprocess) extension that allows you to use a v2 CLIP model which produces slightly more coherent captions than the default BLIP model.\n\n**Create flipped copies:** Don't check this if you are training on a person's likeness, since people are not 100% symmetrical.\n\n**Width/Height:** Match the width/height resolution of your training images. Recommended to use 512x512, but I've used 512x640 many times and it works perfectly fine.\n\nDon't use **deepbooru** for captions since they create anime tags in the captions, and your real life person isn't an anime character.\n\n# Training\n\n**Learning rate:** this is how fast the embedding evolves per training step. The higher the value, the faster it'll learn, but using too high a learning rate for too long can cause the embedding to become inflexible, or cause deformities and visual artifacts to start appearing in your images.\n\nI like to think of it this way: a large learning rate is like using a sledgehammer to create a stone statue from a large boulder. It's great to make rapid progress at the start by knocking off large pieces of stone, but eventually you need to use something smaller like a hammer to get more precision, then finally end up at a chisel to get the fine details you want.\n\nIn my experience, values around the default of 0.005 work best. But we aren't limited to a static learning rate, we can have it change at set step intervals. This is the learning rate formula that I use:\n\n0.05:10, 0.02:20, 0.01:60, 0.005:200, 0.002:500, 0.001:3000, 0.0005\n\nThis means that from step 1-10 it uses a learning rate of 0.05 which is pretty high. 10-20 is lowered to 0.02, 20-60 is lowered to 0.01, etc. After step 3000 it'll train at 0.0005 until you interrupt it. This whole line of text can be plugged into the Embedding Learning Rate text box.\n\nThis formula tends to work well for me, YOUR RESULTS WILL VARY depending on your data set it. This, along with the number of training steps, will need to be experimented with depending on your data set.\n\nThe lower the learning rate goes, the more fine turning happens and the more precise the embedding will become. This should produce decent results in the 200-500 step range, and get better towards 1000-1500 steps. If you have extra time then you can let it run to 3000 steps, but I think that's unnecessary.\n\n**Batch size:** This is how many training images are put into your GPU's VRAM at once. Higher value is always better as long as you don't run out of VRAM. My 12GB GPU can do 18 with:\n\n- The `--xformers` [launch argument](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings) in the .bat file.\n    \n- \"Use cross attention optimizations while training\" is enabled\n    \n\nThe max value is the number of images in your training set. So if you set it to use 18 and you have 10 training images, it'll just automatically downgrade to a batch size of 10.\n\nHaving a high batch size can be important because it helps generate more accurate learning data for the embedding. The picture below helps visualize what happens with different batch sizes. Reaching the red dot in the middle means we accurately represent the subject in our training data.\n\n[](https://preview.redd.it/detailed-guide-on-training-embeddings-on-a-persons-likeness-v0-3xg0p31fhv8a1.jpg?width=473&format=pjpg&auto=webp&s=c3fa7424d63c1ddafa10b9e14605a5962cce3882 \"Image from r/StableDiffusion - How batch size helps to converge on the subject\")\n\nHow batch size helps to converge on the subject\n\n**Gradient accumulation steps:** Think of this as a multiplier to your batch size, and a multiplier to the overall time to train. This value should be set as high as possible without the batch size * gradient accumulation going higher than the total number of images in your data set:\n\nbatch size * gradient accumulation steps <= total number of images in data set\n\nIf you are still fine tuning your training variables you can keep this at 1 so your trainings finish faster, but they'll likely be slightly lower quality.\n\nCheck out this article for a more detailed explanation of what gradient accumulation actually does: [https://towardsdatascience.com/what-is-gradient-accumulation-in-deep-learning-ec034122cfa](https://towardsdatascience.com/what-is-gradient-accumulation-in-deep-learning-ec034122cfa)\n\n**Prompt template file:** `subject_filewords.txt` is a good starting place for training a person's likeness. I use a custom file that I call `custom_subject_filewords.txt` that contains just a single line of text: `a photo of [name], [filewords]` since we care about making photo quality images.\n\n`[name]` gets automatically replaced by the embedding name, and `[filewords]` gets automatically replaced by the captions in the .txt files from earlier.\n\nThese prompt templates are what's used to generate images that the AI uses while learning.\n\nI have not experimented with the prompt templates too much, but if you want to train on something other than a person's likeness then you will need to use a different template file than the one mentioned above.\n\n**Width and Height:** set to your training image dimensions.\n\n**Max steps:** I just set this to 3000 and interrupt it when I think it's done. The more steps the better if you use the learning rate formula from above. If the learning rate is too high for too long the embedding will get corrupted and produce garbage images.\n\n**Save an image and copy of embedding to log directory:** I like to set this to every 10 steps, but use whatever you want. Constantly generating image previews will slow down the training process slightly.\n\n**Read parameters (prompt, etc...) from txt2img tab when making previews:** I leave this unchecked so it just uses the captions for image previews. I've noticed that the quality of the embedding gets worse when this is checked, even though in theory it shouldn't. Maybe there's a bug in the A1111 training code somewhere.\n\n**Latent sampling method:** I don't know what this does, but people say they get better results with Deterministic.\n\n**The rest are left on default settings.**\n\n# Settings tab\n\n**Use cross attention optimizations while training:** Enable this, it speeds up training slightly. It may possibly reduce quality a tiny bit, but nothing noticeable.\n\n**Turn on pin_memory for DataLoader. Makes training slightly faster but can increase memory usage:** Enable this, by memory usage it means RAM, not VRAM. About a 5% speed increase.\n\n**Saves Optimizer state as separate *.optim file. Training of embedding or HN can be resumed with the matching optim file:** Enable this, it creates a EmbedName.optim file next to each EmbedName.pt file that can be used to resume the training if you decide to interrupt it.\n\n**Disable any VAE** you have loaded.\n\n**Disable any Hypernetwork** you have loaded.\n\nThe model you have loaded at the time of training matters. I make sure to always have the normal stable diffusion model loaded, that way it'll work well with all the other models created with it as a base.\n\nIf you try to train on another model chances are you'll get garbage images as output, but if you have extra time this may be something for you to experiment with.\n\n# txt2img tab\n\nMake sure to clear out the prompt and negative prompt textboxes, and set the width/height to your training image resolution. I think there's a bug in Automatic1111 where the \"Read parameters (prompt, etc...) from txt2img tab when making previews\" checkbox isn't fully respected, so I leave this setting unchecked and just set all the settings in the txt2img tab to their defaults.\n\n# Click 'Train Embedding'\n\nBefore clicking the Train Embedding button you should restart stable diffusion since it has memory leak issues. This will free up any lost VRAM and may help speed up training and prevent out of memory errors.\n\nNow we can click Train Embedding. As the embedding trains itself, watch the preview images generated in \"\\textual_inversion\\YYYY-MM-DD\\EmbeddingName\\images\".\n\nIf the images produce garbage and look nothing like your subject then one of your settings was set wrong. The most likely culprit is you're training on a model that isn't the base stable diffusion model, which I've done accidently countless times.\n\nIf you notice the images have random color splotches, particularly on the face, then the learning isn't going well. I see this happen when not enough training images have been provided, or if you are using a low number of steps when rendering the image.\n\nIf the images are not producing people that look like your subject, then your data set may need to be updated to include more high quality face pictures, or it hasn't been trained for long enough at an average learning rate. It is also possible that the person's likeness you are training for is so unique looking that it can't find keywords to use to describe their look, which means you'll never get a good result. In that case I recommend training a hypernetwork instead of an embedding.\n\n~~You should let the embedding train to completion without interrupting it. If you interrupt it, it loses its momentum and will noticeably degrade the quality of the embedding when trying to resume training.~~ This is something that was fixed if you enable the \" Saves Optimizer state as separate *.optim file. Training of embedding or HN can be resumed with the matching optim file.\" setting.\n\n# Inspecting the embedding\n\nDuring training you can run a 3rd party python script to inspect the internal guts of the embedding and make graphs to see what is actually happening:\n\n[https://github.com/Zyin055/Inspect-Embedding-Training](https://github.com/Zyin055/Inspect-Embedding-Training)\n\nThis will make graphs of the learning loss rate and the internal values of the vectors in the embedding.\n\nThe most important part is the strength of the vectors in the vector graph, which tell you how overtrained the embedding is. The more overtrained it is, the less flexible it will be. For example, if the vectors have a strength of ~2.0 and you try to prompt your embedding with \"with blue hair\" it likely won't work as expected most of the time. If the strength is ~0.20 then it should work much better. There is no magic number for how large the vectors should be, it's a tradeoff between accuracy to the original training images versus how flexible it can be with respect to other words in a prompt.\n\n# Picking the final embedding file\n\nAfter training completes, move the new embedding files from \"\\textual_inversion\\YYYY-MM-DD\\EmbeddingName\\embeddings\" to \"\\embeddings\" so that you can use the embeddings in a prompt.\n\nUse the 'X/Y plot' script to make an X/Y plot at various step counts using \"Seed: 1-3\" on the X axis and \"Prompt S/R: 10,100,200,300, ... etc\" on the Y axis to see how the embedding evolved over time. The prompt should be something like \"a photo of EmbedName-10\". You should make several plots using different prompts to see how flexible it is at various training steps. One prompt I like using to test for flexibility is \"a photo of EmbedName-XX with blue hair, smiling\". Low step counts should be able to do this easily, but higher step counts may struggle. Pick the step count that produces the best results.\n\nIf the results don't look great in the base model, try using models that were designed to render humans, such as HassanBlend or Zeipher-f222, which use stable diffusion 1.5 as a base.\n\nIf you see likeness but the quality is not quite as good as you would like, then you likely need to let it train for more steps. For example, on my RTX 3060 12GB it took 15 hours of training on 240 images (16 batch size, 15 gradient accumulation) to get a very nice result. It took about an hour on 15 images (15 batch size, 1 gradient accumulation) to get a decent result.\n\nIf it renders a person sometimes at a specific step range, but starts rendering garbage at other step counts, try doing the training again with a different learning rate, like a static 0.005 and see if that helps.\n\n# Final notes\n\nOne last thing to note is that there is inherit randomness when training an embedding. When using the exact same training parameters, you will never produce the same exact embedding twice. Sometimes some embeddings just work better than others even when using the exact same training parameters. This makes it incredibly difficult to determine if a change in your settings actually helped or hurt the embedding since you can't do side by side comparisons. There's a guy that [edited the training code](https://github.com/Shondoit/stable-diffusion-webui/tree/deterministic-training) to make it more deterministic, so maybe in the future we'll have this luxury as a base feature.\n\nAll my experiments were on stable diffusion 1.5. I have not tried using embeddings with 2.0+ yet.\n\nI am not an embedding expert by any means. It is entirely possible that something I said above is suboptimal.\n\nI hope you found some of this information useful. It has taken me a lot of time to learn how to do this since concrete information about this subject is sparse. Feel free to add any other hints or corrections down in the comments.\n\n# Changelog\n\n2/21/2023\n\n- Better explanation of LoRA\n    \n- \"Use PNG alpha channel as loss weight\" option explained\n    \n\n1/26/2023\n\n- Mentioned LoRA in addition to models/hypernetworks\n    \n- Added more info about initialization texts\n    \n- Added more info about number of tokens per vector\n    \n- Added a training optimization setting \"Turn on pin_memory for DataLoader\"\n    \n- Tweaked gradient accumulation info\n    \n- Info on .optim files and how to enable it\n    \n- Link to masked learning experimental branch\n    \n- Link to experimental deterministic training\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-22T19:36:43.537Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Sublime Snippet for Custom HTML Element",
      "content": "The Sublime Snippet for [[Custom HTML Element]]\n\nI use this snippet in Sublime Text to make creating a new HTML Element easy\n```\n<snippet>\n  <content><![CDATA[\n\nclass ${1:ElementName} extends HTMLElement {\n  connectedCallback(){\n  }\n\n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n    switch(name){\n      default:\n    }\n  }\n    \n  disconnectedCallback() {\n    console.log('Custom element removed from page.')\n  }\n}\n\ncustomElements.define('${2:ElementTagName}', ${1:ElementName})\n\n]]></content>\n  <!-- Optional: Set a tabTrigger to define how to trigger the snippet -->\n  <tabTrigger>HTMLElement</tabTrigger>\n  <!-- Optional: Set a scope to limit where the snippet will trigger -->\n  <!-- <scope>source.python</scope> -->\n</snippet>\n\n```\n\n[[Sublime Text]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-10T15:32:45.279Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Sublime Text Settings",
      "content": "```JSON\n\n{\t\"tab_size\": 2,\n\n\t// Set to true to insert spaces when tab is pressed\n\t\"translate_tabs_to_spaces\": true,\n\t/*\"tab_size\":2,*/\n\t\"line_numbers\": false,\n\n\t// The number of spaces a tab is considered equal to\n\t/*\"tab_size\": 2,*/\n\n\t// Set to false to hide the gutter altogether\n\t\"gutter\": false,\n\t\"margin\": 2,\n\n\n\t\"ignored_packages\":\n\t[\n\t\t\"Vintage\",\n\t],\n\t\"theme\": \"gruvbox.sublime-theme\",\n\t\"color_scheme\": \"Packages/Color Scheme - Baara Dark/Baara Dark.tmTheme\",\n\t\"font_size\": 12,\n}\n\n\n```\n\nInstall gruvbox and Baara Dark for my theme / color scheme these days. Though I need to write my own. \n\n[[Sublime Text]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-05T02:55:27.541Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Sublime Text",
      "content": "```txt\n----- BEGIN LICENSE -----\nLNSY\nSingle User License\nE3D2-1279117-457482\n4305310E B5D37468 6B171055 DB07A371\nE315FCD6 A472F147 B6FF02FD A797108B\nE7AAA169 67154318 09FC412A AC47BD29\nD562C093 99B708A0 E8659779 2DA08BD3\nA8F6236C 2445DC0B C6934244 C58BC0B3\n167D1461 81A43A09 DB370C70 EFBD1F67\n602A34B1 A13D82A2 489A7B94 79F48539\n939FC892 1B84CBC7 2BC7CBF3 1EA9A9E0\n------ END LICENSE ------\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-10T17:43:17.673Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Swagger",
      "content": "[Swagger](https://swagger.io/) is the name associated with some of the most well-known, and widely used tools for implementing the OpenAPI specification. The Swagger toolset includes a mix of open source, free, and commercial tools, which can be used at different stages of the API lifecycle.\n\n## Why haven’t the Swagger tools changed their name to [[OpenAPI]]?\n\nThe Swagger ecosystem has always been comprised of the Specification and the core open source tooling around it, most famously the Swagger UI, Swagger Editor, and Swagger Codegen. A big reason why the Specification became so widely adopted was because of the tooling that lived alongside it.\n\n\n\nused in [[Nest.js]]\n\nhttps://docs.nestjs.com/openapi/introduction\n\n```typescript\nimport { NestFactory } from '@nestjs/core';\nimport { SwaggerModule, DocumentBuilder } from '@nestjs/swagger';\nimport { AppModule } from './app.module';\n\nasync function bootstrap() {\n  const app = await NestFactory.create(AppModule);\n\n  const config = new DocumentBuilder()\n    .setTitle('Cats example')\n    .setDescription('The cats API description')\n    .setVersion('1.0')\n    .addTag('cats')\n    .build();\n  const document = SwaggerModule.createDocument(app, config);\n  SwaggerModule.setup('api', app, document);\n\n  await app.listen(3000);\n}\nbootstrap();\n```\n\n\nThe `DocumentBuilder` helps to structure a base document that conforms to the OpenAPI Specification. It provides several methods that allow setting such properties as title, description, version, etc. In order to create a full document (with all HTTP routes defined) we use the `createDocument()` method of the `SwaggerModule` class. This method takes two arguments, an application instance and a Swagger options object. Alternatively, we can provide a third argument, which should be of type `SwaggerDocumentOptions`. More on this in the [Document options section](https://docs.nestjs.com/openapi/introduction#document-options).\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-06T17:57:32.148Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Sync, Save and Export",
      "content": "Load -- load zip files, populates and loads notebook\nSave -- generates zip file of notebookdata for user to download\nExport -- exports notebook as HTML app\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-05-03T21:55:30.009Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Testing",
      "content": "https://www.cypress.io/\n\nhttps://www.cypress.io/pricing/\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-09-01T04:05:37.188Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "The Negative Prompt",
      "content": "(((deformed))), blurry, bad anatomy, disfigured, poorly drawn face, mutation, mutated, (extra_limb), (ugly), (poorly drawn hands), fused fingers, messy drawing, broken legs censor, censored, censor_bar, multiple breasts, (mutated hands and fingers:1.5), (long body :1.3), (mutation, poorly drawn :1.2), black-white, bad anatomy, liquid body, liquidtongue, disfigured, malformed, mutated, anatomical nonsense, text font ui, error, malformed hands, long neck, blurred, lowers, low res, bad anatomy, bad proportions, bad shadow, uncoordinated body, unnatural body, fused breasts, bad breasts, huge breasts, poorly drawn breasts, extra breasts, liquid breasts, heavy breasts, missingbreasts, huge haunch, huge thighs, huge calf, bad hands, fused hand, missing hand, disappearing arms, disappearing thigh, disappearing calf, disappearing legs, fusedears, bad ears, poorly drawn ears, extra ears, liquid ears, heavy ears, missing ears, old photo, low res, black and white, black and white filter, colorless, \n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-01-17T23:47:25.879Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "The Simple Software Manifesto",
      "content": "\nPeople don't notice -- \n\nStart with Accessibility\n\n\n\n\nIt seems odd that I must declare it, but: The Web is a communications platform. Applications are methods of communication between user and computer and network. \n\nSomewhere along the way we have stopped thinking about the web this way, and it has become the domain of \"enterprise\" and complexity -- massive frameworks that require preproccesors and minifyers. \n\nIn fact, most software would be shipped more quickly with fewer bugs if the tools programmers used didn't obscure what they were doing from the business men and other programmers. \n\n## The Simple Web Manifesto\n### 1. Don't believe the Hype\n\nBefore I wrote software I wrote press releases professionally. It turns out my experience in public relations was more important as a software developer than any computer science I've learned. \n\nThe modern web eco-system is full of framework after framework clamoring for recognition -- you \"have\" to write software this way, because every other organization writes software this way. Large companies generate internal frameworks that solve specific business usecases, and then go to their PR departments and have these frameworks disseminated as \"the proper way\" to write software. \n\n### 2. Software is a method of communication\n\nI think that software should be read by everyone in an organization. \n\n### 3. The Web is Made up of Documents\n\n\n### CSS is Amazing\nCSS used to be a complex\n\nI've used prepropcessors like Sass, but what has happened is all the cool parts of SASS have been incorporated into CSS. We now have varaibles, v\n\nIt doesn't have to be anymore. \n\nI've watched companies waste hundreds of thousands of dollars in JavaScript Development chasing something they could have achieved in CSS. I've seen frameworks claiming to \n\n### Javascript Imports\n\n\n### Custom HTML Elements\n\nThe framework I have used professionally the past few years looks like this: \n\n```js\n\n\n\n```\n\n\n\n# ChatGPG\n\nSimplicity in web development is a philosophy that prioritizes user experience and ease of use over unnecessary complexity and flashy design.\n\n1.  Prioritize user needs: The ultimate goal of web development is to provide a seamless and enjoyable experience for the user. Therefore, user needs should be at the forefront of all design and development decisions.\n    \n2.  Keep it simple: Simplicity is key in web development. Avoid using unnecessary elements and features that do not directly contribute to the user experience. A clean and simple design is often more effective than a complex one.\n    \n3.  Use clear and consistent design: Consistency in design is essential for creating a sense of familiarity and ease of use for the user. Use clear, easy-to-read typography and consistent layout elements to guide the user through the website.\n    \n4.  Optimize for speed: A slow-loading website can be frustrating for users and may cause them to leave. Optimize images, reduce code bloat, and use a content delivery network (CDN) to ensure that your website loads as quickly as possible.\n    \n5.  Test, test, test: User testing is an essential part of the web development process. Use a variety of testing methods to gather feedback and make improvements to the website.\n    \n\nBy following these principles, web development can be kept simple and efficient, while providing a positive experience for users.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-08T00:15:27.460Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Three JS",
      "content": "[[3d Graphics]]\n[[OpenGL]]\n[[OpenGL ES]]\n\n\nhttps://threejs.org/\n\nhttps://threejs.org/docs/index.html#manual/en/introduction/Creating-a-scene\n\n\n```html\n<!DOCTYPE html> \n<html> \n\n<head> \n  <meta charset=\"utf-8\"> \n  <title>My first three.js app</title> \n  <style> body { margin: 0; } </style> \n</head> \n\n<body> \n\n  <script src=\"js/three.js\"></script> \n  <script> \n    const scene = new THREE.Scene(); \n    const camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 0.1, 1000 ); \n    const renderer = new THREE.WebGLRenderer(); \n    renderer.setSize( window.innerWidth, window.innerHeight ); \n    document.body.appendChild( renderer.domElement ); \n    const geometry = new THREE.BoxGeometry(); \n    const material = new THREE.MeshBasicMaterial( { color: 0x00ff00 } ); \n    const cube = new THREE.Mesh( geometry, material ); \n    scene.add( cube ); \n    camera.position.z = 5; \n    function animate() { \n      requestAnimationFrame( animate ); \n      cube.rotation.x += 0.01; \n      cube.rotation.y += 0.01; \n      renderer.render( scene, camera ); \n    }; \n    animate(); \n  </script> \n\n</body> \n</html>\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-23T19:46:57.535Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Tile Server",
      "content": "https://mapserver.org/\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-01-29T22:25:37.149Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Try Catch function",
      "content": "```js\n\nfunction tryCatch({ tryFn, catchFn }) {  \ntry {  \nreturn tryFn();  \n} catch (error) {  \nreturn catchFn(error);  \n}  \n}\n\nfunction writeTransactionsToFile(transactions) {  \n// 👇 we can use const now  \nconst writeStatus = tryCatch({  \ntryFn: () => {  \nfs.writeFileSync('transactions.txt', transactions);  \nreturn 'success';  \n},  \ncatchFn: (error) => 'error';  \n});  \n// do something with writeStatus...  \n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-04-19T16:07:31.807Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Tumblr Upload",
      "content": "To authenticate, create a new app \n\nhttps://api.tumblr.com/console/calls/user/info\n\nhttps://api.tumblr.com/console\n\n\n\n---\n\n\nhey chatgpt, could you write a node.js script that takes a folder of images and uploads them to my tumblr queue?\n\nSure, I can help you with that. To achieve this, we will use the Tumblr API and the `tumblr.js` module which provides a wrapper around the Tumblr API for Node.js.\n\nBefore we begin, you will need to have a Tumblr account and create an application to obtain API keys. You can do this by following the instructions on the Tumblr API documentation.\n\nOnce you have obtained your API keys, you can install the `tumblr.js` module by running the following command in your terminal:\n\nCopy code\n```sh\nnpm install tumblr.js\n```\n\n\nThen, you can use the following script to upload a folder of images to your Tumblr queue:\n\njavascriptCopy code\n```js\nconst fs = require('fs');\nconst tumblr = require('tumblr.js');\n\n// Set your API keys\nconst client = tumblr.createClient({\n  consumer_key: 'your_consumer_key',\n  consumer_secret: 'your_consumer_secret',\n  token: 'your_token',\n  token_secret: 'your_token_secret'\n});\n\n// Set the path to the folder containing the images\nconst folderPath = '/path/to/folder';\n\n// Get an array of file names in the folder\nfs.readdir(folderPath, (err, files) => {\n  if (err) {\n    console.error(err);\n    return;\n  }\n\n  // Loop through the files and upload each one to Tumblr\n  files.forEach((file) => {\n    const filePath = `${folderPath}/${file}`;\n    const caption = ''; // Add your desired caption here\n\n    // Upload the image to Tumblr\n    client.createPhotoPost('your_tumblr_blog_name.tumblr.com', {\n      data: [filePath],\n      caption: caption,\n      state: 'queue'\n    }, (err, res) => {\n      if (err) {\n        console.error(err);\n        return;\n      }\n\n      console.log(`Uploaded ${file} to Tumblr queue.`);\n    });\n  });\n});\n\n```\n\nMake sure to replace the placeholders with your own API keys, the path to your image folder, your desired caption, and your Tumblr blog name.\n\nThis script will upload each image in the folder to your Tumblr queue with the specified caption. The `state` parameter is set to `queue` to add the post to your queue instead of publishing it immediately. If you want to publish the posts immediately, you can set `state` to `published`.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-10-01T18:31:29.684Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Unicode Symbols",
      "content": "# Icon-like\nSmiley\t☺\t☺\t&#x263a;\nHot Springs\t♨\t♨\t&#x2668;\n8-Ball\t➑\t➑\t&#x2791;\nWhite Star\t☆\t☆\t&#x2606;\nBlack Star\t★\t★\t&#x2605;\nWhite Heart\t♡\t♡\t&#x2661;\nBlack Heart\t❤\t❤\t&#x2764;\nAirplane\t✈\t✈\t&#x2708;\nBlack Scissors\t✂\t✂\t&#x2702;\nWhite Scissors\t✄\t✄\t&#x2704;\nCrown\t♕\t♕\t&#x2655;\nCross\t✝\t✝\t&#x271d;\nBlack-White Circle\t◑\t◑\t&#x25d1;\nEight Note\t♪\t♪\t&#x266a;\nBeamed Eighth Notes\t♫\t♫\t&#x266b;\nFour Balloon-Spoked Asterisk\t✣\t✣\t&#x2723;\nCircled White Star\t✪\t✪\t&#x272a;\nWhite Star\t✰\t✰\t&#x2730;\nWhite Four Pointed Star\t✧\t✧\t&#x2727;\nBlack Four Pointed Star\t✦\t✦\t&#x2726;\nBallot Box Check\t☑\t☑\t&#x2611;\nCheck Mark\t✔\t✔\t&#x2714;\nCross Mark\t✘\t✘\t&#x2718;\nPencil\t✎\t✎\t&#x270e;\nWriting Hand\t✍\t✍\t&#x270d;\nFemale\t♀\t♀\t&#x2640;\nMale\t♂\t♂\t&#x2642;\nBlack Telephone\t☎\t☎\t&#x260e;\nWhite Telephone\t☏\t☏\t&#x260f;\nEnvelope\t✉\t✉\t&#x2709;\nTelephone Location\t✆\t✆\t&#x2706;\n\n# Arrows\nLeftwards Arrow\t←\t←\t&#x2190;\nRightwards Arrow\t→\t→\t&#x2192;\nUpwards Arrow\t↑\t↑\t&#x2191;\nDownwards Arrow\t↓\t↓\t&#x2193;\nLeft Right Arrow\t↔\t↔\t&#x2194;\nUp Down Arrow\t↕\t↕\t&#x2195;\nRight And Left Arrows\t⇄\t⇄\t&#x21c4;\nUp And Down Arrows\t⇅\t⇅\t&#x21c5;\nDown-Left 90deg Arrow\t↲\t↲\t&#x21b2;\nDown-Right 90deg Arrow\t↳\t↳\t&#x21b3;\nUp-Right 90deg Arrow\t↱\t↱\t&#x21b1;\nLeftwards Arrow To Bar\t⇤\t⇤\t&#x21e4;\nAnticlockwise Semicircle Arrow\t↶\t↶\t&#x21b6;\nClockwise Semicircle Arrow\t↷\t↷\t&#x21b7;\nAnticlockwise Circle Arrow\t↺\t↺\t&#x21ba;\nClockwise Circle Arrow\t↻\t↻\t&#x21bb;\nWide-Headed Rightwards Arrow\t➔\t➔\t&#x2794;\nDownwards Zigzag Arrow\t↯\t↯\t&#x21af;\nNorth West Arrow\t↖\t↖\t&#x2196;\nHeavy South East Arrow\t➘\t➘\t&#x2798;\nHeavy Rightwards Arrow\t➙\t➙\t&#x2799;\nHeavy North East Arrow\t➚\t➚\t&#x279a;\nDashed Rightwards Arrow\t➟\t➟\t&#x279f;\nDotted Leftwards Arrow\t⇠\t⇠\t&#x21e0;\nBlack Rightwards Arrowhead\t➤\t➤\t&#x27a4;\nLeftwards White Arrow\t⇦\t⇦\t&#x21e6;\nRightwards White Arrow\t⇨\t⇨\t&#x21e8;\nLeft Angle Quotation Mark\t«\t«\t&#xab;\nRight Angle Quotation Mark\t»\t»\t&#xbb;\nRight Black Pointer\t►\t►\t&#x25ba;\nLeft Black Pointer\t◀\t◀\t&#x25c0;\nUp Black Pointer\t▲\t▲\t&#x25b2;\nRight White Pointer\t▷\t▷\t&#x25b7;\nLeft White Pointer\t◁\t◁\t&#x25c1;\nUp White Pointer\t△\t△\t&#x25b3;\n\n# Special\nNumero\t№\t№\t&#x2116;\nCopyright\t©\t©\t&#xa9;\nRegistered\t®\t®\t&#xae;\nTrademark\t™\t™\t&#x2122;\nEstimated\t℮\t℮\t&#x212e;\nBullet\t•\t•\t&#x2022;\nMiddle Dot\t·\t·\t&#xb7;\nCurrency\nEuro\t€\t€\t&#x20ac;\nPound\t£\t£\t&#xa3;\nLira\t₤\t₤\t&#x20a4;\nYen\t¥\t¥\t&#xa5;\nCent\t¢\t¢\t&#xa2;\nCurrency\t¤\t¤\t&#xa4;\nWeather\nDegree\t°\t°\t&#xb0;\nSmall Sun\t☀\t☀\t&#x2600;\nBig Sun\t☼\t☼\t&#x263c;\nCloud\t☁\t☁\t&#x2601;\nSnowflake 1\t❆\t❆\t&#x2746;\nSnowflake 2\t❅\t❅\t&#x2745;\nSnowflake 3\t❄\t❄\t&#x2744;\n\n# Pointers\nPointer Left Black\t☚\t☚\t&#x261a;\nPointer Right Black\t☛\t☛\t&#x261b;\nPointer Left White\t☜\t☜\t&#x261c;\nPointer Up White\t☝\t☝\t&#x261d;\nPointer Right White\t☞\t☞\t&#x261e;\nPointer Down White\t☟\t☟\t&#x261f;\n\n# Card Suits\nSpades Black\t♠\t♠\t&#x2660;\nHearts Black\t♥\t♥\t&#x2665;\nDiamonds Black\t♦\t♦\t&#x2666;\nClubs Black\t♣\t♣\t&#x2663;\nSpades White\t♤\t♤\t&#x2664;\nHearts White\t♡\t♡\t&#x2661;\nDiamonds White\t♢\t♢\t&#x2662;\nClubs White\t♧\t♧\t&#x2667;\n\n# Chess\nKing White\t♔\t♔\t&#x2654;\nQueen White\t♕\t♕\t&#x2655;\nRook White\t♖\t♖\t&#x2656;\nBishop White\t♗\t♗\t&#x2657;\nKnight White\t♘\t♘\t&#x2658;\nPawn White\t♙\t♙\t&#x2659;\nKing Black\t♚\t♚\t&#x265a;\nQueen Black\t♛\t♛\t&#x265b;\nRook Black\t♜\t♜\t&#x265c;\nBishop Black\t♝\t♝\t&#x265d;\nKnight Black\t♞\t♞\t&#x265e;\nPawn Black\t♟\t♟\t&#x265f;\n\n# Maths\nInfinity\t∞\t∞\t&#x221e;\nPlus Minus\t±\t±\t&#xb1;\nLess-Than Or Equal To\t≤\t≤\t&#x2264;\nMore-Than Or Equal To\t≥\t≥\t&#x2265;\nNot Equal To\t≠\t≠\t&#x2260;\nDivision\t÷\t÷\t&#xf7;\nMultiplication x\t×\t×\t&#xd7;\nHeavy Multiplication x\t✖\t✖\t&#x2716;\nSuperscript One\t¹\t¹\t&#xb9;\nSuperscript Two\t²\t²\t&#xb2;\nSuperscript Three\t³\t³\t&#xb3;\nCircled Plus\t⊕\t⊕\t&#x2295;\nCircled Multiplication\t⊗\t⊗\t&#x2297;\nLogical AND\t∧\t∧\t&#x2227;\nLogical OR\t∨\t∨\t&#x2228;\nDelta\t∆\t∆\t&#x2206;\nPie\t∏\t∏\t&#x220f;\nSigma (SUM)\t∑\t∑\t&#x2211;\nOmega\tΩ\tΩ\t&#x3a9;\nEmpty Set\t∅\t∅\t&#x2205;\nAngle\t∠\t∠\t&#x2220;\nParallel\t∥\t∥\t&#x2225;\nPerpendicular\t⊥\t⊥\t&#x22a5;\nAlmost Equal To\t≈\t≈\t&#x2248;\nTriangle\t△\t△\t&#x25b3;\nCircle\t○\t○\t&#x25CB;\nSquare\t□\t□\t&#x25A1;\n\n# Fractions\nOne Quarter (1/4)\t¼\t¼\t&#xbc;\nOne Half (1/2)\t½\t½\t&#xbd;\nThree Quarters (3/4)\t¾\t¾\t&#xbe;\nOne Third (1/3)\t⅓\t⅓\t&#x2153;\nTwo Thirds (2/3)\t⅔\t⅔\t&#x2154;\nOne Eight (1/8)\t⅛\t⅛\t&#x215b;\nThree Eights (3/8)\t⅜\t⅜\t&#x215c;\nFive Eights (5/8)\t⅝\t⅝\t&#x215d;\nSeven Eights (7/8)\t⅞\t⅞\t&#x215e;\nRoman Numerals\nRoman Numeral One\tⅠ\tⅠ\t&#x2160;\nRoman Numeral Two\tⅡ\tⅡ\t&#x2161;\nRoman Numeral Three\tⅢ\tⅢ\t&#x2162;\nRoman Numeral Four\tⅣ\tⅣ\t&#x2163;\nRoman Numeral Five\tⅤ\tⅤ\t&#x2164;\nRoman Numeral Six\tⅥ\tⅥ\t&#x2165;\nRoman Numeral Seven\tⅦ\tⅦ\t&#x2166;\nRoman Numeral Eight\tⅧ\tⅧ\t&#x2167;\nRoman Numeral Nine\tⅨ\tⅨ\t&#x2168;\nRoman Numeral Ten\tⅩ\tⅩ\t&#x2169;\nRoman Numeral Eleven\tⅪ\tⅪ\t&#x216a;\nRoman Numeral Twelve\tⅫ\tⅫ\t&#x216b;\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-07-06T18:20:31.026Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Upload File with Node.JS",
      "content": "```js\nclass FileUploader extends HTMLElement {\n  constructor() {\n    super();\n\n    const template = document.createElement('template');\n    template.innerHTML = `\n      <input type=\"file\" id=\"fileInput\">\n      <button id=\"uploadButton\">Upload</button>\n    `;\n\n    this.attachShadow({ mode: 'open' });\n    this.shadowRoot.appendChild(template.content.cloneNode(true));\n\n    this.fileInput = this.shadowRoot.getElementById('fileInput');\n    this.uploadButton = this.shadowRoot.getElementById('uploadButton');\n    this.uploadButton.addEventListener('click', this.handleUpload.bind(this));\n  }\n\n  handleUpload() {\n    const file = this.fileInput.files[0];\n    if (file) {\n      const formData = new FormData();\n      formData.append('file', file);\n\n      fetch('/upload', {\n        method: 'POST',\n        body: formData,\n      })\n        .then(response => response.json())\n        .then(data => {\n          console.log('File uploaded:', data);\n          // Handle success\n        })\n        .catch(error => {\n          console.error('Error uploading file:', error);\n          // Handle error\n        });\n    }\n  }\n}\n\ncustomElements.define('file-uploader', FileUploader);\n\n```\n\n```js\nconst express = require('express');\nconst multer = require('multer');\n\nconst app = express();\nconst upload = multer({ dest: 'uploads/' });\n\napp.use(express.static('public'));\n\napp.post('/upload', upload.single('file'), (req, res) => {\n  if (req.file) {\n    console.log('File uploaded:', req.file);\n    // Handle file saved in the 'uploads/' directory\n    res.json({ success: true });\n  } else {\n    console.error('No file received');\n    res.status(400).json({ error: 'No file received' });\n  }\n});\n\napp.listen(3000, () => {\n  console.log('Server is running on http://localhost:3000');\n});\n\n```\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <title>File Uploader</title>\n</head>\n<body>\n  <file-uploader></file-uploader>\n\n  <script src=\"index.js\"></script>\n</body>\n</html>\n\n```\n\nLarge file upload with progress:\n\n```js\nconst express = require('express');\nconst multer = require('multer');\nconst fs = require('fs');\nconst { PassThrough } = require('stream');\n\nconst app = express();\n\nconst storage = multer.diskStorage({\n  destination: (req, file, cb) => {\n    cb(null, 'uploads/');\n  },\n  filename: (req, file, cb) => {\n    cb(null, file.originalname);\n  },\n});\n\nconst upload = multer({ storage });\n\napp.use(express.static('public'));\n\napp.post('/upload', upload.single('file'), (req, res) => {\n  if (!req.file) {\n    console.error('No file received');\n    res.status(400).json({ error: 'No file received' });\n    return;\n  }\n\n  const filePath = req.file.path;\n  const fileStream = fs.createReadStream(filePath);\n  const passThrough = new PassThrough();\n\n  const totalSize = fs.statSync(filePath).size;\n  let uploadedSize = 0;\n\n  fileStream.on('data', (chunk) => {\n    uploadedSize += chunk.length;\n    const progress = Math.round((uploadedSize / totalSize) * 100);\n    console.log(`Progress: ${progress}%`);\n    passThrough.emit('progress', progress);\n  });\n\n  fileStream.on('end', () => {\n    console.log('Upload completed');\n    passThrough.emit('progress', 100);\n    passThrough.emit('end');\n  });\n\n  fileStream.pipe(passThrough);\n\n  res.set({\n    'Content-Type': 'application/octet-stream',\n    'Content-Disposition': 'attachment; filename=' + req.file.originalname,\n  });\n\n  passThrough.pipe(res);\n});\n\napp.listen(3000, () => {\n  console.log('Server is running on http://localhost:3000');\n});\n\n```\n\n```html\n\n<!DOCTYPE html>\n<html>\n<head>\n  <title>File Uploader</title>\n</head>\n<body>\n  <input type=\"file\" id=\"fileInput\">\n  <progress id=\"progressBar\" value=\"0\" max=\"100\"></progress>\n  <button id=\"uploadButton\">Upload</button>\n\n  <script>\n    const fileInput = document.getElementById('fileInput');\n    const progressBar = document.getElementById('progressBar');\n    const uploadButton = document.getElementById('uploadButton');\n\n    uploadButton.addEventListener('click', uploadFile);\n\n    function uploadFile() {\n      const file = fileInput.files[0];\n      if (file) {\n        const xhr = new XMLHttpRequest();\n\n        xhr.upload.addEventListener('progress', updateProgress);\n        xhr.addEventListener('load', uploadComplete);\n        xhr.addEventListener('error', uploadFailed);\n        xhr.addEventListener('abort', uploadCanceled);\n\n        xhr.open('POST', '/upload', true);\n\n        xhr.onreadystatechange = function () {\n          if (xhr.readyState === 4 && xhr.status === 200) {\n            console.log('File uploaded successfully');\n            // Handle success\n          }\n        };\n\n        xhr.send(file);\n      }\n    }\n\n    function updateProgress(event) {\n      if (event.lengthComputable) {\n        const progress = Math.round((event.loaded / event.total) * 100);\n        progressBar.value = progress;\n        console.log(`Progress: ${progress}%`);\n      }\n    }\n\n    function uploadComplete() {\n      console.log('Upload completed');\n    }\n\n    function uploadFailed() {\n      console.error('Error uploading file');\n      // Handle error\n    }\n\n    function uploadCanceled() {\n      console.log('Upload canceled');\n    }\n  </script>\n</body>\n</html>\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-12-19T21:00:06.113Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Using ChatGPT 3.5 to Write Tests",
      "content": "I personally think that ChatGPT 3.5 is not able to be copywritten or legally defended. \n\nI think because of this we should turn it into a public good. You can already go download it: _____\n\n``\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-09-21T01:26:58.762Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "VR AI Videos",
      "content": "```\nffmpeg -framerate 10 -pattern_type glob -i \"*.png\" output.mkv\n```\n\n\n\n\n```bash\nffmpeg -i input.mp4 -vf \"scale=trunc(iw/4)*2:trunc(ih/4)*2\" -c:v libx265 -crf 28 half_the_frame_size.mp4\n```\n\n\n\ncut in half:\n\n```sh\nffmpeg -i half_the_frame_size.mp4 -filter_complex \"[0]crop=iw/2:ih:0:0[left];[0]crop=iw/2:ih:ow:0[right]\" -map \"[left]\" left.mp4 -map \"[right]\" right.mp4\n```\n\n\n---\n\nextract audio\n```\nffmpeg -i left.mp4 -vn -acodec copy out.m4a\n```\n\n\nextract pngs for each frame\n```\nffmpeg -i left.mp4 img%04d.png\n```\n\n\n\nhttps://stackoverflow.com/questions/10438713/overlay-animated-images-with-transparency-over-a-static-background-image-using-f\n\nOverlay background\n\n\n```js\nconst fs = require('fs');\nconst path = require('path');\nconst Jimp = require('jimp');\n\nconst inputFolderPath = './imgs'; // Path to the folder with PNGs\nconst backgroundPath = './background.png'; // Path to the background PNG\nconst outputFolderPath = './output_images'; // Path to save the composited images\n\n// Create the output folder if it doesn't exist\nif (!fs.existsSync(outputFolderPath)) {\n  fs.mkdirSync(outputFolderPath);\n}\n\n// Read the background image\nJimp.read(backgroundPath)\n  .then(backgroundImage => {\n    // Read and composite all PNGs in the input folder\n    fs.readdirSync(inputFolderPath).forEach(file => {\n      if (file.endsWith('.png')) {\n        const inputImagePath = path.join(inputFolderPath, file);\n        Jimp.read(inputImagePath)\n          .then(inputImage => {\n            inputImage.resize(backgroundImage.getWidth(), backgroundImage.getHeight());\n            backgroundImage.composite(inputImage, 0, 0);\n            const outputFileName = `output_${file}`;\n            const outputPath = path.join(outputFolderPath, outputFileName);\n            backgroundImage.write(outputPath);\n            console.log(`Composite image saved: ${outputPath}`);\n          })\n          .catch(err => {\n            console.error(`Error processing ${inputImagePath}: ${err}`);\n          });\n      }\n    });\n  })\n  .catch(err => {\n    console.error(`Error reading background image: ${err}`);\n  });\n```\n\nhttps://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-01T04:23:59.397Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "WebASM",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-12T21:23:41.050Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "WebMentions",
      "content": "https://indieweb.org/Webmention\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-11-11T01:20:57.762Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "WebMidi",
      "content": "\nhttps://github.com/starmandeluxe/WebMidiClockSequencer/blob/master/js/sequencer.js\n\n```js\n  for (const entry of midiAccess.inputs) {\n        const input = entry[1];\n        this.devices.innerHTML += `<midi-device\n          type=${input.type}\n          id=${input.id}\n          manufacturer=${input.manufacturer}\n          name=${input.name}\n          version=${input.version}\n          </midi-device>\n          `\n      }\n      for (const entry of midiAccess.outputs) {\n        const output = entry[1];\n        this.devices.innerHTML += `\n        <p>Output port [type:'${output.type}'] id:'${output.id}' manufacturer:'${output.manufacturer}' name:'${output.name}' version:'${output.version}'\n        </p>`\n      }\n\n\n\n```\n\n```js\n   initialize(midiAccess) {\n\n      this.midi = midiAccess\n      for (const entry of midiAccess.inputs) {\n        const input = entry[1];\n        this.input_devices[input.id] = input\n      }\n\n      for (const entry of midiAccess.outputs) {\n        const output = entry[1];\n        this.output_devices[output.id] = output\n      }\n\n      Object.values(this.input_devices).forEach(d => {\n        const device = Object.assign(d, {});\n        console.log(device)\n        const midi_device = document.createElement('midi-device');\n        Object.keys(device).forEach(key => {\n          console.log(device, key, device[key])\n          midi_device.setAttribute(key, device[key]);\n        })\n        this.appendChild(midi_device)\n      })\n\n      this.startLoggingMIDIInput()\n    }\n\n```\n\n#MIDICLOCK \n\nThis software has a lot of jquery around a sequencer core. Sequencer looks like: \n\n```js\n\n\n//Event handler for when midi device picker was changed\n\nfunction changeMIDIOut(e) {\n\tmidiDevice = midiAccess.outputs()[e.target.selectedIndex];\n}\n\n\nif (midiDevice && e.target[e.target.selectedIndex] != \"No Device Available\") {}\n\n\t\n\tmidiDevice = midiAccess.outputs.get(id);\n\n\n// change bpm\n\ntempo = 60 / bpm / 24;\n\n\n\n// stop? \nmidiDevice.send([0xFC]);\n\n\nsetTimeout(function() {\n\t//send midi clock start only the first beat!\n\t//timeout needed to avoid quick first pulse\n\tplayPressed = false;\n\tmidiDevice.send([0xFA]);\n\tmidiDevice.send([0xF8]);\n}, \ncurrentTime + nextClockTime);\n\t\n\n//move the clock forward by tempo intervals (24ppq)\n\n\n//send midi clock signal\n\nmidiDevice.send([0xF8]);\n\n\n//turn off current note playing\n\nmidiDevice.send([0x80, currentNote, 0x40]);\n\n}\n\n//send the current note\n\nmidiDevice.send([0x90, currentNote, 0x7f]);\n\n//the next clock will be at the next tempo marker\n\nnextClockTime += tempo;\n\n}\n\n```\n\n\n```js\n function parseMidiMessage(message) {\n    return {\n      command_hex: message.data[0],\n      command: message.data[0] >> 4,\n      channel: message.data[0] & 0xf,\n      note: message.data[1],\n      velocity: message.data[2] / 127,\n      \n    }\n  }\n\n  function onNote(note, velocity) {}\n  function onPad(pad, velocity) {}\n  function onPitchBend(value) {}\n  function onModWheel(value) {}\n  function onPulse(note, velocity) {}\n\n  /**\n   * Handle a MIDI message from a MIDI input.\n   */\n  function handleMidiMessage(message) {\n\n    // Parse the MIDIMessageEvent.\n    const {command, channel, note, velocity} = parseMidiMessage(message)\n\n    // Stop command.\n    // Negative velocity is an upward release rather than a downward press.\n    if (command === 8) {\n      if      (channel === 0) onNote(note, -velocity)\n      else if (channel === 9) onPad(note, -velocity)\n    }\n\n    // Start command.\n    else if (command === 9) {\n      if      (channel === 0) onNote(note, velocity)\n      else if (channel === 9) onPad(note, velocity)\n    }\n\n    // Knob command.\n    else if (command === 11) {\n      if (note === 1) onModWheel(velocity)\n    }\n\n    // Pitch bend command.\n    else if (command === 14) {\n      onPitchBend(velocity)\n    }\n  }\n\n\n```\n\n---\n\nhttps://medium.com/swinginc/playing-with-midi-in-javascript-b6999f2913c3\n\nhttps://www.donwalizerjr.com/js-midi-synthesizer/\n## Instrument Ideas\n\n\nA Karpers-Strong\nhttps://mohayonao.github.io/timbre.js/PluckGen.html\n\nSoundFonts for Audio:\nhttps://github.com/surikov/webaudiofont\n\nhttps://jsbin.com/wajopuy/1/edit?html,output\n\n```HTML\n\n<html>\n\t<head>\n\t\t<script src='https://surikov.github.io/webaudiofont/npm/dist/WebAudioFontPlayer.js'></script>\n\t\t<script src='https://surikov.github.io/webaudiofontdata/sound/12835_17_JCLive_sf2_file.js'></script>\n\t\t<script src='https://surikov.github.io/webaudiofontdata/sound/12840_1_JCLive_sf2_file.js'></script>\n\t\t<script src='https://surikov.github.io/webaudiofontdata/sound/12842_1_JCLive_sf2_file.js'></script>\n\t\t<script src='https://surikov.github.io/webaudiofontdata/sound/12851_1_JCLive_sf2_file.js'></script>\n\t\t<script src='https://surikov.github.io/webaudiofontdata/sound/12850_1_JCLive_sf2_file.js'></script>\n\t\t<script src='https://surikov.github.io/webaudiofontdata/sound/12848_1_JCLive_sf2_file.js'></script>\n\t\t<script src='https://surikov.github.io/webaudiofontdata/sound/12841_1_JCLive_sf2_file.js'></script>\n\t\t<script>\n\t\t\tvar AudioContextFunc = window.AudioContext || window.webkitAudioContext;\n\t\t\tvar audioContext = new AudioContextFunc();\n\t\t\tvar player=new WebAudioFontPlayer();\n\t\t\tplayer.loader.decodeAfterLoading(audioContext, '_drum_35_17_JCLive_sf2_file');\n\t\t\tplayer.loader.decodeAfterLoading(audioContext, '_drum_40_1_JCLive_sf2_file');\n\t\t\tplayer.loader.decodeAfterLoading(audioContext, '_drum_42_1_JCLive_sf2_file');\n\t\t\tplayer.loader.decodeAfterLoading(audioContext, '_drum_51_1_JCLive_sf2_file');\n\t\t\tplayer.loader.decodeAfterLoading(audioContext, '_drum_50_1_JCLive_sf2_file');\n\t\t\tplayer.loader.decodeAfterLoading(audioContext, '_drum_48_1_JCLive_sf2_file');\n\t\t\tplayer.loader.decodeAfterLoading(audioContext, '_drum_41_1_JCLive_sf2_file');\n\t\t</script>\n\t\t<style type=\"text/css\">\n\t\t\t.bassStyle {position: absolute;left: 220px;top: 280px;width: 170px;height: 170px;}\n\t\t\t.snareStyle {position: absolute;left: 393px;top: 239px;width: 140px;height: 70px;}\n\t\t\t.hihatStyle {position: absolute;left: 463px;top: 133px;width: 143px;height: 86px;}\n\t\t\t.cymbalStyle {position: absolute;left: 76px;top: 27px;width: 160px;height: 95px;}\n\t\t\t.tom1Style {position: absolute;left: 308px;top: 133px;width: 127px;height: 100px;}\n\t\t\t.tom2Style {position: absolute;left: 165px;top: 138px;width: 136px;height: 110px;}\n\t\t\t.tom3Style {position: absolute;left: 41px;top: 255px;width: 155px;height: 164px;}\n\t\t</style>\n</head>\n\t<body>\n\t\t<p><img src=\"https://surikov.github.io/webaudiofont/img/drums.jpg\" width=\"600\" height=\"509\"></p>\n\t\t<a href=\"#\" onmousedown=\"player.queueWaveTable(audioContext, audioContext.destination, _drum_35_17_JCLive_sf2_file, 0, 35, 3);\"><div class=\"bassStyle\">&nbsp;</div></a>\n\t\t<a href=\"#\" onmousedown=\"player.queueWaveTable(audioContext, audioContext.destination, _drum_40_1_JCLive_sf2_file, 0, 40, 3);\"><div class=\"snareStyle\">&nbsp;</div></a>\n\t\t<a href=\"#\" onmousedown=\"player.queueWaveTable(audioContext, audioContext.destination, _drum_42_1_JCLive_sf2_file, 0, 42, 3);\"><div class=\"hihatStyle\">&nbsp;</div></a>\n\t\t<a href=\"#\" onmousedown=\"player.queueWaveTable(audioContext, audioContext.destination, _drum_51_1_JCLive_sf2_file, 0, 51, 3);\"><div class=\"cymbalStyle\">&nbsp;</div></a>\n\t\t<a href=\"#\" onmousedown=\"player.queueWaveTable(audioContext, audioContext.destination, _drum_50_1_JCLive_sf2_file, 0, 50, 3);\"><div class=\"tom1Style\">&nbsp;</div></a>\n\t\t<a href=\"#\" onmousedown=\"player.queueWaveTable(audioContext, audioContext.destination, _drum_48_1_JCLive_sf2_file, 0, 48, 3);\"><div class=\"tom2Style\">&nbsp;</div></a>\n\t\t<a href=\"#\" onmousedown=\"player.queueWaveTable(audioContext, audioContext.destination, _drum_41_1_JCLive_sf2_file, 0, 41, 3);\"><div class=\"tom3Style\">&nbsp;</div></a>\n\t\t<hr/>\n\t\t<p><a href=\"https://github.com/surikov/webaudiofont\">source</a></p>\n\t</body>\n</html>\n\n```\n\nIdea: MIDI through controller. \n\nhttps://developer.mozilla.org/en-US/docs/Web/API/MIDIAccess\n\n```javascript\nnavigator.requestMIDIAccess()\n  .then(function(access) {\n\n     // Get lists of available MIDI controllers\n     const inputs = access.inputs.values();\n     const outputs = access.outputs.values();\n\n     access.onstatechange = event => {\n\n       // Print information about the (dis)connected MIDI controller\n       console.log(event.port.name, event.port.manufacturer, event.port.state);\n     };\n  });\n\n```\n\n\n\nhttps://github.com/djipco/webmidi\n\nhttps://webmidijs.org/docs/\n\n\n\n```html\n<!DOCTYPE html>\n\n<html lang=\"en\">\n\n  <head>\n    <meta charset=\"UTF-8\">\n    <title>WebMidi.js Quick Start</title>\n    <script src=\"https://cdn.jsdelivr.net/npm/webmidi@next/dist/iife/webmidi.iife.js\"></script>\n  </head>\n  \n  <body>\n    <h1>WebMidi.js Quick Start</h1>\n  </body>\n  \n  <script type=\"module\">\n  \n    // Enable WebMidi.js and trigger the onEnabled() function when ready\n    WebMidi\n      .enable()\n      .then(onEnabled)\n      .catch(err => alert(err));\n  \n    // Function triggered when WebMidi.js is ready\n    function onEnabled() {\n  \n      // Display available MIDI input devices\n      if (WebMidi.inputs.length < 1) {\n        document.body.innerHTML+= \"No device detected.\";\n      } else {\n        WebMidi.inputs.forEach((device, index) => {\n          document.body.innerHTML+= `${index}: ${device.name} <br>`;\n        });\n      }\n  \n    }\n    \n  </script>\n\n\n</html>\n```\n\n\nDeeper: https://www.keithmcmillen.com/blog/making-music-in-the-browser-web-midi-api/\n\n\nhttps://developer.mozilla.org/en-US/docs/Web/API/MIDIAccess\n\nTheme\n\n1.  [References](/en-US/docs/Web)\n2.  [Web APIs](/en-US/docs/Web/API)\n3.  [MIDIAccess](/en-US/docs/Web/API/MIDIAccess)\n\nArticle Actions\n\n-   English (US)\n    \n\n## In this article\n\n-   [Properties](#properties)\n-   [Examples](#examples)\n-   [Specifications](#specifications)\n-   [Browser compatibility](#browser_compatibility)\n\n#### Related Topics\n\n1.  **[Web MIDI API](/en-US/docs/Web/API/Web_MIDI_API)**\n2.  **[`MIDIAccess`](/en-US/docs/Web/API/MIDIAccess)**\n3.  Properties\n    \n    1.  [`inputs`](/en-US/docs/Web/API/MIDIAccess/inputs)\n    2.  [`outputs`](/en-US/docs/Web/API/MIDIAccess/outputs)\n    3.  [`sysexEnabled`](/en-US/docs/Web/API/MIDIAccess/sysexEnabled)\n    \n4.  Events\n    \n    1.  [`statechange`](/en-US/docs/Web/API/MIDIAccess/statechange_event)\n    \n5.  Inheritance:\n    \n    1.  [`EventTarget`](/en-US/docs/Web/API/EventTarget)\n    \n6.  Related pages for Web MIDI API\n    \n    1.  [`MIDIConnectionEvent`](/en-US/docs/Web/API/MIDIConnectionEvent)\n    2.  [`MIDIInput`](/en-US/docs/Web/API/MIDIInput)\n    3.  [`MIDIInputMap`](/en-US/docs/Web/API/MIDIInputMap)\n    4.  [`MIDIMessageEvent`](/en-US/docs/Web/API/MIDIMessageEvent)\n    5.  [`MIDIOutput`](/en-US/docs/Web/API/MIDIOutput)\n    6.  [`MIDIOutputMap`](/en-US/docs/Web/API/MIDIOutputMap)\n    7.  [`MIDIPort`](/en-US/docs/Web/API/MIDIPort)\n    8.  [`Navigator.requestMIDIAccess()`](/en-US/docs/Web/API/Navigator/requestMIDIAccess)\n    \n\n## In this article\n\n-   [Properties](#properties)\n-   [Examples](#examples)\n-   [Specifications](#specifications)\n-   [Browser compatibility](#browser_compatibility)\n\n# MIDIAccess\n\n**Secure context:** This feature is available only in [secure contexts](/en-US/docs/Web/Security/Secure_Contexts) (HTTPS), in some or all [supporting browsers](#browser_compatibility).\n\nThe **`MIDIAccess`** interface of the [Web MIDI API](/en-US/docs/Web/API/Web_MIDI_API) provides methods for listing MIDI input and output devices, and obtaining access to those devices.\n\nEventTarget MIDIAccess\n\n## [Properties](#properties \"Permalink to Properties\")\n\n[`MIDIAccess.inputs`](/en-US/docs/Web/API/MIDIAccess/inputs) Read only\n\nReturns an instance of [`MIDIInputMap`](/en-US/docs/Web/API/MIDIInputMap) which provides access to any available MIDI input ports.\n\n[`MIDIAccess.outputs`](/en-US/docs/Web/API/MIDIAccess/outputs) Read only\n\nReturns an instance of [`MIDIOutputMap`](/en-US/docs/Web/API/MIDIOutputMap) which provides access to any available MIDI output ports.\n\n[`MIDIAccess.sysexEnabled`](/en-US/docs/Web/API/MIDIAccess/sysexEnabled) Read only\n\nA boolean attribute indicating whether system exclusive support is enabled on the current MIDIAccess instance.\n\n### [Events](#events \"Permalink to Events\")\n\n[`MIDIAccess.statechange_event`](/en-US/docs/Web/API/MIDIAccess/statechange_event)\n\nCalled whenever a new MIDI port is added or an existing port changes state.\n\n## [Examples](#examples \"Permalink to Examples\")\n\nThe [`Navigator.requestMIDIAccess()`](/en-US/docs/Web/API/Navigator/requestMIDIAccess) method returns a promise that resolves with a [`MIDIAccess`](/en-US/docs/Web/API/MIDIAccess) object. Information about the input and output ports is returned.\n\nWhen a port changes state, information about that port is printed to the console.\nq\n```javascript\nnavigator.requestMIDIAccess()\n  .then(function(access) {\n\n     // Get lists of available MIDI controllers\n     const inputs = access.inputs.values();\n     const outputs = access.outputs.values();\n\n     access.onstatechange = event => {\n\n       // Print information about the (dis)connected MIDI controller\n       console.log(event.port.name, event.port.manufacturer, event.port.state);\n     };\n  });\n```\n\n## [Specifications](#specifications \"Permalink to Specifications\")\n\nSpecification\n\n[Web MIDI API  \n# midiaccess-interface](https://webaudio.github.io/web-midi-api/#midiaccess-interface)\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-12-30T03:03:39.042Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "WebRTC",
      "content": "\nNot sure if this works, but this should allow syncing between two web browsers without a signal server: \n\n```html\n<!doctype html>\n<meta charset=\"utf-8\">\n<title>miniWebRTC</title>\n\n<h3>Create or join a room?</h3>\n<button id=\"createBtn\">BOB: Create</button>\n<button id=\"joinBtn\">ALICE: Join</button>\n<hr>\n<h3 id=\"myModalLabel\">BOB: Send your local offer to ALICE</h3>\n<input id=\"localOffer\" rows=10 cols=50>\n<br>\n<h3>Then, paste the \"answer\" you received</h3>\n<input id=\"remoteAnswer\" rows=10 cols=50>\n<br>\n<br>\n<button id=\"answerRecdBtn\">Okay, I pasted it.</button>\n<hr>\n<h3>ALICE: Paste the \"offer\" you received</h3>\n<input id=\"remoteOffer\" rows=10 cols=50>\n<br>\n<br>\n<button id=\"offerRecdBtn\">Okay, I pasted it.</button>\n<h3>Then, send your local answer to BOB</h3>\n<input id=\"localAnswer\" rows=10 cols=50>\n<hr>\nChat:\n<br>\n<div id=\"chatlog\" style=\"height:200px; overflow:auto; border:1px solid\"></div>\n<br>\n<input type=\"text\" id=\"messageTextBox\" placeholder=\"Type your message here\">\n<button id=\"sendMessageBtn\" onclick=\"sendMessage()\">Send message</button>\n<script>\nlocalOffer.value = remoteAnswer.value = remoteOffer.value = localAnswer.value = \"\";\n\n// BOB: create\ncreateBtn.onclick = function() {\n  dc1 = pc1.createDataChannel('test', {reliable: true})\n  activedc = dc1\n  dc1.onopen = function(e) { }\n  dc1.onmessage = function(e) {\n    if (e.data.size) {\n      fileReceiver1.receive(e.data, {})\n    } else {\n      if (e.data.charCodeAt(0) == 2) {\n        return\n      }\n      var data = JSON.parse(e.data)\n      if (data.type === 'file') {\n        fileReceiver1.receive(e.data, {})\n      } else {\n        chatlog.innerHTML += '[' + new Date() + '] ' + data.message + '</p>';\n        chatlog.scrollTop = chatlog.scrollHeight\n      }\n    }\n  }\n  pc1.createOffer(function(desc) {\n    pc1.setLocalDescription(desc, function() {}, function() {})\n  }, function() { }, sdpConstraints)\n};\n\n// BOB: pasted Alice's answer\nanswerRecdBtn.onclick = function () {\n  var answer = remoteAnswer.value;\n  var answerDesc = new RTCSessionDescription(JSON.parse(answer))\n  pc1.setRemoteDescription(answerDesc);\n};\n\n// ALICE: pasted Bob's answer\nofferRecdBtn.onclick = function() {\n  var offer = remoteOffer.value;\n  var offerDesc = new RTCSessionDescription(JSON.parse(offer))\n  pc2.setRemoteDescription(offerDesc)\n  pc2.createAnswer(function(answerDesc) {\n    pc2.setLocalDescription(answerDesc)\n  },\n  function () { },\n  sdpConstraints)\n};\n\nif (navigator.webkitGetUserMedia) {\n  RTCPeerConnection = webkitRTCPeerConnection\n}\n\nvar cfg = {'iceServers': [{'url': \"stun:stun.gmx.net\"}]},\ncon = { 'optional': [{'DtlsSrtpKeyAgreement': true}] }\n\nvar pc1 = new RTCPeerConnection(cfg, con), dc1 = null, tn1 = null, activedc, pc1icedone = false;\n\nvar sdpConstraints = {\n  optional: [],\n}\n\nfunction sendMessage () {\n  if (messageTextBox.value) {\n    activedc.send(JSON.stringify({message: messageTextBox.value}));\n    chatlog.innerHTML += '[' + new Date() + '] ' + messageTextBox.value + '</p>';\n    messageTextBox.value = \"\";\n  }\n  return false\n}\n\npc1.onicecandidate = function (e) {\n  if (e.candidate == null) {\n    localOffer.value = JSON.stringify(pc1.localDescription);\n  }\n}\n\nvar pc2 = new RTCPeerConnection(cfg, con), dc2 = null, pc2icedone = false;\n\npc2.ondatachannel = function (e) {\n  var datachannel = e.channel || e;\n  dc2 = datachannel\n  activedc = dc2\n  dc2.onopen = function (e) { }\n  dc2.onmessage = function (e) {\n    if (e.data.size) {\n      fileReceiver2.receive(e.data, {})\n    } else {\n      var data = JSON.parse(e.data)\n      if (data.type === 'file') {\n        fileReceiver2.receive(e.data, {})\n      } else {\n        chatlog.innerHTML += '[' + new Date() + '] ' + data.message + '</p>';\n        chatlog.scrollTop = chatlog.scrollHeight;\n      }\n    }\n  }\n}\n\npc2.onicecandidate = function (e) {\n  if (e.candidate == null) {\n    localAnswer.value = JSON.stringify(pc2.localDescription);\n  }\n}\n</script>\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-05-18T17:54:04.111Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "WebUSB",
      "content": "https://www.beyondlogic.org/usbnutshell/usb1.shtml\n\nhttps://web.dev/usb/\n\n```js\nlet device;\n\nnavigator.usb.requestDevice({ filters: [{ vendorId: 0x2341 }] })\n.then(selectedDevice => {\n    device = selectedDevice;\n    return device.open(); // Begin a session.\n  })\n.then(() => device.selectConfiguration(1)) // Select configuration #1 for the device.\n.then(() => device.claimInterface(2)) // Request exclusive control over interface #2.\n.then(() => device.controlTransferOut({\n    requestType: 'class',\n    recipient: 'interface',\n    request: 0x22,\n    value: 0x01,\n    index: 0x02})) // Ready to receive data\n.then(() => device.transferIn(5, 64)) // Waiting for 64 bytes of data from endpoint #5.\n.then(result => {\n  const decoder = new TextDecoder();\n  console.log('Received: ' + decoder.decode(result.data));\n})\n.catch(error => { console.error(error); });\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-08T00:47:01.072Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "WebWorkers",
      "content": "https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers\n\n[[ServiceWorker]]\n[[SharedWorker]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-03-08T00:32:05.830Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "XLST",
      "content": "## XLST: A hidden templating engine\n[[XML]] \nAdapted from here:\n\nhttps://www.w3schools.com/xml/tryit.asp?filename=try_cdcatalog\n\n\n```HTML\n<!DOCTYPE html>\n<html>\n<head>\n<script>\nfunction loadXMLDoc(filename){\n  if (window.ActiveXObject){\n    xhttp = new ActiveXObject(\"Msxml2.XMLHTTP\");\n  } else {\n    xhttp = new XMLHttpRequest();\n  }\n  xhttp.open(\"GET\", filename, false);\n  try {xhttp.responseType = \"msxml-document\"} catch(err) {} \n  // Helping IE11\n  xhttp.send(\"\");\n  return xhttp.responseXML;\n}\n\nfunction displayResult(){\n  xml = loadXMLDoc(\"cdcatalog.xml\");\n  xsl = loadXMLDoc(\"cdcatalog.xsl\");\n  // code for IE\n  if (window.ActiveXObject || xhttp.responseType == \"msxml-document\")\n    {\n    ex = xml.transformNode(xsl);\n    document.getElementById(\"example\").innerHTML = ex;\n    }\n  // code for Chrome, Firefox, Opera, etc.\n  else if (document.implementation && \n    document.implementation.createDocument){\n    xsltProcessor = new XSLTProcessor();\n    xsltProcessor.importStylesheet(xsl);\n    resultDocument = xsltProcessor.transformToFragment(xml, document);\n    document.getElementById(\"example\").appendChild(resultDocument);\n    }\n}\n</script>\n</head>\n<body onload=\"displayResult()\">\n<div id=\"example\" />\n</body>\n</html>\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-03-25T21:05:01.282Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "XML to JSON",
      "content": "\nhttps://www.npmjs.com/package/xml-js\n\n[[Node.js]] \n\n```javascript\nvar convert = require('xml-js');\nvar xml = require('fs').readFileSync('./testscenario.xml', 'utf8');\n\nvar result = convert.xml2json(xml, {compact: true, spaces: 4});\nconsole.log(result);\n```\n\n\n```js\nfunction xmlToJson(xml) {\n\t\n\t// Create the return object\n\tvar obj = {};\n\n\tif (xml.nodeType == 1) { // element\n\t\t// do attributes\n\t\tif (xml.attributes.length > 0) {\n\t\tobj[\"@attributes\"] = {};\n\t\t\tfor (var j = 0; j < xml.attributes.length; j++) {\n\t\t\t\tvar attribute = xml.attributes.item(j);\n\t\t\t\tobj[\"@attributes\"][attribute.nodeName] = attribute.nodeValue;\n\t\t\t}\n\t\t}\n\t} else if (xml.nodeType == 3) { // text\n\t\tobj = xml.nodeValue;\n\t}\n\n\t// do children\n\tif (xml.hasChildNodes()) {\n\t\tfor(var i = 0; i < xml.childNodes.length; i++) {\n\t\t\tvar item = xml.childNodes.item(i);\n\t\t\tvar nodeName = item.nodeName;\n\t\t\tif (typeof(obj[nodeName]) == \"undefined\") {\n\t\t\t\tobj[nodeName] = xmlToJson(item);\n\t\t\t} else {\n\t\t\t\tif (typeof(obj[nodeName].push) == \"undefined\") {\n\t\t\t\t\tvar old = obj[nodeName];\n\t\t\t\t\tobj[nodeName] = [];\n\t\t\t\t\tobj[nodeName].push(old);\n\t\t\t\t}\n\t\t\t\tobj[nodeName].push(xmlToJson(item));\n\t\t\t}\n\t\t}\n\t}\n\treturn obj;\n};\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-05-25T19:12:04.776Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Yes or No",
      "content": "```js\n#!/usr/bin/env node\n\nconst rdo = require('@randomorg/core');\n\nlet rdo1 = new rdo.RandomOrgClient('63811cbf-40d5-4beb-9907-01e7e126446b');\n\nrdo1.generateIntegers(127, 0, 1)\n.then(res => {\n  let answer = false; \n  let num_yes = 0;\n  res.forEach(num => {\n    if(num === 1) num_yes++\n  });\n\n  if(num_yes < 64){\n    console.log('No', \"yes:\",num_yes, \"no:\",127 - num_yes);\n  } else {\n    console.log('Yes', \"yes:\",num_yes, \"no:\",127 - num_yes);\n  }\n});\n\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-17T21:56:26.468Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "a-frame.js",
      "content": "\n# Hans components to aframe.js\n```html\n\n> Assuming the javascript library aframe.js, write a script that takes custom html component, see if there is a function called getAframeComponent(), and if it has that function, create a new object in the aframe <a-scene></a-scene> component\n```\n\nTo begin, we need to create an HTML page that includes the aframe.js library and the custom HTML component that we want to check for the existence of the getAframeComponent() function. For the purposes of this example, let's assume that the custom component is named \"my-custom-component\" and is defined as follows:\n\n\n```html\n\n<html>\n\n<head>\n\n  <script src=\"https://aframe.io/releases/0.9.0/aframe.min.js\"></script>\n\n</head>\n\n<body>\n\n  <a-scene>\n\n    <my-custom-component></my-custom-component>\n\n  </a-scene>\n\n</body>\n\n</html>\n\n```\n\n\nNext, we need to create the script that will check for the existence of the getAframeComponent() function. Here's an example script that accomplishes this:\n\n\n```js\n\n// wait for document to load\n\ndocument.addEventListener(\"DOMContentLoaded\", function() {\n\n  // get all custom HTML elements within the aframe scene\n\n  var customElements = document.querySelector(\"a-scene\").querySelectorAll(\"[is=my-custom-component]\");\n\n  \n\n  // iterate over each custom HTML element\n\n  for (var i = 0; i < customElements.length; i++) {\n\n    var el = customElements[i];\n\n    \n\n    // check if the element has a getAframeComponent() function\n\n    if (typeof el.getAframeComponent === \"function\") {\n\n      // create a new object within the aframe scene\n\n      var newObj = document.createElement(\"a-entity\");\n\n      newObj.setAttribute(\"geometry\", \"primitive: box\");\n\n      newObj.setAttribute(\"material\", \"color: red\");\n\n      newObj.setAttribute(\"position\", \"0 0 -1\");\n\n      el.appendChild(newObj);\n\n    }\n\n  }\n\n});\n\n```\n\n\nThis script first waits for the document to load, then finds all custom HTML elements within the aframe scene that have an \"is\" attribute of \"my-custom-component\". It then iterates over each element and checks if it has a getAframeComponent() function. If it does, it creates a new object within the element that is a red box positioned in front of the element.\n\n\nTo run this script, simply include it in a \\<script> tag within the HTML page after the aframe.js library, like this:\n\n\n```html\n\n<html>\n\n<head>\n\n  <script src=\"https://aframe.io/releases/0.9.0/aframe.min.js\"></script>\n\n</head>\n\n<body>\n\n  <a-scene>\n\n    <my-custom-component></my-custom-component>\n\n  </a-scene>\n\n  \n\n  <script src=\"your-script.js\"></script>\n\n</body>\n\n</html>\n```\n\n\nReplace \"your-script.js\" with the filename of the script that you created. There are no additional dependencies or prerequisites required for this script to run.\n\n\nSome best practices for code readability and maintainability include using descriptive variable names, organizing code into functions where appropriate, and commenting your code to explain what it does. Additionally, it's important to handle any potential errors or exceptions that may arise, such as if the custom HTML component or getAframeComponent() function do not exist. To handle these errors, you could add conditional statements or try/catch blocks to your code.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-10-06T20:58:08.942Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "attribute-editor-component",
      "content": "```js\n\n\nclass AttributeEditor extends HTMLElement {\n  connectedCallback(){\n    const elements = [...this.querySelectorAll('.editable')];\n    elements.forEach(el => {\n      console.log(el.constructor.observedAttributes);\n    })\n  }\n\n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n    switch(name){\n      default:\n    }\n  }\n\n}\n\ncustomElements.define('attribute-editor', AttributeEditor)\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-07T20:23:36.781Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "babel.js",
      "content": "# Babel\nhttps://babeljs.io/\n\n# Babel is a JavaScript compiler.\n\n```html\n```html\n<div id=\"output\"></div>\n<!-- Load Babel -->\n<!-- v6 <script src=\"https://unpkg.com/babel-standalone@6/babel.min.js\"></script> -->\n<script src=\"https://unpkg.com/@babel/standalone/babel.min.js\"></script>\n<!-- Your custom script here -->\n<script type=\"text/babel\">\nconst getMessage = () => \"Hello World\";\ndocument.getElementById('output').innerHTML = getMessage();\n</script>\n```\n\n> See [docs](https://babeljs.io/docs/en/babel-standalone) for full documentation on `@babel/standalone`.\n\nhttps://babeljs.io/docs/en/babel-preset-typescript\n\nStrips out all typescript compilations\n\n\n##\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-12-13T16:44:22.886Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "bowie-oracle",
      "content": "```js\n\n// Get the <audio> element\nconst audioElement = document.getElementById(\"yourAudioElementId\");\n\n// Ensure the audio has loaded before manipulating it\naudioElement.addEventListener(\"loadedmetadata\", function () {\n  // Get the duration of the audio\n  const audioDuration = audioElement.duration;\n\n  // Generate a random time within the audio duration\n  const randomTime = Math.random() * (audioDuration - 1.4);\n\n  // Set the audio's currentTime to the random time\n  audioElement.currentTime = randomTime;\n\n  // Play 1.4 seconds of audio\n  audioElement.play();\n\n  // Stop playback after 1.4 seconds\n  setTimeout(() => {\n    audioElement.pause();\n  }, 1400);\n});\n\n// Start loading the audio\naudioElement.load();\n\n// Get the <audio> element\nconst audioElement = document.getElementById(\"yourAudioElementId\");\n\n// Add an event listener to track the loading progress\naudioElement.addEventListener(\"progress\", function() {\n  const loadedPercentage = (audioElement.buffered.end(0) / audioElement.duration) * 100;\n  console.log(`Loaded: ${loadedPercentage}%`);\n});\n\n// Start loading the audio\naudioElement.load();\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-07T20:48:52.758Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "browserify",
      "content": "https://browserify.org/\n\nuses #require \n\n"
    },
    {
      "tags": [
        "programming",
        "bun-sh"
      ],
      "lastIndexed": "never",
      "lastUpdated": "2023-10-02T18:33:32.905Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "bun.sh",
      "content": "## Install\n\nI installed bun.sh with:\n\n```sh\ncurl -fsSL https://bun.sh/install | bash\nsource /home/lnsy/.bashrc\n\n```\n\nI created a new project with:\n\n```sh\nbun init\n```\n\nI changed index.ts to index.js\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.514Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "command-system",
      "content": "```javascript\n// First we create a function like this one:\nconst addCommands = commands => target =>\n    Object.defineProperties(\n        target,\n        Object.fromEntries(\n            Object.entries(commands).map(([command, action]) => [\n                command,\n                {\n                    get: () => {\n                        action();\n                        return command;\n                    }\n                }\n            ])\n        )\n    );\n\n// This is just to make the window.open shorter:\nconst redirect = url => () => window.open(url);\n\n// And then we add as many commands as we want:\n// It expects an object with the format { commandName: function to call }\naddCommands({\n    twitter: redirect(\"https://twitter.com/lukeshiru\"),\n    dev: redirect(\"https://dev.to/lukeshiru\")\n})(window);\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-17T22:10:51.173Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "create new component",
      "content": "editor opens with\n\n\nbrowser window, divided into 2 columns. The left column has 3 rows of text editor windows. the right column has two rows  -- the top editor with 3d, the bottom a plain html. \n\nName of item is \n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-10-06T19:18:36.776Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "custom events in javascript",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-17T18:12:35.447Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "custom-obsidian-plugins",
      "content": "written in [[typescript]]\n\n> write an overview how to program a custom obsidian plugin\n\n```ai\n\nIntroduction\n\n\nObsidian is a powerful note-taking software that allows users to create, organize, and connect their notes and data. One of the key features of Obsidian is the ability to customize and extend its functionality through plugins. In this guide, we will cover how to program a custom plugin for Obsidian using JavaScript, CSS, and HTML.\n\n\nSetting up the Development Environment\n\n\nTo begin programming a custom plugin for Obsidian, you'll need to set up a development environment. Here's how:\n\n\n1. Install Obsidian on your computer.\n\n\n2. Open Obsidian and navigate to the settings menu by clicking on the gear icon in the bottom left corner of the screen.\n\n\n3. Click on the \"Community plugins\" tab and toggle the switch to enable \"Developer mode\".\n\n\n4. Create a new folder on your computer to hold your plugin code.\n\n\n5. Open your command prompt and navigate to the folder you just created.\n\n\n6. Run the command \"npm init\" to initialize a new Node.js package.\n\n\n7. Install the \"obsidian-api\" package by running the command \"npm install obsidian-api\".\n\n\n8. Create a new file called \"main.ts\" in your project folder. This will be the entry point for your plugin code.\n\n\nWriting and Testing the Plugin Code\n\n\nNow that you have set up your development environment, you can start writing and testing your plugin code. Here are the steps to follow:\n\n\n1. Open the \"main.ts\" file in your code editor.\n\n\n2. Import the necessary modules and libraries, including the Obsidian API.\n\n\n3. Define any required variables, functions, or classes.\n\n\n4. Use the relevant Obsidian API functions and properties to create the desired functionality for your plugin.\n\n\n5. Save your code and run the following command in your terminal: \"npm run build\". This will compile your TypeScript code into JavaScript.\n\n\n6. Open Obsidian and navigate to the \"Developer\" settings menu. Click on the \"Load plugin\" button and select the compiled JavaScript file.\n\n\n7. Enable your plugin and test its functionality.\n\n\nIntegrating the Plugin into Obsidian\n\n\nAfter writing and testing your plugin code, you can integrate it into Obsidian to make it available for use. Here's how:\n\n\n1. Navigate to the \"Community plugins\" tab in the Obsidian settings menu.\n\n\n2. Fill out the required fields to submit your plugin to the Obsidian community. This includes a name, description, icon, and other metadata.\n\n\n3. Upload the compiled JavaScript file to your preferred hosting service, such as GitHub or a personal website.\n\n\n4. Share the link to your plugin with the Obsidian community.\n\n\nExamples of Plugin Functionality\n\n\nHere are a few examples of plugin functionality that you can implement using the Obsidian API and related technologies:\n\n\n1. Creating new commands - You can create new commands for Obsidian by defining related functions in your plugin code and assigning them to specific keyboard shortcuts or menu items.\n\n\n2. Customizing the user interface - You can add new sections, buttons, or other UI elements to the Obsidian interface by using HTML and CSS.\n\n\n3. Accessing the Obsidian API - You can use the Obsidian API to search, modify, or interact with notes and data within the application.\n\n\nResources and Links\n\n\nTo learn more about programming custom plugins for Obsidian, here are some helpful resources and links:\n\n\n1. Obsidian API documentation: https://github.com/obsidianmd/obsidian-api\n\n\n2. Obsidian plugin development tutorial: https://obsidian.md/documentation/plugins/building-a-plugin\n\n\n3. TypeScript documentation: https://www.typescriptlang.org/docs\n\n\n4. HTML and CSS tutorials: https://www.w3schools.com\n\n\nConclusion\n\n\nIn this guide, we have covered the basics of programming a custom plugin for Obsidian using JavaScript, CSS, and HTML. By following these steps and using the Obsidian API, you can create powerful and customizable plugins that enhance the functionality of the Obsidian note-taking software. Remember to share your work with the community and continue learning and exploring new possibilities for your plugins.\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:39:50.844Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "database",
      "content": "```js\nimport { Database } from \"bun:sqlite\";\n\nconst db = new Database('dataroom.db');\n\n// Initialize the database table if it doesn't exist\ndb.run(`\n  CREATE TABLE IF NOT EXISTS file_index (\n    filePath TEXT PRIMARY KEY,\n    content TEXT,\n    keywords TEXT,\n    hashtags TEXT,\n    metadata TEXT,\n    notebook TEXT\n  );\n`);\n\n// Function to upsert file data\nasync function upsertFileData(filePath, content, keywords, hashtags, metadata, notebook) {\n  // Convert arrays and object to string to store in the SQLite database\n  const keywordsString = JSON.stringify(keywords);\n  const hashtagsString = JSON.stringify(hashtags);\n  const metadataString = JSON.stringify(metadata);\n\n  // UPSERT query (insert or update if the entry exists)\n  const query = `\n    INSERT INTO file_index (filePath, content, keywords, hashtags, metadata, notebook)\n    VALUES (?, ?, ?, ?, ?, ?)\n    ON CONFLICT(filePath) DO UPDATE SET\n      content=excluded.content,\n      keywords=excluded.keywords,\n      hashtags=excluded.hashtags,\n      metadata=excluded.metadata,\n      notebook=excluded.notebook;\n  `;\n  await db.run(query, [filePath, content, keywordsString, hashtagsString, metadataString, notebook]);\n  console.log(`Data upserted for file: ${filePath}`);\n}\n\n// Function to search for file data by keywords or hashtags\nasync function searchFileData(searchTerm) {\n  try {\n    // Prepare the query, using placeholders for parameters\n    const query_text = `\n      SELECT *\n      FROM file_index\n      WHERE hashtags LIKE $searchTerm\n         OR keywords LIKE $searchTerm\n         OR metadata LIKE $searchTerm\n         OR content LIKE $searchTerm;\n    `;\n\n    // Format the searchTerm for a partial match\n    const formattedSearchTerm = `%${searchTerm}%`;\n\n    // Execute the query with parameters\n    // Assuming `db` is your database connection and it has a method `execute` or similar\n    const query = db.query(query_text);\n    const results = query.all({$searchTerm: formattedSearchTerm});\n    console.log(results)\n    // Log and return the results\n    return results;\n  } catch (error) {\n    console.error('Error searching file data:', error);\n    // Handle the error as appropriate (e.g., return an error message or throw an error)\n    return {\"error\": \"An error occurred during the search: \" + error.message};\n  }\n}\n\nasync function removeFile(filePath) {\n  try {\n    // Prepare the DELETE query, using placeholders for parameters\n    const query = `\n      DELETE FROM file_index\n      WHERE filePath = ?;\n    `;\n\n    // Execute the query with parameters\n    await db.run(query, [filePath]);\n    console.log(`File removed: ${filePath}`);\n  } catch (error) {\n    console.error('Error removing file data:', error);\n    // Handle the error as appropriate (e.g., return an error message or throw an error)\n    return {\"error\": \"An error occurred during the file removal: \" + error.message};\n  }\n}\n\n\nexport { upsertFileData, searchFileData, removeFile };\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.514Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "dataroom-earth-notes",
      "content": "DATAROOM EARTH NOTES\n\nto convert points to 3d\n\n``` js\nvar phi   = (90-lat)*(Math.PI/180),\ntheta = (lon+180)*(Math.PI/180),\nx = -((radius) * Math.sin(phi)*Math.cos(theta)),\nz = ((radius) * Math.sin(phi)*Math.sin(theta)),\ny = ((radius) * Math.cos(phi));\n\nreturn new THREE.Vector3(x,y,z);\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.514Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "dataroom-element.js",
      "content": "The Dataroom Element is the parent class for all html elements. It is a custom HTMLElement with certain additions. \n\n\nHere is a prototype of an object that observes\nall child nodes, and uses the mutation observer api\nto detect added, removed and updated nodes: \n\n```js\n\n export class DataroomElement extends HTMLElement {\n    connectedCallback() {\n      this.observeChildChanges();\n      this.stepThroughChildNodes(this);\n      this.initialize();\n    }\n\n    async initialize() {\n      // override this class to run initialization code here\n    }\n\n    disconnectedCallback() {\n      this.disconnect();\n    }\n\n    async disconnect() {\n      // override this function to run disconnect code\n    }\n\n    stepThroughChildNodes(node) {\n      if (node.nodeType === Node.ELEMENT_NODE) {\n        // Perform actions on each child node here\n        console.log('Processing child node:', node);\n      }\n\n      for (let i = 0; i < node.childNodes.length; i++) {\n        this.stepThroughChildNodes(node.childNodes[i]);\n      }\n    }\n\n\n    observeChildChanges() {\n      const observer = new MutationObserver((mutations) => {\n        mutations.forEach((mutation) => {\n          if (mutation.type === 'attributes' || mutation.type === 'childList') {\n            this.htmlObjectChanged(mutation);\n          }\n        });\n      });\n\n      const config = { attributes: true, childList: true, subtree: true };\n\n      observer.observe(this, config);\n    }\n\n    htmlObjectChanged(mutation) {\n      // Run your function when child elements are added, removed, or attributes are changed\n      switch(mutation.type){\n      case 'childList':\n        if(mutation.addedNodes.length > 0){\n          console.log('added nodes:',mutation.addedNodes)\n          console.log(mutation.target);\n        } else {\n          console.log('removed nodes:', mutation.removedNodes);\n          console.log(mutation.target);\n\n        }\n        break;\n      case 'attributes':\n        console.log(mutation.target);\n        console.log(mutation.attributeName);\n        console.log(mutation.target.getAttribute(mutation.attributeName));\n        break;\n      }\n    }\n  }\n\ncustomElements.define('observe-component', DataroomElement)\n\n\n```\n\nAn Earlier version with file watching and more server calls looks like: \n\n```js\n/*\n  \n  DATAROOM ELEMENT\n\n  #dataroom\n\n\n */\n\nexport class DataroomElement extends HTMLElement {\n\n  connectedCallback(){\n    this.dtrm_id = this.getAttribute('dtrm-id');\n\n    if(this.dtrm_id === null){\n      console.error('dtrm-id required');\n      this.innerText = 'dtrm-id attribute required'\n      return\n    }\n\n    this.initialize();\n    const dtrm_server = document.querySelector('dataroom-server');\n    dtrm_server.addEventListener(this.dtrm_id, (e) => {\n      this.updateFile();\n    });\n  }\n\n  disconnectedCallback(){\n    console.log(this, \"disconnecting\");\n  }\n\n\n  /*\n  \n    UPDATE FILE\n\n    if you want a different action\n    when the file updates override\n    this function in your subclass\n\n   */\n  async updateFile(){\n    const { content } = await this.getFile(this.dtrm_id);\n    this.innerHTML = content;\n  }\n\n  async initialize(){\n    console.log('please override initialize in your own class');\n  }\n\n  setAttributesFromObject(obj = {}){\n    Object.keys(obj).forEach(key => {\n      this.setAttribute(key, obj[key]);\n    })\n  }\n\n  async checkID(fileId) {\n    if(!fileId || fileId === null){\n      fileId = this.getAttribute('dtrm-id');\n    }\n    try {\n      const response = await fetch('/does-file-exist', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          'file-id': fileId,\n        }),\n      });\n\n      if (response.ok) {\n        const data = await response.json();\n        return data.exists;\n      } else {\n        console.error(`Server returned with status code ${response.status}`);\n        return false;\n      }\n    } catch (err) {\n      console.error('Error querying server');\n      return false;\n    }\n  }\n\n  async createFile(){\n    try {\n      const response = await fetch('/create-file', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          'file-id': this.dtrm_id,\n        }),\n      });\n\n      const data = await response.json();\n\n      if (response.ok) {\n        alert('File saved successfully');\n      } else {\n        alert(`Error: ${data.error}`);\n      }\n    } catch (error) {\n      console.error('Error saving file:', error);\n      alert('Error saving file. Please try again.');\n    }\n  }\n\n  async saveFile(file_content){\n    try {\n      const response = await fetch('/save-file', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          'file-id': this.dtrm_id,\n          content: file_content,\n        }),\n      });\n\n      const data = await response.json();\n\n      if (response.ok) {\n        alert('File saved successfully');\n      } else {\n        alert(`Error: ${data.error}`);\n      }\n    } catch (error) {\n      console.error('Error saving file:', error);\n      alert('Error saving file. Please try again.');\n    }\n  }\n\n  async getFile(){\n    if(this.dtrm_id === null || !this.dtrm_id) return\n    try {\n      const response = await fetch('/load-compiled-notebook-page', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          'file-id': this.dtrm_id,\n        }),\n      });\n\n      if (response.ok) {\n        const data = await response.json();\n        return data;\n      } else {\n        console.error(`Server returned with status code ${response.status}`);\n        return {};\n      }\n    } catch (err) {\n      console.error('Error querying server');\n      return err;\n    }\n  }\n\n  async appendToFile(content){\n    if(this.dtrm_id === null || !this.dtrm_id) return\n\n    try {\n      const response = await fetch('/append-to-file', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          content: content,\n          'file-id': this.dtrm_id,\n        }),\n      });\n\n      if (response.ok) {\n        const result = await response.json();\n        return result\n      } else {\n        const error = await response.json();\n      }\n    } catch (error) {\n      console.error('Error:', error);\n      alert('An error occurred while making the request');\n    }\n  }\n\n  // Emits a custom event\n  dtrmEvent(name, detail = {}){\n    const dtrmEvent = new CustomEvent(name, {\n      detail\n    });\n    this.dispatchEvent(dtrmEvent);\n  }\n}\n\n```\n\nEmitting an event: \n\n```js\nexport class DataroomElement extends HTMLElement {\n\n  emitEvent(name, detail = {}){\n    const dtrmEvent = new CustomEvent(name, {\n      detail\n    });\n    this.dispatchEvent(dtrmEvent);\n  }\n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:45:23.426Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "dataroom-setup",
      "content": "\n# Dataroom Setup\n\n- Installed Ubuntu 22.04 LTS\n- With Minimal Installation, \n- Did not install third party software and drivers\n\n## Node.js\nI installed Node.js with FNM:\nhttps://github.com/Schniz/fnm/tree/master\n\nI installed curl with:\n```sh\nsudo apt install curl\n```\n\nI installed node.js with:\n```sh\ncurl -fsSL https://fnm.vercel.app/install | bash\n```\nI opened a new terminal window and did: \n```sh\nfnm install --lts\n```\n\nI installed git with: \n```sh\nsudo apt install git\n```\n\nI created a new key with:\n```sh\nssh-keygen -t ed25519 -C \"email-here\"\nssh-add ~/.ssh/id_ed25519\n```\n\nI opened micro editor and copied the ssh key with ctrl-c\n\nI went here to add the SSH Key: \nhttps://github.com/settings/keys\n\nI cloned the Dataroom main directory:\n\n```sh\ngit clone git@github.com:DATAROOM-NETWORK/dataroom.git\n```\n\n## SSH Server\nThis is optional. \n\nI set up SSH Server with: \n```sh\nsudo apt install openssh-server\n```\n\n## Goal\n\nI want to create a script that I can use on computers that installs all the software I need to run dataroom. \n\nIt should have the LTS version of Node.js and Python\n\nPerhaps Docker is the right tool? \n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-14T22:24:36.309Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Debian Overview",
      "content": "[[Debian]]\n\nI'm going to have to install video card drivers looks like: \n\nhttps://nouveau.freedesktop.org/\n\nhttps://github.com/swaywm/sway/wiki\n\nInstall Manual:\n\nhttps://www.debian.org/releases/bullseye/amd64/\n\nhttps://www.debian.org/distrib/netinst\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-14T22:24:46.733Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Installing Debian",
      "content": "I installed [[Debian]], using the ethernet cable plugged into the wall. \n\nI had to allow not-free packages to get wifi to work. I did this by adding the following line to `/etc/apt/sources.list`\n\n```\ndeb http://ftp.se.debian.org/debian/ stretch main non-free contrib\n```\n\nthen\n\n```bash\napt install `firmware-iwlwifi`\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-14T22:24:53.581Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "installing docker",
      "content": "on [[Debian]]\nhttps://docs.docker.com/engine/install/debian/\n\n```bash\n sudo apt-get remove docker docker-engine docker.io containerd runc\n```\n\n```bash\nsudo apt-get update\n```\n\n```\nsudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n```\n\n```bash\n     curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n    ```\n\n```bash\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n```\n\n\n```bash\nsudo apt-get update\n```\n```bash\nsudo apt-get install docker-ce docker-ce-cli containerd.io\n```\n\n```bash\nsudo apt upgrade\n\n```\n\n\nSet up my SSH Keys with...\n\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent\n\n```shell\nssh-keygen -t ed25519 -C \"lja@fairplay.ai\"\n```\n\n```bash\necho | cat .ssh/id_ed25519\n```\n\nGit cloned\n\n```bash\ngit clone git@github.com:FairPlay-AI/docs.git\n```\n\n```bash\ncd docs/\n```\n\n```bash\nsudo apt install docker-compose\n```\n\nuninstalled Docker-compose, tried this one: \n```bash\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n```\n\nfrom here: https://docs.docker.com/compose/install/\n\ndocker-compose command did not work, so I did:\n\n```bash\nsudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose\n```\n\n\n```bash\nsudo docker-compose up\n```\n\n\nGo to:\nhttp://localhost:8000/figure/#introduction\n\nI had to change and save a file to make this work, but MVV just pushed a fix to solve that bug\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-14T22:25:01.757Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "kubernetes",
      "content": "for [[Debian]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-24T17:00:56.868Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "deck.gl",
      "content": "# Deck.GL\n\n[[pydeck]]\n\nhttps://github.com/danmarshall/deckgl-typings\nhttps://earthengine-layers.com/\n\nhttps://deck.gl/docs/developer-guide/coordinate-systems\n\nhttps://deck.gl/docs/developer-guide/coordinate-systems\n\n```js\nimport {COORDINATE_SYSTEM} from '@deck.gl/core';\nimport {PointCloudLayer} from '@deck.gl/layers';\n\nnew PointCloudLayer({\n  coordinateSystem: COORDINATE_SYSTEM.METER_OFFSETS,\n  coordinateOrigin: [-122.4004935, 37.7900486, 0],  // anchor point in longitude/latitude/altitude\n  data: [\n    {position: [33.22, 109.87, 1.455]}, // meter offsets from the coordinate origin\n    ...\n  ],\n  radiusPixels: 2,\n  sizeUnits: 'pixels'\n})\n```\n\n\nLoading Data: \n\nhttps://deck.gl/docs/developer-guide/loading-data\n\n```js\nnew ScatterplotLayer({\n  data: 'https://secure-server.com/userActivity',\n  loadOptions: {\n    fetch: {\n      method: 'POST',\n      body: JSON.stringify(requestBody),\n      headers: {\n        'Authorization': `Bearer ${accessToken}`,\n      }\n    }\n  }\n  ...\n});\n```\n\n![[Pasted image 20220224090047.png]]\n\nhttps://deck.gl/examples/data-filter-extension/\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-01-29T22:23:45.756Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "download-link-component",
      "content": "```js\n\nclass DownloadLink extends HTMLElement {\n  function createDownload(data, filename){\n     const blob = new Blob([JSON.stringify(data)], { type: 'application/json' });\n      // Create a URL for the blob\n    const url = window.URL.createObjectURL(blob);\n\n      // Create an anchor element\n      const a = document.createElement('a');\n\n      // Set the href and download attributes\n      a.href = url;\n      a.download = filename;\n      this.innerHTML = ' '; \n      this.appendChild(a);\n  }\n}\n\ncustomElements.define('download-link', DownloadLink)\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:09:44.025Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "draggable element",
      "content": "\n```js\n // Make the DIV element draggable:\n\nfunction dragElement(elmnt) {\n  var pos1 = 0, pos2 = 0, pos3 = 0, pos4 = 0;\n  if (elmnt.querySelector('.draggable-header')) {\n    // if present, the header is where you move the DIV from:\n    elmnt.querySelector('.draggable-header').onmousedown = dragMouseDown;\n  } else {\n    // otherwise, move the DIV from anywhere inside the DIV:\n    elmnt.onmousedown = dragMouseDown;\n  }\n\n  function dragMouseDown(e) {\n    e = e || window.event;\n    e.preventDefault();\n    // get the mouse cursor position at startup:\n    pos3 = e.clientX;\n    pos4 = e.clientY;\n    document.onmouseup = closeDragElement;\n    // call a function whenever the cursor moves:\n    document.onmousemove = elementDrag;\n  }\n\n  function elementDrag(e) {\n    e = e || window.event;\n    e.preventDefault();\n    // calculate the new cursor position:\n    let clientX = e.clientX\n    let clientY = e.clientY\n\n    // if(clientX + elmnt.offsetWidth > window.innerWidth) clientX = window.innerWidth\n    // if(clientY + elmnt.offsetHeight > window.innerHeight) clientY = window.innerHeight\n    // if(clientX - elmnt.offsetWidth < 0) clientX = 0\n    // if(clientY - elmnt.offsetHeight < 0) clientY = 0\n    pos1 = pos3 - clientX;\n    pos2 = pos4 - clientY;\n    pos3 = clientX;\n    pos4 = clientY;\n\n    // set the element's new position:\n    elmnt.style.top = (elmnt.offsetTop - pos2) + \"px\";\n    elmnt.style.left = (elmnt.offsetLeft - pos1) + \"px\";\n  }\n\n  function closeDragElement() {\n    // stop moving when mouse button is released:\n    document.onmouseup = null;\n    document.onmousemove = null;\n  }\n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-15T17:42:31.096Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "elastic search",
      "content": "https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-ubuntu-22-04\n\nhttps://www.elastic.co/elasticsearch/?ultron=B-Stack-Trials-AMER-US-W&gambit=Stack-install-EXT&blade=adwords-s&hulk=paid&Device=c&thor=how%20to%20install%20elasticsearch&gclid=Cj0KCQjw7aqkBhDPARIsAKGa0oKPTdZe3m6520z2Af8FWZisLqkBzPL9eFnNWMbCwyrj5XpTpguALXAaAs7-EALw_wcB\n\n---\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-09T01:10:26.717Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "engineers-log-2024-02-08",
      "content": "LLM Layer for Python, Node.js\n\n[[LLM]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-11T01:57:31.024Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "engineers-log-2024-02-10",
      "content": "17:56\nJavascript API no longer works, now only Earth Engine Code Editor. Odd. \n\nlooked [[askmendel.ai]], fucking a doing [[askmendel-spec-work-sprint]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-11T10:43:53.616Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "engineers-log-2024-02-11",
      "content": "https://kumu.io/tour\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:51.102Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "engineers-log-2024-02-13",
      "content": "What is Dataroom?\n\nDataroom is a file-based semantic web interface for spatial computing. \n\nIt uses already existing web standards.\n\nEvery file has a location and a range from that location. \n\nThese locations can be virtual. \n\nFor instance, there are files that you might want in your house, but you don't want to take everywhere you go. Dataroom reasons about this.\n\n## Architecture\n\nDataroom is designed to be compatible with Obsidian notebooks and other markdown based note taking applications. \n\nIt generates and reasons about markdown with YAML front matter.\n\nIt's plugin based system utilizes the html custom elements API, meaning Dataroom Components can be used independently in standard HTML files with modern browsers, or even in note taking apps like Obsidian.md. \n\n\n[[programming/file-clerk]] -- handles file storage and retrieval. \n[[geo-map]] -- interactive map component\n[[dataroom-editor]] -- in browser editor with autoclose tags and other features for editing markdown with yaml front matter\n[[md-renderer]] -- a renderer platform for markdown files with YAML front matter. Includes mermaid charts and 3d graph prototypes\n[[plugin-wizard]] -- automatically generate Dataroom Plugins\n\n\n\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-20T15:58:21.770Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "engineers-log-2024-02-20",
      "content": "1. - I have a cool idea: a webasm HTML Element. So, we would figure out the toolchain to get something from rust - > webASM, and the boilerplate would allow people to talk to the software by setting attributes in the HTML Element. So, there would be an update() function in the rust that runs when users update their attributes, (or, even, just the standard dataroom-element events)\n        \n    - _[_7:47 AM_]_\n        \n        [https://github.com/rustwasm/rust-webpack-template](https://github.com/rustwasm/rust-webpack-template \"https://github.com/rustwasm/rust-webpack-template\n        (https://github.com/rustwasm/rust-webpack-template)\")\n\n\nhttps://github.com/mitch-keenan/wasm-webpack-cpp-simple\n\n#webpack #webasm-component\n\nhttps://developer.mozilla.org/en-US/docs/WebAssembly/Rust_to_Wasm\n\nhttps://rustwasm.github.io/wasm-pack/book/tutorials/hybrid-applications-with-webpack/using-your-library.html\n\nhttps://github.com/rustwasm/wasm-pack\n\nhttps://github.com/rustwasm/team\n\n#rust #webasm \n\n[[webasm-component]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-23T03:50:03.537Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "engineers-log-2024-02-22",
      "content": "Exciting interfaces for boring software\n\n[[Catalogue Raisonné Generator]]\n\n\n[[Extract Text by Page from PDF]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:13:16.861Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "engineers-log-2024-02-24",
      "content": "[[consolidate-scripts]]\n\n[[vanilla-js-structure]]\n\n\nhttp://shoesrb.com/\n\n[[video-security-system]]\n\n\nTo create a script that listens for changes in a folder recursively and runs an `rsync` command when changes are detected, you can use the `inotifywait` command from the `inotify-tools` package in Linux. This tool allows you to monitor file system events on files or directories.\n\nFirst, ensure you have `inotify-tools` installed on your system. If it's not installed, you can usually install it via your distribution's package manager. For example, on Ubuntu or Debian-based systems, you can install it by running:\n\n```bash\nsudo apt-get update\nsudo apt-get install inotify-tools\n```\n\nHere's a basic script that accomplishes what you've described. This script uses `inotifywait` to watch for any changes in the `docs` directory (and its subdirectories) and then runs the `rsync` command to synchronize the changes to the specified target directory.\n\n```bash\n#!/bin/bash\n\nWATCHED_DIR=\"docs/\"\nTARGET_DIR=\"/media/lnsy/HANS\"\n\n# Ensure the target directory exists\nif [ ! -d \"$TARGET_DIR\" ]; then\n    echo \"Target directory $TARGET_DIR does not exist.\"\n    exit 1\nfi\n\n# Monitoring the directory for any changes\ninotifywait -m -r -e create -e modify -e delete -e move \"$WATCHED_DIR\" --format '%w%f' | while read FILE\ndo\n    echo \"Detected change in $FILE, starting rsync...\"\n    rsync -rav \"$WATCHED_DIR\" \"$TARGET_DIR\"\ndone\n```\n\nSave this script to a file, for example, `monitor_and_sync.sh`, and make it executable by running:\n\n```bash\nchmod +x monitor_and_sync.sh\n```\n\nThen, you can run the script simply by:\n\n```bash\n./monitor_and_sync.sh\n```\n\nThis script will continue running in the foreground and monitor changes until you stop it (e.g., by pressing Ctrl+C).\n\nA few points to note:\n- The `inotifywait` options `-m` (monitor), `-r` (recursive), `-e` (event) are used here to watch for specific events. You can adjust the events you're interested in (`create`, `modify`, `delete`, `move`).\n- The `--format '%w%f'` option formats the output to include the path and filename of the changed file.\n- This script assumes that the `docs` directory and the `/media/lnsy/HANS` mount point already exist.\n- Ensure that you have the necessary permissions to read the watched directory and write to the target directory.\n\n---\n\nTo install a Node.js script as a command line tool on macOS, you need to follow these steps:\n\n1. **Create your Node.js script:** First, ensure your script starts with a \"shebang\" line that points to the Node.js interpreter. This line should be the very first line of your script. For example, if your script is named `mytool.js`, the file should start like this:\n\n   ```javascript\n   #!/usr/bin/env node\n   console.log('Hello, world!');\n   ```\n\n2. **Make your script executable:** Change the permissions of your script to make it executable. You can do this from the terminal with the following command:\n\n   ```bash\n   chmod +x mytool.js\n   ```\n\n3. **Move your script to a location in your PATH:** For your script to be recognized as a command line tool, it needs to be located in a directory that's part of your system's PATH. A common choice for personal scripts is `/usr/local/bin`. Move your script there (you may need to use `sudo` for permission):\n\n   ```bash\n   sudo mv mytool.js /usr/local/bin/mytool\n   ```\n\n   By renaming `mytool.js` to `mytool` in the move command, you're also making the command to call it cleaner.\n\n4. **Test your script:** Now, you should be able to run your script from anywhere in the terminal by simply typing its name:\n\n   ```bash\n   mytool\n   ```\n\n### Making Your Script a Global NPM Package\n\nIf you plan to distribute your script or make it reusable, you can package it as an NPM package and even publish it to the NPM registry. Here's how to make it a global package locally:\n\n1. **Create a package.json file:** In the directory with your script, create a `package.json` file. You can create a basic one with `npm init` and filling out the details. Important: Add a `bin` section that points to your script. For example:\n\n   ```json\n   {\n     \"name\": \"mytool\",\n     \"version\": \"1.0.0\",\n     \"description\": \"A simple CLI tool\",\n     \"bin\": {\n       \"mytool\": \"./mytool.js\"\n     },\n     \"author\": \"\",\n     \"license\": \"ISC\"\n   }\n   ```\n\n2. **Link your package globally:** While in the directory with your `package.json` and script, run:\n\n   ```bash\n   npm link\n   ```\n\n   This command creates a global symlink to your package. After running it, you should be able to call your script from anywhere using the name defined in the `bin` section of your `package.json`.\n\n3. **(Optional) Publish to NPM:** If you want others to be able to install your tool with `npm install -g your-tool-name`, you'll need to publish it to the NPM registry. First, create an account on [npmjs.com](https://www.npmjs.com/) if you haven't already, then log in to NPM from your terminal:\n\n   ```bash\n   npm login\n   ```\n\n   After logging in, publish your package:\n\n   ```bash\n   npm publish --access public\n   ```\n\n   The `--access public` flag is necessary for packages scoped under your username, which is the default for new users.\n\nThese steps should help you install your Node.js script as a command line tool on macOS, either just for personal use or as a global NPM package.\n\n\n---\n[[index-images]]\n\nTo extend the script to search for JPEG files (with both `.jpeg` and `.jpg` extensions) in addition to PNG files, we'll make a few modifications. The primary change involves checking the file extension against a list of accepted image types and adjusting the process accordingly. Below is the updated script:\n\n```js\n#!/usr/bin/env node\n\nconst fs = require('fs');\nconst path = require('path');\nconst crypto = require('crypto');\nconst sharp = require('sharp');\n\n// Process command line arguments\nconst [directory] = process.argv.slice(2);\nif (!directory) {\n  console.error('Usage: node index-pngs.js <directory>');\n  process.exit(1);\n}\n\nconst acceptedExtensions = ['.png', '.jpg', '.jpeg'];\n\nfs.readdir(directory, { withFileTypes: true }, (err, files) => {\n  if (err) {\n    console.error('Error reading directory:', err);\n    return;\n  }\n\n  files.forEach((file) => {\n    const fileExtension = path.extname(file.name).toLowerCase();\n    if (file.isFile() && acceptedExtensions.includes(fileExtension)) {\n      const filePath = path.join(directory, file.name);\n      // Replace the file extension with .md for the markdown file path\n      const markdownPath = filePath.slice(0, -fileExtension.length) + '.md';\n\n      // Check if the markdown file exists\n      if (!fs.existsSync(markdownPath)) {\n        // Get image dimensions\n        sharp(filePath).metadata().then(metadata => {\n          // Generate SHA-256 hash of the file\n          const hash = crypto.createHash('sha256');\n          const input = fs.createReadStream(filePath);\n\n          input.on('readable', () => {\n            const data = input.read();\n            if (data)\n              hash.update(data);\n            else {\n              // File read complete, hash generated\n              const fileHash = hash.digest('hex');\n\n              // Now, create the markdown file with YAML front matter\n              const frontMatter = `---\nwidth: ${metadata.width}\nheight: ${metadata.height}\ndate: ${new Date().toISOString()}\nlatitude: TODO\nlongitude: TODO\ntitle: ${path.basename(file.name, fileExtension)}\nfilename: ${file.name}\nhash: ${fileHash}\n---`;\n\n              fs.writeFileSync(markdownPath, frontMatter);\n              console.log(`Generated Markdown for ${file.name}`);\n            }\n          });\n        }).catch(error => console.error(`Error processing ${file.name}:`, error));\n      }\n    }\n  });\n});\n```\n\n### Key Modifications:\n- **Accepted Extensions List**: We've defined `acceptedExtensions` as an array containing the extensions `.png`, `.jpg`, and `.jpeg` to check if the file is an image of one of these types.\n- **Dynamic Markdown Path**: The script dynamically replaces the image file extension with `.md` for the markdown file path, accommodating different lengths of the image file extensions.\n- **Title Extraction**: The title in the YAML front matter is extracted from the file name by removing the file extension using `path.basename(file.name, fileExtension)`, which now accounts for variable extension lengths.\n\nThis updated script now supports PNG, JPG, and JPEG files, generating a Markdown file with YAML front matter for each image file that lacks a corresponding Markdown document.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T17:26:53.963Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "env files in node.js",
      "content": "Certainly! To load an `.env` file into a Node.js project and read a variable (in this case, `TARGET_FOLDER`) from it, you can use the popular `dotenv` package. This package automatically loads environment variables from an `.env` file into the `process.env` object.\n\nHere's a step-by-step guide:\n\n1. **Install `dotenv` Package**: First, you need to install the `dotenv` package if you haven't already. Run this command in your project directory:\n\n```bash\nnpm install dotenv\n```\n\n2. **Create `.env` File**: In your project's root directory, create a file named `.env` and add your environment variables there. For example:\n\n```\nTARGET_FOLDER=/path/to/your/target\n```\n\n3. **Create a Node.js Script**: Now, create a JavaScript file (e.g., `loadEnv.js`) and use the following script to load the `.env` file and read the `TARGET_FOLDER` variable:\n\n```javascript\n// loadEnv.js\n\n// Require the dotenv package to load the .env file\nrequire('dotenv').config();\n\n// Read the TARGET_FOLDER variable from process.env\nconst targetFolder = process.env.TARGET_FOLDER;\n\nconsole.log('TARGET_FOLDER:', targetFolder);\n```\n\n4. **Run Your Script**: Finally, run your script with Node.js to see the output:\n\n```bash\nnode loadEnv.js\n```\n\nThis will print the value of `TARGET_FOLDER` from your `.env` file to the console.\n\nThis approach is a standard and secure way to manage configuration and environment variables in Node.js applications, allowing you to keep sensitive information out of your codebase.\n\n\n```js\n\nconst dotenv = require(\"dotenv\")\ndotenv.config()\n\n\nlet PORT = process.env.PORT\n\nif(!PORT){\n\nPORT = 3000\n\n}\n\nlet EDIT_KEY = process.env.EDIT_KEY\n\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-24T21:51:58.562Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "ffmpeg",
      "content": "https://ffmpegwasm.netlify.app/\n\n\n[[VR AI Videos]]\n\n\n\n```bash\nffmpeg -i input.mp4 -vf \"scale=trunc(iw/4)*2:trunc(ih/4)*2\" -c:v libx265 -crf 28 half_the_frame_size.mp4\n```\n\n\n\ncut in half:\n\n```sh\nffmpeg -i half_the_frame_size.mp4 -filter_complex \"[0]crop=iw/2:ih:0:0[left];[0]crop=iw/2:ih:ow:0[right]\" -map \"[left]\" left.mp4 -map \"[right]\" right.mp4\n```\n\n\n---\n\nextract audio\n```\nffmpeg -i left.mp4 -vn -acodec copy out.m4a\n```\n\n\nextract pngs for each frame\n```\nffmpeg -i left.mp4 img%04d.png\n```\n\n\n\nhttps://stackoverflow.com/questions/10438713/overlay-animated-images-with-transparency-over-a-static-background-image-using-f\n\nOverlay background\n\n\n```js\nconst fs = require('fs');\nconst path = require('path');\nconst Jimp = require('jimp');\n\nconst inputFolderPath = './imgs'; // Path to the folder with PNGs\nconst backgroundPath = './background.png'; // Path to the background PNG\nconst outputFolderPath = './output_images'; // Path to save the composited images\n\n// Create the output folder if it doesn't exist\nif (!fs.existsSync(outputFolderPath)) {\n  fs.mkdirSync(outputFolderPath);\n}\n\n// Read the background image\nJimp.read(backgroundPath)\n  .then(backgroundImage => {\n    // Read and composite all PNGs in the input folder\n    fs.readdirSync(inputFolderPath).forEach(file => {\n      if (file.endsWith('.png')) {\n        const inputImagePath = path.join(inputFolderPath, file);\n        Jimp.read(inputImagePath)\n          .then(inputImage => {\n            inputImage.resize(backgroundImage.getWidth(), backgroundImage.getHeight());\n            backgroundImage.composite(inputImage, 0, 0);\n            const outputFileName = `output_${file}`;\n            const outputPath = path.join(outputFolderPath, outputFileName);\n            backgroundImage.write(outputPath);\n            console.log(`Composite image saved: ${outputPath}`);\n          })\n          .catch(err => {\n            console.error(`Error processing ${inputImagePath}: ${err}`);\n          });\n      }\n    });\n  })\n  .catch(err => {\n    console.error(`Error reading background image: ${err}`);\n  });\n```\n\nhttps://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav\n\n# FFmpeg - The Ultimate Guide\n\nThis guide covers the ins and outs of FFmpeg starting with fundamental concepts and moving to media transcoding and video and audio processing providing practical examples along the way.\n\n---\n\n-   [![Go to the profile of  Csaba Kopias](media/Go_to_the_profile_of_Csaba_Kopias.jpg)](https://img.ly/blog/author/csaba/ \"Go to the profile of Csaba Kopias\")\n\n[Csaba Kopias](https://img.ly/blog/author/csaba/)\n\n21 Nov 2022•58 min read\n\nShare:[](https://twitter.com/share?text=FFmpeg%20-%20The%20Ultimate%20Guide&url=https://img.ly/blog/ultimate-guide-to-ffmpeg/)[](https://www.linkedin.com/shareArticle?mini=true&url=https://img.ly/blog/ultimate-guide-to-ffmpeg/&title=FFmpeg%20-%20The%20Ultimate%20Guide)[](https://www.facebook.com/sharer/sharer.php?u=https://img.ly/blog/ultimate-guide-to-ffmpeg/)\n\n![FFmpeg - The Ultimate Guide](media/FFmpeg_-_The_Ultimate_Guide.png)\n\n#### On this Page\n\n1.  [Introduction to FFmpeg](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#introduction-to-ffmpeg)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#installing-ffmpeg)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffmpeg-history)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffmpeg-supported-codecs-and-formats)\n    4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#compilation-of-ffmpeg)\n    5.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffmpeg-s-strengths)\n    6.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#filtering)\n    7.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#hardware-acceleration)\n    8.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#versatile-input-output-methods)\n    9.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#running-example-commands)\n2.  [Introduction to media concepts](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#introduction-to-media-concepts)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#audio)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#sampling-rate)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#bitrate)\n    4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#channels)\n    5.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#image-properties)\n    6.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#resolution)\n    7.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#bit-depth)\n    8.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#transparency)\n    9.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#video-properties)\n    10.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#video-codecs)\n    11.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#audio-codecs)\n    12.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#containers)\n3.  [Example Material](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#example-material)\n4.  [FFplay and FFprobe](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffplay-and-ffprobe)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffplay)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffprobe)\n5.  [FFmpeg concepts](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffmpeg-concepts)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#inputs)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#streams)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#outputs)\n    4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#mapping)\n    5.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#filtering-1)\n6.  [FFmpeg's command line system](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffmpeg-s-command-line-system)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffmpeg-cli)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#specifying-an-input-file)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#specifying-an-output)\n    4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#understanding-the-command-line-order)\n    5.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#mapping-files)\n    6.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#multiple-outputs)\n7.  [Hands-on with FFmpeg](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#hands-on-with-ffmpeg)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#inputs-1)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#file)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#network)\n    4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#webcam)\n    5.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#microphone)\n    6.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#pipe)\n    7.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#outputs-1)\n8.  [Transcoding audio with FFmpeg](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#transcoding-audio-with-ffmpeg)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#choosing-a-format)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#setting-the-bitrate)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#setting-the-sample-rate)\n    4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#setting-the-channel-count)\n    5.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#complete-command-line-for-converting-audio-with-ffmpeg)\n    6.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#lossless-formats)\n9.  [Transcoding video with FFmpeg](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#transcoding-video-with-ffmpeg)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#converting-to-h-264)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#converting-to-h-265)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#comparing-crf-values-with-h-264-and-h-265)\n10.  [Basic editing with FFmpeg](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#basic-editing-with-ffmpeg)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#trimming-from-the-beginning-of-the-clip)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#trimming-from-the-end-of-the-clip)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#editing-without-reencoding)\n        1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#remove-audio-while-keeping-the-video-without-reencoding)\n        2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#remove-video-while-keeping-the-audio-without-reencoding)\n        3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#cut-and-trim-without-reencoding)\n        4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#replace-audio-on-video-file-without-reencoding)\n11.  [Filtering overview](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#filtering-overview)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#basic-syntax)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#multiple-filters-in-a-chain)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#input-and-output-pads)\n    4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#multiple-chains)\n12.  [Editing video](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#editing-video)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#resizing-or-scaling)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#adding-text)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#adding-an-overlay)\n        1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#basic)\n        2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#aligned)\n        3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#preprocessing-the-input-for-overlay)\n        4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#reusing-content)\n    4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#chroma-keying-green-screen-blue-screen)\n    5.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#what-else)\n13.  [Audio manipulation](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#audio-manipulation)\n    1.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#gate)\n    2.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#equalization)\n    3.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#compression)\n    4.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#changing-the-volume)\n    5.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#let-s-make-audio-gate-again)\n    6.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#putting-it-all-together)\n    7.  [](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#what-else-1)\n14.  [Documentation](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#documentation)\n\nIn this guide, we'll go through the hot topics of FFmpeg. But before that, we'll cover some base ground to help you understand basic media concepts and FFmpeg. Feel free to skip the parts that are already trivial for you!\n\n## Introduction to FFmpeg\n\n[FFmpeg.org](https://ffmpeg.org/about.html)'s definition is the following: \"FFmpeg is the leading multimedia framework, able to decode, encode, transcode, mux, demux, stream, filter and play pretty much anything that humans and machines have created. It supports the most obscure ancient formats up to the cutting edge. No matter if they were designed by some standards committee, the community or a corporation.\"\n\nI think of FFmpeg as the go-to application for audio/video manipulation in an automated or scripted manner.\n\nWhen you need to implement a service that manipulates video, or just have 300 media files that need to be converted into a different format, FFmpeg is your - nerdy - friend.\n\nFFmpeg can do large chunks of the basic functionalities of a modern Non-linear (NLE) video editors, e.g., Davinci Resolve Studio or Premiere Pro. But, it does not have a graphical interface in that sense as those behemoths do, and unarguably it is way less friendly.\n\nIn a general NLE, you might do things like these:\n\n1.  Click to import a file\n2.  Drop it into the timeline\n3.  Trim and Cut\n4.  Add an overlay image\n5.  Crop that overlay\n6.  Add vignette\n7.  Add some color changing effects, e.g. change the hue\n8.  Add an extra audio track to the mix\n9.  Change the volume\n10.  Add some effects, e.g.: echo\n11.  Export into various formats\n12.  Export into a deployable video format\n13.  Export the master audio in wav\n\nOr, to achieve the exact same thing, you could also execute this command:\n\n```shell\nffmpeg -y  \\\n    -ss 20 -t 60 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n    -i train.jpg \\\n    -ss 4 -i voice_recording.wav \\\n    -filter_complex \"[0:v]hue=h=80:s=1[main] ; [1:v]crop=w=382:h=304:x=289:y=227[train] ; [main][train]overlay=x=200:y=200,vignette=PI/4[video] ; [2:a]volume=1.5,aecho=0.8:0.9:100:0.3[speech] ; [0:a][speech]amix=duration=shortest,asplit[audio1][audio2]\" \\\n    -map '[video]' -map '[audio1]' -metadata title=\"Editor's cut\" bbb_edited.mp4 \\\n    -map '[audio2]' bbb_edited_audio_only.wav\n```\n\nCopy\n\nYes, it isn't friendly at all, but it is very, very powerful once you become friends with FFmpeg.\n\nCheck out this comparison of the original and the edited one:\n\n![](media/img-1-edit-before-after.png)\n\nIf you want to try this command out, get the [example](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#example-material) files and see it for yourself!\n\n### Installing FFmpeg\n\nFFmpeg is available for most common and even uncommon platforms and architectures. You can be on Linux, Mac OS X or Microsoft Windows, and you'll be able to run or link to FFmpeg.\n\nInstalling FFmpeg is easy on most platforms! There is no installer, usually just a compressed archive you need to get for your platform and architecture.\n\nIn the case of Linux, most distributions include a pre-built FFmpeg in their software repositories. Therefore, you can install FFmpeg from those even more quickly.\n\n-   [Download for Microsoft Windows](https://ffmpeg.org/download.html#build-windows)\n-   [Download for Mac](https://ffmpeg.org/download.html#build-mac)\n-   [Download for Linux](https://ffmpeg.org/download.html#build-linux)\n\n### FFmpeg history\n\nThe project was started in 2000 by the awesome [Fabrice Bellard](https://bellard.org/). The name is a concatenation of \"FF\" meaning \"fast-forward\" and MPEG, the name of a video standards group. It has been very well, active and alive since then, [releasing](https://ffmpeg.org/releases) a new release about every three months.\n\n### FFmpeg supported codecs and formats\n\nThe default FFmpeg shipped with my Ubuntu Linux distribution supports about 460 codecs and 370 formats.\n\nSee it for yourself:\n\n```shell\nffmpeg -codecs\nffmpeg -formats\n```\n\nCopy\n\n### Compilation of FFmpeg\n\nKeep in mind that the supported codecs and formats (and filters, demuxers, muxers, input and output methods, etc.) are highly dependent on the so-called compilation flags.\n\nThis means that the above number only represents the fact that it supports at least this many codecs and formats. Still, there are even more that the package builders excluded for various reasons, e.g.: licensing, architecture, size considerations, etc.\n\nSince FFmpeg is [open source](https://ffmpeg.org/download.html#repositories), you can [compile FFmpeg](https://trac.ffmpeg.org/wiki/CompilationGuide) for yourself at any time.\n\nSuppose for example, that you care about your layer's size (therefore the bootstrap speed) in AWS Lambda. In this case, you can compile an FFmpeg binary that only contains the mp3 encoder for example, and nothing else.\n\nAlso, you might not want to run into licensing issues and leave out stuff that would cause problems for your use case. Therefore you choose to leave out particular codecs/formats. I highly recommend checking out the \"--enable-gpl\", \"--enable-nonfree\" and \"--enable-version3\" [compilation flags](https://github.com/FFmpeg/FFmpeg/blob/master/configure) in this case, as well as [this](https://ffmpeg.org/legal.html).\n\nOr you might want to have a standalone FFmpeg binary in your project (e.g.: embedded, or some cloud instance), that does not depend on any operating system libraries. Then you want to make a so-called static build, that compiles in all the libraries into a single binary file, and does not depend on your OS' libraries and the runtime loading of other FFmpeg libraries. Search around for \"--enable-static\" in this case.\n\nFinally, you can find pre-built static FFmpeg builds [right here](https://johnvansickle.com/ffmpeg/) too.\n\n### FFmpeg's strengths\n\nFFmpeg reads and writes most video and audio formats that matter for most of us. It is a very capable and high-performance tool for converting and manipulating these formats.\n\nBut FFmpeg can do even more!\n\n### Filtering\n\nFFmpeg has vast amounts of filters for audio and video. Therefore, video manipulation is also a key feature of FFmpeg.\n\n### Hardware acceleration\n\nIt does support many kinds of hardware accelerations! Video encoding is a very resource-intensive operation, and you might come across quite a few hardware devices or features that might speed up your process!\n\nMost notably, if you have an NVIDIA card, you can increase your H.264 or H.265 encoding and decoding throughput by multipliers compared to your CPU. But other things, such as VDPAU, VAAPI, or OpenCL, can be leveraged to boost your pipeline's throughput.\n\nLearn more about the supported hardware acceleration methods [here](https://trac.ffmpeg.org/wiki/HWAccelIntro).\n\n### Versatile input/output methods\n\nFFmpeg is also very capable when it comes to accessing input and output data.\n\nJust to name a few: it can use your webcam, record from your microphone, grab your screen, or capture from your Blackmagic DeckLink. But FFmpeg can download directly from a web address, open all kinds of streams, read from a pipe, a socket, and of course, from files.\n\nThe same holds true for outputting the data. It can write to your webcam, play audio on your microphone... Just kidding:) It can output to files, streams, pipes, sockets and so on.\n\n### Running example commands\n\nThis article is full of FFmpeg commands that are working examples. The reason for that is that you could test these out for yourself! But the command line interfaces of different operating systems are slightly different, so the commands in this article are meant to be executed in a Linux bash shell.\n\nTo adopt these command lines to Microsoft Windows, you might need to:\n\n1.  Change (cd) into the directory where you extracted the ffmpeg.exe. Alternatively, add that directory to the [path](https://duckduckgo.com/?t=ffab&q=add+binary+to+path+windows) to make it callable from anywhere.\n2.  You might need to replace \"ffmpeg\" to \"ffmpeg.exe\"\n3.  You will need to replace \"**\\**\"-s (backslashes) at the end of the lines with \"**^**\"-s (hats)\n4.  You'll need to replace the `fontfile` argument's value to something like this:  `fontfile=/Windows/Fonts/arial.ttf` to get commands with the drawtext filter working.\n\nMacOS users will need steps #1 and #4.\n\n## Introduction to media concepts\n\nNow let's have a quick overview of media concepts. These concepts will be vital for us if we want to understand the latter sections of this article and FFmpeg's workings. To keep this section brief, it is a higher-level, simplified explanation of these concepts.\n\n### Audio\n\nWe'll briefly cover the following terms:\n\n1.  Sampling rate\n2.  Bitrate\n3.  Channels\n\n### Sampling Rate\n\nThe sampling rate is the factor that shows how many times we measure/scan/sample the input data stream.\n\nThe image below shows the measurement windows (quantization) as gray bars.\n\nWhy does this matter? Because it is a balancing act. If we measure the signal less often, we'll lose more details (bad). Also, by having fewer samples, we'll have less data in the end. Therefore the file size will be smaller (good).\n\n![](media/img-2-sampling-rate.png)\n\nHere are some ballpark values:\n\n-   8 kHz (GSM - Low quality)\n-   44.1 kHz (CD - High quality)\n-   48 kHz (Very high quality)\n-   88.2 kHz (Insane - usually for production only)\n-   96 kHz (Insane - usually for production only)\n\nThere are no definite \"right answers\" here. The question is what is \"good enough\" for your use case? GSM focuses on speech, and not even quality but understandability and the least possible amount of data. Therefore, they found that 8 kHz is enough (there are quite a few more tricks), for their purposes.\n\nThe \"CD quality\" aimed for high quality. Therefore they chose 44.1 kHz, that number has some history in it, but the main reason for aiming above 40 kHz lies in physics and how the human ear works.\n\nThere were two very smart guys whose [theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem) basically says that if you want a quite good signal representation, you have to sample it at twice the speed as its original frequency. Human hearing generally [works](https://en.wikipedia.org/wiki/Hearing_range) up until about 20 kHz, so if you want \"good quality\", you should aim for at least 40 kHz. And 40 kHz + some headroom + some more physics + historical reasons = 44.1 kHz! :)\n\nAs for the higher rates, those are only used when very high-quality audio editing is needed.\n\n### Bitrate\n\nBitrate represents the amount of data per second that results from our transcoding/quantization process. If it is 1411 kbit/s, that means that for every second of audio data, about 1411 kbit of output data will be produced.\n\nTherefore, you can say that 1 minute of audio with 1411 kbit/sec will require:\n\n`(1411 kbit / 8) kbyte * 60 second = 10582 kbyte = 10.33 mbyte`\n\nNow, it is only easy like that with raw audio data and with a few simple codecs, e.g. PCM in WAVs.\n\nCodecs compressing hard might throw your numbers around a little, as input data might be compressible with different rates. Variable bitrate is usually happening to save space. The encoder might output a lower bitrate if the data is \"simple\" and does not require high precision.\n\nHere are some ballpark values:\n\n-   13 kbits/s (GSM quality)\n-   320 kbit/s (High-quality MP3)\n-   1411 kbit/s (16bit WAV, CD quality, PCM)\n\n### Channels\n\nInside of most audio formats, you can have more audio channels. This means multiple, separated audio streams can be in the same file.\n\nMany times, multiple channels have their own name:\n\n-   If you have a single microphone, you will most probably record it into a single channel called Mono.\n-   General music from the FM radio or streaming services usually has two channels in a so-called \"Stereo\" configuration.\n\nWith stereo, there could be several methods how the audio \"image\" can be made richer by leveraging audio [panning](https://en.wikipedia.org/wiki/Panning_(audio)), time and phase-shifting and much more. There is a special recording technique too, called [Binaural recording](https://en.wikipedia.org/wiki/Binaural_recording), which is super awesome. Wear headphones for [this](https://www.youtube.com/watch?v=aQH-jwE_kfo), and don't be scared:)\n\nFor example, here are [Big Buck Bunny](https://peach.blender.org/)'s audio waveforms in [Audacity](https://www.audacityteam.org/):\n\n![](media/img-3-waveforms.png)\n\nYou can see that there are two lines of waveforms and also that they are pretty similar. That is normal, as you usually hear the same thing with your two ears, but the matter is in the subtle differences between the two. That's where directionality, richness, and all kinds of other effects lie.\n\nBut why stop at two? The list continues:\n\n-   2.1, as it is often called, means three channels: 2 for stereo and one for the LFE (\"low-frequency effects\" a.k.a.: \"bass\").\n-   5.1 is similar, with five directional channels (2 front, 1 center, 2 rear) and the LFE.\n\nSo channels are just separate \"recordings\" or \"streams\" of audio signals.\n\n### Image properties\n\nFor images, there are quite a few parameters, but we'll check out only these:\n\n-   Resolution\n-   Bit-depth\n-   Transparency\n\n### Resolution\n\nAn image consists of pixels, single points that have a single color. The resolution of an image determines how many columns and rows of pixels are in an image. In other words: an image has a width and a height.\n\n![](media/img-4-resolution-1.png)\n\nThis image shows the first 10 pixels in the first row.\n\nHere are some ballpark values for resolution:\n\n-   \"HD\" or \"Full HD\" or \"1K\" or \"1080p\" means 1920x1080 pixels.\n-   \"4K\" could mean a few values, but it should be about 3840x2160 pixels.\n-   A regular 16mp photo you make of your cat is about 4608x3456 pixels.\n-   General social media image posts are about 1080x1080 pixels.\n\n### Bit-depth\n\nBit-depth represents the number of bits used for storing a single pixel's color value. This is the same balancing game, and you need to decide between quality or file size.\n\nGeneral ballpark values for bit-depth:\n\nBITS\n\nCOLORS\n\nNOTES\n\n1\n\n2\n\nBlack & White\n\n8\n\n256\n\nB/W or Limited color palette\n\n24\n\n16.7m\n\n3x**8 bit** for R-G-B \"True color\"\n\n30\n\n1073m\n\n3x**10 bit** for R-G-B \"Deep color\"\n\nThese last two sometimes are referred to as \"8 bit\" or \"10 bit\" respectively, especially when talking about videos. That means 8/10 bits per single color channel.\n\n### Transparency\n\nSome image formats support an additional channel together with the red, green, and blue components: the alpha channel. The alpha channel determines how transparent a single pixel is, and it can have different bit-depths, it is usually either 1, 8 or 16 bits.\n\nIf the alpha channel is 1 bit, then the format can encode a pixel to be either transparent or non-transparent. If it is 8 or more bits, then the format can encode 256 or more steps of transparency.\n\n### Video properties\n\nVideo data is built by single images shown right after each other. This brings in most attributes of images and a few more!\n\nSo a video has a `resolution` that is its width and height.\n\nThen the first obvious parameter of a video is the `framerate`, which defines how many images are shown in a second. Common values for this are 24, 25, 30, or 60.\n\nA video file also has a `codec` assigned to it, which is the format describing how all those images were compressed into this video file. There are many more attributes of videos, but this is a good start.\n\n### Video codecs\n\nCompression is a super important thing when it comes to video because you have thousands of images to keep together. If you aren't doing it in a smart way, then the resulting video will be very, very large.\n\nJust imagine a 2-minute video, with 30 fps. That means it will have 60 s * 2 * 30 fps = 3600 frames! I have just taken a screenshot of an HD video, which was 730 kbyte in JPEG format. Now 3600 frame * 730 kbyte equals 2.5 gigabytes!\n\nCan you imagine that? I hope not, and that's because compression brings that way, way down, to the level of tens of megabytes. These days a video of that size is quite high quality and about 2 hours long. Also, don't forget, that JPEG is already compressed, a single frame would be 6 mbyte when uncompressed. Now that 2-minute video would be 21 gigabytes if we'd store it uncompressed.\n\nStandard codecs such as H.264 and H.265 are doing very clever and complex operations to achieve high compression ratios with good quality.\n\nJust think about that, most frames in a video are quite similar, only containing small differences. So if we could only store that little difference between frames, we'd won a huge bonus! And that's just one of the many tricks codecs do.\n\nCodec designers are also exploiting the weaknesses and features of the human eye. Such as the fact that we are more sensitive to light intensity changes than color changes (say hello to [YUV](https://en.wikipedia.org/wiki/YUV)). And they can get away with lower quality details for parts [that are moving fast](https://en.wikipedia.org/wiki/Motion_blur#Biology), and so on.\n\nBecause why lose precious bits for things that you can't even notice?!\n\nThere are many codecs out there, with different goals in mind, although the majority focus on keeping the file size low.\n\n-   H.264, H.265: These are the most common ones, with the widest support in browsers, phones, players, etc. It focuses on small file sizes with good quality. (At the cost of resource intensiveness.)\n-   Apple ProRes, DNxHD: These are common formats for production. They focus on quality and ease of processing and not on file size.\n\n### Audio codecs\n\nThe goal of audio codecs is the same as what we saw with the video codecs. It is just harder to demonstrate it as audio does not consist of single image frames but audio frames/packets. So an analog audio signal is of an almost infinite, or at least very high quality if you think of it.\n\nAt the lowest level, the speed and amplitude resolution is very high. We could say \"atomic\", as we need to measure and store the speed and direction of atoms. So if you want to store that exactly, that will require a super high-quality measurement, which will also result in a very high bitrate data stream.\n\nThankfully, the sound is at least not propagating with light speed so we can save quite a lot just by that fact. (There's no need for an extreme sampling rate.) Then our hearing is very limited if we take the previous paragraph as a scale, so we win there again. We don't need most of that high precision that is there.\n\nBut still, if we take our hearing capability and want to store raw audio data with about 44.1 kHz of sample rate with about 1 Mbit/sec bitrate, we'd still get quite a lot of data. Check the calculations in the [audio bitrate](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#bitrate) section above.\n\nSo raw audio can be compressed further, which is what many popular codecs do. They also exploit the human senses, but this time the human ear. We started with the basics that the human ear has a limit on the frequencies it can detect. Therefore, we can save a lot by cutting out the range of frequencies outside our hearing range. Unless you are a bat, you are fine between 20-20khz! :)\n\nBut there are other tricks, for example, [auditory masking](https://en.wikipedia.org/wiki/Auditory_masking). That means that the presence of one frequency can affect your capability to detect a different frequency. From the codec's viewpoint, it can skip encoding a few frequencies if it is smart enough to know which ones you'll not notice. I'm sure there are a lot more tricks, let me know if you know about a few more interesting ones!\n\nHere is a list of common codecs:\n\n-   MP3, AAC, OGG: These are common lossy audio formats.\n-   PCM (e.g. in a WAV container), FLAC: These are lossless formats.\n-   MIDI: It is a funny format. It is like a music sheet that might sound different on different players or settings. It is usually not made from real audio data, but from recording a digital keyboard or as an output from an audio composing software.\n\n### Containers\n\nNow we got through the fundamental building blocks, the image, the video, the video codecs, and the audio codecs, and we reached the top of this iceberg: the containers.\n\nA container is a format specification, that combines all these streams into a single file format. It defines how to put all these data together, how to attach metadata (e.g. author, description, etc), how to synchronize these streams, and sometimes a container even contains indexes to aid seeking.\n\nSo, for example, a MOV container can contain an H.264 video stream and an AAC audio stream together.\n\nCommon containers:\n\n-   MOV\n-   MP4\n-   MKV\n-   WebM\n-   WAV (audio only)\n\n## Example Material\n\nI will use these example materials as inputs in the following parts of this article. If you'd like to follow along, save these files for yourself!\n\nNAME\n\nRESOURCE\n\nBig Buck Bunny\n\n[http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4](http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4)\n\nTrain\n\n[train.jpg](https://storage.googleapis.com/imgly-static-assets/static/blog/ffmpeg-examples/train.jpg)\n\nSmiley\n\n[smiley.png](https://storage.googleapis.com/imgly-static-assets/static/blog/ffmpeg-examples/smiley.png)\n\nVoice recording\n\n[voice_recording.wav](https://storage.googleapis.com/imgly-static-assets/static/blog/ffmpeg-examples/voice_recording.wav)\n\nBig Buck Bunny's audio\n\nffmpeg -i bbb_sunflower_1080p_60fps_normal.mp4 -map 0:1 bbb_audio.wav\n\nn\n\nAnd we will make our own audio file by extracting the audio from the Big Buck Bunny movie! We'll use this file as an example, so after downloading the video file, please execute this:\n\n```shell\nffmpeg -i bbb_sunflower_1080p_60fps_normal.mp4 -map 0:1 bbb_audio.wav\n```\n\nCopy\n\nBy the middle of this article, you'll understand this command, but for now, just make sure to have the WAV file next to your video file to test out the commands later in the article.\n\nWe'll use these files in the following parts of this article. Therefore make sure to get them!\n\n## FFplay and FFprobe\n\nFFmpeg is the name of the main binary and the project itself, but it is shipped together with two other binaries, ffplay and ffprobe.\n\nLet's check them out quickly, right in the command line!\n\n### FFplay\n\nFFplay is a basic video player, that can be used for playing media. It's not a friendly video player, but it is a good testing ground for various things.\n\nTo execute it, just simply supply a media file:\n\n```shell\nffplay bbb_sunflower_1080p_60fps_normal.mp4\n```\n\nCopy\n\nIf you want to test this exact command, you'll need to get the [example](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#example-material) files.\n\nFor example, it can be used to preview filters (we'll discuss those [later](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#filtering)), but let's see an example:\n\n```shell\nffplay -vf \"drawtext=text='HELLO THERE':y=h-text_h-10:x=(w/2-text_w/2):fontsize=200:f\n```\n\nCopy\n\n![](media/img-5-big-bunny.png)\n\n### FFprobe\n\nFFprobe, as its name implies, is a tool for getting information about media files.\n\nThis command:\n\n```shell\nffprobe bbb_sunflower_1080p_60fps_normal.mp4\n```\n\nCopy\n\nWill return us some general information about the video file:\n\n```plaintext\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from 'bbb_sunflower_1080p_60fps_normal.mp4':\n  Metadata:\n[...]\n    title           : Big Buck Bunny, Sunflower version\n    artist          : Blender Foundation 2008, Janus Bager Kristensen 2013\n[...]\n  Stream #0:0[0x1](und): Video: h264 [...]\n[...]\n  Stream #0:1[0x2](und): Audio: mp3 [...]\n[...]\n  Stream #0:2[0x3](und): Audio: ac3 [...]\n```\n\nCopy\n\nI have abbreviated it heavily, as we'll check this out later.\n\nBut FFprobe is way more powerful than just this!\n\nWith the following command, we can get the same listing in JSON format, which is machine-readable!\n\n```shell\nffprobe -v error -hide_banner -print_format json -show_streams bbb_sunflower_1080p_60fps_normal.mp4\n```\n\nCopy\n\nThe explanation of this command is the following:\n\n-   \"**-v error -hide_banner**\": This part hides extra output, such as headers and the default build information.\n-   \"**-print_format json**\": Obviously, this causes ffprobe to output a JSON.\n-   \"**-show_streams**\" is the main switch that requests the stream information.\n\n```json\n{\n  \"streams\": [\n    {\n      \"index\": 0,\n      \"codec_name\": \"h264\",\n      \"codec_long_name\": \"H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10\",\n      \"width\": 1920,\n      \"height\": 1080,\n      \"bit_rate\": \"4001453\",\n      \"duration\": \"634.533333\",\n      \"############################\": \"[~50 lines removed]\"\n    },\n    {\n      \"index\": 1,\n      \"codec_name\": \"mp3\",\n      \"channels\": 2,\n      \"bit_rate\": \"160000\",\n      \"############################\": \"[~40 lines removed]\"\n    },\n    {\n      \"index\": 2,\n      \"codec_name\": \"ac3\",\n      \"channels\": 6,\n      \"############################\": \"[~20 lines removed]\"\n    }\n  ]\n}\n```\n\nCopy\n\nIn this output, you can see three streams of data in this video file. The first (index: 0) is a video stream, that is an HD video with an H.264 codec. Then we have two audio streams, the first (index: 1) is a simple mp3 stream with stereo audio, and the second (index: 2) is an ac3 stream with 6 channels, most likely in an 5.1 configuration.\n\nI have removed quite a lot of output for brevity, but you can get way more information out of these streams, e.g. fps for the video stream and so on.\n\nOther than **-show_streams**, there are 3 more: **-show_format**, **-show_packets** and **-show_frames**. Unless you are really deep in the rabbit hole, you'll not need the last two, but **-show_format** could be useful:\n\n```shell\nffprobe -v error -hide_banner -print_format json -show_format bbb_sunflower_1080p_60fps_normal.mp4\n```\n\nCopy\n\n```json\n{\n  \"format\": {\n    \"filename\": \"bbb_sunflower_1080p_60fps_normal.mp4\",\n    \"nb_streams\": 3,\n    \"nb_programs\": 0,\n    \"format_name\": \"mov,mp4,m4a,3gp,3g2,mj2\",\n    \"format_long_name\": \"QuickTime / MOV\",\n    \"start_time\": \"0.000000\",\n    \"duration\": \"634.533333\",\n    \"size\": \"355856562\",\n    \"bit_rate\": \"4486529\",\n    \"probe_score\": 100,\n    \"tags\": {\n      \"major_brand\": \"isom\",\n      \"minor_version\": \"1\",\n      \"compatible_brands\": \"isomavc1\",\n      \"creation_time\": \"2013-12-16T17:59:32.000000Z\",\n      \"title\": \"Big Buck Bunny, Sunflower version\",\n      \"artist\": \"Blender Foundation 2008, Janus Bager Kristensen 2013\",\n      \"comment\": \"Creative Commons Attribution 3.0 - http://bbb3d.renderfarming.net\",\n      \"genre\": \"Animation\",\n      \"composer\": \"Sacha Goedegebure\"\n    }\n  }\n}\n```\n\nCopy\n\nThis is an overview of \"what is this file\". As we see, it is a MOV file (format_name), with three streams (nb_streams), and it is 634 seconds long. Also, there are some tags where we can see the title, the artist, and other information.\n\n## FFmpeg concepts\n\nHere is a quick intro to how FFmpeg actually works!\n\nFor those who are just joining in: please get the [example assets](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#example-material) if you want to test out the commands shown in this chapter!\n\n![](media/img-6-input-output.png)\n\nFFmpeg opens the file, decodes it into memory, then encodes the in-memory packets back and puts them into some container: some output file. The term \"codec\" is a mix of the words \"**cod**er & **e**n**c**oder\". Those are the magic parts before and after the \"decoded frames\".\n\nThe decoded frames are uncompressed images in-memory, e.g. the most basic pixel format for video frames is called \"rgb24\". This just stores red, green, and blue values right after each other in 3x8 bits, or 3x1 byte, which could hold 16m colors.\n\nThe importance of this is that other than [a few exceptions](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#editing-without-reencoding), you can only manipulate or encode the decoded frames. So when we get to different audio/video filters or transcoding, you'll need the decoded frames for all that. But don't worry, FFmpeg does this automatically for you.\n\n### Inputs\n\nSo you see and probably guessed, that FFmpeg must access the input data somehow. FFmpeg knows how to handle most media files, as the awesome people who develop FFmpeg and the related libraries made encoders and decoders for most formats available!\n\nDon't think that it is a trivial thing.  Many formats are reverse engineered, a hard task requiring brilliant people.\n\nSo although we often refer to input files, the input could come from many sources, such as the network, a hardware device and so on. We'll learn more about that [later](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#inputs) on in this article.\n\nMany media files are containers for different streams, meaning that a single file might contain multiple streams of content.\n\nFor example, a .mov file might contain one or more streams:\n\n-   video tracks\n-   audio tracks (e.g. for the different languages or audio formats such as stereo or 5.1)\n-   subtitle tracks\n-   thumbnails\n-   ...\n\nAll these are streams of data from the viewpoint of FFmpeg. Input files and their streams are numerically differentiated with a 0-based index. So, for example, 1:0 means the first(0) stream of the second(1) input file. We'll [learn more](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#mapping) about that later too!\n\nImportant to note that FFmpeg can open any number of input files simultaneously, and the filtering and mapping will decide what it will do with those. Again more on that later!\n\n### Streams\n\nAs we have seen in the previous section, streams are the fundamental building blocks of containers. So every input file must have at least one stream. And that's what you can list by the simple `ffmpeg -i` command for example.\n\nA stream might contain an audio format such as MP3, or a video format such as an H.264 stream.\n\nAlso, a stream, depending on the codec, might contain multiple \"things\". For example, an mp3 or a WAV stream might include various audio channels.\n\nSo the building block hierarchy, in this case is: File → Stream → Channels.\n\n### Outputs\n\nOf course, an output could be a local file, but it doesn't need to be. It could be a socket, a stream and so on. In the same way as with inputs, you could have multiple outputs, and the mapping determines what goes into which output file.\n\nThe output also must have some format or container. Most of the time FFmpeg can and will guess that for us, mostly from the extension, but we can specify it too.\n\n### Mapping\n\nMapping refers to the act of connecting input file streams with output file streams. So if you give 3 input files and 4 output files to FFmpeg, you must also define what should go to where.\n\nIf you give a single input and a single output, then FFmpeg will guess it for you without specifying any mapping, but make sure you know how exactly that happens, to avoid surprises. More on all that later!\n\n### Filtering\n\nFiltering stands for the feature of FFmpeg to modify the decoded frames (audio or video). Other applications might call them effects, but i'm sure there is a reason why FFmpeg calls them filters.\n\nThere are two kinds of filtering supported by FFmpeg, simple and complex. In this article we'll only discuss the complex filters, as it is a superset of the simple filters, and this way, we avoid confusion and redundant content.\n\nSimple filters are a single chain of filters between a single input and output. Complex filters can have more chains of filters, with any number of inputs and outputs.\n\nThe following figure extends the previous overview image with the filtering module:\n\n![](media/img-7-encode-decode.png)\n\nA `complex filter graph` is built from `filter chains`, which are built from `filters`.\n\nSo a single **filter** does a single thing, for example, changes the [volume](https://ffmpeg.org/ffmpeg-filters.html#volume). This filter is quite trivial, it has a single input, changes the volume, and it has a single output.\n\nFor video, we could check out the [scale](https://ffmpeg.org/ffmpeg-filters.html#scale) filter, which is also quite straightforward: it has a single input, scales the incoming frames, and it has a single output too.\n\nYou can **chain** these filters, meaning that you connect the output of one to the input of the next one! So you can have a [volume](https://ffmpeg.org/ffmpeg-filters.html#volume) filter after an [echo](https://ffmpeg.org/ffmpeg-filters.html#aecho) filter, for example, and this way, you'll add echo, and then you change the volume.\n\nThis way, your chain will have a single input, and it will do several things with it and will output something at the end.\n\nNow, the \"**complex**\" comes in when you have multiple chains of these filters!\n\nBut before we go there, you should also know that some single filters might have multiple inputs or outputs!\n\nFor example:\n\n-   The [overlay](https://ffmpeg.org/ffmpeg-filters.html#overlay) filter puts 2 video streams above each other and will output a single video stream.\n-   The [split](https://ffmpeg.org/ffmpeg-filters.html#split) filter splits a single video stream into 2+ video streams (by copying).\n\nSo let's discuss a complex example from a bird's eye view! I have two video files, I want to put them above each other, and I want the output in two files/sizes, 720p and 1080p.\n\nNow, that's where complex filtering will be faithful to its name: to achieve this, you'll need several filter chains!\n\n-   Chain 1: `[input1.mp4] [input2.mp4]` → **overlay** → **split** → `[overlaid1] [overlaid2]`\n-   Chain 2: `[overlaid1]` → **scale** → `[720p_output]`\n-   Chain 3: `[overlaid2]` → **scale** → `[1080p_output]`\n\nAs you see, you can connect chains, and you can connect chains to output files. There is a rule that you can only consume a chain once, and that's why we used split instead of the same input for chains 2 and 3.\n\nThe takeaway is this: with complex filter graphs (and mapping), you can:\n\n-   build individual chains of filters\n-   connect input files to filter chains\n-   connect filter chains to filter chains\n-   connect filter chains to output files\n\n## FFmpeg's command line system\n\nFor those who are just joining in: please get the [example assets](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#example-material) if you want to test out the commands shown in this chapter!\n\n### FFmpeg CLI\n\nFinally, we arrived at FFmpeg, and trust me, we'll execute it quite a lot of times! Let's see how FFmpeg's command line options are organized, as that is the first tricky part we need to understand!\n\nFFmpeg mostly thinks about input and output files and their options together with global options. You specify input files with the \"-i\" flag followed by a file name. For the output file, specify it as-is without any preceding CLI (command line interface) flag.\n\n### Specifying an input file\n\nLet's specify just an input file:\n\n```shell\nffmpeg -i bbb_sunflower_1080p_60fps_normal.mp4 \n```\n\nCopy\n\nThe following image helps to understand the output:\n\n![](media/img-8-output.png)\n\n1.  First, you get the \"banner\", where you see the build information and lib versions. If you watch closely, you'll see the compilation flags, starting with **--**, e.g. --enable-shared.\n2.  Then you get the same output as we have seen with ffprobe earlier.\n3.  And then you get a complaint that there is no output file(s) specified. That's fine for now.\n\nYou can remove the banner here with \"-hide_banner\", but for brevity's sake I'll not include that anymore in the commands here, and I will leave it out from the outputs too.\n\nNow, let's get brave, and specify an output file!\n\n### Specifying an output\n\nAs I've said earlier, the output file is understood by FFmpeg as it is just a filename. But more specifically, it is after the input(s) specifications, and it is not a value of any other switches.\n\nDon't be confused for now, but yes, FFmpeg can have as many inputs and outputs as you'd like. We'll cover that in more detail soon!\n\nThis command line specifies a single output file:\n\n```shell\nffmpeg -i bbb_sunflower_1080p_60fps_normal.mp4 audio_only.wav\n```\n\nCopy\n\nBefore taking a look at the output, let me congratulate you! You have just converted a video file into an audio file, by keeping just the audio content!\n\nThis is how you transcode! Of course, you'll want to specify more parameters later on.\n\nSo, here is the output:\n\n![](media/img-9-output.png)\n\nLet's analyze it!\n\n(1) First, we have our input metadata printing, which we saw many times already.\n\n(2) Then we have something called \"stream mapping\". We forced FFmpeg into a decision situation, as we specified an input file with 1 video and 2 audio streams. We said we wanted an audio output (guessed from the .wav extension). But we didn't specify which audio stream we wanted, so let's see what FFmpeg decided:\n\n-   \"**Stream #0:2**\" means \"The first input file's third stream\" or \"input file index 0's stream with index 2.\" This is the input.\n-   \"**-> #0:0**\" means the first output file's first stream. This is the output.\n-   [Here](https://ffmpeg.org/ffmpeg.html#Automatic-stream-selection) you can learn more about how FFmpeg decide this.\n-   Later on, we'll manually override the mapping.\n-   Summary: FFmpeg decided to convert the third stream in the input file (the ac3 5.1 audio) into the first stream of the output file.\n\n(3) Then we have our output metadata information. This reveals what FFmpeg will output. It usually copies most of the metadata, and here you also see the container/format information too.\n\n(4) And then we see the output summary. For example, the transcoding was 181x faster than the playback speed. Nice!\n\n### Understanding the command line order\n\nBefore going further, let's understand FFmpeg's command line arguments from a bird's eye view!\n\nIn the [manual](https://ffmpeg.org/ffmpeg.html#Synopsis), you'll see this:\n\n```shell\nffmpeg [global_options] {[input_file_options] -i input_url} ... {[output_file_options] output_url} ...\n```\n\nCopy\n\n(Parts in [...] are meant to be optional, and parts in {...} are meant to be specified 1 or more times.)\n\nThis is the general outline of how to specify inputs, outputs, input options, output options, and global options. The order matters, but it is easy to remember: global options, inputs and outputs. Also, i/o options come BEFORE the i/o specification.\n\nLet's put these into pseudo command line options, to understand it better:\n\n```shell\n# One inputs, one output, nothing fancy\nffmpeg -i input1.mp4 output1.wav\n\n# Two inputs, one output \nffmpeg -i input1.mp4 -i input2.mp4 output1.wav\n\n# Two inputs, two outputs \nffmpeg -i input1.mp4 -i input2.mp4 output1.wav output2.mp3\n\n# One input, one output, with options\nffmpeg [input1 options] -i input1.mp4 [output2 options] output1.wav\n\n# Two inputs, two outputs with options\nffmpeg [input1 options] -i input1.mp4 \\\n       [input2 options] -i input2.mp4 \\\n       [output1 options] output1.wav \\\n       [output2 options] output2.mp3\n```\n\nCopy\n\nAs for the global options, these are the ones you might care about:\n\n-   **-hide_banner**: To skip printing the banner.\n-   **-y**: To overwrite the output even if it exists.\n\nFor example, you can run this as many times as you want:\n\n```shell\nffmpeg -y -hide_banner -i bbb_sunflower_1080p_60fps_normal.mp4 audio_only.wav\n```\n\nCopy\n\nAnd it will overwrite the output and be less verbose than earlier.\n\nWithout explaining the options themselves, let's just see some real-world examples with options:\n\n![](media/img-10-cmd-order.png)\n\nAnd here it is with two inputs and two outputs:\n\n![](media/img-11-cmd-order.png)\n\n### Mapping files\n\nWe saw above that this command:\n\n```shell\nffmpeg -i bbb_sunflower_1080p_60fps_normal.mp4 audio_only.wav\n```\n\nCopy\n\n... will result in an audio file that contains one of the audio streams from the input video chosen by FFmpeg. This [automatic stream selection](https://ffmpeg.org/ffmpeg.html#Automatic-stream-selection) is usually handy when it is trivial. For example, when you have one stream as input and one output file, you don't need to specify any mapping manually.\n\nBut in cases where it is not so trivial, you are usually better off manually specifying what you really want to do.\n\nThe following image summarises what our current situation is:\n\n![](media/img-12-mapping.png)\n\nThe video stream was not matched, as the output format was an audio file (.wav). But then FFmpeg chose Stream #2, because it has more channels.\n\nSo what if we'd like to get the stereo track instead? That is where mapping comes in! The mapping is a parameter of the OUTPUT file. Therefore the mapping arguments should come right before our output file definition!\n\n```shell\nffmpeg -i bbb_sunflower_1080p_60fps_normal.mp4 -map 0:1 stereo_audio_only.wav\n```\n\nCopy\n\nThe argument **-map 0:1** means, that in the `output` (since we specify it as an output option) we'd like to have `Input #0`'s (the first input file) `Stream #1`!\n\nLet's see the relevant parts from the output!\n\n```plaintext\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from 'bbb_sunflower_1080p_60fps_normal.mp4':\n\n[...]\n\nStream mapping:\n  Stream #0:1 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n  \n[...]\n\nOutput #0, wav, to 'stereo_audio_only.wav':\n  Metadata:\n[...]\n    Stream #0:0(und): [...] stereo [...]\n```\n\nCopy\n\nThe \"Stream #0:1 -> #0:0\" part means that we have successfully overridden the mapping, to get the mp3 stream (0:1) into our output! Also, the output metadata reveals that we'll get a stereo result instead of the 5.1 earlier.\n\n### Multiple outputs\n\nYou can have multiple outputs from a single input, let's see when that might be useful!\n\nLet's say, we want to extract BOTH audio streams into two separate WAV files! It is super easy:\n\n```shell\nffmpeg -y -i bbb_sunflower_1080p_60fps_normal.mp4 -map 0:1 stereo_audio_only.wav -map 0:2 ac3_audio_only.wav\n```\n\nCopy\n\nSee? I have just specified two output files with two mapping specifications! Also, I have sneaked in the \"-y\" to have it overwrite our previous file!\n\nLet's check out the relevant parts of the output!\n\n```plaintext\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from 'bbb_sunflower_1080p_60fps_normal.mp4':\n\n[...]\n\nStream mapping:\n  Stream #0:1 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n  Stream #0:2 -> #1:0 (ac3 (native) -> pcm_s16le (native))\n\n[...]\n\nOutput #0, wav, to 'stereo_audio_only.wav':\n    Stream #0:0(und): [...] stereo\n    \n[...]\n\nOutput #1, wav, to 'ac3_audio_only.wav':\n    Stream #1:0(und): Audio: [...] 5.1(side)\n```\n\nCopy\n\nNow the mapping reveals two lines, as we have two outputs! And indeed, you'll get two .wav files as the output, one is stereo, and one is 5.1!\n\nThere might be several other reasons why you'd want to get multiple outputs. Let's briefly check out a few!\n\nDifferent formats:\n\n```shell\nffmpeg -y -i bbb_sunflower_1080p_60fps_normal.mp4 stereo_audio_only.wav  stereo_audio_only.mp3 \n```\n\nCopy\n\nWow, did you catch that? We just created a WAV and an mp3 in a single command line! I've reverted to the automatic stream selection for brevity's sake.\n\nA bit closer to real-life needs, you might want different output qualities:\n\n```shell\nffmpeg -y  -i bbb_sunflower_1080p_60fps_normal.mp4  \\\n-map 0:1 -b:a 320k stereo_audio_only_high_quality.mp3 \\\n-map 0:1 -b:a 64k  stereo_audio_only_low_quality.mp3 \n```\n\nCopy\n\nHere **-b:a 320k** means \"**b**itrate of **a**udio should be around **320 kbit/sec**\". So I have requested FFmpeg to make two mp3s for me, from the stereo stream of the input.\n\nChecking on the files, this is what we got:\n\n```plaintext\n 25Mb stereo_audio_only_high_quality.mp3\n4,9Mb stereo_audio_only_low_quality.mp3\n```\n\nCopy\n\nOne more common reason for having multiple outputs or using mapping is when we introduce filters into our pipeline, but that will be discussed later!\n\nNow you understand the foundations of how to communicate your basic requirements to FFmpeg via its command line! Great job! Now we can dive even deepert.\n\n## Hands-on with FFmpeg\n\nIn this section, we will discover and even try out some common features of FFmpeg!\n\nFor those who are just joining in: please get the [example assets](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#example-material) if you want to test out the commands shown in this chapter!\n\n### Inputs\n\nLet's see the common ways FFmpeg is fed with different data!\n\n### File\n\nOf course, you have already seen that if you have a local file on your filesystem, FFmpeg is happy to read it!\n\n```shell\nffmpeg -i bbb_sunflower_1080p_60fps_normal.mp4 -map 0:1 stereo_audio_only.wav\n```\n\nCopy\n\nThis command which is exactly the same as one of our previous ones just reads a local file. Really, that's it.\n\n### Network\n\nDid you know, that FFmpeg can open a file directly on the network?!\n\n```shell\nffmpeg -t 5 -i http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4 bbb_first_5_seconds.mp4\n```\n\nCopy\n\nThe command above opens the file directly from the network and saves the first 5 seconds into a local file!\n\nI wanted to spare bandwidth for these awesome guys over renderfarming.net, so I added the duration flag: **-t 5**. FFmpeg doesn't even download the full video for this operation. Isn't that wonderful?!\n\n### Webcam\n\nFFmpeg can also open your webcam!\n\nThis is an example command for Linux:\n\n```shell\nffmpeg -f v4l2 -framerate 25 -video_size 640x480 -t 10 -i /dev/video0 10seconds_of_webcam.webm\n```\n\nCopy\n\nThis would record 10 seconds of your webcam!\n\nAccessing the webcam happens differently on different platforms. Also specifying parameters is different for each platform, so for this reason, if you'd like to access your webcam with FFmpeg, please refer to the documentation:\n\n-   [Linux](https://trac.ffmpeg.org/wiki/Capture/Webcam#Linux)\n-   [Windows](https://trac.ffmpeg.org/wiki/Capture/Webcam#Windows)\n-   [OS X](https://trac.ffmpeg.org/wiki/Capture/Webcam#OSX)\n\n### Microphone\n\nLet's record some audio directly from your microphone!\n\nList microphones:\n\n```shell\narecord -l\n```\n\nCopy\n\nStart 10 seconds of recording:\n\n```shell\nffmpeg -f alsa -i hw:0,0 -t 10 out.wav\n```\n\nCopy\n\nThis command was meant to work on Linux, but you can check out how to do that on [Microsoft Windows](https://trac.ffmpeg.org/wiki/Capture/Desktop#Windows) or [macOS](https://trac.ffmpeg.org/wiki/Capture/Desktop#macOS).\n\n### Pipe\n\nFinally, FFmpeg can read from a pipe, and also output to a pipe.\n\nOn Linux, you could do something like this:\n\n```shell\ncat bbb_sunflower_1080p_60fps_normal.mp4 | ffmpeg -i - -f wav pipe:1 | pv > output.wav\n\n# Alternative, without pv:\ncat bbb_sunflower_1080p_60fps_normal.mp4 | ffmpeg -i - -f wav pipe:1 > output.wav\n```\n\nCopy\n\nThis command would use the **cat** program to simply read in the video file and output it to its standard output. Then this output is piped INTO FFmpeg, through its standard input. The combination \"**-i -**\" means \"read from standard input\". By the way, standard input would be your keyboard otherwise, if we wouldn't use any redirection here.\n\nThen we specify the required output format for FFmpeg, with \"**-f wav**\". This is needed because now we'll have no output file name, and FFmpeg will not be able to guess the format. Then we specify \"**pipe:1**\" as an output, meaning we'd like FFmpeg to output to its standard output.\n\nFrom then, we pipe the data into a program called \"**pv**\", it is just a metering tool, that dumps information on the throughput (from its stdin to its stdout). Finally, we redirect pv's output into a WAV file.\n\nYou might ask why we'd want to do that, why we talk about this. Piping can be useful if you build a complex pipeline from different programs or if you want to spare reading and writing to a local file.\n\nFor example, the node package [fluent-ffmpeg](https://www.npmjs.com/package/fluent-ffmpeg) can leverage this functionality by supplying input and output streams. For example, you can read from an S3 bucket and write to one directly.\n\nBut be warned, hell is awaiting you on that road. No kidding. You need to research the limitations of this technique. For example, many formats can not be streamed in this manner, as they need random access to the output data to write the indices at the beginning of the file after processing.\n\n### Outputs\n\nFFmpeg can output into many protocols, from local file storage and ftp to message queue protocols all the way to streaming protocols.\n\nFor more information, check out the documentation [here](https://ffmpeg.org/ffmpeg-protocols.html#Protocols).\n\n## Transcoding audio with FFmpeg\n\nIn this chapter, we'll be going to see how to transcode into audio with FFmpeg!\n\nThe general formula is:\n\n```shell\nffmpeg -i {input audio or video file with audio} [output options] output_audio.ext\n```\n\nCopy\n\n### Choosing a format\n\nFFmpeg is quite smart, and by the extension, it can determine which codec to use. If you specify \"audio.wav\" or \"audio.mp3\" for example, FFmpeg will use the appropriate codec to do the encoding.\n\nIt is perfectly guessing most of the time. But if you want to specify the format manually, then the \"-f\" flag is your friend.\n\nFor this, you might want to consult the list of formats:\n\n```shell\nffmpeg -formats\n```\n\nCopy\n\nSo, these three commands will do exactly the same, but the last two requires the **-f** flag.\n\n```shell\n# Output codec is determined from the extension\nffmpeg -i bbb_audio.wav bbb_audio.mp3\n\n# No extension in the filename\nffmpeg -i bbb_audio.wav -f mp3 bbb_audio\n\n# Piped output therefore no filename, so no extension to use for guessing\nffmpeg -i bbb_audio.wav -f mp3 pipe:1 > bbb_audio\n```\n\nCopy\n\n### Setting the bitrate\n\nIn most cases. you want to specify the target bitrate you expect from your codec to output. If you are unsure what bitrate is, please read this article's [audio bitrate](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#bitrate) section.\n\nTo specify the audio bitrate, use the \"**-b:a**\" option with a corresponding value, e.g.:\n\n-   **-b:a 320k**: For the mp3 codec this is considered high quality.\n-   **-b:a 128k**: Lower quality.\n-   **-b:a 64k**: Low quality.\n\nFor example:\n\n```shell\nffmpeg -i bbb_audio.wav -b:a 320k bbb_audio_320k.mp3\n```\n\nCopy\n\n### Setting the sample rate\n\nYou may want to specify the sample rate to ensure quality or low output file size. Half the sample rate could mean half the output file size. If you are unsure what the sample rate is, please read the \"[audio sample rate](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#sampling-rate)\" section of this article.\n\nTo specify the audio sample rate, use the \"**-ar**\" option with a corresponding value, e.g.:\n\n-   **-ar 48000**: For high quality.\n-   **-ar 44100**: For CD quality (still high).\n-   **-ar 22500**: A bit of a compromise, not recommended for music, but for speech, it might be enough.\n-   **-ar 8000**: Low quality, e.g. if you only want \"understandable\" speech.\n\nFor example:\n\n```shell\nffmpeg -i bbb_audio.wav -ar 44100 bbb_audio_44100khz.mp3\n```\n\nCopy\n\n### Setting the channel count\n\nSetting the channel count can be useful, for example, if you have a stereo recording of a single person's speech. In that case, you might be content with just a mono output half the size of the original recording.\n\nIf you are unsure what an audio channel is, please read the \"[audio channels](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#channels)\" section of this article.\n\nTo specify the channel count use the  \"**-ac**\" option with a corresponding value, e.g.:\n\n-   **-ac 1**: For mono\n-   **-ac 2**: For stereo\n-   **-ac 6**: For 5.1\n\nFor example:\n\n```shell\nffmpeg -i bbb_audio.wav -ac 1 bbb_audio_mono.mp3\n```\n\nCopy\n\n### Complete command line for converting audio with FFmpeg\n\nThis is how you produce a high-quality output:\n\n```shell\n# Convert wav to mp3\nffmpeg -i bbb_audio.wav -ac 2 -ar 44100 -b:a 320k bbb_audio_hqfull.mp3\n\n# Convert wav to m4a (aac)\nffmpeg -i bbb_audio.wav -ac 2 -ar 44100 -b:a 320k bbb_audio_hqfull.m4a\n\n# Convert wav to ogg (vorbis)\nffmpeg -i bbb_audio.wav -ac 2 -ar 44100 -b:a 320k bbb_audio_hqfull.ogg\n```\n\nCopy\n\nCheck out [this](https://trac.ffmpeg.org/wiki/Encode/HighQualityAudio) documentation about good quality audio transcoding too!.\n\n### Lossless formats\n\nIf you want to convert audio into a lossless format, here are a few choices for you:\n\n```shell\n# Convert to flac (Free Lossless Audio Codec)\nffmpeg -i bbb_audio.wav -compression_level 12 bbb_audio_lossless_12.flac # Best compression, slowest\nffmpeg -i bbb_audio.wav -compression_level 5 bbb_audio_lossless_5.flac   # Default\nffmpeg -i bbb_audio.wav -compression_level 0 bbb_audio_lossless_0.flac   # Least compression, fastest\n\n\n# Convert to wav\ncp bbb_audio.wav bbb_audio_lossless.wav # Just kidding:)\n\n# Convert to wav \nffmpeg -i any_audio.ext bbb_audio_lossless.wav\n```\n\nCopy\n\nIt's good if you know that flac results in a smaller file than WAV, as WAV doesn't actually compress by default:\n\n```plaintext\n117M bbb_audio.wav\n52M  bbb_audio_lossless_0.flac\n45M  bbb_audio_lossless_5.flac\n43M  bbb_audio_lossless_12.flac\n```\n\nCopy\n\nWAV is generally thought of as a lossless format, but keep in mind that the WAV container can contain lossy content too, but by default FFmpeg uses the pcm_s16le format, which is the 16 bit PCM, that could be understood as lossless.\n\nLearn more [here](https://en.wikipedia.org/wiki/WAV#Comparison_of_coding_schemes) and [here](https://trac.ffmpeg.org/wiki/audio%20types).\n\n## Transcoding video with FFmpeg\n\nIn this chapter, we'll be going to see how to transcode a video file into the two most common formats!\n\n### Converting to H.264\n\n[H264](https://en.wikipedia.org/wiki/Advanced_Video_Coding) is one of the most popular video codecs. Most devices, browsers and video players understand how to play it. It is efficient in storing video content, but as with most advanced video codecs, it is a resource intensive-process to encode and decode.\n\nA complete command line for a high-quality H.264 transcoding with high-quality AAC audio is the following:\n\n```shell\nffmpeg -y -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-c:v libx264 -preset slow -crf 22 \\\n-profile:v main -g 250 -pix_fmt yuv420p \\\n-map 0:0 -map 0:1 \\\n-acodec aac -ar 44100 -b:a 320k bbb_transcoded_h264_HQ.mov\n```\n\nCopy\n\nMake sure to understand this command and to customize it to match your needs.\n\nTo help you do that, let's dissect this command!\n\nGlobal options:\n\n-   **-y**: Overwrite the output.\n\nInput options:\n\n-   **-i bbb_sunflower_1080p_60fps_normal.mp4**: The input file.\n\nOutput options:\n\n**-c:v libx264**: Set the codec to libx264.\n\n**-preset slow**: libx264 has a lot of variables that you can be tune, and most of them balance the coding speed and the resulting file size. To make your life easier, there are [presets](https://trac.ffmpeg.org/wiki/Encode/H.264#Preset) by which you can easily declare what you need: small size or speed.\n\n**-crf 22**: This is the constant rate factor, the main option for setting image quality. It is a number between 0-51, where 0 is lossless, and 51 is the worst quality. Generally, you want something between 17 and 28. This is the option to tune the balance between image quality and file size. Check my comparison video [here](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#comparing-crf-values-with-h264-and-h265).\n\n**-profile:v main -g 250 -pix_fmt yuv420p**: These are advanced options, guaranteeing you a quite backward compatible result. (See [this](https://ffmpeg.org/ffmpeg-codecs.html#Options-26), [this](https://trac.ffmpeg.org/wiki/Encode/H.264#Profile), and [this](https://ffmpeg.org/ffmpeg.html#Advanced-Video-options).)\n\n**-map 0:0 -map 0:1**: You might not need this: these options are selecting the correct video and audio streams. [In our case](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffprobe), we have two audio streams, and we need the stereo one to avoid some issues with our aac stream.\n\n**-acodec aac**: Select the AAC (Advanced Audio Coding) [codec](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#audio-codecs) for the audio in the output. We need to be more specific than just **-f** for the format. We need to specify the audio codec here manually.\n\n**-ar 44100**: Set the audio [sampling rate](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#sampling-rate) (learn more about that in previous chapters of this article).\n\n**-b:a 320k**: Set the audio [bitrate](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#bitrate) (learn more about that in previous chapters of this article).\n\n**30seconds_of_bb.mkv**: The output file name. All the options since the last -i (or the last output file) considered to be a modifier for this output.\n\nLet's see the output:\n\n```plaintext\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from 'bbb_sunflower_1080p_60fps_normal.mp4':\n\n[...]\n\nStream mapping:\n  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n  Stream #0:1 -> #0:1 (mp3 (mp3float) -> aac (native))\n\n[...]\n\nOutput #0, mov, to 'bbb_transcoded_h264_HQ.mov':\n    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=-1--1, 60 fps, 15360 tbn, 60 tbc (default)\n    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, 5.1(side), fltp, 320 kb/s (default)\n\n[...]\n\nframe=38074 fps= 35 q=-1.0 Lsize=  324855kB time=00:10:34.51 bitrate=4194.1kbits/s dup=2 drop=0 speed=0.58x \n```\n\nCopy\n\nFrom this, we understand that FFmpeg chose the mp3 stream from the input file because we told it to do so. (Remember, it has two audio streams in it, a stereo mp3 and a 5.1 ac3.) We also see that my machine could transcode with 35fps (0.58 times the playback speed), and our settings resulted in an average video bitrate of 4200 kbit/s.\n\nThe video bitrate is an interesting question in this mode. With the CRF option, we specify the \"constant visual quality\" we want. To reach a constant visual quality, the encoder works hard to guess how much it can compress certain parts of every frame, and the result of that guess defines the final average video bitrate.\n\nIf you want even better results with H.264, and you can afford a bit more processing time and a bit more complicated process, check out the [2-pass encoding](https://trac.ffmpeg.org/wiki/Encode/H.264#twopass) instead of the constant rate factor method introduced above.\n\nTo learn more about these two different rate control methods, read the awesome [Understanding Rate Control Modes](https://slhck.info/video/2017/03/01/rate-control.html) article. And to learn more about the intricacies of H.264 encoding, check out the [H264 encoding guide](https://trac.ffmpeg.org/wiki/Encode/H.264).\n\nFinally, [later on](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#comparing-crf-values-with-h264-and-h265), I will show you a comparison video that shows how different CRF values perform!\n\n### Converting to H.265\n\nH.265 is the successor of H.264, according to the [official FFmpeg manual](https://trac.ffmpeg.org/wiki/Encode/H.265), it offers 25-50% bitrate savings while retaining the same visual quality.\n\nA complete command line for a high-quality H.265 transcoding with high-quality AAC audio is the following:\n\n```shell\nffmpeg -y -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-c:v libx265 -preset slow -crf 27 \\\n-profile:v main -g 250 -pix_fmt yuv420p \\\n-map 0:0 -map 0:1 \\\n-acodec aac -ar 44100 -b:a 320k bbb_transcoded_h265_HQ.mov\n```\n\nCopy\n\nAnd the result is:\n\n```plaintext\n...\nencoded 38074 frames in 3384.84s (11.25 fps), 1720.32 kb/s, Avg QP:35.29\n```\n\nCopy\n\nH.265 also has multiple rate control algorithms, I used the CRF method here. If you want to use a different rate control algorithm, then you may check out the [H.265 encoding guide](https://trac.ffmpeg.org/wiki/Encode/H.265). Also, check out the next section, where I'll reveal how different CRF values perform!\n\nThis command is almost the same as what we used in the [H.264 example](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#converting-to-h264) above, so please refer to that section to understand the arguments.\n\nIf we compare H.264 and H.265 with our commands above, taking into account this 10-minute long video on my system, these are the results:\n\n-   H.264 is 3 times faster (35 fps vs 11 fps)\n-   H.264 produces a 2 times larger file (318 mb vs 156 mb)\n\n### Comparing CRF values with H.264 and H.265\n\nI have created a video for your convenience, that shows the different crf values in action. The selected frame had some movement on it with the leaves in the bunny's hand. Movement is important with video codecs, as usually that's where quality losses are first visible.\n\nThis video shows how the different CRF values perform, from 0-51 with the H.264 and H.265 formats!\n\n[H.264 & H.265 CRF comparison video](https://storage.googleapis.com/imgly-static-assets/static/blog/videos/vid-1-comparison-264-265.mov)\n\n(Can you guess which program I was using to make this?:))\n\n## Basic editing with FFmpeg\n\nIn this section, we'll achieve basic editing tasks by using FFmpeg only!\n\nWe'll just get a basic mp4 with default settings in these examples to keep things simple. But to encode the result in a proper, high quality way, please check the earlier sections where we learned how to encode into H.264 and H.265!\n\n### Trimming from the beginning of the clip\n\nIt is possible to specify an in-point for a media file. By doing that, you essentially cut off the specified amount from the beginning of the input file. Therefore, FFmpeg will skip the first part of the file and only transcode the remainder!\n\nFor this, you need the \"**-ss**\" flag! The value can be specified in seconds (5 or 5.2) or as a timestamp (HOURS:MM:SS.MILLISECONDS).\n\nTo get the outro only, we could seek all the way to the end of the video! (It is 00:10:34.53 or 635 seconds long!)\n\n```shell\n# Get \n# 635 - 4 = 631\nffmpeg -y -ss 631 -i bbb_sunflower_1080p_60fps_normal.mp4 last_4_seconds.mp4\n\n\n# 00:10:34.53 - 4 = 00:10:30.53\nffmpeg -y -ss 00:10:30.53 -i bbb_sunflower_1080p_60fps_normal.mp4 last_4_seconds.mp4\n```\n\nCopy\n\nSeeking can be a bit tricky, so you may want to learn more about seeking [here](https://trac.ffmpeg.org/wiki/Seeking).\n\n### Trimming from the end of the clip\n\nYou can also set an out-point for an input file, therefore shortening it. There are two options for this:\n\n-   **-t**: This sets the duration.\n-   **-to**: This sets the timestamp where the input video should stop.\n\nThese two are mutually exclusive, and also they do the same if no -ss is specified. The value can be specified in seconds (5 or 5.2) or as a timestamp (HOURS:MM:SS.MILLISECONDS).\n\nLet's experiment with them!\n\n```shell\n# \"Get 30 seconds of the input.\"\nffmpeg -y -t 30 -i bbb_sunflower_1080p_60fps_normal.mp4 first_30_seconds.mp4\nffmpeg -y -t 00:00:30.0 -i bbb_sunflower_1080p_60fps_normal.mp4 first_30_seconds.mp4\n\n# \"Get everything until the content's 30th second.\" \nffmpeg -y -to 30 -i bbb_sunflower_1080p_60fps_normal.mp4 first_30_seconds.mp4\nffmpeg -y -to 00:00:30.0 -i bbb_sunflower_1080p_60fps_normal.mp4 first_30_seconds.mp4\n```\n\nCopy\n\nAll four above commands result in exactly the same video. (For nerds: even the md5sum is the same.)\n\nBut let's see how they perform when we introduce seeking!\n\n```shell\n# \"Seek to the 10th second and get me 30 seconds of the input.\"\nffmpeg -y -ss 10 -t 30 -i bbb_sunflower_1080p_60fps_normal.mp4 part_between_10_and_40.mp4\n\n# \"Seek to the 10th second and get the content until the 30th second.\"\nffmpeg -y -ss 10 -to 30 -i bbb_sunflower_1080p_60fps_normal.mp4 part_between_10_and_30.mp4\n```\n\nCopy\n\nThe first command will result in a 30 second long video, while the second command will be 20 seconds long only!\n\nThe figure below shows the difference:\n\n![](media/img-13-trimming.png)\n\n### Editing without reencoding\n\nFFmpeg can do something I'm not aware of in any other popular NLE: it can edit videos without reencoding them!\n\nThe usual [workflow](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#ffmpeg-concepts) is to decode the data frames (a/v) into memory, modify them as much as we like and then encode them into a new video file. The problem with this is that unless you work with raw or lossless codecs, you'll lose some quality in the process. Another issue with this approach is that it is computationally intensive.\n\nFor certain operations, you can configure FFmpeg, to keep the data frames intact, and this way, you can avoid decoding and encoding them! This is incredibly faster than regular transcoding, usually hundreds of times faster.\n\nThe \"certain operations\" are those that don't need to modify the data frames themselves. For example, you can cut and trim this way. Also, you can manipulate streams while keeping others, like you can replace the audio track without touching the video frames.\n\nAll this is a bit of magic, and there are caveats you need to prepare for, but it is good if you know about this, as it is often handy!\n\nThe trick lies in two options:\n\n-   **-c:v copy**: The \"copy\" video codec\n-   **-c:a copy**: The \"copy\" audio codec\n\nLet's see a few examples!\n\n#### Remove audio while keeping the video without reencoding\n\n```shell\nffmpeg -i bbb_sunflower_1080p_60fps_normal.mp4 -c:v copy -an copied_video_only.mp4\n```\n\nCopy\n\nHere, we used the \"**-an**\" option, which removes all audio streams. I remembered it as \"**a**udio **n**o\", but that is just my mnemonic:)\n\nLet's see how fast it was:\n\n```plaintext\nframe=38072 fps=20950 q=-1.0 Lsize=  310340kB time=00:10:34.51 bitrate=4006.7kbits/s speed= 349x\n```\n\nCopy\n\nSo It processed the whole 10 minutes of video in 2 seconds, 349x faster than playback, with 20950 fps!\n\n#### Remove video while keeping the audio without reencoding\n\n```shell\nffmpeg -i bbb_sunflower_1080p_60fps_normal.mp4 -c:a copy -vn copied_audio_only.wav\n```\n\nCopy\n\nHere, we used the \"**-vn**\" option, which removes all video streams. I remembered it as \"**v**ideo **n**o\".\n\nLet's see how fast it was:\n\n```plaintext\nsize=   24772kB time=00:10:34.14 bitrate= 320.0kbits/s speed= 776x \n```\n\nCopy\n\n776x faster than playback, finished in about a second, not bad!\n\n#### Cut and trim without reencoding\n\n```shell\nffmpeg -ss 10 -t 10  -i bbb_sunflower_1080p_60fps_normal.mp4 -c:a copy -c:v copy part_from_10_to_20_copied.mp4\n```\n\nCopy\n\nThere could be precision issues with seeking while you do this, so you may want to learn more about seeking and copying [here](https://trac.ffmpeg.org/wiki/Seeking).\n\n#### Replace audio on video file without reencoding\n\nWe have removed audio and video already, but what if we want to swap them?\n\n```shell\nffmpeg -y \\\n-i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-i voice_recording.wav \\\n-map \"0:v\" -map \"1:a\" \\\n-c:v copy -c:a copy \\\nbbb_with_replaced_audio.mov\n```\n\nCopy\n\nThere is quite a lot going on in here, so let's explain the parts!\n\nFirst, we have two inputs (**-i**), meaning we are better off manually specifying the [mapping](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#mapping). The command would work without the \"**-map**\" options, but it would ignore our second input.\n\n`-map \"0:v\" -map \"1:a\"` means that please use the first file's (first) video stream and the second file's (first) audio stream.\n\nWith `-c:v copy -c:a copy`, we require FFmpeg to copy the already encoded data packets without touching them. Therefore FFmpeg's work is mostly really just copying bytes, no decoding, no encoding.\n\nNot surprisingly, that's what we see in the stream mapping too:\n\n```plaintext\nStream mapping:\n  Stream #0:0 -> #0:0 (copy)\n  Stream #1:0 -> #0:1 (copy)\nPress [q] to stop, [?] for help\nframe=38072 fps=9750 q=-1.0 Lsize=  320645kB time=00:10:34.51 bitrate=4139.7kbits/s speed= 162x  \n```\n\nCopy\n\nAnd since it is just copying, it was crazy fast, 162x of the playback speed, or almost 10k frames per second!\n\nBut!\n\nExecute the exact same command, but with \"bbb_with_replaced_audio.**mp4**\" (.mp4 container instead of .mov) as an output file! You'll get this:\n\n```plaintext\nCould not find tag for codec pcm_s16le in stream #1, codec not currently supported in container\n```\n\nCopy\n\nThe message is quite clear. You can not have a pcm_s16le (raw WAV, say that 10 times:)) stream in an MP4 container. I'm not sure if it is FFmpeg's or the container's lack of support, but we need to solve this. If you run into this situation, you might consider two solutions:\n\n1.  Change the container: I've just tried MOV, and it worked.\n2.  Encode the audio: We still copy the video data, and encoding audio isn't that painful.\n\nI just showed you option #1, so let's see option #2:\n\n```shell\nffmpeg -y \\\n-i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-i voice_recording.wav \\\n-map \"0:v\" -map \"1:a\" \\\n-c:v copy \\\n-c:a aac -b:a 320k -ar 44100 \\\nbbb_with_replaced_audio_aac.mp4\n```\n\nCopy\n\nThis copies the video frames and encodes our WAV into a supported codec to be held in the mp4 container. You can refer back to the [audio encoding](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#how-to-transcode-audio-with-ffmpeg) section if you want to learn more about that.\n\nHere is the output:\n\n```plaintext\nStream mapping:\n  Stream #0:0 -> #0:0 (copy)\n  Stream #1:0 -> #0:1 (pcm_s16le (native) -> aac (native))\nPress [q] to stop, [?] for help\n...\nframe=38072 fps=2176 q=-1.0 Lsize=  313058kB time=00:10:34.51 bitrate=4041.8kbits/s speed=36.3x \n```\n\nCopy\n\n\"Only\" 36x faster than playback, 2176 fps, still not that bad!\n\n## Filtering overview\n\nFFmpeg supports many audio and video [filters](https://ffmpeg.org/ffmpeg-filters.html). Currently, there are 116 audio and 286 video filters, but there are a bit more if we count the hardware accelerated ones too.\n\nSo how do we leverage them?\n\nThere are two ways to define filters, but I'm going to explain the complex filter, as the difference is not much, but it is more versatile. So there is a global option for FFmpeg, called: **`-filter_complex`**. With quite a weird syntax, you can specify all your filters and their parameters right after this option.\n\nYou can imagine the process with the following image:\n\n![](media/img-14-complex_filter_intro.png)\n\nBasically, your filter graph can access all the inputs (-i a.mp4 -i b.mp4 -i c.mp4), and it can produce as many outputs as you like (-map might be needed).\n\n### Basic syntax\n\nLet's take a look at a simple, basic example:\n\n```shell\nffmpeg -y  -t 5 \\\n-i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-filter_complex \"drawtext=text='HELLO THERE':y=20:x=30:fontsize=200:fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf\" \\\nfilter_complex1.mp4\n```\n\nCopy\n\nAlthough `-filter_complex` is a global option, I like to put it after the inputs and before the outputs as it is a bit easier to overlook the whole command that way. Thankfully the command line parser of FFmpeg is smart enough, and it works.\n\nThe command above produces a 5-second-long video, where the text \"HELLO THERE\" is overlaid on the intro of Big Buck Bunny.\n\n![](media/img-15-hello-there.png)\n\nLet's understand the weird format for specifying filters!\n\nWe'll go bottom-up, and we'll build it from there. So the most basic format is this:\n\n```plaintext\nFILTER_NAME=ARGUMENT1=VALUE1:ARGUMENT2=VALUE2\n```\n\nCopy\n\nFor example:\n\n```plaintext\ndrawtext=text='HELLO THERE':y=20:x=30\n```\n\nCopy\n\nThe first thing before the first equal (=) sign is the filter's name, which is the [drawtext](https://ffmpeg.org/ffmpeg-filters.html#drawtext-1) filter in this case. Then we have our first argument, \"text\" and its value \"'HELLO THERE'\". Right after that, separated with a colon (:) comes the next argument, \"y\" with a value of \"20\".\n\nYou can guess what each of the text, y, x, fontsize and fontfile arguments do, as it is quite self-explaining. But especially for the first time, you'll heavily rely on the [filtering documentation](https://ffmpeg.org/ffmpeg-filters.html) to understand every filter and every argument.\n\nAlso, several characters are reserved, such as: `, : =` and a few others depending on your environment, so sooner or later you need to learn about [escaping](https://ffmpeg.org/ffmpeg-filters.html#toc-Notes-on-filtergraph-escaping) too.\n\nTo recap, our pipeline looks like this now:\n\n![](media/img-16-complex_filter_multi.png)\n\n### Multiple filters in a chain\n\nThis previous command is a single filter chain that consists of a single filter only, but you could have more filters put right after each other! It means that the output of one filter will be the input for the next! The way to do this is by separating them with a comma!\n\nLet's draw two boxes with the [drawbox](https://ffmpeg.org/ffmpeg-filters.html#drawbox) filter!\n\n```shell\nffmpeg -y  -t 5 \\\n-i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-filter_complex \"  drawbox=x=10:y=10:w=100:h=100:color=red  ,  drawbox=x=200:y=200:w=100:h=100:color=blue  \" \\\nfilter_complex2.mp4\n```\n\nCopy\n\nSee? The output of the first filter is passed to the output of the second filter!\n\n![](media/img-17-filter-bick-buck.png)\n\nLet's visualize our pipeline again:\n\n![](media/img-18-complex_filter_multi_2.png)\n\n### Input and output pads\n\nNow, we have skipped something this far, because for simple uses FFmpeg is smart enough to do it for us. And this is the specification of a chain's input and output pads!\n\nLet's draw just a single rectangle for now:\n\n```shell\nffmpeg -y  -t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 -filter_complex \"drawbox=x=10:y=10:w=100:h=100:color=red\" filter_complex3.mp4\n```\n\nCopy\n\nFFmpeg sees that the input for our filter chain is a single video file, and the output is a single output video file. Therefore, it safely assumes that we want that single input as the input of our single filter chain. And that single output should be the single output of our single output chain.\n\nThat's really nice, as, in simple situations like this, we don't need to assign and map inputs and outputs manually! But when we get more inputs, filter chains, or outputs, it is no longer possible. Therefore, we need to understand how to assign inputs and outputs!\n\nFirst of all, let's compare the following two command lines. They result in exactly the same result, but the second one represents what FFmpeg does internally (roughly):\n\n```shell\nffmpeg -y  -t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 -filter_complex \"drawbox=x=10:y=10:w=100:h=100:color=red\" filter_complex3.mp4\n\nffmpeg -y  -t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 -filter_complex \"[0:v]drawbox=x=10:y=10:w=100:h=100:color=red[out_link_0]\" -map \"[out_link_0]\" filter_complex3.mp4\n```\n\nCopy\n\nDo you see the difference? Before our filter chain, an \"input pad\" is defined: `[0:v]`. The expected format between the square brackets is documented in the [stream selection](https://ffmpeg.org/ffmpeg.html#Stream-selection) section of the official documentation, and this article already [covered](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#mapping) it.\n\nBut, a quick summary:\n\n-   **0:v**: This means the first video stream of the first input file.\n-   **0:v:0**: Means exactly the same thing but in a long form.\n-   **0:0**: Means the first stream of the first input file (not recommended, as it could be anything in theory. It could be a subtitle stream, a thumbnail, a video or an audio stream...)\n-   **0:a**: This means the first audio stream of the first input file.\n-   **0:a:0**: Means exactly the same thing but in a long form.\n-   **0:a:1**: Means the second (index #1) audio stream of the first input file.\n\nSo we can specify which input file should be connected to which input of the filter graph!\n\nAlso, something similar is going on at the end! Do you see, the `[out_link_0]` output pad definition at the end of our filter chain?\n\nThe naming here is easier, as basically you can specify any arbitrary name in here. It roughly means, \"please store the output data under this name\".\n\nAnd when you specify your output file, you can or need to map it by selecting one of your filter graph outputs! Therefore, we must add the -map \"[out_link_0]\" option before our output file.\n\nThis map option means this: \"Please save the data stream with this name into the following output file.\"\n\nThis is how you can visualize this input/output mapping:\n\n![](media/img-19-complex_filter_multi_3.png)\n\n### Multiple chains\n\nComing from the previous sections, you are now ready to see and understand an even more complicated configuration, which has multiple input files, output files, and filter chains!\n\n```shell\nffmpeg -y  \\\n-i train.jpg \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-filter_complex \"[0:v]drawbox=x=10:y=10:w=100:h=100:color=red[train_box] ; [1:v]drawbox=x=10:y=10:w=100:h=100:color=red[bbb_box]\" \\\n-map \"[train_box]\" filter_complex4_train.jpg \\\n-map \"[bbb_box]\" filter_complex4_bbb.mp4\n```\n\nCopy\n\nLet's see the output (two files next to each other):\n\n![](media/img-20-filters_output_3.png)\n\nWe had two inputs, and we got two output files, an image, and a video, with a red rectangle on them, with a single command!\n\nAre you still here? I hope! Let's understand what happened in that crazy command! We have two input files:\n\n-   **-i train.jpg**: A simple image file\n-   **-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4**: Our video file, but to make it quick, just the first five seconds of it\n\nThen the first thing to note is that we have two filter chains! They are separated with a \"**;**\".\n\nOur first filter graph is this: `[0:v]...[train_box]`\n\n-   This requests the first input file as an input\n-   Draws a red box\n-   Saves the output into the \"train_box\" output pad\n\nOur second filter graph is this: `[1:v]...[bbb_box]`\n\n-   This requests the second input file as an input\n-   Draws a red box\n-   Saves the output into the \"bbb_box\" output pad\n\nAnd finally, we got two outputs, each mapping to one of the outputs of the filter graph:\n\n-   **-map \"[train_box]\" filter_complex4_train.jpg**\n-   **-map \"[bbb_box]\" filter_complex4_bbb.mp4**\n\nHere is the same thing visually:\n\n![](media/img-21-complex_filter_multi_4.png)\n\nIf you are thinking about making it even more complex and making filter graphs that combine multiple inputs into one for example, you are on the right track! It is possible, and we will get to that!\n\nThis was the introduction to the filtering system and its syntax.\n\n## Editing video\n\nNow let's get to know a few filters and make some interesting stuff!\n\n### Resizing or scaling\n\nThe [scale](https://ffmpeg.org/ffmpeg-filters.html#scale) filter is a simple one, yet it is quite powerful!\n\n```shell\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-filter_complex \"scale=width=600:height=-1:force_original_aspect_ratio=decrease\" \\\nfilter_complex5_scaled1.mp4\n```\n\nCopy\n\nThe arguments speak for themselves, but a few things:\n\n-   Specifying -1 to either width or height means rescaling while keeping the aspect ratio.\n-   \"force_original_aspect_ratio\" can be `increase`, `decrease`. Meaning it will increase or decrease the image to fit the specified bounding box while keeping the aspect ratio.\n\n### Adding text\n\nWe have already covered this a little, so let's dive deeper!\n\nThis is what we used earlier:\n\n```shell\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-filter_complex \"drawtext=text='HELLO THERE':y=20:x=30:fontsize=200:fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf\" \\\nfilter_complex1.mp4\n```\n\nCopy\n\nNow let's discover how to align the text!\n\nMany filters, including drawtext, support variables in some of its argument's values. If you scroll down in the [documentation of drawtext](https://ffmpeg.org/ffmpeg-filters.html#drawtext-1), you'll find this:\n\n> \"The parameters for x and y are expressions containing the following constants and functions: \"\n\nAnd after this part, you'll see many variables which you can include in your x and y variables!\n\nLet's see:\n\n```shell\n# Align the text to the center\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-filter_complex \"drawtext=text='HELLO THERE':y=h/2-text_h/2:x=w/2-text_w/2:fontsize=200:fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf\" \\\nfilter_complex6_center.mp4\n# y=h/2-text_h/2 means: y position = (image height / 2) - (text height / 2)\n\n# Align the text to the right:\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-filter_complex \"drawtext=text='HELLO THERE':y=30:x=w-text_w-20:fontsize=200:fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf\" \\\nfilter_complex6_right.mp4\n# x=w-text_w-20 means: x position = image width - text width - 20pixel padding\n\n\n# Align the text to the bottom:\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-filter_complex \"drawtext=text='HELLO THERE':y=h-text_h-20:x=30:fontsize=200:fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf\" \\\nfilter_complex6_bottom.mp4\n# y=h-text_h-20 means: y position = image height - text height - 20pixel padding\n```\n\nCopy\n\nAnd this is what we'll get in the end:\n\n![](media/img-22-filters_output_4.png)\n\nI need to mention one good trick that might not be obvious at first. So the `text_h` variable is a tricky one, because different text will be of different height! E.g.: \"____\" and \"WWW\"  will result in a different height.\n\nFor this reason, you do not always want to use text_h or even just a constant y=value expression but rather, you need to align text by its **[baseline](https://en.wikipedia.org/wiki/Baseline_(typography))**. So just remember to use the \"**ascent**\" variable whenever you need to align text vertically!\n\nCheck out these two examples! Each has two drawtext filters printing \"_\" and \"_H\":\n\n```shell\n# This one uses y=200 for both, still the text isn't aligned properly!\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-filter_complex \"drawtext=text='_':y=200:x=30:fontsize=200:fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf,drawtext=text='_H':y=200:x=500:fontsize=200:fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf\" \\\nfilter_complex7_bad_text.mp4\n\n# This one uses y=200-ascent for both and the text is aligned as expected!\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-filter_complex \"drawtext=text='_':y=200-ascent:x=30:fontsize=200:fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf,drawtext=text='_H':y=200-ascent:x=500:fontsize=200:fontfile=/usr/share/fonts/truetype/freefont/FreeSerif.ttf\" \\\nfilter_complex7_good_text.mp4\n```\n\nCopy\n\nNow let's compare the difference:\n\n![](media/img-23-filters_output_4_textalign.png)\n\nSee? This is the difference between aligning the \"top left\" or the \"baseline\" of the text!\n\n### Adding an overlay\n\nOverlaying is a very interesting thing to do with FFmpeg. Let's jump right in!\n\n#### Basic\n\n```shell\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4  \\\n-i smiley.png \\\n-filter_complex \"overlay\" \\\nfilter_complex8_overlay1.mp4\n```\n\nCopy\n\nEasy as that!\n\n![](media/img-24-overlay_1.png)\n\nOf course, the [overlay](https://ffmpeg.org/ffmpeg-filters.html#overlay) filter has a ton of options, but I wanted to demonstrate the easiest possible command line. We don't even need to mess with input/output pads, as FFmpeg automatically understands the situation: two inputs for the overlay filter and its single output into a single output.\n\nBut just to exercise, we could have executed it like this:\n\n```shell\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4  \\\n-i smiley.png \\\n-filter_complex \"[0:v][1:v]overlay[output]\" \\\n-map \"[output]\" filter_complex8_overlay2.mp4\n```\n\nCopy\n\nAnd this would result in the same output! Check it out, now I have specified the two inputs for the overlay: `[0:v][1:v]`!\n\n#### Aligned\n\nLet's align the smiley into the center!\n\nAs we have seen with the drawtext, the overlay filter's arguments also support a few dynamic variables. We'll use those to achieve what we want!\n\n```shell\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4  \\\n-i smiley.png \\\n-filter_complex \"overlay=x=main_w/2-overlay_w/2:y=main_h/2-overlay_h/2\" \\\nfilter_complex8_overlay3.mp4\n```\n\nCopy\n\n![](media/img-25-overlay_2.png)\n\n#### Preprocessing the input for overlay\n\nLet's get a bit creative!\n\nI want to make it [smaller](https://ffmpeg.org/ffmpeg-filters.html#scale), and I also want to [blur](https://ffmpeg.org/ffmpeg-filters.html#scale) it!\n\nNow pause for a minute, and think about it, how you'd do that?!\n\n...\n\nReady?\n\n```shell\nffmpeg -y  \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4  \\\n-i smiley.png \\\n-filter_complex \"[1:v]scale=w=200:h=-1,gblur=sigma=3[smiley] ; [0:v][smiley]overlay=x=100:y=100\" \\\nfilter_complex8_overlay4.mp4\n```\n\nCopy\n\n![](media/img-26-overlay_3.png)\n\nFor this we needed to have two filter graphs!\n\nThe first one is this: `[1:v]scale=w=200:h=-1,gblur=sigma=3[smiley]`\n\n-   Scales the input image (the smiley).\n-   Then the scaled output is also blurred.\n-   Then the output is saved into the output pad named \"smiley\".\n\nThen, we have our second filter graph: `[0:v][smiley]overlay=x=100:y=100`\n\n-   This takes as input the first input file (the video).\n-   This also takes as input the output pad named \"smiley\". (We are connecting two chains this time!)\n-   Then the overlay filter does its overlaying thing, and we trust FFmpeg to pair the unnamed output with the single output file we specified.\n\n#### Reusing content\n\nLet's do one more, a really complicated one!\n\nLet's have the outro overlaid over the intro!\n\n```shell\nffmpeg -y \\\n-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-t 5 -ss 00:09:40 -i bbb_sunflower_1080p_60fps_normal.mp4  \\\n-filter_complex \" [1:v]scale=w=1920/2:h=-1[outro]; [0:v][outro]overlay\" \\\nfilter_complex8_overlay5.mp4\n```\n\nCopy\n\n![](media/img-27-overlay_4.png)\n\nWe could have achieved it in several ways, e.g. we could use the [trim](https://ffmpeg.org/ffmpeg-filters.html#trim) filter, but to keep it easy, we just open the same file twice and [seek/trim](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#cutting-off-from-the-beginning-of-the-clip) them.\n\n-   **-t 5 -i bbb_sunflower_1080p_60fps_normal.mp4**: Open the video, and keep the first five seconds of it.\n-   **-t 5 -ss 00:09:40 -i bbb_sunflower_1080p_60fps_normal.mp4**: Open the same video again, but seek to the end and keep five seconds from there.\n\nThen we have two filter graphs again, one scales down the outro, and the second is just an overlay.\n\nAre you excited?:) I hope these made-up examples opened up your eye for the possibilities, and I hope you'll create very creative stuff with this knowledge!\n\n### Chroma keying, green screen, blue screen\n\nIn this section, we'll use chroma keying to remove the background from Big Buck Bunny's intro, and then we will put the transparent logo over the original video, as if it would be some kind of a logo overlay!\n\n```shell\nffmpeg -y \\\n-ss 0.5 -t 2 -i bbb_sunflower_1080p_60fps_normal.mp4 \\\n-ss 10 -i bbb_sunflower_1080p_60fps_normal.mp4  \\\n-filter_complex \" [0:v]chromakey=color=0xfdfdfd:similarity=0.1:blend=0.2 , scale=w=-1:h=300 , loop=loop=-1:start=0:size=120[intro] ; [1:v][intro]overlay=x=-40:y=-40\" \\\n-t 10 filter_complex9.mp4\n```\n\nCopy\n\nSo just to recap, Big Buck Bunny's first few seconds are like this:\n\n![](media/img-28-chroma_basic.png)\n\nAnd this is the result:\n\n![](media/img-29-chroma1.png)\n\nAlso, the butterfly moves its wings repeatedly!\n\nLet's examine the command!\n\n-   **-ss 0.5 -t 2 -i bbb_sunflower_1080p_60fps_normal.mp4**: We read in the intro from 0.5 to 2.5 seconds.\n-   **-ss 10 -i bbb_sunflower_1080p_60fps_normal.mp4**: We read in the video, starting from the 10th second.\n\nThen we have two filter graphs, the first being this:\n\n`[0:v]chromakey=color=0xfdfdfd:similarity=0.1:blend=0.2 , scale=w=-1:h=300 , loop=loop=-1:start=0:size=120[intro]`\n\nAs we see, we have three filters in here!\n\n-   **[chromakey](https://ffmpeg.org/ffmpeg-filters.html#chromakey)**: This one takes a color and a few parameters as input, and outputs transparent frames. The specified color + the blended areas will be the transparent sections. In our case we replaced the white-ish (#fdfdfd) background color with transparency.\n-   **[scale](https://ffmpeg.org/ffmpeg-filters.html#scale)**: We resize the full 1080p image into something around 300px high.\n-   **[loop](https://ffmpeg.org/ffmpeg-filters.html#loop)**: With the loop filter, we repeat all the 2 seconds worth of 120 frames (60*2) over and over again, to have the butterfly move its wings continuously.\n\nAnd then, finally we have the second filter graph:\n\n`[1:v][intro]overlay=x=-40:y=-40`\n\nNothing fancy, just an overlay of the original video and our chrome keyed intro.\n\n### What else?\n\nYou might want to check out a few more [filters](https://ffmpeg.org/ffmpeg-filters.html#toc-Video-Filters), that I didn't cover here.\n\nHere are just a few interesting ones:\n\n-   [colorcorrect](https://ffmpeg.org/ffmpeg-filters.html#colorcorrect)\n-   [colorchannelmixer](https://ffmpeg.org/ffmpeg-filters.html#colorchannelmixer)\n-   [colorize](https://ffmpeg.org/ffmpeg-filters.html#colorize)\n-   [fps](https://ffmpeg.org/ffmpeg-filters.html#fps)\n-   [trim](https://ffmpeg.org/ffmpeg-filters.html#trim)\n-   [crop](https://ffmpeg.org/ffmpeg-filters.html#crop)\n-   [delogo](https://ffmpeg.org/ffmpeg-filters.html#delogo)\n-   [derain](https://ffmpeg.org/ffmpeg-filters.html#derain)\n-   [deshake](https://ffmpeg.org/ffmpeg-filters.html#deshake)\n-   [erosion](https://ffmpeg.org/ffmpeg-filters.html#erosion)\n-   [edgedetect](https://ffmpeg.org/ffmpeg-filters.html#edgedetect)\n-   [hflip](https://ffmpeg.org/ffmpeg-filters.html#hflip)\n-   [vflip](https://ffmpeg.org/ffmpeg-filters.html#vflip)\n-   [hstack](https://ffmpeg.org/ffmpeg-filters.html#hstack)\n-   [vstack](https://ffmpeg.org/ffmpeg-filters.html#vstack)\n-   [xstack](https://ffmpeg.org/ffmpeg-filters.html#xstack)\n-   [lumakey](https://ffmpeg.org/ffmpeg-filters.html#lumakey)\n-   [reverse](https://ffmpeg.org/ffmpeg-filters.html#reverse)\n-   [rotate](https://ffmpeg.org/ffmpeg-filters.html#rotate)\n-   [scroll](https://ffmpeg.org/ffmpeg-filters.html#scroll)\n-   [pad](https://ffmpeg.org/ffmpeg-filters.html#pad)\n-   [vignette](https://ffmpeg.org/ffmpeg-filters.html#vignette)\n-   [zoompan](https://ffmpeg.org/ffmpeg-filters.html#zoompan)\n\n## Audio manipulation\n\nIn this chapter, we'll be going to check out some [audio manipulation techniques](https://ffmpeg.org/ffmpeg-filters.html#toc-Audio-Filters) with FFmpeg!\n\nFirst of all, let's see our [example](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#example-material) file:\n\n![](media/img-30-voice_recording.png)\n\nIt is a voice recording, and it is intentionally... well, quite bad.\n\nFrom the waveform, it is obvious that there are very different volume ranges in it. This is an example recording where each sentence was read in different strengths: \"normal\", \"whisper\" or \"powerful\", this is why you see repeating patterns of amplitude ranges on the image.\n\nIt isn't visible, but it has some noise too, and of course, it is not normalized or enhanced in any way. Yet.\n\nPlease note that there are different scenarios, requirements, and ways to enhance audio. This is a simplified method to show the outline of the process in this article. I'm not an audio engineer, although I have some experience in the area. So if you know it better, feel free to fine-tune it for yourself even more, or contact me and recommend improvements!\n\nI'm showing an example here with a very rough input, one that you'd just reject in real life as it would be useless due to its quality. But it is an excellent example to show the different steps of the enhancing process and to see what can be done to it!\n\nThe following steps are built upon each other, and we'll reach the complete command at the [end](https://img.ly/blog/ultimate-guide-to-ffmpeg/?utm_source=hackernewsletter&utm_medium=email&utm_term=fav#putting-it-all-together)!\n\nDon't forget that these settings are specific to this voice recording. Sadly this can not be generalized too much.\n\n### Gate\n\nLet's start with the [gate](https://ffmpeg.org/ffmpeg-filters.html#agate) filter!\n\nA gate is like a switch that opens only if the signal is stronger than the threshold. So if the signal level is lower than the threshold, it cuts to complete silence. Although you might soften or delay this cut with the _knee_, _attack_, and _release_ arguments.\n\nWe'll use this filter as a basic noise reduction method now! This helps us remove the noise between words and sentences by cutting it to silence. It doesn't remove noise in any other way, e.g. it doesn't touch the static on the voice itself.\n\nCheck this out!\n\n```shell\nffmpeg -y \\\n-i voice_recording.wav \\\n-filter_complex \"agate=threshold=0.01:attack=80:release=840:makeup=1:ratio=3:knee=8\" \\\ngate.wav\n```\n\nCopy\n\nLet's hear it: [gate.wav](https://img.ly/blog/upwork50/janbussieck/the-ultimate-guide-to-ffmpeg/-/raw/edit/assets/audio/gate.wav)\n\nAnd let's see it:\n\n![](media/img-31-a_compression_result.png)\n\nAs you can see, the \"silent\" parts were attenuated heavily, while the above-the-threshold parts remained similar. Those parts were still affected by the knee, attack, and release arguments determining how hard (knee) and quick (attack/release) the cut is.\n\nI've left a quite high release timeout here to avoid sudden dips in the amplitude.\n\nThis is where we are right now:\n\n![](media/img-32-gate.png)\n\nThe silent parts are more silent than before, but still, the amplitude range or the dynamic range is quite high. You must change your volume levels to hear everything and void blowing your speakers/brain out.\n\n### Equalization\n\nBefore fixing that, let's do a bit more housekeeping. Let's do some equalization and frequency filtering!\n\nWe'll use these filters:\n\n-   [highpass](https://ffmpeg.org/ffmpeg-filters.html#highpass)\n-   [lowpass](https://ffmpeg.org/ffmpeg-filters.html#lowpass)\n-   [anequalizer](https://ffmpeg.org/ffmpeg-filters.html#anequalizer)\n\n```shell\nffmpeg -y \\\n-i gate.wav  \\\n-filter_complex \"highpass=f=100:width_type=q:width=0.5 , lowpass=f=10000 , anequalizer=c0 f=250 w=100 g=2 t=1|c0 f=700 w=500 g=-5 t=1|c0 f=2000 w=1000 g=2 t=1\" \\\ngate_eq.wav\n```\n\nCopy\n\nLet's hear it: [gate_eq.wav](https://storage.googleapis.com/imgly-static-assets/static/blog/ffmpeg-audio/audio-5-gate.wav)\n\nThis command gradually attenuates frequencies below 100hz, as there are not much valuable content in there, but it can really lower the clarity of the speech.\n\nThen we do the same, but for frequencies above 10 kHz. This is mostly needed because we have a lot of high-frequency noise, so this is a workaround for those. Also, a male voice is generally deeper than a woman's, so you might want to pay attention to how low you can put the bar.\n\nThen comes anequalizer, which has a crazy an exceptional way of setting its arguments:\n\nThis: `anequalizer=c0 f=250 w=100 g=2 t=1|c0 f=700 w=500 g=-5 t=1|c0 f=2000 w=1000 g=2 t=1` means:\n\n-   at 250hz with a width of 100hz boost by 2 db, with Chebyshev type 1 filter on channel 0.\n-   at 700hz with a width of 500hz attenuate by 5 db, with Chebyshev type 1 filter on channel 0.\n-   at 2000hz with a width of 1000hz attenuate by 2 db, with Chebyshev type 1 filter on channel 0.\n\nI agree. You might have used a friendlier equalizer in your life than this one:)\n\nThose values are based on experimentation and common recommendations for voice. Feel free to tune it for your own needs!\n\nLet's compare the frequency plots before and after:\n\n![](media/img-33-a_eq.png)\n\nTip: To see the frequency plot in Audacity, open a file, select all, and choose Analyze → Plot spectrum!\n\n### Compression\n\nThe [compressor](https://ffmpeg.org/ffmpeg-filters.html#acompressor) filter applies [dynamic range compression](https://en.wikipedia.org/wiki/Dynamic_range_compression) on the incoming audio data. To simplify this, the compressor varies the attenuation based on the incoming signal level. Basically, when you watch a badly mastered movie, this is what you are doing. When it is way too loud in some action scene, you reach for the remote control or mouse to lower the volume, but in the next moment, you will not hear what your heroes are saying, so you increase it back again.\n\nDynamic range compression roughly does the same. You may set it up in a way so that it would attenuate louder parts, therefore keeping the overall volume range relatively small.\n\nIt often happens that performers on the stage use a high dynamic range. Many performers will shout at one moment and then whisper in the next to increase drama or keep the attention. If you want to avoid manually adjusting the volume in real-time (while blowing off your speakers and pulling your hair out), then a compressor will save you in these situations!\n\nThis is why our example audio consists of different speaking strengths, so that we could see the dramatic effect of this filter.\n\n```shell\nffmpeg -y \\\n-i gate_eq.wav \\\n-filter_complex \"acompressor=level_in=6:threshold=0.025:ratio=20:makeup=6\" \\\ngate_eq_comp.wav\n```\n\nCopy\n\nLet's hear it: [gate_eq_comp.wav](https://storage.googleapis.com/imgly-static-assets/static/blog/ffmpeg-audio/audio-1-gate-eq-comp.wav)\n\nAnd let's compare the result of this with the original waveform!\n\nOriginal:\n\n![](media/img-34-voice_recording.png)\n\nResult:\n\n![](media/img-35-gate_eq_comp.png)\n\nQuite dramatic, isn't it?:)\n\nLet's analyze this: `acompressor=level_in=6:threshold=0.025:ratio=20:makeup=6`\n\nFirst, `level_in=6`  sets the input gain. It is 1 by default, but since our example, audio is extremely silent at places, we boost up the whole thing before processing.\n\nThen `threshold=0.025` defines that everything above 0.025 should be attenuated.\n\nBased on the image below, I've decided to cut at this point, as this is above most of the whispering, which cuts hard pops and \"s\"-es even in the \"whisper zone\".\n\n![](media/img-36-eq.png)\n\nThen `ratio=20` means 1:20 in attenuation ratio, which means that if the level rises 20 dB above the threshold, it will be only 1 dB above the line after the attenuation. Basically, this is a very strong compression ratio, it is almost a [limiter](https://ffmpeg.org/ffmpeg-filters.html#alimiter).\n\nThis far, we boosted the signal, then turned down everything that was above our \"whisper line\" with a quite strong ratio, and now, everything is basically at the whisper level, even the parts that are shouting.\n\nFinally, with the `makeup=6` we just bring back everything to the level where the \"normal\" parts were before.\n\nLet's take a look back now, to understand why we used the gate and did the equalization before the compressor.\n\nGenerally, you want to remove unneeded parts and frequencies before compression, as the compressor will likely increase those too! So by removing most of the noise in the gaps, we avoided `level_in=6` to increase them too! And the same goes for the high- and lowpass filtering.\n\n### Changing the volume\n\nNow, if we want to make the result a bit louder, we could increase the previous step's `makeup` argument, or leverage the volume [filter](https://ffmpeg.org/ffmpeg-filters.html#volume).\n\nWhile we are at it, let's cut the first 4 seconds too with `-ss 4`.\n\n```shell\nffmpeg -y \\\n-ss 4 -i gate_eq_comp.wav \\\n-filter_complex \"volume=1.1\" \\\ngate_eq_volume_comp.wav\n```\n\nCopy\n\nLet's hear it: [gate_eq_volume_comp.wav](https://storage.googleapis.com/imgly-static-assets/static/blog/ffmpeg-audio/audio-2-gate_eq_volume_comp.wav)\n\n### Let's make audio gate again\n\nExcuse me for that title:)\n\nSo as I've described earlier, compression can amplify the noises, so you might want to run the result through a gate again:\n\n```shell\nffmpeg -y \\\n-i gate_eq_volume_comp.wav \\\n-filter_complex \"agate=threshold=0.1:attack=50:release=50:ratio=1.5:knee=4\" \\\ngate_eq_volume_comp_gate.wav\n```\n\nCopy\n\nLet's hear it: [gate_eq_volume_comp_gate.wav](https://storage.googleapis.com/imgly-static-assets/static/blog/ffmpeg-audio/audio-3-gate_eq_volume_comp_gate.wav)\n\nIn this case, I've used a softer gate, with `ratio=1.5`. Because of this, I could use shorter attack and release delays too, as the attenuation is not that strong, it isn't causing hard dips in the audio.\n\n### Putting it all together\n\nJust a single command could have achieved all the steps above:\n\n```shell\nffmpeg -y \\\n-i voice_recording.wav \\\n-filter_complex \"agate=threshold=0.01:attack=80:release=840:makeup=1:ratio=3:knee=8 , highpass=f=100:width_type=q:width=0.5 , lowpass=f=10000 , anequalizer=c0 f=250 w=100 g=2 t=1|c0 f=700 w=500 g=-5 t=1|c0 f=2000 w=1000 g=2 t=1 , acompressor=level_in=6:threshold=0.025:ratio=20:makeup=6 , volume=1.1 , agate=threshold=0.1:attack=50:release=50:ratio=1.5:knee=4\" \\\ngate_eq_volume_comp_gate_together.wav\n```\n\nCopy\n\nI just copy-pasted all the filters right after each other with a comma between them.\n\nIsn't it beautiful? Yeah, it isn't, but it is very practical:)\n\nFor the last time, check out the difference:\n\n-   Original: [voice_recording.wav](https://storage.googleapis.com/imgly-static-assets/static/blog/ffmpeg-audio/audio-4-voice_recording.wav)\n-   Final: [gate_eq_volume_comp_gate.wav](https://storage.googleapis.com/imgly-static-assets/static/blog/ffmpeg-audio/audio-3-gate_eq_volume_comp_gate.wav)\n\nIt has less noise, more clear voice, and a small volume range. Therefore it is easy on your ears!\n\n### What else?\n\nYou might want to check out a few more [filters](https://ffmpeg.org/ffmpeg-filters.html#toc-Audio-Filters) that I didn't cover here.\n\nHere are just a few interesting ones:\n\n-   [adeclick](https://ffmpeg.org/ffmpeg-filters.html#adeclick)\n-   [adeclip](https://ffmpeg.org/ffmpeg-filters.html#adeclip)\n-   [aecho](https://ffmpeg.org/ffmpeg-filters.html#aecho)\n-   [deesser](https://ffmpeg.org/ffmpeg-filters.html#deesser)\n-   [alimiter](https://ffmpeg.org/ffmpeg-filters.html#alimiter)\n\n## Documentation\n\nFor your convenience, let me list the most important documentations that might be important for you! Most of these were already linked many times in this article.\n\n-   [FFmpeg main documentation](https://ffmpeg.org/ffmpeg.html)\n-   [FFmpeg WIKI](https://trac.ffmpeg.org/wiki)\n-   [FFmpeg compilation guide](https://trac.ffmpeg.org/wiki/CompilationGuide)\n-   [FFmpeg filters documentation](https://ffmpeg.org/ffmpeg-filters.html)\n-   [FFmpeg formats documentation](https://ffmpeg.org/ffmpeg-formats.html)\n-   [H.264 Video Encoding Guide](https://trac.ffmpeg.org/wiki/Encode/H.264)\n-   [H.265 Video Encoding Guide](https://trac.ffmpeg.org/wiki/Encode/H.265)\n\nIf you got this far from top to bottom, then you are a true hero! I hope you enjoyed this, and I also hope that it inspired you to create something awesome with FFmpeg!\n\nPlease consider [donating](https://ffmpeg.org/donations.html) to FFmpeg they are awesom\n"
    },
    {
      "file-id": "file-clerk-overview",
      "date-created": "Tue Dec 12 21:33:48 2023",
      "last-updated": "Tue Dec 12 21:34:01 2023",
      "type": "markdown",
      "lastIndexed": "never",
      "lastUpdated": "2024-02-20T22:54:12.670Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "file-clerk",
      "content": "\nFile Clerk generates a SQL directory from markdown files and then serves a JSON file of the entire file structure. It runs natural language processing to extract names and unique key words from a file and storing them for later retrieval in a graph structure.\n\nDatabase stores -- last updated, which if it is later than browsers update serves those dates where the browser then merges the objects for search.\n\nSearch with fuse.js, 3d graph interface, geo-map.\n\nFile Clerk can serve and update files in Dataroom. These files can be reasoned with with other markdown based note taking systems.\n\n# file-clerk.md\n\n\n## Get notebook page example\n\n```js\n\nasync function getNotebookPage(file_id){\n  const response = await fetch(\"/load-notebook-page\", {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify({\"file-id\":file_id})\n  });\n  const data = response.json();\n  return data;\n}\n\ngetNotebookPage('index.md').then(res => {\n  console.log(res);\n})\n\n```\n\n## Tests\n\n#file-clerk.list-notebooks.tests.prompt\n#file-clerk.load-notebook-page.tests.prompt\n#file-clerk.hanging.tests.prompt\n\n\n#file-clerk.list-notebooks.tests.prompt\n#file-clerk.load-notebook-page.tests.prompt\n\nSome Manual tests that seem to work:\n\n```js\n\nasync function checkIfFileExists(file_id = 'index.md'){\nconst response = await fetch(\"/does-file-exist\", {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify({\"file-id\":file_id})\n  });\n  const data = await response.json();\n  console.log(file_id, \"exists?\", data.exists);\n  return data;\n}\n\ncheckIfFileExists();\n\n\nasync function deleteFile(file_id = 'index.md'){\nconst response = await fetch(\"/delete-file\", {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify({\"file-id\":file_id})\n  });\n  const data = await response.json();\n  console.log(file_id, 'deleted');\n  return data;\n}\n\ndeleteFile();\ncheckIfFileExists();\n\n\n```\n\n\nHey Hans, \n\nHere is an example of some tests we have: \n\n```\nconst assert = require('assert');\nconst { queryChatGPT, processFile } = require('./chat-gpt.js');\n\n// Mocha tests\ndescribe('queryChatGPT', () => {\n  it('should return the completion message', async () => {\n    const prompt = [{ role: 'system', content: 'You are a helpful assistant.' }, { role: 'user', content: 'Hello, how are you?' }];\n\n    const result = await queryChatGPT(prompt);\n    console.log(result);\n\n    // Assert the type of the result\n    assert.strictEqual(typeof result, 'object');\n\n    // Assert that the result contains the message\n    assert.ok(result);\n  });\n});\n\ndescribe('processFile', () => {\n  it('should return the completion message for the file content', async () => {\n    const filePath = './notebook/chat-gpt.tests.prompt';\n\n    const result = await processFile(filePath);\n    console.log(result);\n\n    // Assert the type of the result\n    assert.strictEqual(typeof result, 'object');\n\n    // Assert that the result contains the message\n    assert.ok(result);\n  });\n\n  it('should throw an error if file reading fails', async () => {\n    const filePath = 'nonexistent/file.txt';\n\n    // Assert that an error is thrown\n    await assert.rejects(async () => {\n      await processFile(filePath);\n    }, /*Error reading file*/);\n  });\n});\n\n```\n\nCould you write mocha tests for the following endpoints: \n\n```js\n\n/*\n  \n  FILE CLERK\n\n  Here to save the day, as usual\n\n\n */\n\nconst path = require('path');\nconst fs = require('fs');\nconst fsPromises = require('fs').promises;\n\nfunction generateNewFile(file_id){\n  return `---\n{\n  \"file-id\":\"${file_id}\",\n  \"date-created\":\"${new Date()}\",\n  \"last-updated\":\"${new Date()}\"\n}\n---\n\n# ${file_id}\n\n`\n}\n\n\nmodule.exports = function (app) {\n\n  /*\n  \n    List All Notebook Pages\n\n   */\n  \n  app.post('/list-notebook-pages', async function (req, res) {\n    try {\n      const files = await fsPromises.readdir(path.join(global.root_directory, 'notebook'));\n      res.json(files);\n    } catch (err) {\n      res.status(500).json({ error: 'Error listing files' });\n    }\n  });\n\n  /*\n  \n    Get a single notebook page. If the page doesn't exist, create it.\n\n  */\n  app.post('/load-notebook-page', async function (req, res) {\n    if(!req.body[\"file-id\"]){\n      return res.status(400).json({ error: 'file-id is required in the request body' });\n    }\n    const file_id = req.body[\"file-id\"];\n    const file_path = path.join(global.root_directory, 'notebook', file_id);\n    try {\n      const content = await fsPromises.readFile(file_path, 'utf8');\n      res.json({ content });\n    } catch (err) {\n      const new_file = generateNewFile(file_id);\n      await fsPromises.writeFile(file_path, new_file, 'utf8', (err) => {\n        if (err) {return res.status(500)}\n      });\n      const content = await fsPromises.readFile(file_path, 'utf8');\n      res.json({ content });\n    }\n  });\n\n  /*\n    \n    Check if a File Exists\n\n   */\n  app.post('/does-file-exist', async function (req, res) {\n    if(!req.body[\"file-id\"]){\n      return res.status(400).json({ error: 'file-id is required in the request body' });\n    }\n\n    const file_id = req.body[\"file-id\"];\n    const file_path = path.join(global.root_directory, 'notebook', file_id);\n\n    try {\n      // Check if the file exists\n      const exists = await fsPromises.access(file_path, fs.constants.F_OK)\n        .then(() => true)\n        .catch(() => false);\n\n      res.json({ exists });\n    } catch (err) {\n      res.status(500).json({ error: 'Error checking file existence' });\n    }\n  });\n\n  /*\n  \n    DELETE FILE\n\n  */\n \n  app.post('/delete-file', async function (req, res) {\n    if (!req.body[\"file-id\"]) {\n      return res.status(400).json({ error: 'file-id is required in the request body' });\n    }\n    const file_id = req.body[\"file-id\"];\n    const file_path = path.join(global.root_directory, 'notebook', file_id);\n\n    try {\n      await fsPromises.unlink(file_path);\n      res.json({ message: 'File deleted successfully' });\n    } catch (err) {\n      res.status(500).json({ error: 'Error deleting the file' });\n    }\n  });\n\n\n  /*\n    Save a file\n\n   */\n  app.post('/save-file', async function (req, res) {\n    if (!req.body.content || !req.body[\"file-id\"]) {\n        return res.status(400).json({ error: 'Both content and file-id are required in the request body' });\n    }\n    const file_id = req.body[\"file-id\"];\n    // Construct the file path based on the provided file_path\n    const file_path = path.join(global.root_directory, 'notebook',  file_id );\n    // Write the content to the file\n    fs.writeFile(file_path, req.body.content, 'utf8', (err) => {\n      if (err) {\n          return res.status(500).json({ error: 'Error saving the file' });\n      }\n      res.json({ message: 'File saved successfully' });\n    });\n  });\n\n}\n\n```\n\nOur current tests look like:\n\n```\nconst assert = require(\"assert\");\nconst fsPromises = require(\"fs\").promises;\nconst path = require(\"path\");\n\ndescribe(\"File Clerk Endpoints\", () => {\n  let app;\n  beforeEach(() => {\n    // Create a new express app instance before each test\n    app = express();\n  });\n\n  describe(\"POST /list-notebook-pages\", () => {\n    it(\"should return a list of notebook pages\", async () => {\n      const mockFiles = [\"page1\", \"page2\", \"page3\"];\n      // Stub the fsPromises.readdir method to return the mock files\n      fsPromises.readdir = jest.fn().mockResolvedValue(mockFiles);\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/list-notebook-pages\")\n        .expect(200);\n\n      // Assert that the response contains the mock files\n      assert.deepStrictEqual(response.body, mockFiles);\n    });\n\n    it(\"should return an error if the file listing fails\", async () => {\n      // Stub the fsPromises.readdir method to throw an error\n      fsPromises.readdir = jest\n        .fn()\n        .mockRejectedValue(new Error(\"Error listing files\"));\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/list-notebook-pages\")\n        .expect(500);\n\n      // Assert that the response contains the error message\n      assert.deepStrictEqual(response.body, { error: \"Error listing files\" });\n    });\n  });\n\n  describe(\"POST /load-notebook-page\", () => {\n    it(\"should return the content of an existing notebook page\", async () => {\n      const mockFileId = \"page1\";\n      const mockContent = \"# page1\\n\";\n\n      // Stub the fsPromises.readFile method to return the mock content\n      fsPromises.readFile = jest.fn().mockResolvedValue(mockContent);\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/load-notebook-page\")\n        .send({ \"file-id\": mockFileId })\n        .expect(200);\n\n      // Assert that the response contains the mock content\n      assert.deepStrictEqual(response.body, { content: mockContent });\n    });\n\n    it(\"should create a new notebook page if it does not exist\", async () => {\n      const mockFileId = \"page2\";\n\n      // Mock the fsPromises.readFile and fsPromises.writeFile methods\n      fsPromises.readFile = jest\n        .fn()\n        .mockRejectedValue(new Error(\"File not found\"));\n      fsPromises.writeFile = jest.fn().mockResolvedValue();\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/load-notebook-page\")\n        .send({ \"file-id\": mockFileId })\n        .expect(200);\n\n      // Assert that the response contains the new page content\n      const newFileContent = `---\\n{\n  \"file-id\":\"${mockFileId}\",\n  \"date-created\":\"${new Date()}\",\n  \"last-updated\":\"${new Date()}\"\n}\\n---\\n\\n# ${mockFileId}\\n`;\n      assert.deepStrictEqual(response.body, { content: newFileContent });\n    });\n\n    it(\"should return an error if the file read/write fails\", async () => {\n      const mockFileId = \"page3\";\n\n      // Stub the fsPromises.readFile method to throw an error\n      fsPromises.readFile = jest\n        .fn()\n        .mockRejectedValue(new Error(\"Error reading file\"));\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/load-notebook-page\")\n        .send({ \"file-id\": mockFileId })\n        .expect(500);\n\n      // Assert that the response contains the error message\n      assert.deepStrictEqual(response.body, { error: \"Error reading file\" });\n    });\n  });\n\n  describe(\"POST /does-file-exist\", () => {\n    it(\"should return true if the file exists\", async () => {\n      const mockFileId = \"page1\";\n      const mockFilePath = path.join(\n        global.root_directory,\n        \"notebook\",\n        mockFileId,\n      );\n\n      // Stub the fsPromises.access method to resolve without an error\n      fsPromises.access = jest.fn().mockResolvedValue();\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/does-file-exist\")\n        .send({ \"file-id\": mockFileId })\n        .expect(200);\n\n      // Assert that the response contains the existence flag as true\n      assert.deepStrictEqual(response.body, { exists: true });\n\n      // Assert that the fsPromises.access method was called with the correct file path\n      assert(fsPromises.access.mock.calls[0][0] === mockFilePath);\n    });\n\n    it(\"should return false if the file does not exist\", async () => {\n      const mockFileId = \"page2\";\n\n      // Stub the fsPromises.access method to reject with an error\n      fsPromises.access = jest\n        .fn()\n        .mockRejectedValue(new Error(\"File not found\"));\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/does-file-exist\")\n        .send({ \"file-id\": mockFileId })\n        .expect(200);\n\n      // Assert that the response contains the existence flag as false\n      assert.deepStrictEqual(response.body, { exists: false });\n    });\n\n    it(\"should return an error if the file existence check fails\", async () => {\n      const mockFileId = \"page3\";\n\n      // Stub the fsPromises.access method to throw an error\n      fsPromises.access = jest\n        .fn()\n        .mockRejectedValue(new Error(\"Error checking file existence\"));\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/does-file-exist\")\n        .send({ \"file-id\": mockFileId })\n        .expect(500);\n\n      // Assert that the response contains the error message\n      assert.deepStrictEqual(response.body, {\n        error: \"Error checking file existence\",\n      });\n    });\n  });\n\n  describe(\"POST /delete-file\", () => {\n    it(\"should delete the file and return a success message\", async () => {\n      const mockFileId = \"page1\";\n      const mockFilePath = path.join(\n        global.root_directory,\n        \"notebook\",\n        mockFileId,\n      );\n\n      // Stub the fsPromises.unlink method to resolve without an error\n      fsPromises.unlink = jest.fn().mockResolvedValue();\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/delete-file\")\n        .send({ \"file-id\": mockFileId })\n        .expect(200);\n\n      // Assert that the response contains the success message\n      assert.deepStrictEqual(response.body, {\n        message: \"File deleted successfully\",\n      });\n\n      // Assert that the fsPromises.unlink method was called with the correct file path\n      assert(fsPromises.unlink.mock.calls[0][0] === mockFilePath);\n    });\n\n    it(\"should return an error if the file deletion fails\", async () => {\n      const mockFileId = \"page2\";\n\n      // Stub the fsPromises.unlink method to throw an error\n      fsPromises.unlink = jest\n        .fn()\n        .mockRejectedValue(new Error(\"Error deleting the file\"));\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/delete-file\")\n        .send({ \"file-id\": mockFileId })\n        .expect(500);\n\n      // Assert that the response contains the error message\n      assert.deepStrictEqual(response.body, {\n        error: \"Error deleting the file\",\n      });\n    });\n  });\n\n  describe(\"POST /save-file\", () => {\n    it(\"should save the file and return a success message\", async () => {\n      const mockFileId = \"page1\";\n      const mockFilePath = path.join(\n        global.root_directory,\n        \"notebook\",\n        mockFileId,\n      );\n      const mockContent = \"Some content\";\n\n      // Stub the fsPromises.writeFile method to resolve without an error\n      fsPromises.writeFile = jest.fn().mockResolvedValue();\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/save-file\")\n        .send({ \"file-id\": mockFileId, content: mockContent })\n        .expect(200);\n\n      // Assert that the response contains the success message\n      assert.deepStrictEqual(response.body, {\n        message: \"File saved successfully\",\n      });\n\n      // Assert that the fsPromises.writeFile method was called with the correct arguments\n      assert(fsPromises.writeFile.mock.calls[0][0] === mockFilePath);\n      assert(fsPromises.writeFile.mock.calls[0][1] === mockContent);\n      assert(fsPromises.writeFile.mock.calls[0][2] === \"utf8\");\n    });\n\n    it(\"should return an error if the file saving fails\", async () => {\n      const mockFileId = \"page2\";\n      const mockContent = \"Some content\";\n\n      // Stub the fsPromises.writeFile method to throw an error\n      fsPromises.writeFile = jest\n        .fn()\n        .mockRejectedValue(new Error(\"Error saving the file\"));\n\n      // Make a request to the endpoint\n      const response = await request(app)\n        .post(\"/save-file\")\n        .send({ \"file-id\": mockFileId, content: mockContent })\n        .expect(500);\n\n      // Assert that the response contains the error message\n      assert.deepStrictEqual(response.body, { error: \"Error saving the file\" });\n    });\n\n    it(\"should return an error if the content or file-id is missing\", async () => {\n      // Make a request to the endpoint without the required fields\n      const response = await request(app).post(\"/save-file\").expect(400);\n\n      // Assert that the response contains the error message\n      assert.deepStrictEqual(response.body, {\n        error: \"Both content and file-id are required in the request body\",\n      });\n    });\n  });\n});\n\n```\n\nThe result is:\n\n```sh\n\n\n> test\n> mocha tests.js\n\n\n\n  0 passing (0ms)\n\n\n\n  1) File Clerk Endpoints\n       \"before each\" hook for \"should return a list of notebook pages\":\n     ReferenceError: express is not defined\n      at Context.<anonymous> (plugins/file-clerk/file-clerk.tests.js:9:5)\n      at process.processImmediate (node:internal/timers:478:21)\n\n```\n\nCould you rewrite these tests using Chai? \n\n\n\nI have an endpoint that looks like: \n\n```\nmodule.exports = function (app) {\n\n  app.post('/load-notebook-page', async function (req, res) {\n    if(!req.body[\"file-id\"]){\n      return res.status(400).json({ error: 'file-id is required in the request body' });\n    }\n    const file_id = req.body[\"file-id\"];\n    const file_path = path.join(global.root_directory, 'notebook', file_id);\n    try {\n      const content = await fsPromises.readFile(file_path, 'utf8');\n      res.json({ content });\n    } catch (err) {\n      const new_file = generateNewFile(file_id);\n      await fsPromises.writeFile(file_path, new_file, 'utf8', (err) => {\n        if (err) {return res.status(500)}\n      });\n      const content = await fsPromises.readFile(file_path, 'utf8');\n      res.json({ content });\n    }\n  });\n}\n```\n\nWhere app is an express.js app. \n\nI am using Mocha and Chai for tests. My initial code for these tests looks like: \n\n```js\nconst chai = require(\"chai\");\nconst chaiHttp = require(\"chai-http\");\nconst fsPromises = require(\"fs\").promises;\nconst path = require(\"path\");\nconst app = require('express')();  // Assuming Express is properly set up in your project\nconst server = require('http').Server(app);  // Create an HTTP server using the Express app\nconst routes_path = path.join(global.root_directory, 'routes.js');\nconst routes = require(routes_path)(app);\nconst sinon = require('sinon');\n\n\nconst expect = chai.expect;\n\nchai.use(chaiHttp);\n\ndescribe(\"File Clerk Endpoints\", () => {\n\n  describe(\"POST /load-notebook-page\", () => {\n\n  });\n\n});\n\n```\n\n# Response \n\nBased on your code, it seems like you want to write tests for the \"/load-notebook-page\" endpoint in your Express.js app. Here's an example of how you can approach writing the tests using Mocha and Chai:\n\n```js\nconst chai = require(\"chai\");\nconst chaiHttp = require(\"chai-http\");\nconst fsPromises = require(\"fs\").promises;\nconst path = require(\"path\");\nconst { createApp } = require(\"./app\"); // Assuming you have a separate file for creating the Express app\nconst sinon = require(\"sinon\");\n\nconst expect = chai.expect;\nchai.use(chaiHttp);\n\ndescribe(\"File Clerk Endpoints\", () => {\n  let app;\n  before(() => {\n    app = createApp(); // Create the Express app before running the tests\n  });\n\n  describe(\"POST /load-notebook-page\", () => {\n    it(\"should return 'file-id is required' error if file-id is not provided\", async () => {\n      const res = await chai\n        .request(app)\n        .post(\"/load-notebook-page\")\n        .send({}); // Send an empty request body\n\n      expect(res).to.have.status(400);\n      expect(res.body).to.deep.equal({\n        error: \"file-id is required in the request body\",\n      });\n    });\n\n    it(\"should return the content of the file if it exists\", async () => {\n      // Stub the fsPromises.readFile function to return a test content\n      const readFileStub = sinon.stub(fsPromises, \"readFile\");\n      readFileStub.resolves(\"Test file content\");\n\n      const res = await chai\n        .request(app)\n        .post(\"/load-notebook-page\")\n        .send({ \"file-id\": \"test-file-id\" });\n\n      expect(res).to.have.status(200);\n      expect(res.body.content).to.equal(\"Test file content\");\n\n      readFileStub.restore(); // Restore the original function\n    });\n\n    it(\"should create a new file and return its content if it doesn't exist\", async () => {\n      // Stub the fsPromises.readFile and fsPromises.writeFile functions\n      const readFileStub = sinon.stub(fsPromises, \"readFile\");\n      const writeFileStub = sinon.stub(fsPromises, \"writeFile\");\n      readFileStub.rejects(new Error(\"File not found\"));\n      writeFileStub.resolves();\n\n      const res = await chai\n        .request(app)\n        .post(\"/load-notebook-page\")\n        .send({ \"file-id\": \"test-file-id\" });\n\n      expect(res).to.have.status(200);\n      expect(res.body.content).to.equal(\"Generated file content\");\n\n      readFileStub.restore(); // Restore the original functions\n      writeFileStub.restore();\n    });\n  });\n});\n```\n\nIn this example, I've created three test cases for the \"/load-notebook-page\" endpoint:\n\n1. The first test case checks if the server returns a 400 status code and the correct error message when the \"file-id\" property is missing from the request body.\n2. The second test case stubs the `fsPromises.readFile` function to return a test content and verifies that the server returns the expected content in the response body.\n3. The third test case stubs the `fsPromises.readFile` and `fsPromises.writeFile` functions to simulate the scenario where the file doesn't exist. It verifies that the server creates a new file, returns its content in the response body, and handles the file creation error correctly.\n\nNote that I have added a `createApp` function in the code example. In this function, you should create and configure your Express app instance. You can move your existing code for creating the app and setting up routes into this function. It's good practice to separate app creation logic from test cases to make it easier to reuse the app and mock dependencies in tests.\n\nHope this helps! Let me know if you have any further questions.\n\n\nI have an endpoint that looks like: \n\n```\nmodule.exports = function (app) {\n\n  app.post('/list-notebook-pages', async function (req, res) {\n    try {\n      const files = await fsPromises.readdir(path.join(global.root_directory, 'notebook'));\n      res.json(files);\n    } catch (err) {\n      res.status(500).json({ error: 'Error listing files' });\n    }\n  });\n}\n```\n\nWhere app is an express.js app. \n\nI am using Mocha and Chai for tests. My initial code for these tests looks like: \n\n```js\nconst chai = require(\"chai\");\nconst chaiHttp = require(\"chai-http\");\nconst fsPromises = require(\"fs\").promises;\nconst path = require(\"path\");\nconst app = require('express')();  // Assuming Express is properly set up in your project\nconst server = require('http').Server(app);  // Create an HTTP server using the Express app\nconst routes_path = path.join(global.root_directory, 'routes.js');\nconst routes = require(routes_path)(app);\nconst sinon = require('sinon');\n\n\nconst expect = chai.expect;\n\nchai.use(chaiHttp);\n\ndescribe(\"File Clerk Endpoints\", () => {\n\n  describe(\"POST /list-notebook-pages\", () => {\n\n  });\n\n});\n\n```\n\nCould you complete the tests for this end point? No need to give me anything other than code. Please only give me code responses.\n\n\n\n# File Clerk\nHere to save the day, as usual\n\n## Functions\n\nupsert-metadata\n  - add new metadata\n\nCreate new File\n  - Generate a new markdown file with JSON front matter\nImport file\n  - if Markdown\n    - check if YAML front matter\n      - if yaml front matter convert to JSON front matter\n      - create new mark down file\n      - use llm to summarize\n      - get most unique words and add to JSON front matter as \"keywords\"\n      - get hashtags and add to JSON front matter as \"hashtags\"\n      - convert obsidian / wikimedia links to hashtags and / or embeds\n\n  - if image file\n      - get image data\n      - read exif data\n      - place image in assets folder\n      - generate new markdown file with file metadata including\n           - file size\n          - file width\n          - file height\n          - exif prompt\n          - negative prompt\n          - model\n   - if PDF\n        - get text for each page\n        - generate markdown file for each page with page content\n        - get most unique words\n        - divide text into paragraphs,\n        - divide paragraphs into sentences\n        - divide paragraphs into grammar positions\n        - get subject, object, create graph representation\n\n  add metadata to search DB\n\nGet File\n  Takes file id,\n  - if markdown file, renders file with view\n  - if image or video, return data\n\n  \n\n\nBackup Archive \n  compress and backup archive to local harddisk (multiple harddisks?) \n  \n\nfile-clerk.js\n```js\nimport fs from 'fs';\nimport path from 'path';\nimport {parseJSONFrontmatter, removeFrontMatter} from './file-processing.js';\n\n// Function to save a file with metadata and content\nexport async function saveFile(file_id, notebook, metadata, content) {\n  metadata.lastUpdated = new Date();\n  const filePath = path.join(global.root_directory, 'notebooks', notebook, `${fileId}.md`);\n  const fileContent = `---\\n${JSON.stringify(metadata)}\\n---\\n\\n${content}`;\n\n  fs.writeFileSync(filePath, fileContent, 'utf-8');\n\n  console.log(`File saved successfully at: ${filePath}`);\n}\n\nexport async function fileExists(fileId, notebook) {\n  const filePath = path.join(global.root_directory, 'notebooks', notebook, `${fileId}.md`);\n  return fs.existsSync(filePath);\n}\n\n```\n\n## file-processing.js\n```js\nexport function parseJSONFrontmatter(markdownContent) {\n  // Regular expression to match YAML or JSON frontmatter\n  const frontmatterRegex = /^---\\s*[\\r\\n]+([\\s\\S]*?)[\\r\\n]+---\\s*[\\r\\n]+/;\n\n  // Check if frontmatter exists in the markdown content\n  const match = markdownContent.match(frontmatterRegex);\n\n  if(match === null){\n    return {}\n  }\n\n  if (match && match[1]) {\n    // Extract the frontmatter string\n    const frontmatterString = match[1];\n\n    try {\n      // Parse the frontmatter string into a JavaScript object\n      const frontmatterObject = JSON.parse(frontmatterString);\n\n      return frontmatterObject;\n    } catch (error) {\n      console.error('Error parsing frontmatter:', error);\n      return {};\n    }\n  }\n\n  // If no frontmatter is found, return null\n  return null;\n}\n\n// Function to remove YAML front matter from a string\nexport function removeFrontMatter(content) {\n    const yamlRegex = /^---\\n([\\s\\S]*?)\\n---/;\n    return content.replace(yamlRegex, '').trim();\n}\n\n```\n\n## file-watcher.js\n```js\n// Import required modules\nimport fs from 'fs/promises';\nimport chokidar from 'chokidar';\nimport indexFile from './index-file.js';\nimport { removeFile } from './database.js';\n\n// Watch the folder recursively for any changes\nexport default function watchFolder(folderPath = './notebooks'){\n  const watcher = chokidar.watch([`${folderPath}/**/*.md`], {\n      persistent: true,\n      ignored: /node_modules/,\n      ignoreInitial: false,\n      awaitWriteFinish: {\n      stabilityThreshold: 2000,\n      pollInterval: 100,\n    },\n  });\n\n  watcher.on('unlink', (path) => {\n    // Remove the file\n    const pathSegments = path.split(/[\\\\/]/); // Split by both forward and backslash to handle different OS\n    const fileName = pathSegments.slice(-1)[0];\n    const file_id = fileName.split('.')[0];\n\n    removeFile(file_id);\n\n  });\n\n\n  watcher.on('add', async (filePath) => {\n    try {\n      const fileContent = await fs.readFile(filePath, 'utf-8');\n      // Assuming indexFile can handle different types of files\n      indexFile(fileContent, filePath);\n      // Add your further processing logic here\n    } catch (error) {\n      console.error('Error reading file:', error);\n    }\n  });\n\n  // Event listener for file changes\n  watcher.on('change', async (filePath) => {\n  // Run the indexFile function on the changed file\n    try {\n      const fileContent = await fs.readFile(filePath, 'utf-8');\n      // Assuming indexFile can handle different types of files\n      indexFile(fileContent, filePath);\n      // Add your further processing logic here\n    } catch (error) {\n      console.error('Error reading file:', error);\n    }\n  });\n\n  console.log(`Watching folder: ${folderPath} for .json and .md files`);\n};\n\n```\n\n## index-file.js\n```js\n// Import necessary modules\nimport natural from 'natural';\nimport { upsertFileData } from './database.js';\n// Define the tokenizer\nconst tokenizer = new natural.WordTokenizer();\n\nfunction removeFrontMatter(content) {\n  try {\n    const yamlRegex = /^---\\n([\\s\\S]*?)\\n---/;\n    return content.replace(yamlRegex, '').trim();\n  } catch(e){\n    return content\n  }\n}\n\nfunction parseJSONFrontmatter(markdownContent) {\n  // Regular expression to match YAML or JSON frontmatter\n  const frontmatterRegex = /^---\\s*[\\r\\n]+([\\s\\S]*?)[\\r\\n]+---\\s*[\\r\\n]+/;\n\n  // Check if frontmatter exists in the markdown content\n  const match = markdownContent.match(frontmatterRegex);\n\n  if(match === null){\n    return {}\n  }\n\n  if (match && match[1]) {\n    // Extract the frontmatter string\n    const frontmatterString = match[1];\n\n    try {\n      // Parse the frontmatter string into a JavaScript object\n      const frontmatterObject = JSON.parse(frontmatterString);\n\n      return frontmatterObject;\n    } catch (error) {\n      console.error('Error parsing frontmatter:', error);\n      return {};\n    }\n  }\n\n  // If no frontmatter is found, return null\n  return null;\n}\n\n// Function to index a file\nexport default function indexFile(_fileContent, filePath) {\n  // Extract notebook name from filePath\n  const pathSegments = filePath.split(/[\\\\/]/); // Split by both forward and backslash to handle different OS\n  const fileName = pathSegments.slice(-1)[0];\n  const file_id = fileName.slice(0, fileName.lastIndexOf('.'));\n  const notebooksIndex = pathSegments.indexOf('notebooks');\n  const notebookName = pathSegments[notebooksIndex + 1]; // Notebook name is the segment after 'notebooks'\n\n\n  const fileContent = removeFrontMatter(_fileContent);\n  const metadata = parseJSONFrontmatter(_fileContent);\n  metadata.notebookName = notebookName; // Add the notebook name to metadata\n\n  // Tokenize the content of the file\n  const tokens = tokenizer.tokenize(fileContent);\n\n  // Calculate frequency of each token\n  const frequency = tokens.reduce((acc, token) => {\n    token = token.toLowerCase(); // Convert token to lowercase to ensure case-insensitivity\n    acc[token] = (acc[token] || 0) + 1;\n    return acc;\n  }, {});\n\n  // Sort tokens by frequency (ascending) and then select the least frequent words\n  const uniqueTokens = Object.entries(frequency)\n    .sort((a, b) => a[1] - b[1])\n    .filter(([token, freq]) => freq === 1)\n    .map(([token]) => token);\n\n  // Extract keywords (assuming unique words are keywords)\n  // Limit the number of keywords if needed\n  const keywords = uniqueTokens.slice(0, 10); // Adjust the number as needed\n\n  // Extract hashtags using the provided regex\n  const hashtagRegex = /(^|[^#\\w])#([a-zA-Z0-9\\-./]+)(?![^<>]*>)/g;\n  let match;\n  const hashtags = [];\n\n  while ((match = hashtagRegex.exec(fileContent)) !== null) {\n    hashtags.push(match[2]); // match[2] contains the hashtag text without the '#' symbol\n  }\n\n  upsertFileData(file_id, fileContent, keywords, hashtags, metadata, notebookName);\n\n  // Further processing can be done here such as saving the keywords and hashtags to a database or a file\n}\n\n```\n\n## routes.js\n\n```js\nimport path from 'path';\nimport { promises as fsPromises } from 'fs';\nimport watchFolder from './file-watcher.js';\nimport { searchFileData } from './database.js';\n\n\nwatchFolder();\nexport default function (app) {\n  // Define the 'get-file' route\n  // \n  \n  /*\n    \n    GET NOTEBOOK PAGE\n\n   */\n  app.post('/get-notebook-page', async (req, res) => {\n    try {\n      // Extract 'dtrm-id' and 'notebook' from the request body\n      const { dtrmId, notebook } = req.body;\n\n      // Construct the file path\n      const filePath = path.join(global.root_directory, 'notebooks', notebook, `${dtrmId}.md`);\n\n      // Read the file\n      const fileContent = await fsPromises.readFile(filePath, 'utf-8');\n\n      // Send the file content as the response\n      res.json({content:fileContent});\n    } catch (error) {\n      // If the file is not found, return a 404 message\n      if (error.code === 'ENOENT') {\n        res.send(`File not found`);\n      } else {\n        // Handle other errors\n        res.status(500).send('Internal Server Error');\n      }\n    }\n  });\n\n  /*\n    \n    SEARCH\n\n   */\n\n  app.post('/query-db', async (req, res) => {\n    try {\n      // Extract 'search-term' from the request body\n      const { searchTerm } = req.body;\n\n      // Validate the input\n      if (!searchTerm) {\n        return res.status(400).send('Search term is required.');\n      }\n\n      // Use the searchFileData function to query the database\n      const searchResults = await searchFileData(searchTerm);\n\n      // Send the search results as the response\n      res.send(searchResults);\n    } catch (error) {\n      // Log the error and send a 500 Internal Server Error response\n      console.error('Error querying the database:', error);\n      res.status(500).send('Internal Server Error');\n    }\n  });\n\n  /*\n    \n    Check if File Exists\n\n   */\n\n  app.post('/file-exists', async (req, res) => {\n    try {\n      // Extract 'fileId' and 'notebook' from the request body\n      const { fileId, notebook } = req.body;\n      \n      // Validate the input\n      if (!fileId || !notebook) {\n        return res.status(400).send('Both fileId and notebook are required.');\n      }\n\n      // Use the fileExists function to check if the file exists\n      const exists = await fileExists(fileId, notebook);\n      \n      // Send the existence status as the response\n      res.send({ exists });\n    } catch (error) {\n      // Log the error and send a 500 Internal Server Error response\n      console.error('Error checking file existence:', error);\n      res.status(500).send('Internal Server Error');\n    }\n  });\n\n  /*\n  \n    Save File\n  \n  */\n  app.post('/save-file', async (req, res) => {\n    try {\n      // Extract 'fileId', 'notebook', 'metadata', and 'content' from the request body\n      const { fileId, notebook, metadata, content } = req.body;\n      \n      // Validate the input\n      if (!fileId || !notebook || !metadata || !content) {\n        return res.status(400).send('FileId, notebook, metadata, and content are required.');\n      }\n\n      // Use the saveFile function to save the file\n      await saveFile(fileId, notebook, metadata, content);\n      \n      // Send a success message as the response\n      res.send(`File ${fileId} saved successfully in notebook ${notebook}.`);\n    } catch (error) {\n      // Log the error and send a 500 Internal Server Error response\n      console.error('Error saving file:', error);\n      res.status(500).send('Internal Server Error');\n    }\n  });\n\n\n}\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-17T19:58:08.891Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "file-system-layout",
      "content": "Home / hans-js\n\n\n\nhans-js \n- projects\n\t- projects-each-have-a-name-like-this\n\t- each project is an obsidian notebook\n\t- and a terminal window open to it -- \n\t- help in terminal opens up obsidian help, which is always open. Command to create a new entry, pipe man commands\n\t- a set of images are sent to the training server\n\t- each llm prompt looks for markdown in range of selection\n-  lists each file and status (last updated) in mongodb.\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-10-06T19:23:09.148Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "file-upload-component",
      "content": "```js\nclass FileUploadComponent extends HTMLElement {\n  connectedCallback() {\n    this.file_upload = document.createElement('input');\n    this.file_upload.setAttribute('type', 'file');\n    this.appendChild(this.file_upload)\n    this.file_upload.addEventListener('change', (e) => {\n      this.handleFileUpload(e)\n    })\n  }\n\n  handleFileUpload(e) {\n    const file = this.file_upload.files[0];\n    if (file) {\n      const reader = new FileReader();\n      reader.onload = (e) => {\n        const fileContent = e.target.result;\n        const fileType = file.type;\n        const fileName = file.name;\n        const fileObject = {\n          name: fileName,\n          type: fileType,\n          content: fileContent\n        };\n        this.dispatchEvent(\n          new CustomEvent('FILE-UPLOADED', { detail: fileObject })\n        );\n      };\n      reader.readAsText(file);\n    }\n  }\n\n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value) {\n    switch (name) {\n      default:\n    }\n  }\n}\n\ncustomElements.define('file-upload', FileUploadComponent)\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-07-23T15:16:07.439Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "firefox-plugin",
      "content": "From Google Bard:\n\nTo create a Firefox plugin that runs a Node.js server, you can use the following steps:\n\n1. Create a new directory for your plugin.\n2. In the directory, create a file called `manifest.json`.\n3. In the `manifest.json` file, add the following properties:\n\n```\n{\n  \"name\": \"My Firefox Plugin\",\n  \"version\": \"1.0\",\n  \"description\": \"A Firefox plugin that runs a Node.js server.\",\n  \"content_scripts\": [\n    {\n      \"matches\": [\"*://*/*\"],\n      \"js\": [\"contentscript.js\"]\n    }\n  ],\n  \"permissions\": [\"tabs\", \"contextMenus\"]\n}\n```\n\n1. Create a file called `contentscript.js`.\n2. In the `contentscript.js` file, add the following code:\n\n```javascript\nvar http = require(\"http\");\n\nvar server = http.createServer(function(req, res) {\n  res.writeHead(200, {\"Content-Type\": \"text/plain\"});\n  res.end(\"Hello, world!\");\n});\n\nserver.listen(3000, function() {\n  console.log(\"Server listening on port 3000\");\n});\n```\n\n1. Restart Firefox.\n2. In Firefox, open the menu bar and select \"Add-ons\" > \"Extensions\".\n3. Click the \"+\" button and select \"Install Add-on from File\".\n4. Select the directory where you created your plugin.\n5. Click \"Open\".\n6. Your plugin should now be installed and enabled.\n\nTo test your plugin, open a web page in Firefox and right-click on it. Select \"Add-ons\" > \"My Firefox Plugin\". You should see a new menu item called \"Run Node.js Server\". Click this menu item to start a Node.js server on port 3000. You can now access the server at `http://localhost:3000`.\n\n---\n\n\n\nhttps://support.mozilla.org/en-US/questions/1292666\n\n```\nHi Kevin, I think this is not fully debugged and that's why it isn't in the MDN article yet, but if you want to experiment:\n\n**(A) Enable the \"Single Site Browser\" feature in Firefox**\n\n(1) In a new tab, type or paste **about:config** in the address bar and press Enter/Return. Click the button accepting the risk.\n\n(2) In the search box in the page, type or paste **ssb** and pause while the list is filtered\n\n(3) Double-click the **browser.ssb.enabled** preference to switch the value from false to true\n\n**(B) Launch the URL with the -ssb switch**\n\nFor example:\n\n\"C:\\Program Files\\Mozilla Firefox\\firefox.exe\" **-ssb** https://www.mozilla_._org/\n\nIs that roughly what you're looking for?\n\n[](https://support.mozilla.org/en-US/user/jscher2000/)\n\n\n```\n\nopen firefox without window chrome. \n\n\nwrite an outline how I might write a custom firefox plugin in JavaScript. \n\nHere is an outline for creating a custom Firefox plugin using JavaScript:\n\n\n1. Identify a problem that the plugin will solve: \n\nStart by thinking of a problem that you or others face while using Firefox. It could be a repetitive task, a limitation in the browser's functionality, or a need for customization.\n\n\n2. Research existing plugins: \n\nSearch for plugins that address the problem you identified in step 1. Analyze their features, ratings, and reviews to understand their strengths and weaknesses. This will help you design a plugin that offers unique value.\n\n\n3. Plan the plugin's functionality:\n\nBased on your research, come up with a plan for the features and functionality of the plugin. Think about how the plugin will improve on the existing solutions and enhance the user experience. \n\n\n4. Design the user interface:\n\nCreate a mockup or wireframe of the user interface of the plugin. Consider the layout, buttons, menus, and forms. Make sure the UI is intuitive, user-friendly, and visually appealing.\n\n\nTools: Figma, Sketch, Adobe XD.\n\n\n5. Write the code:\n\nStart coding the plugin in JavaScript. Use the Mozilla Developer Network as a resource for the Firefox Add-on SDK and other libraries. Ensure that the code adheres to the best practices of JavaScript development, such as modularity, error handling, and optimization.\n\n\nTools: Visual Studio Code, Sublime Text, Brackets.\n\n\n6. Test the plugin:\n\nTest the plugin thoroughly to ensure that it works as expected and does not break other Firefox features. Write test cases and use debugging tools to identify and fix bugs.\n\n\nTools: Firefox Developer Edition, Selenium, Cypress.\n\n\n7. Publish the plugin:\n\nSubmit the plugin to the Firefox Add-ons marketplace after testing and polishing it. Optimize the metadata, icon, and description to attract users and increase the ratings and visibility of the plugin.\n\n\nTools: Mozilla Add-ons Developer Hub.\n\n\nRemember that creating a custom Firefox plugin using JavaScript requires a lot of creativity, technical knowledge, and testing. Follow this outline as a guide, but be ready to adapt and iterate as you go through the development process. Good luck!\n\n---\n\nexplain to me how to setup sublime text 3, node.js and terminal up for generating a firefox plugin\n\nSetting Up a Development Environment for Generating a Firefox Plugin using Sublime Text 3, Node.js, and Terminal\n\n\nTo set up a development environment for generating a Firefox plugin using Sublime Text 3, Node.js, and Terminal, follow the instructions below:\n\n\nSublime Text 3\n\n\n1. Download and install Sublime Text 3 by visiting the official website https://www.sublimetext.com/3.\n\n\n2. Open Sublime Text 3.\n\n\n3. Click on the \"Tools\" menu and select \"Install Package Control.\" This will allow you to install the necessary packages and plugins for plugin development.\n\n\n4. Install the following packages and plugins: \n\n\n  - JavaScript Completions\n\n  - JavaScript & NodeJS Snippets\n\n  - Nodejs\n\n\nTo install a package or plugin, use the following steps:\n\n\n  i. Open the command palette by pressing \"cmd+shift+p\" on macOS or \"ctrl+shift+p\" on Windows/Linux.\n\n  ii. Type \"Package Control: Install Package\" and press enter.\n\n  iii. Type the name of the package or plugin and press enter.\n\n\n5. Once you have installed all the packages and plugins, you are now ready to start developing your Firefox plugin.\n\n\nNode.js\n\n\n1. Download and install Node.js by visiting the official website https://nodejs.org/en/download/.\n\n\n2. Open the Terminal application.\n\n\n3. Run the following command to check if Node.js is installed:\n\n\n    node -v\n\n\n4. If Node.js is installed, the version number will be displayed. If it is not installed, follow the instructions on the Node.js website to install it.\n\n\n5. Once Node.js is installed, you can install any necessary packages or dependencies using npm (Node Package Manager). To install a package, run the following command:\n\n\n    npm install [package-name]\n\n\nFirefox Plugin Generation\n\n\n1. Navigate to the directory where you want to create your Firefox plugin.\n\n\n2. Run the following commands to create a new Firefox plugin:\n\n\n    mkdir my-addon\n\n    cd my-addon\n\n    jpm init\n\n\n3. This will create a basic plugin structure for you.\n\n\n4. You can now start adding code to your plugin by editing the files in the \"lib\" directory.\n\n\n5. To test your plugin, run the following command:\n\n\n    jpm run\n\n\n6. This will launch Firefox with your plugin installed.\n\n\nBest Practices\n\n\n- Make sure to keep your code organized and commented to make it easier to understand and maintain.\n\n- Follow Mozilla's Add-on Development Guide (https://developer.mozilla.org/en-US/Add-ons) for best practices and guidelines.\n\n- Test your plugin on multiple versions of Firefox to ensure compatibility.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-20T22:53:23.638Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "force-graph-component",
      "content": "```js\nimport \"//unpkg.com/3d-force-graph\";\nimport { CSS2DRenderer, CSS2DObject } from '//unpkg.com/three/examples/jsm/renderers/CSS2DRenderer.js';\n\n\n\nclass ForceGraphComponent extends HTMLElement {\n  connectedCallback(){\n\n    this.src = this.getAttribute('src');\n    if(this.src === null){\n      this.innerText = 'Cannot load JSON';\n      return\n    }\n\n    this.width = this.getAttribute('width');\n    if(this.width === null){\n      this.width = 400;\n    }\n\n    this.height = this.getAttribute('height');\n    if(this.height === null){\n      this.height = 400; \n    }\n\n    const style = window.getComputedStyle(this, null);\n\n    this.backgroundColor = style.backgroundColor; \n    this.foregroundColor = style.color;\n\n    this.init();\n\n  }\n\n  async init(){\n    const Graph = ForceGraph3D({ controlType: 'orbit',  extraRenderers: [new CSS2DRenderer()] })\n    (this)\n      .width(this.width)\n      .height(this.height)\n      .backgroundColor(this.backgroundColor)\n      .linkColor('pink')\n      .linkOpacity(1)\n      .linkDirectionalParticles(10)\n      .linkWidth(0)\n      .jsonUrl(this.src)\n      .nodeAutoColorBy('group')\n      .nodeThreeObject(node => {\n        const nodeEl = document.createElement('div');\n        nodeEl.textContent = node.id;\n        nodeEl.style.color =  this.foregroundColor;\n        nodeEl.className = 'node-label';\n        return new CSS2DObject(nodeEl);\n      })\n      .nodeThreeObjectExtend(true)\n      .zoomToFit(10,10, node => true)\n      .onNodeClick((node, event) => {\n        console.log(node)\n      })\n\n\n  }\n\n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n    switch(name){\n      default:\n    }\n  }\n}\n\ncustomElements.define('force-graph-component', ForceGraphComponent)\n```\n\nUse like: \n\n```html\n\n          <force-graph-component width=\"800\" src=\"./assets/skills.json\" class=\"screen-only\">\n          </force-graph-component>\n\n\n```\n\n\n\nCode to grab html elements: \n\n```js\n    const markup_nodes = [...this.querySelectorAll('graph-node')].map(node => {\n      return {id: node.id}\n    });\n    const markup_links = [...this.querySelectorAll('graph-link')].map(link => {\n      return {\n        source: link.getAttribute('source'),\n        target: link.getAttribute('target')\n      }\n    });\n\n    graph_data.nodes = Object.assign(graph_data.nodes, markup_nodes);\n    graph_data.links = Object.assign(graph_data.links, markup_links);\n\n```\n\n\nCollapsable nodes:\n```js\n    const rootId = 0;\n\n    // Random tree\n    const N = 300;\n    const gData = {\n      nodes: [...Array(N).keys()].map(i => ({ id: i, collapsed: i !== rootId, childLinks: [] })),\n      links: [...Array(N).keys()]\n        .filter(id => id)\n        .map(id => ({\n          source: Math.round(Math.random() * (id - 1)),\n          target: id\n        }))\n    };\n\n    // link parent/children\n    const nodesById = Object.fromEntries(gData.nodes.map(node => [node.id, node]));\n    gData.links.forEach(link => {\n      nodesById[link.source].childLinks.push(link);\n    });\n\n    const getPrunedTree = () => {\n      const visibleNodes = [];\n      const visibleLinks = [];\n\n      (function traverseTree(node = nodesById[rootId]) {\n        visibleNodes.push(node);\n        if (node.collapsed) return;\n        visibleLinks.push(...node.childLinks);\n        node.childLinks\n          .map(link => ((typeof link.target) === 'object') ? link.target : nodesById[link.target]) // get child node\n          .forEach(traverseTree);\n      })(); // IIFE\n\n      return { nodes: visibleNodes, links: visibleLinks };\n    };\n\n    const elem = document.getElementById('graph');\n    const Graph = ForceGraph()(elem)\n      .graphData(getPrunedTree())\n      .onNodeHover(node => elem.style.cursor = node && node.childLinks.length ? 'pointer' : null)\n      .onNodeClick(node => {\n        if (node.childLinks.length) {\n          node.collapsed = !node.collapsed; // toggle collapse state\n          Graph.graphData(getPrunedTree());\n        }\n      })\n      .linkDirectionalParticles(1)\n      .linkDirectionalParticleWidth(2.5)\n      .nodeColor(node => !node.childLinks.length ? 'green' : node.collapsed ? 'red' : 'yellow');\n\n\n\n```\n"
    },
    {
      "date-created": "Tue Dec 12 2023 11:17:16 GMT-0800 (Pacific Standard Time)",
      "file-id": "generate-new-component",
      "last-updated": "2023-12-12T21:55:10.906Z",
      "lastIndexed": "never",
      "lastUpdated": "2023-12-13T16:44:22.913Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "generate-new-component",
      "content": "<generate-new-component \n  id=\"4334762d-3197-4aa3-a170-4fa971d39865\"\n>\n</generate-new-component>\n\n\n```js\n\n    const file_exists = await fetch(`/file-exists?&file-id=${this.id}`).then(res => res.json());\n\n    if(file_exists){\n      this.innerHTML = `<mark-down src=\"/${this.id}.md\"></mark-down>`;\n      return\n    }\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.514Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "generate-plugin",
      "content": "Assuming express.js with es6 imports. \n\nthe Generate plugin endpoint creates a new plugin with a specific name and purpose. \n\nThe front end will post to the endpoint with the body of: \n\n```json\n{\"plugin-name\":\"Plugin Name here\", \n\"plugin-prompt\":\"Plugin Prompt here\"\n}\n\n```\n\nA plugin can have several files. Your job is to generate the appropriate files. \n\nPlugin name should be converted into a dash-case name for the plugin. \n\nThe script should create a folder in the folder located at\n\n```js\nglobal.root_directory + '/plugins'\n```\n\nif it is appropriate for the plugin to have a route is should generate a file called route.js that looks something like: \n\n```js\nimport pluginFunction from './{plugin-name}.js';\n\nexport default function (app) {\n  app.post('/plugin-endpoint-name', async function(req, res){\n    const new_data = await pluginFunction(req.body);\n    res.json(new_data);\n  });\n}\n\n```\n\nif it appropriate to have a front end element for this plugin, we use custom HTML elements. Our custom HTML elements extend a class called DataroomElement. The code for the Dataroom Element class looks something like: \n\n```js\nexport class DataroomElement extends HTMLElement {\n  connectedCallback(){\n    this.initialize();\n  }\n\n  async initialize(){\n    // override this class to run initialization code here\n  }\n\n  disconnectedCallback(){\n    this.disconnect();\n  }\n\n  async disconnect(){\n    // override this function to run disconnect code\n  }\n}\n\n```\n\n"
    },
    {
      "file-id": "geo-map",
      "file-created": "2023-12-12T20:01:30.223Z",
      "last-updated": "2023-12-12T21:32:01.963Z",
      "lastIndexed": "never",
      "lastUpdated": "2024-02-07T13:27:42.380Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "geo-map",
      "content": "\n\n<geo-map id=5a9d55fc-dbaa-4e83-a7c1-9a16028f07a8\n  id=\"geo_map\"\n  accesstoken=pk.eyJ1IjoibG5zeWFzdGVyaXVzIiwiYSI6ImNsNXp0bG1zZTFnOWszYnF2Nm1jbjdxamUifQ.NBU_Y2rMUWOKon2Z2WY7MQ\n  styleurl=mapbox://styles/lnsyasterius/clnkp8o2o002c01qwaqxp6rvl\n  latitude= 33.86716840617632\n  longitude=-118.12701323464881\n  zoom=3\n  bearing=0\n  pitch=45\n  navigation\n  geolocate\n  geocoder=true\n>\n<geo-json src=\"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.geojson\" variable=\"mag\"></geo-json>\n\n</geo-map>\n\n\n\n\n\n#mapping \n\n[[gardening-index]]\n\nRewrite notes.\n\ngeo-map-component is a wrapper for MapLibre GL that gives you a simple HTML element to interact with maps. \n\n```html\n\n<body lang=\"en\">\n\n<link rel=\"stylesheet\" href=\"https://use.typekit.net/zep2ala.css\">\n\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<script type=\"module\" src=\"https://lindseyjohnasterius.github.io/markdown-component/markdown-component.js\"></script>\n\n<script src=\"index.js\" type=\"module\"></script>\n<link rel=\"stylesheet\" type=\"text/css\" href=\"geo-map-component.css\">\n\n<style>\n\n\n  :root {\n  --geo-map-background-color: transparent;\n  --geo-map-foreground-color: rgba(0,0,0,0.8);\n  --geo-map-border-color: #2d2d2d;\n  --geo-map-secondary-background-color: rgba(0,0,0,0.5);\n  --geo-map-secondary-foreground-color: #ffffff;\n  --column-footer-height: 1em;\n  --column-footer-offset: 1em;\n  --column-header-size: 1em;\n  --column-text-color: black;\n  --column-background-color: transparent;\n}\n\n\n  h1 {\n    font-family: \"macula-line\", sans-serif;\nfont-weight: 400;\nfont-style: normal;\n  }\n\n  geo-map-modal {\n    border-radius: 1em;\n  }\n\n  geo-map-modal main {\n    padding: 1em;\n    background-color: rgba(255,255,255,0.5);\n  }\n\n\n</style>\n\n<div id=\"loading_div\" style=\"position:fixed;left:50%;top:50%;transform:translate(-50%, -50%);\">Loading</div>\n\n<geo-map id=\"geo_map\"\n  id=\"geo_map\"\n  accesstoken=pk.eyJ1IjoibG5zeWFzdGVyaXVzIiwiYSI6ImNsNXp0bG1zZTFnOWszYnF2Nm1jbjdxamUifQ.NBU_Y2rMUWOKon2Z2WY7MQ\n  styleurl=mapbox://styles/lnsyasterius/clhz6wjgs00uj01rhe3fdbl9q\n  latitude= 33.86716840617632\n  longitude=-118.12701323464881\n  zoom=9\n  bearing=0\n  navigation-control=true\n  geolocate=true\n  geocoder=true\n  share=true\n  search-bounds=\"-118.48176410291592, 33.66337686568919, -117.58037748630301, 34.41894361494393\"\n>\n\n  <geo-json src=\"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_hour.geojson\n\" variable=\"mag\"></geo-json>\n\n  <geo-map-column side=\"left\">\n    \n  </geo-map-column>\n\n  <script src=\"app.js\" type=\"module\"></script>\n\n</geo-map>\n\n\n</body>\n\n```\n\n---\n\nThoughts on refactor of Geo-Map-Component\n\nnear, mid and far could be rewritten, maybe with classes where the particular div is \n\n"
    },
    {
      "file-id": "git-submodules",
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.514Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "git-submodules",
      "content": "\nFrom: \nhttps://git-scm.com/book/en/v2/Git-Tools-Submodules\n\nAdding a submodule \n\n```sh\ngit submodule add ${submodule repo}\ngit status\ngit push origin main\n\n```\n\nCloning a project with submodules\n\n```sh\ngit clone ${main-repo}\ngit submodule init\ngit submodule update --recursive\n\n```\n\nPulling Upstream changes\n\n```\ngit pull\ngit submodule foreach git pull origin master\n```\n\nRemove a Submodule\n\n- Remove it from the .git configuration files:\n```sh\ngit rm the_submodule\n```\n- Remove it from the modules folder. You can also do this from a UI file explorer of some type:\n```sh\nrm -rf .git/modules/the_submodule\n```\nYou may also need to remove the subfolder in your repository.\n\n\n\n\n```llm-prompt\n---\n{\"file-id\":\"git-submodule-endpoint.prompt\"}\n---\n\nAsssuming node.js with ES5 modules\nWrite an endpoint called \"update-dataroom\" that updates all submodules in a directory\n\n```\n\n## Further Reading\nhttps://www.sitepoint.com/git-submodules-introduction/\n\nhttps://stackoverflow.com/questions/5007161/can-you-develop-directly-in-git-submodules\n\nhttps://gist.github.com/gitaarik/8735255\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-07-01T20:47:58.070Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "hans query",
      "content": "I have a framework called hans-js. It is written in node.js and javascript, and optimized to work in firefox browser. \n\nWhen I create a new component it auto generates several files based on the following templates: \n\nA file in Aframe.js:\n```html\n<a-entity class=\"${component-id}-aframe ${component-id}\">\n  <a-entity text=\"value: ${ComponentName}\" id=\"${component-id}-label\"></a-entity>\n</a-entity>\n```\n\nA CSS file: \n```css\n${component-id} {\n  display:block;\n}\n\n```\nAn HTML File:\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  <script src=\"../index.js\" type=\"module\"></script>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"../index.css\">\n  <title>${ComponentName}</title>\n</head>\n<body>\n  <mark-down src=\"./${component-id}.md\"></mark-down>\n</body>\n</html>\n```\n\nA Javascript file that creates a custom html component from the component's id, meant to be run on the browser: \n```js\n/*\n  ${ComponentName}\n\n  <${component-id}></${component-id}>\n\n  See https://javascript.info/custom-elements for more information\n*/\n\nclass ${ComponentName} extends HTMLElement {\n  constructor() {\n    super();\n    // element created\n  }\n\n  connectedCallback(){\n    // browser calls this method when the element is added to the document\n    // (can be called many times if an element is repeatedly added/removed)\n    this.innerHTML = `${ComponentName} initialized`;\n    this.fetchData();\n  }\n\n  async fetchData(post = {}){\n    const response = await fetch(\"/${component-id}\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify(post)\n    });\n    const data = response.json();\n    return data;\n  }\n\n  disconnectedCallback() {\n    // browser calls this method when the element is removed from the document\n    // (can be called many times if an element is repeatedly added/removed)\n  }\n\n  adoptedCallback() {\n    // called when the element is moved to a new document\n    // (happens in document.adoptNode, very rarely used)\n  }\n\n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n    switch(name){\n      default:\n    }\n  }\n}\n\ncustomElements.define('${component-id}', ${ComponentName});\n```\n\nA markdown file that looks like: \n```md\n# ${ComponentName}\n\n<${component-id}></${component-id}>\n\nUse:\n\n\\```html\n\t<${component-id}></${component-id}>\n\\```\n\n```\n\nA Json File that looks like:\n```JSON\n{\n  \"name\":\"${ComponentName}\",\n  \"id\":\"${component-id}\"\n}\n\n```\n\nand a route that hooks up to an Express.js app that looks like: \n```js\n/*\n\n  ${ComponentName} Server Code\n\n  To create an end point, open up hans-js and add... blah\n\n  @todo: write tutorial \n\n\n*/\n\nconst metadata = require('./metadata.json');\n\nasync function ${ComponentName}(){\n  return metadata\n}\n\nmodule.exports = function(app) {\n  app.post('/${component-id}', async function(req, res) {\n    const request_data = req.body;\n    const data = await ${ComponentName}();\n    res.json(data);\n  });\n};\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-22T16:13:46.782Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "hans-js-pitch",
      "content": "AI assistant for Crypto Currency, computer security, legal, medical and psychological information,  note taking, sensitive data muxing, always on listening device, romance novels.  \n\n\"There is no moat\" -- open source is moving faster than the companies\n\nMostly offline device -- how do we make a device \"safe\" -- parts of it can hook up to the network -- perhaps only through SSH? \n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-17T18:35:47.955Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "hans-js-project-switcher",
      "content": "switches:\n\nwhich obsidian notebook is open\nwhich files are in the html -- files labeled to publish are included in project folder, with markdown components.\n\nThese folders are watched. \n\n[[Atom text editor]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:51.114Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "hans-js-project-workflow",
      "content": "# project workflow\n\n[[create-new-project]]\n[[delete-project]]\n[[save-project]]\n[[auto-reload]]\n\n[[programming/file-clerk]]\n\n[[notification-workflow wss]]\n\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-28T15:19:52.541Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "hans-js-starter-prompt",
      "content": "\nI have a framework called hans-js. It is written in node.js and javascript, and optimized to work in firefox browser. \n\nWhen I create a new component it auto generates several files based on the following templates: \n\nA file in Aframe.js:\n```html\n<a-entity class=\"${component-id}-aframe ${component-id}\">\n  <a-entity text=\"value: ${ComponentName}\" id=\"${component-id}-label\"></a-entity>\n</a-entity>\n```\n\nA CSS file: \n```css\n${component-id} {\n  display:block;\n}\n\n```\nAn HTML File:\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  <script src=\"../index.js\" type=\"module\"></script>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"../index.css\">\n  <title>${ComponentName}</title>\n</head>\n<body>\n  <mark-down src=\"./${component-id}.md\"></mark-down>\n</body>\n</html>\n```\n\nA Javascript file that creates a custom html component from the component's id, meant to be run on the browser: \n```js\n/*\n  ${ComponentName}\n\n  <${component-id}></${component-id}>\n\n  See https://javascript.info/custom-elements for more information\n*/\n\nclass ${ComponentName} extends HTMLElement {\n  constructor() {\n    super();\n    // element created\n  }\n\n  connectedCallback(){\n    // browser calls this method when the element is added to the document\n    // (can be called many times if an element is repeatedly added/removed)\n    this.innerHTML = `${ComponentName} initialized`;\n    this.initUpdatesDiv();\n    this.startDataStream(\"${ComponentName}\", \"${component-id}\");\n  }\n\n  initUpdatesDiv() {\n    this.updates = document.createElement('details');\n    this.appendChild(this.updates);\n  }\n\n  async startDataStream(argument_1, argument_2) {\n    const response = await fetch(\"/${component-id}\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify({arguments:[argument_1, argument_2]})\n    });\n\n    const reader = response.body.getReader();\n    let result;\n    \n    while (!(result = await reader.read()).done) {\n      const chunk = new TextDecoder(\"utf-8\").decode(result.value);\n      this.updateUI(chunk);\n    }\n  }\n\n  updateUI(data) {\n    this.updates.innerText += data;\n  }\n\n  disconnectedCallback() {\n    // browser calls this method when the element is removed from the document\n    // (can be called many times if an element is repeatedly added/removed)\n  }\n\n  adoptedCallback() {\n    // called when the element is moved to a new document\n    // (happens in document.adoptNode, very rarely used)\n  }\n\n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n    switch(name){\n      default:\n    }\n  }\n}\n\ncustomElements.define('${component-id}', ${ComponentName});\n\n```\n\nA markdown file that looks like: \n```md\n# ${ComponentName}\n\n<${component-id}></${component-id}>\n\nUse:\n\n\\```html\n\t<${component-id}></${component-id}>\n\\```\n\n```\n\nA Json File that looks like:\n```JSON\n{\n  \"name\":\"${ComponentName}\",\n  \"id\":\"${component-id}\"\n}\n\n```\n\nand a route that hooks up to an Express.js app that looks like: \n```js\n/*\n\n  ${ComponentName} Server Code\n\n  To create an end point, open up hans-js and add... blah\n\n  @todo: write tutorial \n\n\n*/\n\n\nconst { spawn } = require('child_process');\nconst metadata = require('./metadata.json');\n\nmodule.exports = function(app) {\n  app.post('/${component-id}', async function(req, res) {\n    const request_data = req.body;\n    console.log(request_data.arguments);\n    try {\n      const pythonProcess = spawn('python3', ['./components/${component-id}/${component-id}.py',request_data.arguments[0], request_data.arguments[1]]);\n      pythonProcess.stdout.on('data', (data) => {\n        // Send the data as a stream to the browser\n        res.write(data);\n      });\n\n      pythonProcess.stderr.on('data', (data) => {\n        // Handle any error output from the Python process\n        console.error(`Python error: ${data}`);\n        res.write(data);\n\n      });\n\n      pythonProcess.on('close', (code) => {\n        // Signal the end of the stream and close the response\n        res.end();\n      });\n    } catch(err){\n      res.write(err);\n      res.end();\n    }\n\n  });\n};\n\n```\n\nA python file that looks like:\n\n```python\nimport sys\nimport json\n\n# Check if the correct number of arguments are provided\nif len(sys.argv) != 3:\n    print(\"Please provide two arguments.\")\n    sys.exit(1)\n\n# Extract the arguments\narg1 = sys.argv[1]\narg2 = sys.argv[2]\n\n# Create a dictionary with the arguments\nresult = {\n    \"${ComponentName}\": arg1,\n    \"${component-id}\": arg2\n}\n\n# Convert the dictionary to a JSON object\njson_result = json.dumps(result)\n\n# Print the JSON object\nprint(json_result)\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-04T07:03:53.613Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "hans-js",
      "content": "\nclick here to copy password\n\n[[hans-js-secret-password-copy]]\n\n\n\n\n# Overview\n\nHans JS is your personal knowledge assistant. Working with conjunction with obsidian notes.\n\n[[device-0-overview]]\n\nquery -- loads each index into single query, ignores all text tagged with ai code output\n\n>how to open firefox from terminal with debug open on ubuntu?\n\n\nTo open Firefox in debug mode on Ubuntu, follow these steps:\n\n\n1. Open the terminal by pressing Ctrl+Alt+T.\n\n2. Enter the following command: ``` firefox -console -foreground ```\n\n\nThe `-console` flag specifies that Firefox's debug output will be printed to the console, while the `-foreground` flag ensures that Firefox will be brought to the foreground when it opens. \n\n\nDebug mode allows you to troubleshoot problems with Firefox and its components by providing detailed error messages and other diagnostic information. It can be especially helpful for identifying and fixing issues related to add-ons or website compatibility. The benefits of using debug mode for debugging and troubleshooting include faster problem resolution and an increased understanding of the internal workings of Firefox.\n\n\n\n\n\nlink to external computers\n\nqr code hooks up to dataroom with UUID. Serves webpage and shares code. \n\nthis code also works with external servers -- uploads this data set ready for ai\n\nproject folder, obsidian opens up\n\nprompt builder is a notebook, generated mostly by the user, uses indices ala -- [[johnny-decimal]]\n\nI want this cluster of prompts for this problem\n\n```yaml\npublish_to:['project-name', 'project-name', 'project-name']\n```\n\n> assuming node.js, write a script that watches a folder of markdown files recursively. When one is changed it trys to parse yaml. If yaml parses, it goes on to run other commands with the file data\n> \n> \n> ai\n\nHere's an example Node.js script that meets the requirements:\n\n\n```javascript\n\nconst fs = require('fs');\nconst path = require('path');\nconst yaml = require('js-yaml');\nconst watchPath = './md-files'; // Folder to watch\n\nlet watchedFiles = new Set(); // Set to keep track of watched files\n\nconst parseYaml = (markdown) => {\n\n  // Parses YAML front-matter from markdown string\n\n  const match = /^\\s*---\\n([\\s\\S]*?)\\n?---\\n?([\\s\\S]*)$/.exec(markdown);\n\n  try {\n    return [\n      match[1] ? yaml.load(match[1]) : {}, // Parsed YAML object\n      match[2] // Markdown content\n    ];\n  } catch (e) {\n    console.error(`Failed to parse YAML:\\n${e}`);\n\n    return [null, markdown];\n  }\n};\n\n\nconst processFile = (filepath) => {\n\n  // Reads file content and calls processing function if YAML can be parsed\n\n  fs.readFile(filepath, 'utf8', (err, markdown) => {\n\n    if (err) {\n\n      console.error(`Failed to read file: ${filepath}\\n${err}`);\n\n      return;\n\n    }\n\n    const [yamlData, content] = parseYaml(markdown);\n\n    if (yamlData) {\n\n      // Replace this with your own processing function(s)\n\n      console.log(`Parsed YAML from ${filepath}\\nData:\\n${JSON.stringify(yamlData, null, 2)}\\nContent:\\n${content}`);\n\n    }\n\n  });\n\n};\n\n\nconst watchFiles = (dir) => {\n\n  // Watches directory for changes to markdown files\n\n  fs.readdir(dir, (err, files) => {\n\n    if (err) {\n\n     \n``` console.error(`Failed to read directory: ${dir}\\n${err}`);\n\n      return;\n\n    }\n    files.forEach((file) => {\n      const filepath = path.join(dir, file);\n) || !file.endsWith('.md')) {\n\n        return;\n\n      }\n\n      watchedFiles.add(filepath);\n\n      fs.watch(filepath, (event) => {\n\n        if (event === 'change') {\n\n          processFile(filepath);\n\n        }\n\n      });\n\n      processFile(filepath);\n\n    });\n\n  });\n\n};\n\n\nwatchFiles(watchPath);\n\n```\n\n\nThis script uses the `fs` and `path` modules built into Node.js to watch the specified folder for changes, read file contents, and manipulate file paths. It also uses the `js-yaml` library for parsing YAML front-matter.\n\n\nTo run this script, save the code to a file (e.g. `watch-md-files.js`) and run `node watch-md-files.js` from the command line in the same directory. You may need to run `npm install js-yaml` first to install the `js-yaml` library.\n\n\nTo modify the YAML parsing, you can edit the `parseYaml()` function to change the regular expression used to match the front-matter and the parsing of the resulting string. You could also replace the `js-yaml` library with another YAML parsing library if you prefer.\n\n\nTo modify the command execution functionality, you can replace the `console.log()` call in the `processFile()` function with your own custom processing function(s), which can use the parsed YAML data and markdown content to perform whatever actions you need.\n\n\nTo ensure efficiency and performance, this script uses a `Set` to keep track of watched files and avoids unnecessarily re-watching files that have already been processed. It also only processes files with a `.md` extension to avoid reading and parsing irrelevant files.\n\n      if (watchedFiles.has(filepath\n\n\n\n\n\nexternal device -- when a cell phone is scanned, it can become a listening device that is hooked up to whisper. The transcript is sent directly back to the project file that is open. \n\nif no project file is open, write to index\n\n"
    },
    {
      "date-created": "Tue Dec 12 2023 05:15:40 GMT-0800 (Pacific Standard Time)",
      "file-id": "help",
      "last-updated": "2023-12-12T18:30:46.564Z",
      "lastIndexed": "never",
      "lastUpdated": "2023-12-13T16:44:22.914Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "help",
      "content": "# DATAROOM EDITOR\n\nDataroom is a new way to interact with the internet. One that you control. It is extensible and entirely open source. It runs on a host computer, and provides a client you can access with various devices. \n\n## Editor\n\nThere is an arrow at the upper left of the editing window. If you click on it you will find a JSON editor. DATAROOM generates markdown with JSON flavored front matter. You can edit this front matter.\n\nThere are three buttons at the top of the JSON editor: save, download and load. \n\nSave saves the file at the target of file-id. \n\nDownload allows you to download the markdown file manually.\n\nLoad gives you a file window to load a markdown file. Keep in mind if this markdown file exists outside of \n\n\n## Key Commands\n\n*Ctrl-S* - In #lnsy-edit Save the current file and render.\n*Ctrl-P* - Open up the #control-panel\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-16T18:27:23.152Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "helpers",
      "content": "```js\nfunction getNewID() {\n  return 'dtrm-xxxxxxxxxxxxxxxx-xxxxxxxxxxxxxxxx-'\n    .replace(/[xy]/g, function(c) {\n      var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);\n      return v.toString(16)\n    }) + Date.now()\n}\n\n\nmodule.exports = {\n  getNewID,\n}\n\n```\n\n```js\n/*\n  *** BEGIN ASCII ART ***\n        ___       __   ___  __   __\n  |__| |__  |    |__) |__  |__) /__`\n  |  | |___ |___ |    |___ |  \\ .__/\n\n  *** END ASCII ART ***\n\n  \"Look for the Helpers\" -- Mr. Rogers\n\n*/\n\n//random gnar char generator\nfunction getNewID() {\n  return 'dtrm-xxxxxxxxxxxxxxxx-'\n    .replace(/[xy]/g, function(c) {\n      var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);\n      return v.toString(16)\n  }) + Date.now()\n}\n\nfunction getValuesFromURL(URL = window.location.href ){\n  const search_params = new URLSearchParams(URL)\n  let options = {\n  }\n  for (const [key, unparsed_value] of search_params) {\n    if(key !== window.location.origin + window.location.pathname + '?' ){\n      try {\n        const value = JSON.parse(decodeURI(unparsed_value))\n        options[key] = value\n      } catch {\n        options[key] = decodeURI(unparsed_value)\n      }\n    }\n  }\n  return options\n}\n\nfunction getAndClearCookie(cname) {\n  let name = cname + \"=\"\n  let decodedCookie = decodeURIComponent(document.cookie)\n  let ca = decodedCookie.split(';')\n  for(let i = 0; i <ca.length; i++) {\n    let c = ca[i]\n    while (c.charAt(0) == ' ') {\n      c = c.substring(1)\n    }\n    if (c.indexOf(name) == 0) {\n      return c.substring(name.length, c.length)\n    }\n  }\n  document.cookie = cname + \"=; expires=Thu, 01 Jan 1970 00:00:00 UTC; path=/;\"\n\n  return \"\"\n}\n\n/*\n\nFor Express.js setting a cookie looks something like this:\n\napp.get('/',(req,res) => { \n  res.cookie('chaka', JSON.stringify({\n    GITHUB_KEY: process.env.GITHUB_PERSONAL_TOKEN,\n    GITHUB_USERNAME: process.env.GITHUB_USER_NAME\n  }));\n\n  res.sendFile(`${__dirname}/blah.html`)\n})\n\n*/\n\n\n/*\n\n  *** begin ascii art ***\n\n    8888b.  88 .dP\"Y8 88\"\"Yb    db    888888  dP\"\"b8 88  88\n     8I  Yb 88 `Ybo.\" 88__dP   dPYb     88   dP   `\" 88  88\n     8I  dY 88 o.`Y8b 88\"\"\"   dP__Yb    88   Yb      888888\n    8888Y\"  88 8bodP' 88     dP\"\"\"\"Yb   88    YboodP 88  88\n\n  *** end ascii art ***\n\n\n  dispatches a custom event with a detail to the application.\n  \n\n*/\n\nfunction dispatch(name, detail = {}, div = document){\n  const initialize_event = new CustomEvent(name, {detail: detail})\n  div.dispatchEvent(initialize_event)\n}\n\n\n/*\n\n  Create New Div with the options set as attributes\n\n*/\n\nconst input_types = [\"button\",\n  \"checkbox\",\n  \"color\",\n  \"date\",\n  \"datetime-local\",\n  \"email\",\n  \"file\",\n  \"hidden\",\n  \"image\",\n  \"month\",\n  \"number\",\n  \"password\",\n  \"radio\",\n  \"range\",\n  \"reset\",\n  \"search\",\n  \"submit\",\n  \"tel\",\n  \"text\",\n  \"time\",\n  \"url\",\n  \"week\"]\n\nfunction createNewDiv(divopt){\n  let div\n  if(input_types.indexOf(divopt.type) > -1){\n    div = document.createElement('input')\n    div.type = divopt.type\n  } else {\n    div = document.createElement(divopt.type ? divopt.type : 'div')\n  }\n  delete divopt.type\n  Object.keys(divopt).forEach(key => {\n    div.setAttribute(key, divopt[key])\n  })\n  return div\n}\n\n/*\n    \n    READY\n\n    Use Like:\n\n    ready(event => {\n      \n    })\n\n*/\n\nfunction ready(callbackFunction){\n  if(document.readyState != 'loading')\n    callbackFunction(event)\n  else\n    document.addEventListener(\"DOMContentLoaded\", callbackFunction)\n}\n\n\nfunction getURLValues(URL = window.location.href ){\n  const search_params = new URLSearchParams(URL)\n  let options = {}\n  for (const [key, unparsed_value] of search_params) {\n    if(key !== window.location.origin + window.location.pathname + '?' ){\n      try {\n        const value = JSON.parse(decodeURI(unparsed_value))\n        options[key] = value\n      } catch {\n        options[key] = decodeURI(unparsed_value)\n      }\n    }\n  }\n  return options\n}\n\nfunction setURLValues(obj){\n  let url = window.location.origin + window.location.pathname + '?'\n  Object.keys(obj).forEach(key => {\n    url += `&${key}=${obj[key]}`\n  })\n  history.pushState(obj, '', url)\n}\n\n// I always end up including this anyway: \n\n/**\n * Created by Jacob Strieb\n * May 2020\n */\n\nvar b64 = (function() {\n\n  // Generate a dictionary with {key: val} as {character: index in input string}\n  function generateIndexDict(a) {\n    let result = {};\n    for (let i = 0; i < a.length; i++) {\n      result[a[i]] = i;\n    }\n    return result;\n  }\n\n  // Decode URL safe even though it is not the primary encoding mechanism\n  const _a = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\";\n  const _aRev = generateIndexDict(_a);\n  _aRev[\"-\"] = _aRev[\"+\"];\n  _aRev[\"_\"] = _aRev[\"/\"];\n\n  const _enc = new TextEncoder(\"utf-8\");\n  const _dec = new TextDecoder(\"utf-8\");\n\n  return {\n\n    // Encode a string as base64\n    decode: function(s) {\n      return this.binaryToAscii(this.base64ToBinary(s));\n    },\n\n    // Decode base64 to a string\n    encode: function(s) {\n      return this.binaryToBase64(this.asciiToBinary(s));\n    },\n\n    // Convert a string to a Uint8Array\n    // FIXME: TextEncoding and TextDecoding are not actually inverses\n    asciiToBinary: function(text) {\n      return _enc.encode(text);\n    },\n\n\n    // Convert a Uint8Array to a string\n    // FIXME: TextEncoding and TextDecoding are not actually inverses\n    binaryToAscii: function(binary) {\n      return _dec.decode(binary);\n    },\n\n\n    // Return a base64-encoded string from a Uint8Array input\n    binaryToBase64: function(originalBytes) {\n      // Pad the output array to a multiple of 3 bytes\n      let length = originalBytes.length;\n      let added = (length % 3 == 0) ? 0 : (3 - length % 3);\n      let bytes = new Uint8Array(length + added);\n      bytes.set(originalBytes);\n\n      let output = \"\";\n      for (let i = 0; i < bytes.length; i += 3) {\n        // Convert 3 8-bit bytes into 4 6-bit indices and get a character from\n        // the master list based on each 6-bit index\n        //    3 x 8-bit:  |------ --|---- ----|-- ------|\n        // => 4 x 6-bit:  |------|-- ----|---- --|------|\n\n        // Get the first 6 bits of the first byte\n        output += _a[ bytes[i] >>> 2 ];\n        // Merge the end 2 bits of the first byte with the first 4 of the second\n        output += _a[ ((bytes[i] & 0x3) << 4) | (bytes[i + 1] >>> 4) ];\n        // Merge the end 4 bits of the second byte with the first 2 of the third\n        output += _a[ ((bytes[i + 1] & 0xF) << 2) | (bytes[i + 2] >>> 6) ];\n        // Get the last 6 bits of the third byte\n        output += _a[ bytes[i + 2] & 0x3F ];\n      }\n\n      // Turn the final \"A\" characters into \"=\" depending on necessary padding\n      if (added > 0) {\n        output = output.slice(0, -added) + (\"=\".repeat(added));\n      }\n\n      return output;\n    },\n\n\n    // Takes a Base64 encoded string and returns a decoded Uint8Array. Throws\n    // an error if the input string does not appear to be a valid base64\n    // encoding. Attempts to add padding to un-padded base64 strings.\n    base64ToBinary: function(s) {\n      let bytes = [];\n\n      // Base64 strings have at most 2 padding characters to make their length\n      // a multiple of 4, so they could be missing up to 2 characters and still\n      // be valid. But if 3 padding characters would be needed, the input\n      // cannot be valid. Try and add padding characters if necessary/possible.\n      if (s.length % 4 == 1) {\n        throw \"Invalid base64 input\";\n      } else if (s.length % 4 != 0) {\n        s += \"=\".repeat(4 - (s.length % 4));\n      }\n\n      for (let i = 0; i <= (s.length - 4); i += 4) {\n        // Check that each character in this group of 4 is valid\n        for (let j = 0; j < 4; j++) {\n          if (s[i + j] != \"=\" && !(s[i + j] in _aRev)) {\n            throw \"Invalid base64 input\";\n          } else if (s[i + j] == \"=\" && Math.abs(s.length - (i + j)) > 2) {\n            throw \"Invalid base64 input\";\n          }\n        }\n\n        // Convert 4 6-bit indices into 3 8-bit bytes by finding the index of\n        // each 6-bit character in the master list and combining\n        //    4 x 6-bit:  |------|-- ----|---- --|------|\n        // => 3 x 8-bit:  |------ --|---- ----|-- ------|\n\n        // Get all 6 bits of the first byte and first 2 bits of the second byte\n        bytes.push((_aRev[s[i]] << 2) | (_aRev[s[i + 1]] >>> 4));\n        if (s[i + 2] != \"=\") {\n          // If not padding, merge end 4 bits of the second byte and first 4 of\n          // the third\n          bytes.push(((_aRev[s[i + 1]] & 0xF) << 4) | (_aRev[s[i + 2]] >>> 2));\n        }\n        if (s[i + 3] != \"=\") {\n          // If not padding, take the last 2 bits of the third byte and all 6 of\n          // the fourth. Note that if the fourth byte is padding, then certainly\n          // the third byte is, so we only have to check the fourth\n          bytes.push(((_aRev[s[i + 2]] & 0x3) << 6) | _aRev[s[i + 3]]);\n        }\n      }\n\n      return new Uint8Array(bytes);\n    }\n\n  }\n})();\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-04T02:00:01.885Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "index",
      "content": "[[search-pdf]]\n\n[[fuse.js]]\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-12-17T20:27:54.893Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "indexedDB",
      "content": "https://javascript.info/indexeddb\n\n# IndexedDB\n\nIndexedDB is a database that is built into a browser, much more powerful than `localStorage`.\n\n-   Stores almost any kind of values by keys, multiple key types.\n-   Supports transactions for reliability.\n-   Supports key range queries, indexes.\n-   Can store much bigger volumes of data than `localStorage`.\n\nThat power is usually excessive for traditional client-server apps. IndexedDB is intended for offline apps, to be combined with ServiceWorkers and other technologies.\n\nThe native interface to IndexedDB, described in the specification [https://www.w3.org/TR/IndexedDB](https://www.w3.org/TR/IndexedDB), is event-based.\n\nWe can also use `async/await` with the help of a promise-based wrapper, like [https://github.com/jakearchibald/idb](https://github.com/jakearchibald/idb). That’s pretty convenient, but the wrapper is not perfect, it can’t replace events for all cases. So we’ll start with events, and then, after we gain an understanding of IndexedDb, we’ll use the wrapper.\n\nWhere’s the data?\n\nTechnically, the data is usually stored in the visitor’s home directory, along with browser settings, extensions, etc.\n\nDifferent browsers and OS-level users have each their own independant storage.\n\n## [Open database](https://javascript.info/indexeddb#open-database)\n\nTo start working with IndexedDB, we first need to `open` (connect to) a database.\n\nThe syntax:\n\n`let openRequest = indexedDB.open(name, version);`\n\n-   `name` – a string, the database name.\n-   `version` – a positive integer version, by default `1` (explained below).\n\nWe can have many databases with different names, but all of them exist within the current origin (domain/protocol/port). Different websites can’t access each other’s databases.\n\nThe call returns `openRequest` object, we should listen to events on it:\n\n-   `success`: database is ready, there’s the “database object” in `openRequest.result`, we should use it for further calls.\n-   `error`: opening failed.\n-   `upgradeneeded`: database is ready, but its version is outdated (see below).\n\n**IndexedDB has a built-in mechanism of “schema versioning”, absent in server-side databases.**\n\nUnlike server-side databases, IndexedDB is client-side, the data is stored in the browser, so we, developers, don’t have full-time access to it. So, when we have published a new version of our app, and the user visits our webpage, we may need to update the database.\n\nIf the local database version is less than specified in `open`, then a special event `upgradeneeded` is triggered, and we can compare versions and upgrade data structures as needed.\n\nThe `upgradeneeded` event also triggers when the database doesn’t yet exist (technically, its version is `0`), so we can perform the initialization.\n\nLet’s say we published the first version of our app.\n\nThen we can open the database with version `1` and perform the initialization in an `upgradeneeded` handler like this:\n\n`let openRequest = indexedDB.open(\"store\", _1_);  openRequest.onupgradeneeded = function() {   // triggers if the client had no database   // ...perform initialization... };  openRequest.onerror = function() {   console.error(\"Error\", openRequest.error); };  openRequest.onsuccess = function() {   let db = openRequest.result;   // continue working with database using db object };`\n\nThen, later, we publish the 2nd version.\n\nWe can open it with version `2` and perform the upgrade like this:\n\n`let openRequest = indexedDB.open(\"store\", _2_);  openRequest.onupgradeneeded = function(event) {   // the existing database version is less than 2 (or it doesn't exist)   let db = openRequest.result;   switch(event.oldVersion) { // existing db version     case 0:       // version 0 means that the client had no database       // perform initialization     case 1:       // client had version 1       // update   } };`\n\nPlease note: as our current version is `2`, the `onupgradeneeded` handler has a code branch for version `0`, suitable for users that are accessing for the first time and have no database, and also for version `1`, for upgrades.\n\nAnd then, only if `onupgradeneeded` handler finishes without errors, `openRequest.onsuccess` triggers, and the database is considered successfully opened.\n\nTo delete a database:\n\n`let deleteRequest = indexedDB.deleteDatabase(name) // deleteRequest.onsuccess/onerror tracks the result`\n\nWe can’t open a database using an older open call version\n\nIf the current user database has a higher version than in the `open` call, e.g. the existing DB version is `3`, and we try to `open(...2)`, then that’s an error, `openRequest.onerror` triggers.\n\nThat’s rare, but such a thing may happen when a visitor loads outdated JavaScript code, e.g. from a proxy cache. So the code is old, but his database is new.\n\nTo protect from errors, we should check `db.version` and suggest a page reload. Use proper HTTP caching headers to avoid loading the old code, so that you’ll never have such problems.\n\n### [Parallel update problem](https://javascript.info/indexeddb#parallel-update-problem)\n\nAs we’re talking about versioning, let’s tackle a small related problem.\n\nLet’s say:\n\n1.  A visitor opened our site in a browser tab, with database version `1`.\n2.  Then we rolled out an update, so our code is newer.\n3.  And then the same visitor opens our site in another tab.\n\nSo there’s a tab with an open connection to DB version `1`, while the second one attempts to update it to version `2` in its `upgradeneeded` handler.\n\nThe problem is that a database is shared between two tabs, as it’s the same site, same origin. And it can’t be both version `1` and `2`. To perform the update to version `2`, all connections to version 1 must be closed, including the one in the first tab.\n\nIn order to organize that, the `versionchange` event triggers on the “outdated” database object. We should listen for it and close the old database connection (and probably suggest a page reload, to load the updated code).\n\nIf we don’t listen for the `versionchange` event and don’t close the old connection, then the second, new connection won’t be made. The `openRequest` object will emit the `blocked` event instead of `success`. So the second tab won’t work.\n\nHere’s the code to correctly handle the parallel upgrade. It installs the `onversionchange` handler, that triggers if the current database connection becomes outdated (db version is updated elsewhere) and closes the connection.\n\n`let openRequest = indexedDB.open(\"store\", 2);  openRequest.onupgradeneeded = ...; openRequest.onerror = ...;  openRequest.onsuccess = function() {   let db = openRequest.result;    _db.onversionchange = function() {     db.close();     alert(\"Database is outdated, please reload the page.\")   };_    // ...the db is ready, use it... };  _openRequest.onblocked = function() {   // this event shouldn't trigger if we handle onversionchange correctly    // it means that there's another open connection to the same database   // and it wasn't closed after db.onversionchange triggered for it };_`\n\n…In other words, here we do two things:\n\n1.  The `db.onversionchange` listener informs us about a parallel update attempt, if the current database version becomes outdated.\n2.  The `openRequest.onblocked` listener informs us about the opposite situation: there’s a connection to an outdated version elsewhere, and it doesn’t close, so the newer connection can’t be made.\n\nWe can handle things more gracefully in `db.onversionchange`, prompt the visitor to save the data before the connection is closed and so on.\n\nOr, an alternative approach would be to not close the database in `db.onversionchange`, but instead use the `onblocked` handler (in the new tab) to alert the visitor, tell him that the newer version can’t be loaded until they close other tabs.\n\nThese update collisions happen rarely, but we should at least have some handling for them, at least an `onblocked` handler, to prevent our script from dying silently.\n\n## [Object store](https://javascript.info/indexeddb#object-store)\n\nTo store something in IndexedDB, we need an _object store_.\n\nAn object store is a core concept of IndexedDB. Counterparts in other databases are called “tables” or “collections”. It’s where the data is stored. A database may have multiple stores: one for users, another one for goods, etc.\n\nDespite being named an “object store”, primitives can be stored too.\n\n**We can store almost any value, including complex objects.**\n\nIndexedDB uses the [standard serialization algorithm](https://www.w3.org/TR/html53/infrastructure.html#section-structuredserializeforstorage) to clone-and-store an object. It’s like `JSON.stringify`, but more powerful, capable of storing much more datatypes.\n\nAn example of an object that can’t be stored: an object with circular references. Such objects are not serializable. `JSON.stringify` also fails for such objects.\n\n**There must be a unique `key` for every value in the store.**\n\nA key must be one of these types – number, date, string, binary, or array. It’s a unique identifier, so we can search/remove/update values by the key.\n\nAs we’ll see very soon, we can provide a key when we add a value to the store, similar to `localStorage`. But when we store objects, IndexedDB allows setting up an object property as the key, which is much more convenient. Or we can auto-generate keys.\n\nBut we need to create an object store first.\n\nThe syntax to create an object store:\n\n`db.createObjectStore(name[, keyOptions]);`\n\nPlease note, the operation is synchronous, no `await` needed.\n\n-   `name` is the store name, e.g. `\"books\"` for books,\n-   `keyOptions` is an optional object with one of two properties:\n    -   `keyPath` – a path to an object property that IndexedDB will use as the key, e.g. `id`.\n    -   `autoIncrement` – if `true`, then the key for a newly stored object is generated automatically, as an ever-incrementing number.\n\nIf we don’t supply `keyOptions`, then we’ll need to provide a key explicitly later, when storing an object.\n\nFor instance, this object store uses `id` property as the key:\n\n`db.createObjectStore('books', {keyPath: 'id'});`\n\n**An object store can only be created/modified while updating the DB version, in `upgradeneeded` handler.**\n\nThat’s a technical limitation. Outside of the handler we’ll be able to add/remove/update the data, but object stores can only be created/removed/altered during a version update.\n\nTo perform a database version upgrade, there are two main approaches:\n\n1.  We can implement per-version upgrade functions: from 1 to 2, from 2 to 3, from 3 to 4 etc. Then, in `upgradeneeded` we can compare versions (e.g. old 2, now 4) and run per-version upgrades step by step, for every intermediate version (2 to 3, then 3 to 4).\n2.  Or we can just examine the database: get a list of existing object stores as `db.objectStoreNames`. That object is a [DOMStringList](https://html.spec.whatwg.org/multipage/common-dom-interfaces.html#domstringlist) that provides `contains(name)` method to check for existance. And then we can do updates depending on what exists and what doesn’t.\n\nFor small databases the second variant may be simpler.\n\nHere’s the demo of the second approach:\n\n`let openRequest = indexedDB.open(\"db\", 2);  // create/upgrade the database without version checks openRequest.onupgradeneeded = function() {   let db = openRequest.result;   if (!db.objectStoreNames.contains('books')) { // if there's no \"books\" store     db.createObjectStore('books', {keyPath: 'id'}); // create it   } };`\n\nTo delete an object store:\n\n`db.deleteObjectStore('books')`\n\n## [Transactions](https://javascript.info/indexeddb#transactions)\n\nThe term “transaction” is generic, used in many kinds of databases.\n\nA transaction is a group of operations, that should either all succeed or all fail.\n\nFor instance, when a person buys something, we need to:\n\n1.  Subtract the money from their account.\n2.  Add the item to their inventory.\n\nIt would be pretty bad if we complete the 1st operation, and then something goes wrong, e.g. lights out, and we fail to do the 2nd. Both should either succeed (purchase complete, good!) or both fail (at least the person kept their money, so they can retry).\n\nTransactions can guarantee that.\n\n**All data operations must be made within a transaction in IndexedDB.**\n\nTo start a transaction:\n\n`db.transaction(store[, type]);`\n\n-   `store` is a store name that the transaction is going to access, e.g. `\"books\"`. Can be an array of store names if we’re going to access multiple stores.\n-   `type` – a transaction type, one of:\n    -   `readonly` – can only read, the default.\n    -   `readwrite` – can only read and write the data, but not create/remove/alter object stores.\n\nThere’s also `versionchange` transaction type: such transactions can do everything, but we can’t create them manually. IndexedDB automatically creates a `versionchange` transaction when opening the database, for `upgradeneeded` handler. That’s why it’s a single place where we can update the database structure, create/remove object stores.\n\nWhy are there different types of transactions?\n\nPerformance is the reason why transactions need to be labeled either `readonly` and `readwrite`.\n\nMany `readonly` transactions are able to access the same store concurrently, but `readwrite` transactions can’t. A `readwrite` transaction “locks” the store for writing. The next transaction must wait before the previous one finishes before accessing the same store.\n\nAfter the transaction is created, we can add an item to the store, like this:\n\n`let transaction = db.transaction(\"books\", \"readwrite\"); // (1)  // get an object store to operate on it _let books = transaction.objectStore(\"books\"); // (2)_  let book = {   id: 'js',   price: 10,   created: new Date() };  _let request = books.add(book); // (3)_  request.onsuccess = function() { // (4)   console.log(\"Book added to the store\", request.result); };  request.onerror = function() {   console.log(\"Error\", request.error); };`\n\nThere were basically four steps:\n\n1.  Create a transaction, mentioning all the stores it’s going to access, at `(1)`.\n2.  Get the store object using `transaction.objectStore(name)`, at `(2)`.\n3.  Perform the request to the object store `books.add(book)`, at `(3)`.\n4.  …Handle request success/error `(4)`, then we can make other requests if needed, etc.\n\nObject stores support two methods to store a value:\n\n-   **put(value, [key])** Add the `value` to the store. The `key` is supplied only if the object store did not have `keyPath` or `autoIncrement` option. If there’s already a value with the same key, it will be replaced.\n    \n-   **add(value, [key])** Same as `put`, but if there’s already a value with the same key, then the request fails, and an error with the name `\"ConstraintError\"` is generated.\n    \n\nSimilar to opening a database, we can send a request: `books.add(book)`, and then wait for `success/error` events.\n\n-   The `request.result` for `add` is the key of the new object.\n-   The error is in `request.error` (if any).\n\n## [Transactions’ autocommit](https://javascript.info/indexeddb#transactions-autocommit)\n\nIn the example above we started the transaction and made `add` request. But as we stated previously, a transaction may have multiple associated requests, that must either all succeed or all fail. How do we mark the transaction as finished, with no more requests to come?\n\nThe short answer is: we don’t.\n\nIn the next version 3.0 of the specification, there will probably be a manual way to finish the transaction, but right now in 2.0 there isn’t.\n\n**When all transaction requests are finished, and the [microtasks queue](https://javascript.info/microtask-queue) is empty, it is committed automatically.**\n\nUsually, we can assume that a transaction commits when all its requests are complete, and the current code finishes.\n\nSo, in the example above no special call is needed to finish the transaction.\n\nTransactions auto-commit principle has an important side effect. We can’t insert an async operation like `fetch`, `setTimeout` in the middle of a transaction. IndexedDB will not keep the transaction waiting till these are done.\n\nIn the code below, `request2` in the line `(*)` fails, because the transaction is already committed, and can’t make any request in it:\n\n`let request1 = books.add(book);  request1.onsuccess = function() {   fetch('/').then(response => {     _let request2 = books.add(anotherBook); // (*)_     request2.onerror = function() {       console.log(request2.error.name); // TransactionInactiveError     };   }); };`\n\nThat’s because `fetch` is an asynchronous operation, a macrotask. Transactions are closed before the browser starts doing macrotasks.\n\nAuthors of IndexedDB spec believe that transactions should be short-lived. Mostly for performance reasons.\n\nNotably, `readwrite` transactions “lock” the stores for writing. So if one part of the application initiated `readwrite` on `books` object store, then another part that wants to do the same has to wait: the new transaction “hangs” till the first one is done. That can lead to strange delays if transactions take a long time.\n\nSo, what to do?\n\nIn the example above we could make a new `db.transaction` right before the new request `(*)`.\n\nBut it will be even better, if we’d like to keep the operations together, in one transaction, to split apart IndexedDB transactions and “other” async stuff.\n\nFirst, make `fetch`, prepare the data if needed, afterwards create a transaction and perform all the database requests, it’ll work then.\n\nTo detect the moment of successful completion, we can listen to `transaction.oncomplete` event:\n\n`let transaction = db.transaction(\"books\", \"readwrite\");  // ...perform operations...  transaction.oncomplete = function() {   console.log(\"Transaction is complete\"); };`\n\nOnly `complete` guarantees that the transaction is saved as a whole. Individual requests may succeed, but the final write operation may go wrong (e.g. I/O error or something).\n\nTo manually abort the transaction, call:\n\n`transaction.abort();`\n\nThat cancels all modification made by the requests in it and triggers `transaction.onabort` event.\n\n## [Error handling](https://javascript.info/indexeddb#error-handling)\n\nWrite requests may fail.\n\nThat’s to be expected, not only because of possible errors at our side, but also for reasons not related to the transaction itself. For instance, the storage quota may be exceeded. So we must be ready to handle such case.\n\n**A failed request automatically aborts the transaction, canceling all its changes.**\n\nIn some situations, we may want to handle the failure (e.g. try another request), without canceling existing changes, and continue the transaction. That’s possible. The `request.onerror` handler is able to prevent the transaction abort by calling `event.preventDefault()`.\n\nIn the example below a new book is added with the same key (`id`) as the existing one. The `store.add` method generates a `\"ConstraintError\"` in that case. We handle it without canceling the transaction:\n\n`let transaction = db.transaction(\"books\", \"readwrite\");  let book = { id: 'js', price: 10 };  let request = transaction.objectStore(\"books\").add(book);  request.onerror = function(event) {   // ConstraintError occurs when an object with the same id already exists   if (request.error.name == \"ConstraintError\") {     console.log(\"Book with such id already exists\"); // handle the error     event.preventDefault(); // don't abort the transaction     // use another key for the book?   } else {     // unexpected error, can't handle it     // the transaction will abort   } };  transaction.onabort = function() {   console.log(\"Error\", transaction.error); };`\n\n### [Event delegation](https://javascript.info/indexeddb#event-delegation)\n\nDo we need onerror/onsuccess for every request? Not every time. We can use event delegation instead.\n\n**IndexedDB events bubble: `request` → `transaction` → `database`.**\n\nAll events are DOM events, with capturing and bubbling, but usually only bubbling stage is used.\n\nSo we can catch all errors using `db.onerror` handler, for reporting or other purposes:\n\n`db.onerror = function(event) {   let request = event.target; // the request that caused the error    console.log(\"Error\", request.error); };`\n\n…But what if an error is fully handled? We don’t want to report it in that case.\n\nWe can stop the bubbling and hence `db.onerror` by using `event.stopPropagation()` in `request.onerror`.\n\n`request.onerror = function(event) {   if (request.error.name == \"ConstraintError\") {     console.log(\"Book with such id already exists\"); // handle the error     event.preventDefault(); // don't abort the transaction     event.stopPropagation(); // don't bubble error up, \"chew\" it   } else {     // do nothing     // transaction will be aborted     // we can take care of error in transaction.onabort   } };`\n\n## [Searching](https://javascript.info/indexeddb#searching)\n\nThere are two main types of search in an object store:\n\n1.  By a key value or a key range. In our “books” storage that would be a value or range of values of `book.id`.\n2.  By another object field, e.g. `book.price`. This required an additional data structure, named “index”.\n\n### [By key](https://javascript.info/indexeddb#by-key)\n\nFirst let’s deal with the first type of search: by key.\n\nSearching methods support both exact key values and so-called “ranges of values” – [IDBKeyRange](https://www.w3.org/TR/IndexedDB/#keyrange) objects that specify an acceptable “key range”.\n\n`IDBKeyRange` objects are created using following calls:\n\n-   `IDBKeyRange.lowerBound(lower, [open])` means: `≥lower` (or `>lower` if `open` is true)\n-   `IDBKeyRange.upperBound(upper, [open])` means: `≤upper` (or `<upper` if `open` is true)\n-   `IDBKeyRange.bound(lower, upper, [lowerOpen], [upperOpen])` means: between `lower` and `upper`. If the open flags is true, the corresponding key is not included in the range.\n-   `IDBKeyRange.only(key)` – a range that consists of only one `key`, rarely used.\n\nWe’ll see practical examples of using them very soon.\n\nTo perform the actual search, there are following methods. They accept a `query` argument that can be either an exact key or a key range:\n\n-   `store.get(query)` – search for the first value by a key or a range.\n-   `store.getAll([query], [count])` – search for all values, limit by `count` if given.\n-   `store.getKey(query)` – search for the first key that satisfies the query, usually a range.\n-   `store.getAllKeys([query], [count])` – search for all keys that satisfy the query, usually a range, up to `count` if given.\n-   `store.count([query])` – get the total count of keys that satisfy the query, usually a range.\n\nFor instance, we have a lot of books in our store. Remember, the `id` field is the key, so all these methods can search by `id`.\n\nRequest examples:\n\n`// get one book books.get('js')  // get books with 'css' <= id <= 'html' books.getAll(IDBKeyRange.bound('css', 'html'))  // get books with id < 'html' books.getAll(IDBKeyRange.upperBound('html', true))  // get all books books.getAll()  // get all keys, where id > 'js' books.getAllKeys(IDBKeyRange.lowerBound('js', true))`\n\nObject store is always sorted\n\nAn object store sorts values by key internally.\n\nSo requests that return many values always return them in sorted by key order.\n\n### [By a field using an index](https://javascript.info/indexeddb#by-a-field-using-an-index)\n\nTo search by other object fields, we need to create an additional data structure named “index”.\n\nAn index is an “add-on” to the store that tracks a given object field. For each value of that field, it stores a list of keys for objects that have that value. There will be a more detailed picture below.\n\nThe syntax:\n\n`objectStore.createIndex(name, keyPath, [options]);`\n\n-   **`name`** – index name,\n-   **`keyPath`** – path to the object field that the index should track (we’re going to search by that field),\n-   **`option`** – an optional object with properties:\n    -   **`unique`** – if true, then there may be only one object in the store with the given value at the `keyPath`. The index will enforce that by generating an error if we try to add a duplicate.\n    -   **`multiEntry`** – only used if the value on `keyPath` is an array. In that case, by default, the index will treat the whole array as the key. But if `multiEntry` is true, then the index will keep a list of store objects for each value in that array. So array members become index keys.\n\nIn our example, we store books keyed by `id`.\n\nLet’s say we want to search by `price`.\n\nFirst, we need to create an index. It must be done in `upgradeneeded`, just like an object store:\n\n`openRequest.onupgradeneeded = function() {   // we must create the index here, in versionchange transaction   let books = db.createObjectStore('books', {keyPath: 'id'});   _let index = books.createIndex('price_idx', 'price');_ };`\n\n-   The index will track `price` field.\n-   The price is not unique, there may be multiple books with the same price, so we don’t set `unique` option.\n-   The price is not an array, so `multiEntry` flag is not applicable.\n\nImagine that our `inventory` has 4 books. Here’s the picture that shows exactly what the `index` is:\n\nAs said, the index for each value of `price` (second argument) keeps the list of keys that have that price.\n\nThe index keeps itself up to date automatically, we don’t have to care about it.\n\nNow, when we want to search for a given price, we simply apply the same search methods to the index:\n\n`let transaction = db.transaction(\"books\"); // readonly let books = transaction.objectStore(\"books\"); let priceIndex = books.index(\"price_idx\");  _let request = priceIndex.getAll(10);_  request.onsuccess = function() {   if (request.result !== undefined) {     console.log(\"Books\", request.result); // array of books with price=10   } else {     console.log(\"No such books\");   } };`\n\nWe can also use `IDBKeyRange` to create ranges and looks for cheap/expensive books:\n\n`// find books where price <= 5 let request = priceIndex.getAll(IDBKeyRange.upperBound(5));`\n\nIndexes are internally sorted by the tracked object field, `price` in our case. So when we do the search, the results are also sorted by `price`.\n\n## [Deleting from store](https://javascript.info/indexeddb#deleting-from-store)\n\nThe `delete` method looks up values to delete by a query, the call format is similar to `getAll`:\n\n-   **`delete(query)`** – delete matching values by query.\n\nFor instance:\n\n`// delete the book with id='js' books.delete('js');`\n\nIf we’d like to delete books based on a price or another object field, then we should first find the key in the index, and then call `delete`:\n\n`// find the key where price = 5 let request = priceIndex.getKey(5);  request.onsuccess = function() {   let id = request.result;   let deleteRequest = books.delete(id); };`\n\nTo delete everything:\n\n`books.clear(); // clear the storage.`\n\n## [Cursors](https://javascript.info/indexeddb#cursors)\n\nMethods like `getAll/getAllKeys` return an array of keys/values.\n\nBut an object storage can be huge, bigger than the available memory. Then `getAll` will fail to get all records as an array.\n\nWhat to do?\n\nCursors provide the means to work around that.\n\n**A _cursor_ is a special object that traverses the object storage, given a query, and returns one key/value at a time, thus saving memory.**\n\nAs an object store is sorted internally by key, a cursor walks the store in key order (ascending by default).\n\nThe syntax:\n\n`// like getAll, but with a cursor: let request = store.openCursor(query, [direction]);  // to get keys, not values (like getAllKeys): store.openKeyCursor`\n\n-   **`query`** is a key or a key range, same as for `getAll`.\n-   **`direction`** is an optional argument, which order to use:\n    -   `\"next\"` – the default, the cursor walks up from the record with the lowest key.\n    -   `\"prev\"` – the reverse order: down from the record with the biggest key.\n    -   `\"nextunique\"`, `\"prevunique\"` – same as above, but skip records with the same key (only for cursors over indexes, e.g. for multiple books with price=5 only the first one will be returned).\n\n**The main difference of the cursor is that `request.onsuccess` triggers multiple times: once for each result.**\n\nHere’s an example of how to use a cursor:\n\n`let transaction = db.transaction(\"books\"); let books = transaction.objectStore(\"books\");  let request = books.openCursor();  // called for each book found by the cursor request.onsuccess = function() {   let cursor = request.result;   if (cursor) {     let key = cursor.key; // book key (id field)     let value = cursor.value; // book object     console.log(key, value);     cursor.continue();   } else {     console.log(\"No more books\");   } };`\n\nThe main cursor methods are:\n\n-   `advance(count)` – advance the cursor `count` times, skipping values.\n-   `continue([key])` – advance the cursor to the next value in range matching (or immediately after `key` if given).\n\nWhether there are more values matching the cursor or not – `onsuccess` gets called, and then in `result` we can get the cursor pointing to the next record, or `undefined`.\n\nIn the example above the cursor was made for the object store.\n\nBut we also can make a cursor over an index. As we remember, indexes allow to search by an object field. Cursors over indexes do precisely the same as over object stores – they save memory by returning one value at a time.\n\nFor cursors over indexes, `cursor.key` is the index key (e.g. price), and we should use `cursor.primaryKey` property for the object key:\n\n`let request = priceIdx.openCursor(IDBKeyRange.upperBound(5));  // called for each record request.onsuccess = function() {   let cursor = request.result;   if (cursor) {     let primaryKey = cursor.primaryKey; // next object store key (id field)     let value = cursor.value; // next object store object (book object)     let key = cursor.key; // next index key (price)     console.log(key, value);     cursor.continue();   } else {     console.log(\"No more books\");   } };`\n\n## [Promise wrapper](https://javascript.info/indexeddb#promise-wrapper)\n\nAdding `onsuccess/onerror` to every request is quite a cumbersome task. Sometimes we can make our life easier by using event delegation, e.g. set handlers on the whole transactions, but `async/await` is much more convenient.\n\nLet’s use a thin promise wrapper [https://github.com/jakearchibald/idb](https://github.com/jakearchibald/idb) further in this chapter. It creates a global `idb` object with [promisified](https://javascript.info/promisify) IndexedDB methods.\n\nThen, instead of `onsuccess/onerror` we can write like this:\n\n`let db = await idb.openDB('store', 1, db => {   if (db.oldVersion == 0) {     // perform the initialization     db.createObjectStore('books', {keyPath: 'id'});   } });  let transaction = db.transaction('books', 'readwrite'); let books = transaction.objectStore('books');  try {   await books.add(...);   await books.add(...);    await transaction.complete;    console.log('jsbook saved'); } catch(err) {   console.log('error', err.message); }`\n\nSo we have all the sweet “plain async code” and “try…catch” stuff.\n\n### [Error handling](https://javascript.info/indexeddb#error-handling-2)\n\nIf we don’t catch an error, then it falls through, till the closest outer `try..catch`.\n\nAn uncaught error becomes an “unhandled promise rejection” event on `window` object.\n\nWe can handle such errors like this:\n\n`window.addEventListener('unhandledrejection', event => {   let request = event.target; // IndexedDB native request object   let error = event.reason; //  Unhandled error object, same as request.error   ...report about the error... });`\n\n### [“Inactive transaction” pitfall](https://javascript.info/indexeddb#inactive-transaction-pitfall)\n\nAs we already know, a transaction auto-commits as soon as the browser is done with the current code and microtasks. So if we put a _macrotask_ like `fetch` in the middle of a transaction, then the transaction won’t wait for it to finish. It just auto-commits. So the next request in it would fail.\n\nFor a promise wrapper and `async/await` the situation is the same.\n\nHere’s an example of `fetch` in the middle of the transaction:\n\n`let transaction = db.transaction(\"inventory\", \"readwrite\"); let inventory = transaction.objectStore(\"inventory\");  await inventory.add({ id: 'js', price: 10, created: new Date() });  await fetch(...); // (*)  await inventory.add({ id: 'js', price: 10, created: new Date() }); // Error`\n\nThe next `inventory.add` after `fetch` `(*)` fails with an “inactive transaction” error, because the transaction is already committed and closed at that time.\n\nThe workaround is the same as when working with native IndexedDB: either make a new transaction or just split things apart.\n\n1.  Prepare the data and fetch all that’s needed first.\n2.  Then save in the database.\n\n### [Getting native objects](https://javascript.info/indexeddb#getting-native-objects)\n\nInternally, the wrapper performs a native IndexedDB request, adding `onerror/onsuccess` to it, and returns a promise that rejects/resolves with the result.\n\nThat works fine most of the time. The examples are at the lib page [https://github.com/jakearchibald/idb](https://github.com/jakearchibald/idb).\n\nIn few rare cases, when we need the original `request` object, we can access it as `promise.request` property of the promise:\n\n`let promise = books.add(book); // get a promise (don't await for its result)  let request = promise.request; // native request object let transaction = request.transaction; // native transaction object  // ...do some native IndexedDB voodoo...  let result = await promise; // if still needed`\n\n## [Summary](https://javascript.info/indexeddb#summary)\n\nIndexedDB can be thought of as a “localStorage on steroids”. It’s a simple key-value database, powerful enough for offline apps, yet simple to use.\n\nThe best manual is the specification, [the current one](https://www.w3.org/TR/IndexedDB-2/) is 2.0, but few methods from [3.0](https://w3c.github.io/IndexedDB/) (it’s not much different) are partially supported.\n\nThe basic usage can be described with a few phrases:\n\n1.  Get a promise wrapper like [idb](https://github.com/jakearchibald/idb).\n2.  Open a database: `idb.openDb(name, version, onupgradeneeded)`\n    -   Create object storages and indexes in `onupgradeneeded` handler or perform version update if needed.\n3.  For requests:\n    -   Create transaction `db.transaction('books')` (readwrite if needed).\n    -   Get the object store `transaction.objectStore('books')`.\n4.  Then, to search by a key, call methods on the object store directly.\n    -   To search by an object field, create an index.\n5.  If the data does not fit in memory, use a cursor.\n\nHere’s a small demo app:\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:11:36.788Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "initialize code",
      "content": "\n```js\n\n/*\n  \n  These scripts run to bootstrap a new instance of HANS. \n\n*/\n\nconst fs = require('fs')\nconst helpers = require('./helpers.js')\n\nconst dotenv = require(\"dotenv\")\ndotenv.config()\n\nlet new_env = []\n\nconst envfile = `PORT=${process.env.PORT ? process.env.PORT : 3000}\nADMIN_KEY=${process.env.ADMIN_KEY ? process.env.ADMIN_KEY : helpers.getNewID()}\nDATAROOM_KEY=${process.env.DATAROOM_KEY ? process.env.DATAROOM_KEY : helpers.getNewID()}\nCOMMON_KEY=${process.env.COMMON_KEY ? process.env.COMMON_KEY : helpers.getNewID()}\nAMAZON_KEY=${process.env.AMAZON_KEY ? process.env.AMAZON_KEY : null}`\n\nfs.writeFileSync('.env', envfile)\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-13T18:47:10.157Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "install mongodb",
      "content": "note: chat gpt was wrong. here are the instructions I used:\n\nhttps://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/\n\n```sh\nsudo apt-get install gnupg\n```\n\n```sh\ncurl -fsSL https://pgp.mongodb.com/server-6.0.asc | \\\n   sudo gpg -o /usr/share/keyrings/mongodb-server-6.0.gpg \\\n   --dearmor\n```\n\n```sh\necho \"deb [ arch=amd64,arm64 signed-by=/usr/share/keyrings/mongodb-server-6.0.gpg ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/6.0 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list\n```\n\n```sh\nsudo apt-get update\n```\n\n```\nsudo apt-get install -y mongodb-org\n```\n\n```\nsudo systemctl start mongod\n```\n\nOn my mini laptop this does not work. Might go put it on Muckraker. \n\n\n\n>hey chat, assuming ubuntu latest, give me instructions on how to install mongodb\n\nChatGPT\n\nTo install MongoDB on Ubuntu, you can follow these steps:\n\n1. Update the package list to ensure you have the latest available packages:\n\nsql\n\n`sudo apt update`\n\n2. Install MongoDB by running the following command:\n\n`sudo apt install mongodb`\n\n3. After the installation completes, MongoDB will start automatically. You can check the status of the MongoDB service with the following command:\n\nlua\n\n`sudo systemctl status mongodb`\n\n4. If the service is not running, start it using the following command:\n\nsql\n\n`sudo systemctl start mongodb`\n\n5. To enable MongoDB to start on system boot, run the following command:\n\nbash\n\n`sudo systemctl enable mongodb`\n\n6. You can verify that MongoDB is running by executing the MongoDB shell with the `mongo` command:\n\n`mongo`\n\nThis should connect you to the MongoDB shell, where you can interact with the database.\n\nThat's it! MongoDB is now installed on your Ubuntu system. You can proceed with configuring and using MongoDB as per your requirements.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-22T20:24:59.147Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "json-ld",
      "content": "\nhttps://json-ld.org/primer/latest/\n# JSON-LD Primer\n\n## A Context-based JSON Serialization for Linked Data\n\n## Draft Community Group Report 12 January 2023\n\nLatest editor's draft:\n\n[https://json-ld.org/primer/latest/](https://json-ld.org/primer/latest/)\n\nEditor:\n\n[David I. Lehn](http://dil.lehn.org/) ([Digital Bazaar](https://digitalbazaar.com/))\n\nParticipate:\n\n[GitHub json-ld/json-ld.org](https://github.com/json-ld/json-ld.org/)\n\n[File a bug](https://github.com/json-ld/json-ld.org/issues/)\n\n[Commit history](https://github.com/json-ld/json-ld.org/commits/gh-pages)\n\n[Pull requests](https://github.com/json-ld/json-ld.org/pulls/)\n\n[Copyright](https://www.w3.org/Consortium/Legal/ipr-notice#Copyright) © 2023 the Contributors to the JSON-LD Primer Specification, published by the [JSON for Linking Data W3C Community Group](https://www.w3.org/community/json-ld/) under the [W3C Community Contributor License Agreement (CLA)](https://www.w3.org/community/about/agreements/cla/). A human-readable [summary](https://www.w3.org/community/about/agreements/cla-deed/) is available.\n\n---\n\n## Abstract\n\nThis document attempts to provide a gentle introduction and examples of [JSON-LD](https://json-ld.org/) and to be a companion to the [JSON-LD specification](https://json-ld.org/spec/latest/).\n\n## Status of This Document\n\nThis specification was published by the [JSON for Linking Data W3C Community Group](https://www.w3.org/community/json-ld/). It is not a W3C Standard nor is it on the W3C Standards Track. Please note that under the [W3C Community Contributor License Agreement (CLA)](https://www.w3.org/community/about/agreements/cla/) there is a limited opt-out and other conditions apply. Learn more about [W3C Community and Business Groups](https://www.w3.org/community/).\n\nThis document is an experimental work in progress.\n\nNOTE\n\nThis document is a very early attempt at a primer. It is very incomplete and should not be relied upon. Any comments and suggestions are welcome and can be sent to the [JSON-LD](https://json-ld.org/) mailing list.\n\nIf you wish to make comments regarding this document, please send them to [public-linked-json@w3.org](mailto:public-linked-json@w3.org) ([subscribe](mailto:public-linked-json-request@w3.org?subject=subscribe), [archives](https://lists.w3.org/Archives/Public/public-linked-json/)).\n\n## table of contents\n\n1. [1.Introduction](https://json-ld.org/primer/latest/#introduction)\n    1. [1.1Examples Theme](https://json-ld.org/primer/latest/#examples-theme)\n    2. [1.2Example: \"Links Bike Shop\"](https://json-ld.org/primer/latest/#example-links-bike-shop)\n2. [2.Use Cases](https://json-ld.org/primer/latest/#use-cases)\n    1. [2.1Linked Data Processing](https://json-ld.org/primer/latest/#linked-data-processing)\n    2. [2.2Conversion to Known Format](https://json-ld.org/primer/latest/#conversion-to-known-format)\n3. [3.Data Sources](https://json-ld.org/primer/latest/#data-sources)\n    1. [3.1Example: Linked Data Format Independence](https://json-ld.org/primer/latest/#example-linked-data-format-independence)\n4. [4.Framing](https://json-ld.org/primer/latest/#framing)\n    1. [4.1Example: Basic Framing](https://json-ld.org/primer/latest/#example-basic-framing)\n    2. [4.2Example: Alternate Views](https://json-ld.org/primer/latest/#example-alternate-views)\n5. [5.Putting It All Together](https://json-ld.org/primer/latest/#putting-it-all-together)\n    1. [5.1Example: ?](https://json-ld.org/primer/latest/#example)\n6. [A.References](https://json-ld.org/primer/latest/#references)\n    1. [A.1Normative references](https://json-ld.org/primer/latest/#normative-references)\n    2. [A.2Informative references](https://json-ld.org/primer/latest/#informative-references)\n\n## 1. Introduction[](https://json-ld.org/primer/latest/#introduction)\n\nJSON-LD [[JSON-LD](https://json-ld.org/primer/latest/#bib-json-ld \"JSON-LD 1.0\")] combines the simplicity, power, and web ubiquity of JSON [[RFC4627](https://json-ld.org/primer/latest/#bib-rfc4627 \"The application/json Media Type for JavaScript Object Notation (JSON)\")] with the concepts of Linked Data [[LINKED-DATA](https://json-ld.org/primer/latest/#bib-linked-data \"Linked Data Design Issues\")] [[JSON-LD-REQUIREMENTS](https://json-ld.org/primer/latest/#bib-json-ld-requirements \"JSON-LD Requirements\")]. This document attempts to provide an introduction to the concepts and usage of JSON-LD as well as some examples of how it can be utilized in practice.\n\nThe requirements for JSON-LD can be found in [[JSON-LD-REQUIREMENTS](https://json-ld.org/primer/latest/#bib-json-ld-requirements \"JSON-LD Requirements\")] document and provide some basic definitions for concepts and terms used here. The full specification for JSON-LD can be found in [[JSON-LD](https://json-ld.org/primer/latest/#bib-json-ld \"JSON-LD 1.0\")] and is the basis for the examples given here. Please refer to these documents as needed.\n\nThe semantic web and linked data are a foundation of knowledge representation. What follows is a high-level view for the purposes of this document. A full discussion of these concepts is out of the scope of this document but see [[JSON-LD-REQUIREMENTS](https://json-ld.org/primer/latest/#bib-json-ld-requirements \"JSON-LD Requirements\")] for a better description of these concepts. Linked data systems are most often built using the concept of \"triples\". A single triple is built from a subject, a property, and a value. A collection of these triples can form a graph of data.\n\nApplications processing linked data can do so in a number of ways. One is to access the raw triples. This is very flexible but often is cumbersome. Another is to use some form of graph processing API, of which many variations exist. Another is to create a tree view from a portion of the graph.\n\nJSON-LD combines these features. At a low-level it provides a standardized way to represent linked data in JSON. However, it has been found that much of the linked data that is practically processed in JSON can be converted into tree structures that are more natural to handle. Many programming languages even offer native natural access to tree-like structures and no special APIs are required.\n\nConverting linked data graphs to easily accessible tree structures solves one problem of linked data processing. Another is that in many cases the components of a triple are represented as IRIs. Using long IRIs everywhere to access data is very flexible and has many benefits but from a programming view point is rather unwieldy.\n\nJSON-LD provides the ability to add \"context\" to the data and \"coerce\" values into forms that are easier to process. In fact, the end result of good JSON-LD usage is data structures that look like simple JSON but are in fact full linked data graphs. This provides a good deal of power for application developers to convert the linked data they are processing into easily manipulatable JSON data.\n\n### 1.1 Examples Theme[](https://json-ld.org/primer/latest/#examples-theme)\n\nThroughout this document the examples are based on a theme of processing data for a online store. Linked data uses IRIs to represent types and properties. The examples here will use two root URLs as well as a few simple types and properties. A real linked data system should use a common standard such as the [GoodRelations](http://www.heppnetz.de/projects/goodrelations/) vocabulary.\n\n`http://ns.example.com/store#`\n\nThe URL of the vocabulary. Abbreviated as `store` in CURIES.\n\n`http://store.example.com/`\n\nThe fictitious \"Links Bike Shop\". Abbreviated as `links` in CURIES.\n\n`store:Store`\n\nA store type. Instances have descriptive and product properties.\n\n`store:Product`\n\nA product for sale. Instances have descriptive, category, price, and availability properties.\n\n`store:Category`\n\nA product category type. Instances have descriptive properties.\n\n`store:product`\n\nA `store:Store` property linking to a `store:Product`.\n\n`store:category`\n\nA `store:Product` property linking to a `store:Category`.\n\n`store:price`\n\nA `store:Product` property linking to a price.\n\n`store:stock`\n\nA `store:Product` property linking to the quantity of the product in stock.\n\n### 1.2 Example: \"Links Bike Shop\"[](https://json-ld.org/primer/latest/#example-links-bike-shop)\n\nNOTE\n\nFIXME: How should this be organized? Start with basic JSON, add LD? Start with pieces, combine into full doc? Something else?\n\nLet's start by building up a fictitious bike store called \"Links Bike Shop\". We've already got our bike store setup at `http://store.example.com/` and are using linked data principles. Here's some of the URLs:\n\n- `http://store.example.com/`: The home page of the store.\n- `http://store.example.com/products/links-swift-chain`: A chain product.\n- `http://store.example.com/products/links-speedy-lube`: A chain lube product.\n\nWe want to start creating some linked data for this fictitious store and start with rough JSON data on the store itself.\n\n[EXAMPLE 1](https://json-ld.org/primer/latest/#p1)\n\n```\n{\n    \"@id\": \"http://store.example.com/\",\n    \"@type\": \"Store\",\n    \"name\": \"Links Bike Shop\",\n    \"description\": \"The most \\\"linked\\\" bike store on earth!\"\n}\n```\n\nThat was easy, right? Next let's create some rough data for our two premier products.\n\n[EXAMPLE 2](https://json-ld.org/primer/latest/#example-2)\n\n```\n{\n    \"@id\": \"http://store.example.com/products/links-swift-chain\",\n    \"@type\": \"Product\",\n    \"name\": \"Links Swift Chain\",\n    \"description\": \"A fine chain with many links.\",\n    \"category\": [\n        \"http://store.example.com/categories/parts\",\n        \"http://store.example.com/categories/chains\"\n    ],\n    \"price\": \"10.00\",\n    \"stock\": 10\n}\n```\n\n[EXAMPLE 3](https://json-ld.org/primer/latest/#example-3)\n\n```\n{\n    \"@id\": \"http://store.example.com/products/links-speedy-lube\",\n    \"@type\": \"Product\",\n    \"name\": \"Links Speedy Lube\",\n    \"description\": \"Lubricant for your chain links.\",\n    \"category\": [\n        \"http://store.example.com/categories/lubes\",\n        \"http://store.example.com/categories/chains\"\n    ],\n    \"price\": \"5.00\",\n    \"stock\": 20\n}\n```\n\nTo make this into a full JSON-LD document we combine the data, add a `@context`, and adjust some values.\n\n[EXAMPLE 4](https://json-ld.org/primer/latest/#example-4)\n\n```\n{\n    \"@id\": \"http://store.example.com/\",\n    \"@type\": \"Store\",\n    \"name\": \"Links Bike Shop\",\n    \"description\": \"The most \\\"linked\\\" bike store on earth!\",\n    \"product\": [\n        {\n            \"@id\": \"p:links-swift-chain\",\n            \"@type\": \"Product\",\n            \"name\": \"Links Swift Chain\",\n            \"description\": \"A fine chain with many links.\",\n            \"category\": [\"cat:parts\", \"cat:chains\"],\n            \"price\": \"10.00\",\n            \"stock\": 10\n        },\n        {\n            \"@id\": \"p:links-speedy-lube\",\n            \"@type\": \"Product\",\n            \"name\": \"Links Speedy Lube\",\n            \"description\": \"Lubricant for your chain links.\",\n            \"category\": [\"cat:lube\", \"cat:chains\"],\n            \"price\": \"5.00\",\n            \"stock\": 20\n        }\n    ],\n    \"@context\": {\n        \"Store\": \"http://ns.example.com/store#Store\",\n        \"Product\": \"http://ns.example.com/store#Product\",\n        \"product\": \"http://ns.example.com/store#product\",\n        \"category\":\n        {\n          \"@id\": \"http://ns.example.com/store#category\",\n          \"@type\": \"@id\"\n        },\n        \"price\": \"http://ns.example.com/store#price\",\n        \"stock\": \"http://ns.example.com/store#stock\",\n        \"name\": \"http://purl.org/dc/terms/title\",\n        \"description\": \"http://purl.org/dc/terms/description\",\n        \"p\": \"http://store.example.com/products/\",\n        \"cat\": \"http://store.example.com/category/\"\n    }\n}\n```\n\n## 2. Use Cases[](https://json-ld.org/primer/latest/#use-cases)\n\nThe following use cases are motivating in the design of JSON-LD.\n\n### 2.1 Linked Data Processing[](https://json-ld.org/primer/latest/#linked-data-processing)\n\nJSON-LD provides the ability to take linked data from many different sources and present it to an application in an easy to process JSON format. In many cases the transformation from a linked data graph to a JSON tree makes the data appear to just be a simple JSON structure.\n\n### 2.2 Conversion to Known Format[](https://json-ld.org/primer/latest/#conversion-to-known-format)\n\nLinked data may be input in a form that an application is not prepared to handle. JSON-LD offers the ability to convert linked data into a form that each application can specify on its own.\n\n## 3. Data Sources[](https://json-ld.org/primer/latest/#data-sources)\n\nJSON-LD is not dependent on any particular source of data. It is possible to convert many types of semantic web formats into JSON-LD. This is one of the classic benefits of the semantic web and its foundation of triples. Depending on the application and where it is used, a source of data may come from many places:\n\n- JSON-LD (native data) [[JSON-LD](https://json-ld.org/primer/latest/#bib-json-ld \"JSON-LD 1.0\")]\n- RDFa [[RDFA-CORE](https://json-ld.org/primer/latest/#bib-rdfa-core \"RDFa Core 1.1 - Third Edition\")]\n- Microdata [[MICRODATA](https://json-ld.org/primer/latest/#bib-microdata \"HTML Microdata\")]\n- Microformats [[MICROFORMATS](https://json-ld.org/primer/latest/#bib-microformats \"Microformats\")]\n- RDF\n- various other triples formats (N-Triples, Turtle, etc)\n\nA source-specific processor must convert the data into JSON-LD. In most cases if you can convert a data format into a form of triples, then the conversion into an expanded form of JSON-LD is trivial. Once this has taken place, it is possible to use framing and other JSON-LD processing concepts to convert the data into a form which is easier to process at the application level. This ability allows you process linked data provided in many formats in a standardized way.\n\n### 3.1 Example: Linked Data Format Independence[](https://json-ld.org/primer/latest/#example-linked-data-format-independence)\n\nFIXME: same triples in JSON-LD, RDFa, Microdata, triples\n\n## 4. Framing[](https://json-ld.org/primer/latest/#framing)\n\nMany applications wish to access data as if it is a simple tree structure. This is natural in many programming languages and often comes for free without a specialized API. The flexibility of the JSON-LD format and linked data it represents does come with a problem.\n\n### 4.1 Example: Basic Framing[](https://json-ld.org/primer/latest/#example-basic-framing)\n\nFIXME: ex of simple frame features\n\n### 4.2 Example: Alternate Views[](https://json-ld.org/primer/latest/#example-alternate-views)\n\nFIXME: multiple ex of different views into the same source data\n\n## 5. Putting It All Together[](https://json-ld.org/primer/latest/#putting-it-all-together)\n\n### 5.1 Example: ?[](https://json-ld.org/primer/latest/#example)\n\nFIXME: more complex example\n\n## A. References[](https://json-ld.org/primer/latest/#references)\n\n### A.1 Normative references[](https://json-ld.org/primer/latest/#normative-references)\n\n[JSON-LD]\n\n[JSON-LD 1.0](https://www.w3.org/TR/json-ld/). Manu Sporny; Gregg Kellogg; Markus Lanthaler. W3C. 3 November 2020. W3C Recommendation. URL: [https://www.w3.org/TR/json-ld/](https://www.w3.org/TR/json-ld/)\n\n[RFC4627]\n\n[The application/json Media Type for JavaScript Object Notation (JSON)](https://www.rfc-editor.org/rfc/rfc4627). D. Crockford. IETF. July 2006. Informational. URL: [https://www.rfc-editor.org/rfc/rfc4627](https://www.rfc-editor.org/rfc/rfc4627)\n\n### A.2 Informative references[](https://json-ld.org/primer/latest/#informative-references)\n\n[JSON-LD-REQUIREMENTS]\n\n[JSON-LD Requirements](https://json-ld.org/requirements/latest/). Gregg Kellogg. URL: [https://json-ld.org/requirements/latest/](https://json-ld.org/requirements/latest/)\n\n[LINKED-DATA]\n\n[Linked Data Design Issues](https://www.w3.org/DesignIssues/LinkedData.html). Tim Berners-Lee. W3C. 27 July 2006. W3C-Internal Document. URL: [https://www.w3.org/DesignIssues/LinkedData.html](https://www.w3.org/DesignIssues/LinkedData.html)\n\n[MICRODATA]\n\n[HTML Microdata](https://www.w3.org/TR/microdata/). Chaals Nevile; Dan Brickley; Ian Hickson. W3C. 28 January 2021. W3C Note. URL: [https://www.w3.org/TR/microdata/](https://www.w3.org/TR/microdata/)\n\n[MICROFORMATS]\n\n[Microformats](https://microformats.org/). URL: [https://microformats.org](https://microformats.org/)\n\n[RDFA-CORE]\n\n[RDFa Core 1.1 - Third Edition](https://www.w3.org/TR/rdfa-core/). Ben Adida; Mark Birbeck; Shane McCarron; Ivan Herman et al. W3C. 17 March 2015. W3C Recommendation. URL: [https://www.w3.org/TR/rdfa-core/](https://www.w3.org/TR/rdfa-core/)\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-04T12:52:11.259Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "kepler.gl",
      "content": "https://eng.uber.com/keplergl/\n\nkepler.gl is a data-agnostic, high-performance web-based application for visual exploration of large-scale geolocation data sets. Built on top of [[deck.gl]], kepler.gl can render millions of points representing thousands of trips and perform spatial aggregations on the fly, as shown in Figure 4, below:\n\n![](media/image1-3.png)\n\n\n### Behind kepler.gl\n\nkepler.gl is built on top of [deck.gl](http://uber.github.io/deck.gl/), a WebGL-powered data visualization library, and [react-map-gl](https://uber.github.io/react-map-gl/#/), a React wrapper for Mapbox-gl, both of which are included in the open source [Vis.gl](http://vis.gl/) suite developed in-house by Uber ‘s Data Visualization team.\n\nkepler.gl is a React component that uses Redux to manage its state and data flow. It can easily be embedded into other React-Redux applications and customized like any other Redux state.\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:11:51.718Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "key-commands",
      "content": "```js\n\ndocument.addEventListener('MOVE', function(e){\n  switch(e.detail.dir){\n    case 'FORWARD':\n      // const coords = getReflectedCoordinates()\n      // moveCameraToCoordinates(coords)\n    case 'BACKWARD':\n    case 'LEFT':\n    case 'RIGHT':\n    case 'UP':\n    case 'DOWN':\n    default: \n  }\n\n})\n\ndocument.addEventListener('keydown', function(e){\n\n  let sprint = e.shiftKey\n\n  let command = ''\n\n  switch(e.key){\n    case 'Escape':\n      [...document.querySelectorAll('hans-tag')].forEach(tag => tag.remove())\n\n      break;\n    case 'ArrowUp':\n    case 'w':\n      dispatch('MOVE', {dir: 'FORWARD', sprint})\n      break\n    case 'ArrowDown':\n    case 's':\n      dispatch('MOVE', {dir: 'BACKWARD', sprint})\n      break\n    case 'ArrowLeft':\n    case 'a':\n      dispatch('MOVE', {dir: 'LEFT', sprint})\n      break\n    case 'ArrowRight':\n      dispatch('MOVE', {dir: 'RIGHT', sprint})\n      break\n    case 'q':\n      dispatch('MOVE', {dir:'UP', sprint})\n      break\n    case 'e':\n      dispatch('MOVE', {dir:'DOWN', sprint})\n      break;\n    default: \n  }\n})\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.245Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Localization",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.246Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Log Content",
      "content": "```js\nconst fs = require('fs');\nconst dotenv = require(\"dotenv\");\ndotenv.config();\n\nconst path_name = process.env.OBSIDIAN_PATH_NAME\nconst date = new Date();\nconst day = date.getDate();\nconst month = date.getMonth() + 1;\nconst year = date.getFullYear();\n\nconst logFileName = `${day}-${month}-${year}.log.md`;\n\nfunction logContent(content){\n  fs.exists(__dirname + path_name + logFileName, (exists) => {\n    if (exists) {\n      fs.appendFile(__dirname + path_name + logFileName, content, (err) => {\n        if (err) throw err;\n        console.log('Content appended to log file');\n      });\n    } else {\n      fs.writeFile(__dirname + path_name + logFileName, content, (err) => {\n        if (err) throw err;\n        console.log('Log file created and content appended');\n      });\n    }\n  });  \n}\n\nmodule.exports = { logContent };\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T20:18:40.246Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "Login via link",
      "content": "```html\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  <title>Login</title>\n  <script type=\"module\">\n\n    function getValuesFromURL(URL = window.location.href ){\n      const search_params = new URLSearchParams(URL)\n      let options = {\n      }\n      for (const [key, unparsed_value] of search_params) {\n        if(key !== window.location.origin + window.location.pathname + '?' ){\n          try {\n            const value = JSON.parse(decodeURI(unparsed_value))\n            options[key] = value\n          } catch {\n            options[key] = decodeURI(unparsed_value)\n          }\n        }\n      }\n      return options\n    }\n\n    function setURLValues(obj){\n      let url = window.location.origin + window.location.pathname + '?'\n      Object.keys(obj).forEach(key => {\n        url += `&${key}=${obj[key]}`\n      })\n      history.pushState(obj, '', url)\n    }\n\n    function clearURLValues(){\n      window.history.pushState({}, document.title, window.location.pathname);\n    }\n\n\n\n\n\n    /*\n      \n      Get API Keys from URL. If there is not a value in link, check local storage. \n      If local storage does not have an API key throw an error\n\n    */\n\n    const app_name = 'hans'\n\n    async function init(){\n\n      const url_values = getValuesFromURL();\n\n\n      let api_key = null\n      if(url_values[app_name]){\n        api_key = url_values[app_name];\n        localStorage.setItem(app_name, decodeURIComponent(url_values[app_name]));\n        console.log(api_key)\n      } else {\n        api_key = localStorage.getItem(app_name);\n        if(api_key === null){\n          return alert(\"API KEY REQUIRED.\")\n        }\n      }\n\n      if(url_values.server_address){\n        const server_address = url_values.server_address; \n        localStorage.setItem('server_address', decodeURIComponent(server_address))\n      } else {\n        server_address = localStorage.getItem('server_address');\n        if(server_address === null){\n          return alert(\"Server Address Required\");\n        }\n      }\n\n      clearURLValues();\n      window.location.replace(\"/\");\n\n    } // end init\n\n    init();\n\n  </script>\n</head>\n<body>\n\n</body>\n</html>\n\n```\n\nSet URL Values:\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <title>Dynamic Key/Value Inputs</title>\n  <style>\n\n    body {\n      font-family: monospace;\n    }\n\n    button {\n      margin: 0.25em;\n    }\n\n    ul {\n      \n    }\n\n\n  </style>\n</head>\n<body>\n  <h1>Dynamic Key/Value Inputs</h1>\n  \n  <form id=\"inputForm\">\n    <div>\n      <label for=\"keyInput\">Key:</label>\n      <input type=\"text\" id=\"keyInput\">\n      <label for=\"valueInput\">Value:</label>\n      <input type=\"text\" id=\"valueInput\">\n      <button type=\"button\" onclick=\"addInput()\">Add</button>\n    </div>\n  </form>\n  \n  <ul id=\"inputList\"></ul>\n\n  <button type=\"button\" onclick=\"addUrl()\">Submit</button>\n\n  <script>\n\n    function setURLValues (obj){\n      let url = window.location.origin + '/login.html' + '?'\n      Object.keys(obj).forEach(key => {\n        url += `&${encodeURIComponent(key)}=${encodeURIComponent(obj[key])}`\n      })\n      history.pushState(obj, '', url)\n    }\n\n    // Function to add a new key/value input to the list\n    function addInput() {\n      var keyInput = document.getElementById(\"keyInput\").value;\n      var valueInput = document.getElementById(\"valueInput\").value;\n\n      if (keyInput !== '' && valueInput !== '') {\n        var listItem = document.createElement(\"li\");\n        listItem.innerHTML = `<span class=\"key\">${keyInput}</span>:<span class=\"value\">${valueInput}</value>`;\n        \n        var deleteButton = document.createElement(\"button\");\n        deleteButton.innerHTML = \"Delete\";\n        deleteButton.onclick = function() {\n          listItem.parentNode.removeChild(listItem);\n        };\n\n        listItem.appendChild(deleteButton);\n        document.getElementById(\"inputList\").appendChild(listItem);\n\n        // Clear input fields\n        document.getElementById(\"keyInput\").value = '';\n        document.getElementById(\"valueInput\").value = '';\n      }\n    }\n\n    function addUrl(){\n      const lis = [...document.querySelectorAll('li')];\n      let new_url_object = {}\n      lis.forEach(li => {\n        const key = li.querySelector('.key').innerText; \n        const value = li.querySelector('.value').innerText; \n        new_url_object[key] = value;\n      });\n\n      setURLValues(new_url_object);\n    }\n  </script>\n</body>\n</html>\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.514Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "fri-19-feb-2021-09-27-06-AM-PST",
      "content": "installing node on a fresh linux install\n\nBhodi Linux, so ubuntu 18\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-10-23T17:50:48.393Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "localhost",
      "content": "Make localhost https: \n\nchrome://flags/\n\nInsecure origins treated as secure\n\nadd http://localhost\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.518Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "on-software-and-business",
      "content": "ON SOFTWARE AND BUSINESS\n(An Attempt on Fri 26 Feb 2021 11:50:06 AM PST)\n \nby LNSY\n \nNota bena: opinions and facts subject to change with the introduction of new information. Please make sure you are reading the latest version -- LNSY. \n \n###\n \nBefore I wrote software professionally I was a temp. I bounced around a lot and saw a lot of really bad enterprise software. I think a lot of the reason I am so passionate about enterprise software is that I've seen those minutes of my life slip away to bad interface. Interfaces that are hard and confusing to use so you make mistakes, software that requires more time than necessary to do something. These minutes add up. \n \nLet's do some math. \n \nSo, say you're paying me $15 an hour. Really, if you own a business by the time you pay for taxes, infrastructure, capital outlay and insurance you are really paying about $45 an hour for me to hang out and do what you tell me to do at varying levels of competency. You need to make that much more value from my labor per-hour or you are going to go out of business. \n \nSay I have a piece of software that, because of a miscommunication between the developers who wrote it and the people who have to use the software (ideally this is what management is for but, lolz) has added 30 seconds to a transaction I do 20 times an hour. This means that, suddenly, there are 10 minutes of labor added to this task on aggregate an hour. \n \nIf you have a piece of software that wastes 10 minutes of my time, you just wasted $7.50 worth of my labor. But, of course, I'm using this software for 8 hours a day. So that is $60 of money wasted a day. \n \nSo, really, you thought you needed to make $45 an hour from my labor, but you just added $7.50 to the total. So, $52.50, and now you have a morale problem to boot: because the folks who are using the software are now accomplishing less than they used to for the same amount of work. \n \nMore often than not, management then blames the employees using the software for the labor slow down -- because they've already paid the vendor for the software. \"They just don't get it\". And, no matter what the profession or professional, bad morale is bad morale. And the best way to kill morale is to blame someone for something they don't have any way of fixing. \n \nI think a lot of young software developers have never had to go through the temp grind, and so they don't know how crushing it is to have to do the same meaningless task over and over and over. So when they see bad software designed they only think about how to implement it, not how it's going to feel to use it. \n \nThe reason I am writing DATAROOM is because I think software is only going to get good when the people who have to use it can write it. We have this amazing communication framework called HTML, CSS and Javascript, but our toolchain has become a complicated mess. Even our low and no code options back us into mind bending corners. \n \nThe solution is to create an interface directly into HTML, CSS and Javascript that is sliced into tiny portions. Spreadsheet sized chunks of information. So, a page, a cell. What is the HTML, CSS and Javascript on a device that has a host of sensors that is the equivalent of a spreadsheet page? That is my design problem. \n \nWe have also separated work and play too much, and hew to older skeumorphisms out of organizational cargo culting more than any logical reason. We see how people take to Minecraft -- doing repetitive tasks that build up into something much larger. We take satisfaction in it. Modern enterprise software rarely if ever provides this sort of feedback. DATAROOM asks the question: why can't we have a Minecraft like interface for business? \n \nOf course, now I have to convince you all of the win: that, in fact, I can get you that $45 an hour of software value for your gig economy work force. And that is the primary motive going forward for this phase of software development. I have a geo-located, self-indexing distributed document store and a scripting language to reason about it, and I can scale this software up to several billion devices (if it can run a browser, it can run DATAROOM, and, soon, if it can run JS, it can run DATAROOM). Now, how do I adjust the organization that uses it to understand software in this manner -- so the delivery person and the factory worker aren't just meeting objectives and making quotas, but thinking about the entire process of what they are part of. When the people who are using the software have real feedback about it, they will find the efficiencies for our businesses for us. And when people can understand the value of their labor in the context of the organization, they can make sure they are providing real value for their employer. \n \nPeople don't need more bumpers and wizzywhigs when it comes to software -- they need more training and agency. And with that training and agency your business objectives and solutions will become clear. \n \n###\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:14:25.381Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "sat-13-feb-2021-07-36-33-am-ps",
      "content": "# INTRODUCTION\n\n## Weiren, our hacker, LNSY, lays out the first steps of dataroom\n\nI initialized this project, intending to write a version 1.0 of some software that has been kicking around my head for several years. \n\nI have built many prototypes, and I still have a hard time summarizing what I am building. So, let me attempt to summarize it again here. \n\nDATAROOM.NETWORK is a multi-modal distributed scripting environment.\n\nIt is built on HTML, CSS and Javascript, and Node.js, and written to be hackable. I have avoided modern build schemes and older cludges (webpack, requirify) at sacrifice tosome older conveniences, but that sacrifice has ended up with, in my opinion, far more readable code. Code is not minified. The web is a two way medium, and so I feel that it is rude to obfusicate what you are running on a user's computer -- they should be able to read it and understand it. \n\nDATAROOM moves between several different command paradigms. In designing it I have considered verbal, visual and textual inputs. I have also considered the fact that users might want to edit the code of DATAROOM themselves and to run their own servers. \n\nIt is also my goal that this project be extremely well documented for the end user. It is a tool. \n\nSo, with that in mind, here is my current understanding of the file system: \n\n\nindex.js\n  the central file that is run by the server\n\nREADME\n  the overview and basic install instructions.\n\ndocs/ \n  here is where we put our voluminous, well mainted documentation\n  lnsys_log/\n    you're reading it, dudes\n  architecture.md\n    the description of the architecture of DATAROOM. \n  philosophies.md\n    my long winded diatribed\n  deploy.md\n  users.md\n  language.md\n\nclient/\n  public/\n  scripts/\n    vendor/ \n      all my lovingly modified libraries\n  styles/ \n  editor.html\n  viewer.html\n  admin.html\n  splash.html\n\nserver/\n  file-handling\nshared/\n  hans.js\nplugins/\n  where all the plugins will live\n\n\nIn lnsys_log, I intend to keep all the commands I have run to set this project up, it might be long winded. But this is for my reference, also.\n\ncurrently I am building on GUNDB, I hate the name, I am uncertain about the project, but it really has the best interaction I've seen for a graph db. When it's not being flakey. \n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.514Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "sat-march-6-2021",
      "content": "best option so far:\n\nhttps://github.com/spencermountain/compromise\n\nhttps://observablehq.com/@spencermountain/compromise-plugins\n\nhttps://observablehq.com/@spencermountain/compromise-hash\n\n\nBUT, going pure AI is maybe better:\n\nhttps://github.com/BrainJS/brain.js\n\nputting together a training workflow....\n\nhttps://scrimba.com/scrim/c36zkcb\n\nhttps://github.com/BrainJS/brain.js/blob/master/examples/javascript/gpu.html\n\nhttps://github.com/wanasit/chrono\n\nBodyPix:\nhttps://ml5js.org/reference/api-BodyPix/\n\n\nhttps://github.com/ml5js/ml5-library\n\nKmeans for optimization: https://editor.p5js.org/ml5/sketches/KMeans_imageSegmentation/\n\nhttps://www.youtube.com/watch?v=onKT9OwMiMU&ab_channel=ImadEddineToubal\nhttps://imadtoubal.github.io/Emotion-Recognition-with-ML5/#\nhttps://github.com/imadtoubal/Emotion-Recognition-with-ML5\n\nhttps://www.webrtc.ventures/2020/01/ai-in-webrtc-background-removal-with-tensorflow-in-an-agora-video-chat-2/\n\nhttps://github.com/vasturiano/d3-force-3d\n\nhttps://github.com/iperov/DeepFaceLab\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:38:13.396Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "thu-15-feb-2023",
      "content": "Archive:\n\nMy first computer was an Apple II+ that booted into basic. Most of the discs didn't work. But I had learned a few programming tools. I could make the computer beep at a frequency, loop, increment a variable and print something. \n\nThis kept me occupied for days and days. Expirimenting here and there. \n\nThe simplicity, utility and ease of this interface taught me a facility with programming and ruined me for contemporary programming. Contemporary programming requires setup after setup after setup to do anything useful. It is an index of fine print and gotchas. It is my hope that dataroom and it's languages solve most of these problems for most people, and get them programming. \n\n\n## It's just f****** javascript\n  My dad is a sign painter, and there is an organization of sign painters called The Letterheads. They are all about sharing what they know about making signs and just generally making beautiful things with everyone. They don't believe in secret knowlege. Anyway, their slogan is \"It's Just a f***** Sign\", or IJAFS for short. So, I say: IJFJS. It's just f****** javascript, bro. \n\n  Dataroom strives to get javascript directly into the users hands. It doesn't try to manage you, it tries to make solid architectural decisions that will provide the most flexibility. But in the end, dataroom is just HTML, CSS and Javascript, there is nothing fancy here, so don't be scared to open up the project with a text editor and start editing. You can only break it! \n\n\n## Nothing Fancy\n\tWhen people read my code they aren't going to see anything fancy. It is my hope that for most users, they won't ever have to look at my code. But to the ones that do, they will find how I have written DATAROOM \n\n4. Only Data\n\t1. Every variable in dataroom should be considered a snippet of data. If you want to cast it in a direction that is your business. But dataroom strives to deal only in information. \n\n5. The User comes first\n  And for what it's worth: if you're writing for Law Enforcement, that means your user is the aresstee, not the officer. \n\n5. Becoming a drone should be much simpler than become a a Queen. That is to say, joining this software project should be\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.518Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "tue-16-feb-2021-02-16-24",
      "content": "Tue 16 Feb 2021 02:26:24 PM PST\n\nShipped something on Saturday / Sunday with old architecture. Built on a database called Gun.js. It got... hairy. Anyway, I went back to the drawing board, and did some more research. \n\nOver this summer I was intrigued with the idea of a website that could be bootstrapped from another website. \n\nI had the hack mostly done, but got stuck on an encoding issue, and put it aside. Luckily, someone has already written it: \n\nhttps://jstrieb.github.io/link-lock/create/\nhttps://github.com/jstrieb/urlpages\n\nhttps://github.com/LazarSoft/jsqrcode/tree/master/src\n\n\nThis means I can ditch the old database, and move directly into working with devices and passing JSON back and forth using peer.js\n\nSo, how this will look: there will be a seed device. It will run node.js. If you would like video chat, it will have to have an HTTPS device. This device will hook up to it's global peers (that share a common key), and from it new devices can be spawned and created. The workflow is based on one time codes. So, the seed device will create a new one time code, you can connect, if it's password protected enter the password\n\nThis page then opens a page that loads the peer.js library from a CDN, and connects to the common network that the user just created. \n\nThe client application then is loaded directly from the seed device, not from the server. \n\nThis allows the seed device to host large files, without me having to deal with them.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.518Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "wed-03-mar-2021-03-02-40-PM-PST",
      "content": "A fun little animation I figured out:\n\n```HTML\n    <a-entity id=\"processing-animation\" animation=\"\n      property:rotation; \n      from: 0 0 0;\n      to: 0 360 0;\n      loop: true;\n      dur: 10000;\n      easing: linear;\n    \">\n    <a-entity id=\"boxes\" layout=\"type:box;columns:8;align:center;margin:1;\"></a-entity>\n\n    <a-entity scale=\"18.25 18.25 18.25\" \n      position=\"0 1.25 0\"\n      text=\"font: /Atkinson-Hyperlegible-Bold-102-msdf.json; \n      value: DATAROOM.NETWORK; \n      align:center; \n      side:double;\">\n    </a-entity>\n\n    <script>\n      const anim = document.querySelector('#boxes')\n      let count = 0\n      while(count < 8){\n        const new_div = document.createElement('a-box')\n        new_div.setAttribute('animation__appear', `\n          property: scale;\n          from: 0 0 0;\n          to: 1 1 1;\n          delay: ${count * 100}\n\n        `)\n\n        new_div.setAttribute('animation__opacity_oscillation', `\n          property: opacity;\n          from: 0.2;\n          to: 0.8;\n          loop:true;\n          dur: 1000;\n          delay: ${count * 200}\n        `)\n\n        anim.appendChild(new_div)\n        count++\n      }\n    </script>\n\n    </a-entity>\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-17T22:06:09.049Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "loading-and-transferring-files",
      "content": "\nassuming node.js, write a script that listens for usb dongles to be plugged in our removed, if a device is plugged in return a list of every file as json\n\n\neach file has 3 parts: the js, the markdown and aframe component. For an image there is js and aframe as well as the image file. These three files are auto generated for every item.\n\njs - contains json object assigned to objects id.\naframe contains what the object looks like. If it is text it is a square you can click to read (perhaps with title) \n\nHere's an example implementation of the script:\n\n\n```javascript\n\nconst usb = require('usb');\nconst fs = require('fs');\n\nusb.on('attach', function(device) {\n  var list = [];\n  var size = 0;\n  var path = device.mountPath;\n  var files = fs.readdirSync(path);\n  files.forEach(function(file) {\n    var fullpath = path + \"/\" + file;\n    var stats = fs.statSync(fullpath);\n    size += stats.size;\n    list.push({\n      name: file,\n      size: stats.size,\n      mtime: stats.mtime\n    });\n  });\n  console.log(JSON.stringify({\n    name: device.deviceDescriptor.product,\n    size: size,\n    files: list\n  }));\n});\n\nusb.on('detach', function(device) {\n  console.log(\"Device detached\");\n});\n\n```\n\nIn this script, we listens for the 'attach' event and retrieves the device's mount path using `device.mountPath`. We then use `fs.readdirSync` to retrieve a list of files in the device's directory, and loop through them to retrieve their statistics using `fs.statSync`. We accumulate the total size of the files and store them in a list with their respective names and modification dates. Finally, we output a JSON object containing the device name, total size, and file list using `console.log`.\n\nFor errors that may arise, it's best practice to use try-catch blocks to handle them appropriately.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-09-01T23:48:42.607Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "local wikipedia",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-20T21:36:21.864Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "markdown-parser",
      "content": "thought about obsidian and decided to write a simple parser for markdown to generate the kinds of pages I like.\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-15T17:58:31.913Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "node nlp",
      "content": "https://github.com/axa-group/nlp.js/blob/master/docs/v4/quickstart.md\n\n# Quick Start\n\n## Install the library\nAt the folder where is your node project, install the basic library, that will install the core and basic plugins for working in backend.\n\n```bash\nnpm i @nlpjs/basic\n```\n\n## Create the code\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/01.basic\nThen you can create a file called index.js with this content:\n\n```javascript\nconst { dockStart } = require('@nlpjs/basic');\n\n(async () => {\n  const dock = await dockStart({ use: ['Basic']});\n  const nlp = dock.get('nlp');\n  nlp.addLanguage('en');\n  // Adds the utterances and intents for the NLP\n  nlp.addDocument('en', 'goodbye for now', 'greetings.bye');\n  nlp.addDocument('en', 'bye bye take care', 'greetings.bye');\n  nlp.addDocument('en', 'okay see you later', 'greetings.bye');\n  nlp.addDocument('en', 'bye for now', 'greetings.bye');\n  nlp.addDocument('en', 'i must go', 'greetings.bye');\n  nlp.addDocument('en', 'hello', 'greetings.hello');\n  nlp.addDocument('en', 'hi', 'greetings.hello');\n  nlp.addDocument('en', 'howdy', 'greetings.hello');\n  \n  // Train also the NLG\n  nlp.addAnswer('en', 'greetings.bye', 'Till next time');\n  nlp.addAnswer('en', 'greetings.bye', 'see you soon!');\n  nlp.addAnswer('en', 'greetings.hello', 'Hey there!');\n  nlp.addAnswer('en', 'greetings.hello', 'Greetings!');  \n  await nlp.train();\n  const response = await nlp.process('en', 'I should go now');\n  console.log(response);\n})();\n```\n\n## Extracting the corpus into a file\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/02.filecorpus\nYou can create the corpus as json files. The format of the json is:\n\n```json\n{\n  \"name\": \"Name of the corpus\",\n  \"locale\": \"en-US\",\n  \"data\": [\n    {\n      \"intent\": \"agent.birthday\",\n      \"utterances\": [\n        \"when is your birthday\",\n        \"when do you celebrate your birthday\",\n        \"when were you born\",\n        \"when do you have birthday\",\n        \"date of your birthday\"\n      ],\n      \"answers\": [\n        \"Wait, are you planning a party for me? It's today! My birthday is today!\",\n        \"I'm young. I'm not sure of my birth date\",\n        \"I don't know my birth date. Most virtual agents are young, though, like me.\"\n      ]\n    },\n    ...\n  ]\n}\n```\n\nSo the new code will be: \n\n```javascript\nconst { dockStart } = require('@nlpjs/basic');\n\n(async () => {\n  const dock = await dockStart({ use: ['Basic']});\n  const nlp = dock.get('nlp');\n  await nlp.addCorpus('./corpus-en.json');\n  await nlp.train();\n  const response = await nlp.process('en', 'Who are you');\n  console.log(response);\n})();\n```\n\n## Extracting the configuration into a file\n\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/03.config\nNow we can remove things that are configuration into a file. \n\nAdd a _conf.json_ file with this content:\n\n```json\n{\n  \"settings\": {\n    \"nlp\": {\n      \"corpora\": [\n        \"./corpus-en.json\"\n      ]\n    }\n  },\n  \"use\": [\"Basic\"]\n}\n```\n\nAnd the new code will be:\n```javascript\nconst { dockStart } = require('@nlpjs/basic');\n\n(async () => {\n  const dock = await dockStart();\n  const nlp = dock.get('nlp');\n  await nlp.train();\n  const response = await nlp.process('en', 'Who are you');\n  console.log(response);\n})();\n```\n\nAs you can see now we don't need to provide the plugins to dockStart, nor do we need to add the corpus manually.\n\n## Creating your first pipeline\n\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/04.firstpipeline\n\nNow create a _pipelines.md_ file with this content:\n```markdown\n# default\n\n## main\nnlp.train\n```\n\n\nAnd remove the nlp.train() from the code:\n```javascript\nconst { dockStart } = require('@nlpjs/basic');\n\n(async () => {\n  const dock = await dockStart();\n  const nlp = dock.get('nlp');\n  const response = await nlp.process('en', 'Who are you');\n  console.log(response);\n})();\n```\n\nWe are defining a pipeline called _main_ and it will be executed after loading the configuration and mounting the plugins, so the train process will be executed automatically in the dockStart process.\n\n## Adding your first connector\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/05.consoleconnector\nNow modify the _conf.json_ to also use the plugin called _ConsoleConnector_:\n\n```json\n{\n  \"settings\": {\n    \"nlp\": {\n      \"corpora\": [\n        \"./corpus-en.json\"\n      ]\n    }\n  },\n  \"use\": [\"Basic\", \"ConsoleConnector\"]\n}\n```\n\nAnd in the _index.js_ you will only need the dockStart:\n\n```javascript\nconst { dockStart } = require('@nlpjs/basic');\n\n(async () => {\n  await dockStart();\n})();\n```\n\nNow when you execute you can talk with your bot in the terminal, read the corpus to know what you can ask your bot.\n\n## Extending your bot with the pipeline\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/06.javascriptpipelines\nNow we will do two modifications: \nThe first if for our chatbot to write \"Say something!\" in the console when it starts.\nTo do that, we can change the pipeline _main_\n\n```markdown\n# default\n\n## main\nnlp.train\nconsole.say \"Say something!\"\n```\n\nAlso, we want the console to quit the chat process when we type \"quit\". \nTo end the process, the console plugin has a method called _exit_. \nAnd we want to write the code in the pipeline in javascript, so this is what we add to the _pipelines.md_ file:\n\n```markdown\n## console.hear\n// compiler=javascript\nif (message === 'quit') {\n  return console.exit();\n}\nnlp.process();\nthis.say();\n```\n\nTo explain the pipeline better: \n- The name of the pipeline is _console.hear_ because it's the name of the event that the console connector will raise when it hears something. If this event does not exists in the pipeline, then it will do the default action. The code inside the pipeline will be executed with the input that this method receives.\n- The line \"// compiler=javascript\" is specifying which compiler to use for the pipeline. The default compiler is very simple, but you can also write your pipelines in javascript or python (adding the corresponding plugin).\n- \"nlp.process()\" is calling the _process_ method of the plugin _nlp_. Notable here: this method returns a promise but you don't need to put the await in the pipelines, the await is automatically done. Also, no arguments are being provided: when the pipeline javascript compiler finds a method where we do not pass any argument, by default it adds the current input of the pipeline.\n- \"this.say()\" as the _console.hear_ is executed by the _console_ plugin, _this_ refers to this plugin. As in the \"nlp.process\" we are not providing arguments, so the input is automatically provided.\n\nThe _index.js_ file will be:\n\n```javascript\nconst { dockStart } = require('@nlpjs/basic');\n\n(async () => {\n  await dockStart();\n})();\n```\n\n## Adding Multilanguage\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/07.multilanguage\nNow we want to add a corpus in spanish. First at all we must install the spanish language plugin:\n```bash\nnpm i @nlpjs/lang-es\n```\n\nThen add the _LangEs_ plugin in the configuration, and of course the corpus to the corpora:\n```json\n{\n  \"settings\": {\n    \"nlp\": {\n      \"corpora\": [\n        \"./corpus-en.json\",\n        \"./corpus-es.json\"\n      ]\n    }\n  },\n  \"use\": [\"Basic\", \"LangEs\", \"ConsoleConnector\"]\n}\n```\n\nAnd add an Spanish corpus. In the example, the Spanish corpus does not have answers, and the default behaviour of ConsoleConnector is to do an echo. To show the intent and the score in the console, we can add the property debug to the console settings, and set the value to true, modifying the configuration as follows:\n```json\n{\n  \"settings\": {\n    \"nlp\": {\n      \"corpora\": [\n        \"./corpus-en.json\",\n        \"./corpus-es.json\"\n      ]\n    },\n    \"console\": {\n      \"debug\": true\n    }\n  },\n  \"use\": [\"Basic\", \"LangEs\", \"ConsoleConnector\"]\n}\n```\n\nNow when you talk with the chatbot you can ask questions from the English corpus or from the Spanish corpus. The NLP process will automatically identify the language and send the utterance to the correct trained model.\n\n## Adding API and WebChat\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/08.webchat\nFirst you will need an Api Server to serve the web. For this you can install the plugin _ExpressApiServer_ and that will create an api server using Express.\n```bash\nnpm i @nlpjs/express-api-server\n```\n\nThe internal name of the plugin is \"api-server\". \nAlso you will have to configure the plugin to provide the port, and to set that it will serve a bot using webchat (Microsoft Webchat CDN).\nHere is the _conf.json_ content:\n```json\n{\n  \"settings\": {\n    \"nlp\": {\n      \"corpora\": [\n        \"../corpora/corpus50en.json\",\n        \"../corpora/corpus50es.json\"\n      ]\n    },\n    \"api-server\": { \"port\": 3000, \"serveBot\": true }\n  },\n  \"use\": [\"Basic\", \"LangEs\", \"ConsoleConnector\", \"ExpressApiServer\", \"DirectlineConnector\"]\n}\n```\n\nNow if you start the application, and in your browser navigate to http://localhost:3000, you will see an empty chat saying \"impossible to connect\".\n\nSo lets add the Directline Connector, that will create an API like the Microsoft Directline, but exposed at your localhost with your API server. To do this install the DirectlineConnector plugin:\n```bash\nnpm i @nlpjs/directline-connector\n```\n\nRestart your application and navigate once more to http://localhost:3000 and you'll be able to chat with your bot.\n<div align=\"center\">\n<img src=\"https://github.com/axa-group/nlp.js/raw/master/screenshots/webchat.png\" width=\"auto\" height=\"auto\"/>\n</div>\n\n## Using Microsoft Bot Framework\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/09.microsoftbot\nThere is a Microsoft Bot Framework Connector. First install the library:\n```bash\nnpm i @nlpjs/msbf-connector\n```\nThen use the plugin by adding it to your _conf.json_:\n\n```json\n{\n  \"settings\": {\n    \"nlp\": {\n      \"corpora\": [\n        \"./corpus-en.json\",\n        \"./corpus-es.json\"\n      ]\n    },\n    \"console\": {\n      \"debug\": true\n    },\n    \"api-server\": {\n      \"port\": 3000,\n      \"serveBot\": true\n    }\n  },\n  \"use\": [\"Basic\", \"LangEs\", \"ConsoleConnector\", \"ExpressApiServer\", \"DirectlineConnector\", \"MsbfConnector\"]\n}\n```\n\nNow start your app and use Microsoft Bot Framework Emulator https://aka.ms/botemulator\nThe endpoint will be http://localhost:3000/default/api/messages\n<div align=\"center\">\n<img src=\"https://github.com/axa-group/nlp.js/raw/master/screenshots/microsoftemulator.png\" width=\"auto\" height=\"auto\"/>\n</div>\n\nWhy is /default added to the api path? \nBecause it's the name of the container: NLP.js is built so you can have different containers with different names running at the same time in the application, allowing you to build a chatbot exposed to the same channel in different ways, i.e., you can have a chatbot sharing corpus, models, etc. but with different behaviour by channel or by country or any other setting.\n\nIf you want the api to be exposed in /api/messages you can set the settings of msfb in the _conf.json:\n```json\n{\n  \"settings\": {\n    \"nlp\": {\n      \"corpora\": [\n        \"./corpus-en.json\",\n        \"./corpus-es.json\"\n      ]\n    },\n    \"console\": {\n      \"debug\": true\n    },\n    \"api-server\": {\n      \"port\": 3000,\n      \"serveBot\": true\n    },\n    \"msbf\": {\n      \"apiPath\": \"\",\n      \"messagesPath\": \"/api/messages\"\n    }\n  },\n  \"use\": [\"Basic\", \"LangEs\", \"ConsoleConnector\", \"ExpressApiServer\", \"DirectlineConnector\", \"MsbfConnector\"]\n}\n```\n\nHow to add the Microsoft Application ID and the Microsoft Bot Password? \nYou have 3 different ways:\n1. Providing it in the settings:\n```json\n    \"msbf\": {\n      \"apiPath\": \"\",\n      \"messagesPath\": \"/api/messages\",\n      \"appId\": \"<YOUR MICROSOFT BOT APP ID>\",\n      \"appPassword\": \"<YOUR MICROSOFT BOT PASSWORD>\"\n    }\n```\n\n2. Define the environment variables MSBF_BOT_APP_ID and MSBF_BOT_APP_PASSWORD and these will be loaded if there are no _appId_ or _appPassword_ in the plugin settings.\n3. You can define those environment variables in a _.env_ file, the _.env_ file is automatically loaded at the dockStart process if it exists without installing dotenv.\n\n## Recognizing the bot name and the channel\n\nWith the last code, try this sentence in console, web and Microsoft emulator: \"where am I\".\nYou'll notice that the answer is something like: \"you're talking from console, app is default channel is console\"\nThis happens because the answers to this intents are written like this:\n```json\n      \"answers\": [\n        { \"answer\": \"you're talking from console, app is {{ app }} channel is {{ channel }}\", \"opts\": \"channel==='console'\" },\n        { \"answer\": \"you're talking from directline, app is {{ app }} channel is {{ channel }}\", \"opts\": \"channel==='directline'\" },\n        { \"answer\": \"you're talking from microsoft emulator, app is {{ app }} channel is {{ channel }}\", \"opts\": \"channel==='msbf-emulator'\" }\n      ]\n```\nHere we are mixing two things:\n1. The context variables: _{{ app }}_ and _{{ channel }}_ will be replaced by the context variables app (bot name) and channel (channel name).\n2. Opts: the opts for an answer are the conditions to return this answer, and can be any condition in javascript format.\n\n## One bot per connector\n\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/10.threebots\n\nIn the _conf.json_ what you have defined so far is the configuration of the default container. But containers can have child containers, with their own configuration and plugins, and they can access the plugins and resources of their parent containers.\nPut this in your _conf.json_\n\n```\n{\n  \"settings\": {\n    \"nlp\": {\n      \"corpora\": [\n        \"./corpus-en.json\",\n        \"./corpus-es.json\"\n      ]\n    },\n    \"api-server\": {\n      \"port\": 3000,\n      \"serveBot\": true\n    }\n  },\n  \"childs\": {\n    \"bot1\": {\n      \"settings\": {\n        \"console\": {\n          \"debug\": true\n        },\n        \"use\": [\"ConsoleConnector\"]\n      }\n    },\n    \"bot2\": {\n      \"use\": [\"DirectlineConnector\"]\n    },\n    \"bot3\": {\n      \"settings\": {\n        \"msbf\": {\n          \"apiPath\": \"\",\n          \"messagesPath\": \"/api/messages\"\n        }\n      },\n      \"use\": [\"MsbfConnector\"]\n    }\n  },\n  \"use\": [\"Basic\", \"LangEs\", \"ExpressApiServer\"]\n}\n```\n\nThis will create 3 childrens (childs) containers where each container represents a bot: bot1 in Console, bot2 in Webchat and Directline and bot3 with the Microsoft Bot Framework Connector.\nAs the ExpressApiServer plugin and configuration are in the default container,  bot2 and bot3 will use this express configuration.\n\nThe problem now is that when you execute the app it will crash because the pipelines we're trying to use in the console plugin come from the default container, but this plugin is in bot1.\nSo replace the _pipelines.md_ with this content:\n\n```markdown\n# default\n\n## main\nnlp.train\n\n# bot1\n\n# main\nconsole.say \"Say something!\"\n\n## console.hear\n// compiler=javascript\nif (message === 'quit') {\n  return console.exit();\n}\nnlp.process();\nthis.say();\n```\n\nAs you can see the \"# main\" title of the pipelines is the name of the container, that way if you use the same plugin in two different containers, they can behave diferently.\n\nNow you can repeat the \"where am I\" utterance, and you will notice something different: app is no longer default and is replaced with bot1, bot2 or bot3.\n\n## Different port for Microsoft Bot Framework and Webchat\n\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/11.differentports\n\nIn the last example the ExpressApiServer plugin was in the default container, but we can move it into bot2 and bot3 with a different configuration:\n```\n{\n  \"settings\": {\n    \"nlp\": {\n      \"corpora\": [\n        \"./corpus-en.json\",\n        \"./corpus-es.json\"\n      ]\n    }\n  },\n  \"childs\": {\n    \"bot1\": {\n      \"settings\": {\n        \"console\": {\n          \"debug\": true\n        },\n        \"use\": [\"ConsoleConnector\"]\n      }\n    },\n    \"bot2\": {\n      \"settings\": {\n        \"api-server\": {\n          \"port\": 3000,\n          \"serveBot\": true\n        }\n      },\n      \"use\": [\"ExpressApiServer\", \"DirectlineConnector\"]\n    },\n    \"bot3\": {\n      \"settings\": {\n        \"msbf\": {\n          \"apiPath\": \"\",\n          \"messagesPath\": \"/api/messages\"\n        },\n        \"api-server\": {\n          \"port\": 4000,\n          \"serveBot\": false\n        }\n      },\n      \"use\": [\"ExpressApiServer\", \"MsbfConnector\"]\n    }\n  },\n  \"use\": [\"Basic\", \"LangEs\"]\n}\n```\n\n__Important!__ The plugins are loaded in order. Because both DirectlineConnector and MsbfConnector need an api-server, the ExpressApiServer should be added before each of these.\n\n\n## Adding logic to an intent\nThe code for this example is here: https://github.com/jesus-seijas-sp/nlpjs-examples/tree/master/01.quickstart/12.onintent\n\nSuppose that you want to have an intent for telling jokes about Chuck Norris, and you know that a service that returns random Chuck Norris jokes exists: http://api.icndb.com/jokes/random\n\nFirst you need to add the intent to the corpus:\n```json\n    {\n      \"intent\": \"joke.chucknorris\",\n      \"utterances\": [\n        \"tell me a chuck norris fact\",\n        \"tell me a joke about chuck norris\",\n        \"say a chuck norris joke\",\n        \"some chuck norris fact\"\n      ]\n    },\n```\n\nThen add this to the _pipelines.md_ in the default section:\n\n```markdown\n## onIntent(joke.chucknorris)\n// compiler=javascript\nconst something = request.get('http://api.icndb.com/jokes/random');\nif (something && something.value && something.value.joke) {\n  input.answer = something.value.joke;\n}\n```\n\nExplanation: the _onIntent(<intentname>)_ is called when an intent is recognized, so you can react to doing things and modifying the input as you want, from classifications, entities and of course the answer.\nWe set the compiler to JavaScript. \nWe have a plugin _request_ that is for handling requests, then we call the API to retrieve an answer, and set it in the input.\n\n<div align=\"center\">\n<img src=\"https://github.com/axa-group/nlp.js/raw/master/screenshots/chucknorris.png\" width=\"auto\" height=\"auto\"/>\n</div>\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-20T21:52:37.609Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "node-firefox",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-07-30T03:25:04.236Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "node.js Check if Folder Exists",
      "content": "```js\nif (!fs.existsSync(outputFolderPath)) { fs.mkdirSync(outputFolderPath); } \n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-18T20:36:36.283Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "nomnoml",
      "content": "https://nomnoml.com/\n\nhttps://github.com/skanaar/nomnoml\n\n```shell\nnpm install nomnoml\n```\n\n```js\nvar nomnoml = require('nomnoml')\nvar src = '[nomnoml] is -> [awesome]'\nconsole.log(nomnoml.renderSvg(src))\n\n```\n\n```html\n\n<script src=\"//unpkg.com/graphre/dist/graphre.js\"></script>\n<script src=\"//unpkg.com/nomnoml/dist/nomnoml.js\"></script>\n\n<canvas id=\"target-canvas\"></canvas>\n<script>\n  var canvas = document.getElementById('target-canvas')\n  var source = '[nomnoml] is -> [awesome]'\n  nomnoml.draw(canvas, source)\n</script>\n\n## [](https://github.com/skanaar/nomnoml#command-line-interface)\n  \n```\n\n## Association types\n\n**association** -  \n**association** ->  \n**association** <->  \n**dependency** -->  \n**dependency** <-->  \n**generalization** -:>  \n**implementation** --:>  \n**composition** +-  \n**composition** +->  \n**aggregation** o-  \n**aggregation** o->  \n**ball and socket** -o)  \n**ball and socket** o<-)  \n**ball and socket** ->o  \n**note** --  \n**hidden** -/-  \n**weightless edge** _>  \n**weightless dashed** __  \n\n## Class diagram types\n\n[class]\n\nclass\n\n[<abstract> abstract]\n\nabstract\n\n[<instance> instance]\n\ninstance\n\n[<reference> reference]\n\nreference\n\n[<package> package|components]\n\npackagecomponents\n\n[<frame> frame|]\n\nframe\n\n## Component diagram types\n\n[Component] - [<socket> socket]\n\nComponentsocket\n\n[<lollipop> lollipop] - [Component]\n\nlollipopComponent\n\n## Flow chart types\n\n\n[<start> start]\n\n[<end> end]\n\n[<state> state]\n\nstate\n\n[<choice> choice]\n\nchoice\n\n[<sync> sync]\n\n[<input> input]\n\ninput\n\n[<sender> sender]\n\nsender\n\n[<receiver> receiver]\n\nreceiver\n\n[<transceiver> transceiver]\n\ntransceiver\n\n## Use case types\n\n[<actor> actor]\n\nactor\n\n[<usecase> usecase]\n\nusecase\n\n## Miscalleneous types\n\n[<note> note]\n\nnote\n\n[<label> label]\n\nlabel\n\n[<hidden> hidden]\n\n[<database> database]\n\ndatabase\n\n[<table> table| a | 5 || b | 7]\n\ntablea5b7\n\n## Directives\n\n#import: filename  \n#arrowSize: 1  \n#bendSize: 0.3  \n#direction: down | right  \n#gutter: 5  \n#edgeMargin: 0  \n#gravity: 1  \n#edges: hard | rounded  \n#background: transparent  \n#fill: #eee8d5; #fdf6e3  \n#fillArrows: false  \n#font: Calibri  \n#fontSize: 12  \n#leading: 1.25  \n#lineWidth: 3  \n#padding: 8  \n#spacing: 40  \n#stroke: #33322E  \n#title: filename  \n#zoom: 1  \n#acyclicer: greedy  \n#ranker: network-simplex | tight-tree | longest-path  \n\n## Custom classifier styles\n\nA directive that starts with \".\" define a classifier style. The style is written as a space separated list of modifiers and key/value pairs.\n\n#.box: fill=#8f8 dashed\n#.blob: visual=ellipse title=bold\n[<box> GreenBox]\n[<blob> Blobby]\n\nGreenBoxBlobby\n\n### Modifiers\n\ndashed  \n\n### Key/value pairs\n\nfill=(any css color)  \n  \nstroke=(any css color)  \n  \nalign=center  \nalign=left  \n  \ndirection=right  \ndirection=down  \n  \nvisual=actor  \nvisual=class  \nvisual=database  \nvisual=ellipse  \nvisual=end  \nvisual=frame  \nvisual=hidden  \nvisual=input  \nvisual=none  \nvisual=note  \nvisual=package  \nvisual=receiver  \nvisual=rhomb  \nvisual=roundrect  \nvisual=sender  \nvisual=start  \nvisual=sync  \nvisual=table  \nvisual=transceiver  \n\n### Style title and text body\n\ntitle=left,italic,bold  \nbody=center,italic,bold  \n\n### Text modifiers\n\nbold  \ncenter  \nitalic  \nleft  \nunderline\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-10-28T18:31:34.429Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "normalize.css",
      "content": "```css\n/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */\n\n/* Document\n   ========================================================================== */\n\n/**\n * 1. Correct the line height in all browsers.\n * 2. Prevent adjustments of font size after orientation changes in iOS.\n */\n\nhtml {\n  line-height: 1.15; /* 1 */\n  -webkit-text-size-adjust: 100%; /* 2 */\n}\n\n/* Sections\n   ========================================================================== */\n\n/**\n * Remove the margin in all browsers.\n */\n\nbody {\n  margin: 0;\n}\n\n/**\n * Render the `main` element consistently in IE.\n */\n\nmain {\n  display: block;\n}\n\n/**\n * Correct the font size and margin on `h1` elements within `section` and\n * `article` contexts in Chrome, Firefox, and Safari.\n */\n\nh1 {\n  font-size: 2em;\n  margin: 0.67em 0;\n}\n\n/* Grouping content\n   ========================================================================== */\n\n/**\n * 1. Add the correct box sizing in Firefox.\n * 2. Show the overflow in Edge and IE.\n */\n\nhr {\n  box-sizing: content-box; /* 1 */\n  height: 0; /* 1 */\n  overflow: visible; /* 2 */\n}\n\n/**\n * 1. Correct the inheritance and scaling of font size in all browsers.\n * 2. Correct the odd `em` font sizing in all browsers.\n */\n\npre {\n  font-family: monospace, monospace; /* 1 */\n  font-size: 1em; /* 2 */\n}\n\n/* Text-level semantics\n   ========================================================================== */\n\n/**\n * Remove the gray background on active links in IE 10.\n */\n\na {\n  background-color: transparent;\n}\n\n/**\n * 1. Remove the bottom border in Chrome 57-\n * 2. Add the correct text decoration in Chrome, Edge, IE, Opera, and Safari.\n */\n\nabbr[title] {\n  border-bottom: none; /* 1 */\n  text-decoration: underline; /* 2 */\n  text-decoration: underline dotted; /* 2 */\n}\n\n/**\n * Add the correct font weight in Chrome, Edge, and Safari.\n */\n\nb,\nstrong {\n  font-weight: bolder;\n}\n\n/**\n * 1. Correct the inheritance and scaling of font size in all browsers.\n * 2. Correct the odd `em` font sizing in all browsers.\n */\n\ncode,\nkbd,\nsamp {\n  font-family: monospace, monospace; /* 1 */\n  font-size: 1em; /* 2 */\n}\n\n/**\n * Add the correct font size in all browsers.\n */\n\nsmall {\n  font-size: 80%;\n}\n\n/**\n * Prevent `sub` and `sup` elements from affecting the line height in\n * all browsers.\n */\n\nsub,\nsup {\n  font-size: 75%;\n  line-height: 0;\n  position: relative;\n  vertical-align: baseline;\n}\n\nsub {\n  bottom: -0.25em;\n}\n\nsup {\n  top: -0.5em;\n}\n\n/* Embedded content\n   ========================================================================== */\n\n/**\n * Remove the border on images inside links in IE 10.\n */\n\nimg {\n  border-style: none;\n}\n\n/* Forms\n   ========================================================================== */\n\n/**\n * 1. Change the font styles in all browsers.\n * 2. Remove the margin in Firefox and Safari.\n */\n\nbutton,\ninput,\noptgroup,\nselect,\ntextarea {\n  font-family: inherit; /* 1 */\n  font-size: 100%; /* 1 */\n  line-height: 1.15; /* 1 */\n  margin: 0; /* 2 */\n}\n\n/**\n * Show the overflow in IE.\n * 1. Show the overflow in Edge.\n */\n\nbutton,\ninput { /* 1 */\n  overflow: visible;\n}\n\n/**\n * Remove the inheritance of text transform in Edge, Firefox, and IE.\n * 1. Remove the inheritance of text transform in Firefox.\n */\n\nbutton,\nselect { /* 1 */\n  text-transform: none;\n}\n\n/**\n * Correct the inability to style clickable types in iOS and Safari.\n */\n\nbutton,\n[type=\"button\"],\n[type=\"reset\"],\n[type=\"submit\"] {\n  -webkit-appearance: button;\n}\n\n/**\n * Remove the inner border and padding in Firefox.\n */\n\nbutton::-moz-focus-inner,\n[type=\"button\"]::-moz-focus-inner,\n[type=\"reset\"]::-moz-focus-inner,\n[type=\"submit\"]::-moz-focus-inner {\n  border-style: none;\n  padding: 0;\n}\n\n/**\n * Restore the focus styles unset by the previous rule.\n */\n\nbutton:-moz-focusring,\n[type=\"button\"]:-moz-focusring,\n[type=\"reset\"]:-moz-focusring,\n[type=\"submit\"]:-moz-focusring {\n  outline: 1px dotted ButtonText;\n}\n\n/**\n * Correct the padding in Firefox.\n */\n\nfieldset {\n  padding: 0.35em 0.75em 0.625em;\n}\n\n/**\n * 1. Correct the text wrapping in Edge and IE.\n * 2. Correct the color inheritance from `fieldset` elements in IE.\n * 3. Remove the padding so developers are not caught out when they zero out\n *    `fieldset` elements in all browsers.\n */\n\nlegend {\n  box-sizing: border-box; /* 1 */\n  color: inherit; /* 2 */\n  display: table; /* 1 */\n  max-width: 100%; /* 1 */\n  padding: 0; /* 3 */\n  white-space: normal; /* 1 */\n}\n\n/**\n * Add the correct vertical alignment in Chrome, Firefox, and Opera.\n */\n\nprogress {\n  vertical-align: baseline;\n}\n\n/**\n * Remove the default vertical scrollbar in IE 10+.\n */\n\ntextarea {\n  overflow: auto;\n}\n\n/**\n * 1. Add the correct box sizing in IE 10.\n * 2. Remove the padding in IE 10.\n */\n\n[type=\"checkbox\"],\n[type=\"radio\"] {\n  box-sizing: border-box; /* 1 */\n  padding: 0; /* 2 */\n}\n\n/**\n * Correct the cursor style of increment and decrement buttons in Chrome.\n */\n\n[type=\"number\"]::-webkit-inner-spin-button,\n[type=\"number\"]::-webkit-outer-spin-button {\n  height: auto;\n}\n\n/**\n * 1. Correct the odd appearance in Chrome and Safari.\n * 2. Correct the outline style in Safari.\n */\n\n[type=\"search\"] {\n  -webkit-appearance: textfield; /* 1 */\n  outline-offset: -2px; /* 2 */\n}\n\n/**\n * Remove the inner padding in Chrome and Safari on macOS.\n */\n\n[type=\"search\"]::-webkit-search-decoration {\n  -webkit-appearance: none;\n}\n\n/**\n * 1. Correct the inability to style clickable types in iOS and Safari.\n * 2. Change font properties to `inherit` in Safari.\n */\n\n::-webkit-file-upload-button {\n  -webkit-appearance: button; /* 1 */\n  font: inherit; /* 2 */\n}\n\n/* Interactive\n   ========================================================================== */\n\n/*\n * Add the correct display in Edge, IE 10+, and Firefox.\n */\n\ndetails {\n  display: block;\n}\n\n/*\n * Add the correct display in all browsers.\n */\n\nsummary {\n  display: list-item;\n}\n\n/* Misc\n   ========================================================================== */\n\n/**\n * Add the correct display in IE 10+.\n */\n\ntemplate {\n  display: none;\n}\n\n/**\n * Add the correct display in IE 10.\n */\n\n[hidden] {\n  display: none;\n}\n\n\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-07T18:55:45.225Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "npm build",
      "content": "# Npm Build\nhttps://docs.npmjs.com/cli/v6/commands/npm-build\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:39:18.969Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "package.json.md",
      "content": "```json\n{\n  \"name\": \"dataroom\",\n  \"version\": \"0.5.0\",\n  \"type\": \"module\",\n  \"description\": \"LLM Aware Semantic Web editor\",\n  \"main\": \"server.js\",\n  \"directories\": {\n    \"doc\": \"docs\"\n  },\n  \"scripts\": {\n    \"test\": \"mocha\",\n    \"start\": \"bun run --watch server.js\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+ssh://git@github.com/DATAROOM-NETWORK/dataroom.git\"\n  },\n  \"keywords\": [\n    \"Semantic\",\n    \"Web\",\n    \"AI\"\n  ],\n  \"author\": \"LNSY\",\n  \"license\": \"ISC\",\n  \"bugs\": {\n    \"url\": \"https://github.com/DATAROOM-NETWORK/dataroom/issues\"\n  },\n  \"homepage\": \"https://github.com/DATAROOM-NETWORK/dataroom#readme\",\n  \"dependencies\": {\n    \"body-parser\": \"^1.20.2\",\n    \"chokidar\": \"^3.5.3\",\n    \"dotenv\": \"^16.3.1\",\n    \"express\": \"^4.18.2\",\n    \"mysql2\": \"^3.7.0\",\n    \"natural\": \"^6.10.4\",\n    \"nocache\": \"^4.0.0\",\n    \"sqlite\": \"^5.1.1\"\n  }\n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T18:22:15.749Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "persistent checkbox",
      "content": "```js\nclass PersistentCheckbox extends HTMLElement {\n  connectedCallback(){\n    const label = this.innerText;\n    this.id = this.getAttribute('id');\n    if(this.id === null){\n      this.innerHTML = \"<error>ID required</error>\";\n    }\n    this.toggled_class = this.getAttribute('toggle-class');\n    let value = localStorage.getItem(this.id);\n    if(value === null){\n      value = false\n      localStorage.setItem(this.id, value);\n    }\n    this.innerHTML = `<label>${label}<input type=\"checkbox\" id=\"${this.id}-checkbox\" value=\"false\"></label>`\n    const inp = this.querySelector(`#${this.id}-checkbox`);\n    inp.checked = JSON.parse(value);\n    inp.addEventListener('change', (e) => {\n      localStorage.setItem(this.id, inp.checked);\n      this.handleChange(inp.checked);\n    });\n    this.handleChange(JSON.parse(value));\n  }\n\n  handleChange(checked){\n    if(checked){\n      document.body.classList.add(this.toggled_class);\n    } else {\n      document.body.classList.remove(this.toggled_class);\n    }\n  }\n\n\n}\n\ncustomElements.define('persistent-checkbox', PersistentCheckbox)\n```\n\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:12:16.818Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "phone-number-check",
      "content": "```js\nconst valid_phone_numbers = ['3235469773', '13235469773']\n\nfunction isValidPhoneNumber(phone_number){\n  return new Promise((respond, reject) => {\n    if(valid_phone_numbers.indexOf(phone_number) > -1){\n      respond(true)\n    } else {\n      reject(new Error('CANNOT FIND PHONE NUMBER IN DATABASE'))\n    }\n  })\n}\n\nmodule.exports = isValidPhoneNumber\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-13T19:08:03.772Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "pipe a man command to a markdown file",
      "content": "```bash\nman screen | col -b > screen_manual.md\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-11-13T19:17:11.991Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "pochade-web-framework",
      "content": "https://webpack.js.org/plugins/ignore-plugin/\nidea: exclude dev components\ndev vs production compoennt\n\n[[952abb65f7b7cbc3451536cbfa78e05e_MD5.png|Open: Pasted image 20231107112224.png]]\n![[952abb65f7b7cbc3451536cbfa78e05e_MD5.png]]\nTwo templates to read from: \n\n```js\nconst fs = require('fs');\nconst path = require('path');\n\n// Define the path to the folder you want to delete\nconst folderPath = '/path/to/your/folder';\n\n// Use the fs.rm() method to recursively remove the folder\nfs.rm(folderPath, { recursive: true }, (err) => {\n  if (err) {\n    console.error(`Error deleting folder: ${err.message}`);\n  } else {\n    console.log(`Folder \"${folderPath}\" has been deleted.`);\n  }\n});\n\n```\n\n```js\nconst fs = require('fs');\n\n// Function to remove lines containing a specific string from a file\nfunction removeLinesMatchingString(filePath, stringToRemove) {\n  fs.readFile(filePath, 'utf8', (err, data) => {\n    if (err) {\n      console.error(`Error reading file: ${err.message}`);\n      return;\n    }\n\n    // Split the file content into an array of lines\n    const lines = data.split('\\n');\n\n    // Filter out lines that don't contain the string to remove\n    const filteredLines = lines.filter((line) => !line.includes(stringToRemove));\n\n    // Join the filtered lines back into a single string\n    const updatedContent = filteredLines.join('\\n');\n\n    // Write the updated content back to the file\n    fs.writeFile(filePath, updatedContent, 'utf8', (err) => {\n      if (err) {\n        console.error(`Error writing file: ${err.message}`);\n      } else {\n        console.log(`Removed lines containing \"${stringToRemove}\" from ${filePath}`);\n      }\n    });\n  });\n}\n\n// Usage example\nconst filePath = 'path/to/your/file.txt'; // Replace with the path to your file\nconst stringToRemove = 'string-to-remove'; // Replace with the string you want to remove\n\nremoveLinesMatchingString(filePath, stringToRemove);\n\n```\n\n---\n\n# Directory List\n\n```js\n/**\n * Gets all folders in a sub folder\n * @param  {[type]} folderPath [description]\n * @return {[type]}            [description]\n */\nfunction getDirectoriesInSubfolder(folderPath = './component-templates') {\n  // Create an empty array to store the directory paths.\n  const directories = [];\n\n  // This is a recursive function that traverses directories and collects directory paths.\n  function collectDirectories(dir) {\n    // Read the contents of the current directory and store them in the 'files' array.\n    const files = fs.readdirSync(dir);\n\n    // Iterate through each file in the 'files' array.\n    for (const file of files) {\n      // Create the full path to the current file.\n      const filePath = path.join(dir, file);\n\n      // Check if the current file is a directory.\n      const isDirectory = fs.statSync(filePath).isDirectory();\n\n      // If the current file is a directory, add its path to the 'directories' array.\n      if (isDirectory) {\n        directories.push(filePath);\n\n        // Recursively call the 'collectDirectories' function to explore subdirectories.\n        collectDirectories(filePath);\n      }\n    }\n  }\n\n  // Start collecting directories by calling the 'collectDirectories' function with the provided folder path.\n  collectDirectories(folderPath);\n\n  // Return the array containing all the directory paths.\n  return directories;\n}\n\n```\n\n```js\n    const directories = getDirectoriesInSubfolder().map(d => {\n      return d.split('/').pop();\n    });\n\n    const directories_list = directories.map((d,i) => {\n      return `${i}: ${d}`\n    });\n    console.log(directories_list);\n    rl.close();\n    return\n\n```\n\n[[Stable Diffusion Component]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-06-18T13:59:02.605Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "printed-books",
      "content": "[[annurev-polisci-051120-013649.pdf]]\nExperiments and Surveys on Political Elites\n\npolitical elites, elite experiments, elite surveys\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-08T03:40:33.898Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "programming-2024-02-07",
      "content": "https://github.com/devidw/tabgod\n\n"
    },
    {
      "tags": [],
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T19:40:36.645Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "programming",
      "content": "\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-17T20:33:22.016Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "project-system",
      "content": "Project system lists current projects\nand 1 line notes.\n\n1 line notes can extract hashtags\n\nwhen project loads,\n\nfresh html page with link, \n\nlink happens, \n\nall javascript reloads\nall html reloads\n\nassuming node.js, write a script that takes html, and if it is of a specific tag, for instance \n```html\n<h-data value=\"56\"></h-data>\n```\n\nit parses the XML object into a JavaScript Object\n\n\n\nHere is an example script in Node.js that takes an HTML file as input and searches for a specific tag:\n\n\n```javascript\n\nconst fs = require('fs');\n\nconst xml2js = require('xml2js');\n\n\nconst parser = new xml2js.Parser();\n\n\n// Read the input file as a string\n\nconst inputFile = process.argv[2];\n\nconst inputString = fs.readFileSync(inputFile, 'utf8');\n\n\n// Search for tags with the specified name\n\nconst tagName = 'h-data';\n\nconst tagAttrs = {\n\n  value: ''\n\n};\n\n\nconst output = [];\n\n\nparser.parseString(inputString, (err, result) => {\n\n  if (err) {\n\n    console.error(err);\n\n    return;\n\n  }\n\n\n  const tags = result.getElementsByTagName(tagName);\n\n\n  for (let i = 0; i < tags.length; i++) {\n\n    const tag = tags[i];\n\n\n    // Check if this tag has the specified attributes\n\n    let match = true;\n\n    for (const [key, value] of Object.entries(tagAttrs)) {\n\n      if (!tag.hasAttribute(key) || value !== '' && tag.getAttribute(key) !== value) {\n\n        match = false;\n\n        break;\n\n      }\n\n    }\n\n\n    // Parse the tag into a JavaScript object and add it to the output\n\n    if (match) {\n\n      const object = {};\n\n      for (const attr of tag.attributes) {\n\n        object[attr.name] = attr.value;\n\n      }\n\n      output.push(object);\n\n    }\n\n  }\n\n\n  console.log(output);\n\n});\n\n```\n\n\nThis script uses the `xml2js` library to parse the HTML file as an XML object and search for tags with the specified name and attributes. It then converts each matching tag into a JavaScript object and adds it to the output array. Finally, the script outputs the array of JavaScript objects.\n\n\nTo run this script, you will need to have Node.js and the `xml2js` library installed. You can install the library by running `npm install xml2js`. You can then run the script using the following command:\n\n```\n\nnode parse-html.js input.html\n\n```\n\nwhere `parse-html.js` is the name of the script file and `input.html` is the name of the input file.\n\nthis parsed object helps generate the html page -- that is output\n\nany file downloaded goes to the open project\n\nbrowser plugin in firefox that allows user to add to different project. Maybe add to project drop down?\n\n\"polite mode\" -- keep personal data separate, don't even show it\n\n\n\nhtml is served with self signed certificate\n\n\n\t, it would do a specific thing\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-04-02T06:04:55.427Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "pydeck",
      "content": "\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-15T21:47:08.031Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "record div component",
      "content": "\n```javascript\nclass recordDiv extends HTMLElement {\n  connectedCallback(){\n    const style_tag = document.createElement('style')\n    style_tag.innerText = `\n      record-div {\n        display: block;\n        padding: 1em;\n        sizing:box;\n      }\n    `\n    this.appendChild(style_tag)\n  }\n\n  getImage(){\n    domtoimage.toPng(this)\n    .then(function(dataUrl){\n      var img = new Image();\n      img.src = dataUrl;\n      document.body.appendChild(img);\n    })\n  }\n}\n\ncustomElements.define('record-div', recordDiv)\n\n\n```\n\n```javascript\n\n(function (global) {\n    'use strict';\n\n    var util = newUtil();\n    var inliner = newInliner();\n    var fontFaces = newFontFaces();\n    var images = newImages();\n\n    // Default impl options\n    var defaultOptions = {\n        // Default is to fail on error, no placeholder\n        imagePlaceholder: undefined,\n        // Default cache bust is false, it will use the cache\n        cacheBust: false\n    };\n\n    var domtoimage = {\n        toSvg: toSvg,\n        toPng: toPng,\n        toJpeg: toJpeg,\n        toBlob: toBlob,\n        toPixelData: toPixelData,\n        impl: {\n            fontFaces: fontFaces,\n            images: images,\n            util: util,\n            inliner: inliner,\n            options: {}\n        }\n    };\n\n    if (typeof module !== 'undefined')\n        module.exports = domtoimage;\n    else\n        global.domtoimage = domtoimage;\n\n\n    /**\n     * @param {Node} node - The DOM Node object to render\n     * @param {Object} options - Rendering options\n     * @param {Function} options.filter - Should return true if passed node should be included in the output\n     *          (excluding node means excluding it's children as well). Not called on the root node.\n     * @param {String} options.bgcolor - color for the background, any valid CSS color value.\n     * @param {Number} options.width - width to be applied to node before rendering.\n     * @param {Number} options.height - height to be applied to node before rendering.\n     * @param {Object} options.style - an object whose properties to be copied to node's style before rendering.\n     * @param {Number} options.quality - a Number between 0 and 1 indicating image quality (applicable to JPEG only),\n                defaults to 1.0.\n     * @param {String} options.imagePlaceholder - dataURL to use as a placeholder for failed images, default behaviour is to fail fast on images we can't fetch\n     * @param {Boolean} options.cacheBust - set to true to cache bust by appending the time to the request url\n     * @return {Promise} - A promise that is fulfilled with a SVG image data URL\n     * */\n    function toSvg(node, options) {\n        options = options || {};\n        copyOptions(options);\n        return Promise.resolve(node)\n            .then(function (node) {\n                return cloneNode(node, options.filter, true);\n            })\n            .then(embedFonts)\n            .then(inlineImages)\n            .then(applyOptions)\n            .then(function (clone) {\n                return makeSvgDataUri(clone,\n                    options.width || util.width(node),\n                    options.height || util.height(node)\n                );\n            });\n\n        function applyOptions(clone) {\n            if (options.bgcolor) clone.style.backgroundColor = options.bgcolor;\n\n            if (options.width) clone.style.width = options.width + 'px';\n            if (options.height) clone.style.height = options.height + 'px';\n\n            if (options.style)\n                Object.keys(options.style).forEach(function (property) {\n                    clone.style[property] = options.style[property];\n                });\n\n            return clone;\n        }\n    }\n\n    /**\n     * @param {Node} node - The DOM Node object to render\n     * @param {Object} options - Rendering options, @see {@link toSvg}\n     * @return {Promise} - A promise that is fulfilled with a Uint8Array containing RGBA pixel data.\n     * */\n    function toPixelData(node, options) {\n        return draw(node, options || {})\n            .then(function (canvas) {\n                return canvas.getContext('2d').getImageData(\n                    0,\n                    0,\n                    util.width(node),\n                    util.height(node)\n                ).data;\n            });\n    }\n\n    /**\n     * @param {Node} node - The DOM Node object to render\n     * @param {Object} options - Rendering options, @see {@link toSvg}\n     * @return {Promise} - A promise that is fulfilled with a PNG image data URL\n     * */\n    function toPng(node, options) {\n        return draw(node, options || {})\n            .then(function (canvas) {\n                return canvas.toDataURL();\n            });\n    }\n\n    /**\n     * @param {Node} node - The DOM Node object to render\n     * @param {Object} options - Rendering options, @see {@link toSvg}\n     * @return {Promise} - A promise that is fulfilled with a JPEG image data URL\n     * */\n    function toJpeg(node, options) {\n        options = options || {};\n        return draw(node, options)\n            .then(function (canvas) {\n                return canvas.toDataURL('image/jpeg', options.quality || 1.0);\n            });\n    }\n\n    /**\n     * @param {Node} node - The DOM Node object to render\n     * @param {Object} options - Rendering options, @see {@link toSvg}\n     * @return {Promise} - A promise that is fulfilled with a PNG image blob\n     * */\n    function toBlob(node, options) {\n        return draw(node, options || {})\n            .then(util.canvasToBlob);\n    }\n\n    function copyOptions(options) {\n        // Copy options to impl options for use in impl\n        if(typeof(options.imagePlaceholder) === 'undefined') {\n            domtoimage.impl.options.imagePlaceholder = defaultOptions.imagePlaceholder;\n        } else {\n            domtoimage.impl.options.imagePlaceholder = options.imagePlaceholder;\n        }\n\n        if(typeof(options.cacheBust) === 'undefined') {\n            domtoimage.impl.options.cacheBust = defaultOptions.cacheBust;\n        } else {\n            domtoimage.impl.options.cacheBust = options.cacheBust;\n        }\n    }\n\n    function draw(domNode, options) {\n        return toSvg(domNode, options)\n            .then(util.makeImage)\n            .then(util.delay(100))\n            .then(function (image) {\n                var canvas = newCanvas(domNode);\n                canvas.getContext('2d').drawImage(image, 0, 0);\n                return canvas;\n            });\n\n        function newCanvas(domNode) {\n            var canvas = document.createElement('canvas');\n            canvas.width = options.width || util.width(domNode);\n            canvas.height = options.height || util.height(domNode);\n\n            if (options.bgcolor) {\n                var ctx = canvas.getContext('2d');\n                ctx.fillStyle = options.bgcolor;\n                ctx.fillRect(0, 0, canvas.width, canvas.height);\n            }\n\n            return canvas;\n        }\n    }\n\n    function cloneNode(node, filter, root) {\n        if (!root && filter && !filter(node)) return Promise.resolve();\n\n        return Promise.resolve(node)\n            .then(makeNodeCopy)\n            .then(function (clone) {\n                return cloneChildren(node, clone, filter);\n            })\n            .then(function (clone) {\n                return processClone(node, clone);\n            });\n\n        function makeNodeCopy(node) {\n            if (node instanceof HTMLCanvasElement) return util.makeImage(node.toDataURL());\n            return node.cloneNode(false);\n        }\n\n        function cloneChildren(original, clone, filter) {\n            var children = original.childNodes;\n            if (children.length === 0) return Promise.resolve(clone);\n\n            return cloneChildrenInOrder(clone, util.asArray(children), filter)\n                .then(function () {\n                    return clone;\n                });\n\n            function cloneChildrenInOrder(parent, children, filter) {\n                var done = Promise.resolve();\n                children.forEach(function (child) {\n                    done = done\n                        .then(function () {\n                            return cloneNode(child, filter);\n                        })\n                        .then(function (childClone) {\n                            if (childClone) parent.appendChild(childClone);\n                        });\n                });\n                return done;\n            }\n        }\n\n        function processClone(original, clone) {\n            if (!(clone instanceof Element)) return clone;\n\n            return Promise.resolve()\n                .then(cloneStyle)\n                .then(clonePseudoElements)\n                .then(copyUserInput)\n                .then(fixSvg)\n                .then(function () {\n                    return clone;\n                });\n\n            function cloneStyle() {\n                copyStyle(window.getComputedStyle(original), clone.style);\n\n                function copyStyle(source, target) {\n                    if (source.cssText) target.cssText = source.cssText;\n                    else copyProperties(source, target);\n\n                    function copyProperties(source, target) {\n                        util.asArray(source).forEach(function (name) {\n                            target.setProperty(\n                                name,\n                                source.getPropertyValue(name),\n                                source.getPropertyPriority(name)\n                            );\n                        });\n                    }\n                }\n            }\n\n            function clonePseudoElements() {\n                [':before', ':after'].forEach(function (element) {\n                    clonePseudoElement(element);\n                });\n\n                function clonePseudoElement(element) {\n                    var style = window.getComputedStyle(original, element);\n                    var content = style.getPropertyValue('content');\n\n                    if (content === '' || content === 'none') return;\n\n                    var className = util.uid();\n                    clone.className = clone.className + ' ' + className;\n                    var styleElement = document.createElement('style');\n                    styleElement.appendChild(formatPseudoElementStyle(className, element, style));\n                    clone.appendChild(styleElement);\n\n                    function formatPseudoElementStyle(className, element, style) {\n                        var selector = '.' + className + ':' + element;\n                        var cssText = style.cssText ? formatCssText(style) : formatCssProperties(style);\n                        return document.createTextNode(selector + '{' + cssText + '}');\n\n                        function formatCssText(style) {\n                            var content = style.getPropertyValue('content');\n                            return style.cssText + ' content: ' + content + ';';\n                        }\n\n                        function formatCssProperties(style) {\n\n                            return util.asArray(style)\n                                .map(formatProperty)\n                                .join('; ') + ';';\n\n                            function formatProperty(name) {\n                                return name + ': ' +\n                                    style.getPropertyValue(name) +\n                                    (style.getPropertyPriority(name) ? ' !important' : '');\n                            }\n                        }\n                    }\n                }\n            }\n\n            function copyUserInput() {\n                if (original instanceof HTMLTextAreaElement) clone.innerHTML = original.value;\n                if (original instanceof HTMLInputElement) clone.setAttribute(\"value\", original.value);\n            }\n\n            function fixSvg() {\n                if (!(clone instanceof SVGElement)) return;\n                clone.setAttribute('xmlns', 'http://www.w3.org/2000/svg');\n\n                if (!(clone instanceof SVGRectElement)) return;\n                ['width', 'height'].forEach(function (attribute) {\n                    var value = clone.getAttribute(attribute);\n                    if (!value) return;\n\n                    clone.style.setProperty(attribute, value);\n                });\n            }\n        }\n    }\n\n    function embedFonts(node) {\n        return fontFaces.resolveAll()\n            .then(function (cssText) {\n                var styleNode = document.createElement('style');\n                node.appendChild(styleNode);\n                styleNode.appendChild(document.createTextNode(cssText));\n                return node;\n            });\n    }\n\n    function inlineImages(node) {\n        return images.inlineAll(node)\n            .then(function () {\n                return node;\n            });\n    }\n\n    function makeSvgDataUri(node, width, height) {\n        return Promise.resolve(node)\n            .then(function (node) {\n                node.setAttribute('xmlns', 'http://www.w3.org/1999/xhtml');\n                return new XMLSerializer().serializeToString(node);\n            })\n            .then(util.escapeXhtml)\n            .then(function (xhtml) {\n                return '<foreignObject x=\"0\" y=\"0\" width=\"100%\" height=\"100%\">' + xhtml + '</foreignObject>';\n            })\n            .then(function (foreignObject) {\n                return '<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"' + width + '\" height=\"' + height + '\">' +\n                    foreignObject + '</svg>';\n            })\n            .then(function (svg) {\n                return 'data:image/svg+xml;charset=utf-8,' + svg;\n            });\n    }\n\n    function newUtil() {\n        return {\n            escape: escape,\n            parseExtension: parseExtension,\n            mimeType: mimeType,\n            dataAsUrl: dataAsUrl,\n            isDataUrl: isDataUrl,\n            canvasToBlob: canvasToBlob,\n            resolveUrl: resolveUrl,\n            getAndEncode: getAndEncode,\n            uid: uid(),\n            delay: delay,\n            asArray: asArray,\n            escapeXhtml: escapeXhtml,\n            makeImage: makeImage,\n            width: width,\n            height: height\n        };\n\n        function mimes() {\n            /*\n             * Only WOFF and EOT mime types for fonts are 'real'\n             * see http://www.iana.org/assignments/media-types/media-types.xhtml\n             */\n            var WOFF = 'application/font-woff';\n            var JPEG = 'image/jpeg';\n\n            return {\n                'woff': WOFF,\n                'woff2': WOFF,\n                'ttf': 'application/font-truetype',\n                'eot': 'application/vnd.ms-fontobject',\n                'png': 'image/png',\n                'jpg': JPEG,\n                'jpeg': JPEG,\n                'gif': 'image/gif',\n                'tiff': 'image/tiff',\n                'svg': 'image/svg+xml'\n            };\n        }\n\n        function parseExtension(url) {\n            var match = /\\.([^\\.\\/]*?)$/g.exec(url);\n            if (match) return match[1];\n            else return '';\n        }\n\n        function mimeType(url) {\n            var extension = parseExtension(url).toLowerCase();\n            return mimes()[extension] || '';\n        }\n\n        function isDataUrl(url) {\n            return url.search(/^(data:)/) !== -1;\n        }\n\n        function toBlob(canvas) {\n            return new Promise(function (resolve) {\n                var binaryString = window.atob(canvas.toDataURL().split(',')[1]);\n                var length = binaryString.length;\n                var binaryArray = new Uint8Array(length);\n\n                for (var i = 0; i < length; i++)\n                    binaryArray[i] = binaryString.charCodeAt(i);\n\n                resolve(new Blob([binaryArray], {\n                    type: 'image/png'\n                }));\n            });\n        }\n\n        function canvasToBlob(canvas) {\n            if (canvas.toBlob)\n                return new Promise(function (resolve) {\n                    canvas.toBlob(resolve);\n                });\n\n            return toBlob(canvas);\n        }\n\n        function resolveUrl(url, baseUrl) {\n            var doc = document.implementation.createHTMLDocument();\n            var base = doc.createElement('base');\n            doc.head.appendChild(base);\n            var a = doc.createElement('a');\n            doc.body.appendChild(a);\n            base.href = baseUrl;\n            a.href = url;\n            return a.href;\n        }\n\n        function uid() {\n            var index = 0;\n\n            return function () {\n                return 'u' + fourRandomChars() + index++;\n\n                function fourRandomChars() {\n                    /* see http://stackoverflow.com/a/6248722/2519373 */\n                    return ('0000' + (Math.random() * Math.pow(36, 4) << 0).toString(36)).slice(-4);\n                }\n            };\n        }\n\n        function makeImage(uri) {\n            return new Promise(function (resolve, reject) {\n                var image = new Image();\n                image.onload = function () {\n                    resolve(image);\n                };\n                image.onerror = reject;\n                image.src = uri;\n            });\n        }\n\n        function getAndEncode(url) {\n            var TIMEOUT = 30000;\n            if(domtoimage.impl.options.cacheBust) {\n                // Cache bypass so we dont have CORS issues with cached images\n                // Source: https://developer.mozilla.org/en/docs/Web/API/XMLHttpRequest/Using_XMLHttpRequest#Bypassing_the_cache\n                url += ((/\\?/).test(url) ? \"&\" : \"?\") + (new Date()).getTime();\n            }\n\n            return new Promise(function (resolve) {\n                var request = new XMLHttpRequest();\n\n                request.onreadystatechange = done;\n                request.ontimeout = timeout;\n                request.responseType = 'blob';\n                request.timeout = TIMEOUT;\n                request.open('GET', url, true);\n                request.send();\n\n                var placeholder;\n                if(domtoimage.impl.options.imagePlaceholder) {\n                    var split = domtoimage.impl.options.imagePlaceholder.split(/,/);\n                    if(split && split[1]) {\n                        placeholder = split[1];\n                    }\n                }\n\n                function done() {\n                    if (request.readyState !== 4) return;\n\n                    if (request.status !== 200) {\n                        if(placeholder) {\n                            resolve(placeholder);\n                        } else {\n                            fail('cannot fetch resource: ' + url + ', status: ' + request.status);\n                        }\n\n                        return;\n                    }\n\n                    var encoder = new FileReader();\n                    encoder.onloadend = function () {\n                        var content = encoder.result.split(/,/)[1];\n                        resolve(content);\n                    };\n                    encoder.readAsDataURL(request.response);\n                }\n\n                function timeout() {\n                    if(placeholder) {\n                        resolve(placeholder);\n                    } else {\n                        fail('timeout of ' + TIMEOUT + 'ms occured while fetching resource: ' + url);\n                    }\n                }\n\n                function fail(message) {\n                    console.error(message);\n                    resolve('');\n                }\n            });\n        }\n\n        function dataAsUrl(content, type) {\n            return 'data:' + type + ';base64,' + content;\n        }\n\n        function escape(string) {\n            return string.replace(/([.*+?^${}()|\\[\\]\\/\\\\])/g, '\\\\$1');\n        }\n\n        function delay(ms) {\n            return function (arg) {\n                return new Promise(function (resolve) {\n                    setTimeout(function () {\n                        resolve(arg);\n                    }, ms);\n                });\n            };\n        }\n\n        function asArray(arrayLike) {\n            var array = [];\n            var length = arrayLike.length;\n            for (var i = 0; i < length; i++) array.push(arrayLike[i]);\n            return array;\n        }\n\n        function escapeXhtml(string) {\n            return string.replace(/#/g, '%23').replace(/\\n/g, '%0A');\n        }\n\n        function width(node) {\n            var leftBorder = px(node, 'border-left-width');\n            var rightBorder = px(node, 'border-right-width');\n            return node.scrollWidth + leftBorder + rightBorder;\n        }\n\n        function height(node) {\n            var topBorder = px(node, 'border-top-width');\n            var bottomBorder = px(node, 'border-bottom-width');\n            return node.scrollHeight + topBorder + bottomBorder;\n        }\n\n        function px(node, styleProperty) {\n            var value = window.getComputedStyle(node).getPropertyValue(styleProperty);\n            return parseFloat(value.replace('px', ''));\n        }\n    }\n\n    function newInliner() {\n        var URL_REGEX = /url\\(['\"]?([^'\"]+?)['\"]?\\)/g;\n\n        return {\n            inlineAll: inlineAll,\n            shouldProcess: shouldProcess,\n            impl: {\n                readUrls: readUrls,\n                inline: inline\n            }\n        };\n\n        function shouldProcess(string) {\n            return string.search(URL_REGEX) !== -1;\n        }\n\n        function readUrls(string) {\n            var result = [];\n            var match;\n            while ((match = URL_REGEX.exec(string)) !== null) {\n                result.push(match[1]);\n            }\n            return result.filter(function (url) {\n                return !util.isDataUrl(url);\n            });\n        }\n\n        function inline(string, url, baseUrl, get) {\n            return Promise.resolve(url)\n                .then(function (url) {\n                    return baseUrl ? util.resolveUrl(url, baseUrl) : url;\n                })\n                .then(get || util.getAndEncode)\n                .then(function (data) {\n                    return util.dataAsUrl(data, util.mimeType(url));\n                })\n                .then(function (dataUrl) {\n                    return string.replace(urlAsRegex(url), '$1' + dataUrl + '$3');\n                });\n\n            function urlAsRegex(url) {\n                return new RegExp('(url\\\\([\\'\"]?)(' + util.escape(url) + ')([\\'\"]?\\\\))', 'g');\n            }\n        }\n\n        function inlineAll(string, baseUrl, get) {\n            if (nothingToInline()) return Promise.resolve(string);\n\n            return Promise.resolve(string)\n                .then(readUrls)\n                .then(function (urls) {\n                    var done = Promise.resolve(string);\n                    urls.forEach(function (url) {\n                        done = done.then(function (string) {\n                            return inline(string, url, baseUrl, get);\n                        });\n                    });\n                    return done;\n                });\n\n            function nothingToInline() {\n                return !shouldProcess(string);\n            }\n        }\n    }\n\n    function newFontFaces() {\n        return {\n            resolveAll: resolveAll,\n            impl: {\n                readAll: readAll\n            }\n        };\n\n        function resolveAll() {\n            return readAll(document)\n                .then(function (webFonts) {\n                    return Promise.all(\n                        webFonts.map(function (webFont) {\n                            return webFont.resolve();\n                        })\n                    );\n                })\n                .then(function (cssStrings) {\n                    return cssStrings.join('\\n');\n                });\n        }\n\n        function readAll() {\n            return Promise.resolve(util.asArray(document.styleSheets))\n                .then(getCssRules)\n                .then(selectWebFontRules)\n                .then(function (rules) {\n                    return rules.map(newWebFont);\n                });\n\n            function selectWebFontRules(cssRules) {\n                return cssRules\n                    .filter(function (rule) {\n                        return rule.type === CSSRule.FONT_FACE_RULE;\n                    })\n                    .filter(function (rule) {\n                        return inliner.shouldProcess(rule.style.getPropertyValue('src'));\n                    });\n            }\n\n            function getCssRules(styleSheets) {\n                var cssRules = [];\n                styleSheets.forEach(function (sheet) {\n                    try {\n                        util.asArray(sheet.cssRules || []).forEach(cssRules.push.bind(cssRules));\n                    } catch (e) {\n                        console.log('Error while reading CSS rules from ' + sheet.href, e.toString());\n                    }\n                });\n                return cssRules;\n            }\n\n            function newWebFont(webFontRule) {\n                return {\n                    resolve: function resolve() {\n                        var baseUrl = (webFontRule.parentStyleSheet || {}).href;\n                        return inliner.inlineAll(webFontRule.cssText, baseUrl);\n                    },\n                    src: function () {\n                        return webFontRule.style.getPropertyValue('src');\n                    }\n                };\n            }\n        }\n    }\n\n    function newImages() {\n        return {\n            inlineAll: inlineAll,\n            impl: {\n                newImage: newImage\n            }\n        };\n\n        function newImage(element) {\n            return {\n                inline: inline\n            };\n\n            function inline(get) {\n                if (util.isDataUrl(element.src)) return Promise.resolve();\n\n                return Promise.resolve(element.src)\n                    .then(get || util.getAndEncode)\n                    .then(function (data) {\n                        return util.dataAsUrl(data, util.mimeType(element.src));\n                    })\n                    .then(function (dataUrl) {\n                        return new Promise(function (resolve, reject) {\n                            element.onload = resolve;\n                            element.onerror = reject;\n                            element.src = dataUrl;\n                        });\n                    });\n            }\n        }\n\n        function inlineAll(node) {\n            if (!(node instanceof Element)) return Promise.resolve(node);\n\n            return inlineBackground(node)\n                .then(function () {\n                    if (node instanceof HTMLImageElement)\n                        return newImage(node).inline();\n                    else\n                        return Promise.all(\n                            util.asArray(node.childNodes).map(function (child) {\n                                return inlineAll(child);\n                            })\n                        );\n                });\n\n            function inlineBackground(node) {\n                var background = node.style.getPropertyValue('background');\n\n                if (!background) return Promise.resolve(node);\n\n                return inliner.inlineAll(background)\n                    .then(function (inlined) {\n                        node.style.setProperty(\n                            'background',\n                            inlined,\n                            node.style.getPropertyPriority('background')\n                        );\n                    })\n                    .then(function () {\n                        return node;\n                    });\n            }\n        }\n    }\n})(this);\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-13T18:27:54.278Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "recursive folder of files",
      "content": "> hey chat, assuming node.js, and mongodb write a script that recursively steps through a folder of markdown files and upserts each file to mongodb. the path of each file should be split and added as tags to each mongodb entry\n\nCertainly! Here's an example script that recursively steps through a folder of markdown files, reads each file, and upserts it into MongoDB. The path of each file is split, and the resulting tags are added to each MongoDB entry as an array.\n\nPlease make sure you have the `mongodb` and `fs` modules installed by running `npm install mongodb fs`.\n\n```js\nconst fs = require('fs');\nconst { MongoClient } = require('mongodb');\nconst { promisify } = require('util');\n\nconst readFileAsync = promisify(fs.readFile);\n\nconst mongoURL = 'mongodb://localhost:27017';\nconst dbName = 'your_database_name';\nconst collectionName = 'your_collection_name';\nconst folderPath = '/path/to/markdown/files/';\n\nasync function upsertMarkdownFiles(folderPath, tags = []) {\n  const client = new MongoClient(mongoURL);\n\n  try {\n    await client.connect();\n    const db = client.db(dbName);\n    const collection = db.collection(collectionName);\n\n    const files = fs.readdirSync(folderPath);\n\n    for (const file of files) {\n      const filePath = `${folderPath}/${file}`;\n      const stat = fs.statSync(filePath);\n\n      if (stat.isDirectory()) {\n        const subFolder = `${folderPath}/${file}`;\n        const subTags = [...tags, file];\n        await upsertMarkdownFiles(subFolder, subTags);\n      } else if (file.endsWith('.md')) {\n        const data = await readFileAsync(filePath, 'utf8');\n        const entry = {\n          content: data,\n          tags: tags\n        };\n        const query = { tags: { $all: tags } };\n        const options = { upsert: true };\n\n        await collection.updateOne(query, { $set: entry }, options);\n        console.log(`Upserted file: ${filePath}`);\n      }\n    }\n  } catch (err) {\n    console.error('Error:', err);\n  } finally {\n    client.close();\n  }\n}\n\nupsertMarkdownFiles(folderPath);\n\n```\n\nMake sure to replace `'mongodb://localhost:27017'` with your MongoDB connection URL, `'your_database_name'` with the name of your database, and `'your_collection_name'` with the name of the collection where you want to upsert the markdown files.\n\nThe script reads each markdown file using `fs.readFile`, splits the file path to generate tags, and performs an upsert operation using `collection.updateOne`. The `upsertMarkdownFiles` function is recursive, allowing it to handle subfolders as well.\n\nRemember to adjust the `folderPath` variable to point to the correct directory containing your markdown files.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:51:36.859Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "renderer",
      "content": "\n## routes.js\n```js\n// Import necessary modules\nimport fs from 'fs';\nimport path from 'path';\n\nexport default function (app) {\n  app.get('/:fileName/:view?', (req, res) => {\n    // Extract fileName and view from route parameters\n    const { fileName, view } = req.params;\n\n    // Define the default view if :view parameter is not provided\n    const renderedView = view || 'default';\n\n    // Define the file path based on the view name\n    const filePath = path.join(global.root_directory, 'renderer', `${renderedView}.html`);\n\n\n    // Check if the file exists\n    if (fs.existsSync(filePath)) {\n      // Read the file content\n      let fileContent = fs.readFileSync(filePath, 'utf-8');\n\n      // Replace variables in the file content\n      fileContent = fileContent.replace(/\\$\\{fileName\\}/g, fileName);\n\n      // Send the modified content as the response\n      res.send(fileContent);\n    } else {\n      // If the file doesn't exist, send a 404 response\n      res.status(404).send('View not found.');\n    }\n  });\n}\n\n```\n\n## default.html\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n  <title>${fileName}</title>\n  <script src=\"/index.js\" type=\"module\" defer></script>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"/index.css\">\n</head>\n<body>\n<mark-down dtrm-id=\"${fileName}\"></mark-down>\n</body>\n</html>\n\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-17T00:23:24.909Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "run node.js script on startup",
      "content": "]\n1. Setting up an init script or using a package manager like systemd or upstart:\n\n\n- On Ubuntu 16.04 or later, the most common way to run a Node.js script on startup is to use systemd. To create a systemd service file, first create a new file at /etc/systemd/system/ with the .service extension, such as myscript.service. \n\n\n- In this file, the basic syntax for a systemd service file begins with defining the unit of the service with [Unit] and including a description of the service. \n\n\n- Next, create a new section for [Service], where you specify the path to the Node.js script and any required environment variables. \n\n\n- Finally, add a section for [Install], where you specify when the service should start, such as when the system finishes booting up. You can use \"multi-user.target\" as the dependency to start the service in full multi-user mode.\n\n\n- Once the systemd service file is created, use the command \"systemctl enable myscript.service\" to enable the service at startup.\n\n\n2. Defining the path to the Node.js script and any necessary arguments:\n\n\n- In the service file, specify the path to the Node.js script with the ExecStart option under the [Service] section. For example, \"ExecStart=/usr/bin/node /path/to/myscript.js\". \n\n\n- If your script requires any arguments, add them after the file path. For example, \"ExecStart=/usr/bin/node /path/to/myscript.js arg1 arg2\".\n\n\n3. Setting up any environment variables required by the script:\n\n\n- In the service file, specify the environment variables the script requires with the Environment option under the [Service] section. For example, \"Environment=MYSQL_USER=root MYSQL_PASSWORD=mypassword\".\n\n\n4. Specifying the user under which the script should run:\n\n\n- In the service file, specify the user under which the script should run with the User and Group options under the [Service] section. For example, \"User=www-data Group=www-data\".\n\n\n5. Testing the script to ensure that it runs correctly on startup:\n\n\n- After creating the service file, use the command \"systemctl start myscript.service\" to start the service. \n\n\n- Check the status of the service using \"systemctl status myscript.service\". If the status shows \"active (running)\", the script is running successfully. \n\n\n- Reboot the system and check the status of the service again using \"systemctl status myscript.service\" to ensure that the script starts automatically on startup. \n\n\nNote: This is just one example of how to run a Node.js script on startup. There are other ways to accomplish this depending on your system or specific requirements.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:13:01.871Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "s3-file-upload",
      "content": "```js\n/*\n\n  \n\n\n*/\n\nconst aws = require('aws-sdk')\n\nconst AWS_ACCESS_KEY= process.env.AWS_ACCESS_KEY\nconst AWS_SECRET_ACCESS_KEY = process.env.AWS_SECRET_ACCESS_KEY\n\nconst S3_BUCKET = 'dataroomnetwork'\naws.config.region = 'us-west-1'\naws.config.accessKeyId = AWS_ACCESS_KEY\naws.config.secretAccessKey = AWS_SECRET_ACCESS_KEY\n\n\napp.get(process.env.UPLOAD_URL, (req, res) => {\n  console.log(req.query['file-name'], req.query['file-type'])\n  const s3 = new aws.S3()\n  const fileName =  req.query['file-name']\n  const fileType = req.query['file-type']\n  // const dataroomKey = req.query['dataroom-key']\n  const s3Params = {\n    Bucket: S3_BUCKET,\n    Key: fileName,\n    Expires: 60,\n    ContentType: fileType,\n    ACL: 'public-read'\n  }\n\n  s3.getSignedUrl('putObject', s3Params, (err, data) => {\n    if(err){\n      console.log(err)\n      return res.end()\n    }\n    const returnData = {\n      signedRequest: data,\n      url: `https://${S3_BUCKET}.s3.amazonaws.com/${fileName}`\n    }\n\n    console.log(returnData)\n    res.write(JSON.stringify(returnData))\n    res.end()\n  })\n})\n\n/*\n\nimport { fetchPlugin, getNewID, getReflectedCoordinates } from  './helpers.js'\nimport { parseVariables, generateVariablesSnippet} from './variables.js'\n\n\nasync function createNewImage(image){\n  console.log(image)\n  const new_image = await fetchPlugin('image')\n  const img_vars = parseVariables(new_image.variables)\n  const keys = {\n    hans_id:getNewID(),\n    view_key:getNewID(),\n    edit_key:getNewID()\n  }\n  const ref_coord = getReflectedCoordinates()\n  img_vars.position = ref_coord.position\n  img_vars.rotation = ref_coord.rotation\n  const new_img_vars_2 = Object.assign(img_vars, image)\n  const new_variables = generateVariablesSnippet(new_img_vars_2)\n  const new_hans_image = Object.assign(image, new_image, img_vars, keys)\n  new_hans_image.variables = new_variables\n  dispatch('UPDATE OBJECT',new_hans_image)\n}\n\nexport function openUploadTag(){\n\n  const hans_tag = createHansTag('upload')\n\n\n  const upload_form = document.createElement('input')\n  upload_form.setAttribute('id', 'upload-form')\n  upload_form.classList.add('centered')\n  upload_form.setAttribute('type', 'file')\n  upload_form.setAttribute('name', 'upload-form')\n  upload_form.setAttribute('multiple', 'true')\n  hans_tag.appendChild(upload_form)\n\n  document.body.appendChild(hans_tag)\n\n\n  document.querySelector('#upload-form').onchange = function(e){\n    const new_file = e.target.files[0]\n    if(new_file.type === 'text/csv'){\n      console.log('NEW CSV!', new_file)\n      return  \n    }\n    \n\n    Object.values(e.target.files).forEach((file,index) => {\n      beginFileUpload(file).then(async (res) => {\n        let type = res.type.split('/')[0]\n        switch(type){\n          case \"image\":\n            createNewImage(res)\n            break\n          default:\n\n        }\n      })\n    })\n  }// end upload form query\n\n}// end open upload tag\n\nfunction uploadFile(file, signedRequest, url){\n  console.log('uploading.... ', file, url)\n  return new Promise((response, reject) => {\n    const file_type = file.type\n    const file_size = file.size/1024/1024\n    const fr = new FileReader()\n    fr.onload = (loadedevent) => {\n      const loaded_file = loadedevent.target.result\n      const xhr = new XMLHttpRequest()\n      xhr.open('PUT', signedRequest)\n      xhr.onreadystatechange = () =>{\n        if(xhr.readyState === 4){\n          if(xhr.status === 200){\n            const file_path = xhr.responseURL.split('?')[0]\n            response({\n              file_path,\n              type: file_type,\n              file_size,\n            })\n\n          } else {\n            reject(\"COULD NOT UPLOAD FILE\")\n          }\n        }\n      }\n      xhr.setRequestHeader('Content-Type', file.type);\n      xhr.send(loaded_file)\n    }\n    fr.readAsArrayBuffer(file)\n    fr.onerror = (err) => {\n      console.error(e,err)\n    }\n    fr.onprogress = (prog) => {\n      console.log(prog)\n    }\n  })\n}\n\n\nexport function beginFileUpload(file){\n\n  return new Promise((respond, reject) => {\n    const xhr = new XMLHttpRequest()\n    xhr.open('GET', `/util/sign-s3?file-name=${encodeURI(file.name)}&file-type=${encodeURI(file.type)}`)\n    xhr.onreadystatechange = () => {\n      if(xhr.readyState === 4){\n        if(xhr.status === 200){\n          console.log(xhr.responseText)\n          const response = JSON.parse(xhr.responseText)\n          uploadFile(file, response.signedRequest, response.url).then(function(uploaded_file){\n            respond(uploaded_file)\n          })\n        }\n        else {\n          alert('could not get signed url')\n        }\n      }\n    }\n    xhr.send()\n  })\n}\n\n*/\n\n\n```\n\n"
    },
    {
      "file-id": "sanitize-file-names.md",
      "date-created": "Wed Dec 13 2023 08:46:24 GMT-0800 (Pacific Standard Time)",
      "last-updated": "Wed Dec 13 2023 08:46:24 GMT-0800 (Pacific Standard Time)",
      "lastIndexed": "never",
      "lastUpdated": "2023-12-18T21:04:26.348Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "sanitize-file-names",
      "content": "\n# sanitize-file-names.md\n\n```js\nconst fs = require('fs');\nconst path = require('path');\n\nconst folderPath = './notebook'; // Replace with the path to your folder\n\n// Function to lowercase file names and preserve periods between words\nfunction sanitizeFileName(fileName) {\n    const lowercasedFileName = fileName.toLowerCase();\n    const preservedPeriodsFileName = lowercasedFileName.replace(/ /g, '-');\n    return preservedPeriodsFileName;\n}\n\n// Read the files in the folder\nfs.readdir(folderPath, (err, files) => {\n    if (err) {\n        console.error('Error reading folder:', err);\n        return;\n    }\n\n    // Process each file\n    files.forEach((file) => {\n        const filePath = path.join(folderPath, file);\n        const sanitizedFileName = sanitizeFileName(file);\n        const newFilePath = path.join(folderPath, sanitizedFileName);\n\n        // Rename the file\n        fs.rename(filePath, newFilePath, (renameErr) => {\n            if (renameErr) {\n                console.error(`Error renaming file ${file}:`, renameErr);\n            } else {\n                console.log(`File ${file} renamed to ${sanitizedFileName}`);\n            }\n        });\n    });\n});\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:07:16.234Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "server",
      "content": "```js\n/*\n\n  SERVER\n\n  This is to wire together components and prototype quick ideas, not run the \n  business logic.\n\n  Software is, above all things, a human / computer interface. This bundle of \n  text is your interface between the server and you: keep it clear and humane.\n\n*/\n\n\n// Import external libraries\nimport express from 'express';\nimport { createServer } from 'https';\nimport { readFileSync, existsSync } from 'fs';\nimport path, { join } from 'path';\nimport os from 'os';\nimport { execSync } from 'child_process';\nimport dotenv from 'dotenv';\nimport routes from './routes.js';\n\n\n// Initialize Express Server\nconst app = express();\n\n// Load the .env file\ndotenv.config();\nlet PORT = process.env.PORT || 3000;\n\n// Get the local IP address and stash it in a global variable\n\nfunction getLocalIpAddress() {\n  const interfaces = os.networkInterfaces();\n  for (const key in interfaces) {\n    for (const iface of interfaces[key]) {\n      if (iface.family === 'IPv4' && !iface.internal && iface.address !== '127.0.0.1') {\n        return iface.address;\n      }\n    }\n  }\n  return null;\n}\n\nglobal.ip_address = getLocalIpAddress();\n\n// Store the Hostname globalls\nglobal.hostname = os.hostname();\n\n\n// Get the root directory and store it globally\nconst currentModuleURL = new URL(import.meta.url);\nconst rootDirectory = decodeURIComponent(new URL('.', currentModuleURL).pathname);\nglobal.root_directory = rootDirectory;\n\n/*\n\n  ROUTES\n\n*/\n\nconst routesInstance = routes(app, express);\n\n// Check if private-key.pem and certificate.pem files exist\nconst privateKeyPath = join(rootDirectory, 'private-key.pem');\nconst certificatePath = join(rootDirectory, 'certificate.pem');\n\nif (!existsSync(privateKeyPath) || !existsSync(certificatePath)) {\n  console.log('Certificates not found. Generating new certificates...');\n  // Generate new self-signed certificates using openssl\n  try {\n    execSync(`openssl req -x509 -newkey rsa:4096 -keyout ${privateKeyPath} -out ${certificatePath} -days 365 -nodes -subj \"/CN=${hostname}\"`);\n    console.log('New certificates generated successfully.');\n  } catch (error) {\n    console.error('Error generating certificates:', error.message);\n  }\n}\n\n// Configure HTTPS server\nconst httpsOptions = {\n  key: readFileSync(privateKeyPath),\n  cert: readFileSync(certificatePath),\n};\n\nconst httpsServer = createServer(httpsOptions, app);\nhttpsServer.listen(PORT, () => {\n  console.log(`Server listening on port https://${global.hostname}:${PORT} and serving ${global.root_directory}`);\n});\n\n```\n\n\n\nDataroom is written in node.js using ES6 modules.\n\nThis is what the server may look like:\n\n```js\n/*\n  *** begin ascii art ***\n\n          ,a8a,\n         ,8\" \"8,                       8I\n         d8   8b                       8I\n         88   88                       8I\n         88   88                       8I\n         Y8   8P  ,ggg,,ggg,     ,gggg,8I   ,ggg,      ,gg,   ,gg\n         `8, ,8' ,8\" \"8P\" \"8,   dP\"  \"Y8I  i8\" \"8i    d8\"\"8b,dP\"\n    8888  \"8,8\"  I8   8I   8I  i8'    ,8I  I8, ,8I   dP   ,88\"\n    `8b,  ,d8b, ,dP   8I   Yb,,d8,   ,d8b, `YbadP' ,dP  ,dP\"Y8,\n      \"Y88P\" \"Y88P'   8I   `Y8P\"Y8888P\"`Y8888P\"Y8888\"  dP\"   \"Y88\n\n  *** end ascii art ***\n\n  server.js,\n\n  This is to wire together components and prototype quick ideas, not run the \n  business logic.\n\n  Software is, above all things, a human / computer interface. This bundle of \n  text is your interface between the server and you: keep it clear and humane.\n\n*/\n```\n\nImports\n\n```js\nimport express from 'express';\nimport { createServer } from 'https';\nimport { readFileSync, existsSync } from 'fs';\nimport path, { join } from 'path';\nimport os from 'os';\nimport { execSync } from 'child_process';\nimport dotenv from 'dotenv';\nimport routes from './routes.js';\n\n```\n\nExpress Server\n\n```js\nconst app = express();\n\n```\n\ndot env\n```js \ndotenv.config();\nlet PORT = process.env.PORT || 3000;\n```\n\nGlobal IP address\n\n```js\nfunction getLocalIpAddress() {\n  const interfaces = os.networkInterfaces();\n  for (const key in interfaces) {\n    for (const iface of interfaces[key]) {\n      if (iface.family === 'IPv4' && !iface.internal && iface.address !== '127.0.0.1') {\n        return iface.address;\n      }\n    }\n  }\n  return null;\n}\n\nglobal.ip_address = getLocalIpAddress();\nglobal.hostname = os.hostname();\n\n```\n\nRoot Directory\n\n```js \nconst currentModuleURL = new URL(import.meta.url);\nconst rootDirectory = decodeURIComponent(new URL('.', currentModuleURL).pathname);\nglobal.root_directory = rootDirectory;\n```\n\nRoutes\n\n```js\napp.use(express.json());\n\n// BASIC ROUTES\n\napp.use(express.json());\napp.use('/plugins', express.static(join(rootDirectory, '/plugins')));\napp.use(\"/index.css\", express.static(join(rootDirectory, '/index.css')));\napp.use(\"/index.js\", express.static(join(rootDirectory, '/index.js')));\n\napp.get('/', (req, res) => {\n  res.sendFile(path.join(global.root_directory, 'index.html'));\n});\n\n\n```\n\nInitialize Routes File\n(routes is loaded in imports)\n\n```js\nconst routesInstance = routes(app);\n```\n\n\nHTTPS server\n\n```js\n\n// Check if private-key.pem and certificate.pem files exist\nconst privateKeyPath = join(rootDirectory, 'private-key.pem');\nconst certificatePath = join(rootDirectory, 'certificate.pem');\n\nif (!existsSync(privateKeyPath) || !existsSync(certificatePath)) {\n  console.log('Certificates not found. Generating new certificates...');\n  // Generate new self-signed certificates using openssl\n  try {\n    execSync(`openssl req -x509 -newkey rsa:4096 -keyout ${privateKeyPath} -out ${certificatePath} -days 365 -nodes -subj \"/CN=${hostname}\"`);\n    console.log('New certificates generated successfully.');\n  } catch (error) {\n    console.error('Error generating certificates:', error.message);\n  }\n}\n\n// Configure HTTPS server\nconst httpsOptions = {\n  key: readFileSync(privateKeyPath),\n  cert: readFileSync(certificatePath),\n};\n\nconst httpsServer = createServer(httpsOptions, app);\nhttpsServer.listen(PORT, () => {\n  console.log(`Server listening on port https://${global.hostname}:${PORT} and serving ${global.root_directory}`);\n});\n\n```\n\nYou probably want\n\n[[server.js]]\n\n\nindex.js and index.css endpoints.\n\n\n## ChatGPT Prompt\n\nthe /index.js endpoint loads all front end components. It renders a js file that imports all index.js files found in the plugins folders. \n\nAn endpoint in this software looks like: \n\n```js\n\nexport default function (app) {\n  app.get('/index.js', async function(req, res){\n    const index_js_content = '' // generate index_js_content here\n    res.send(index_js_content);\n  })\n}\n\n```\n\nthere should be a node.js express.js endpoint written with es6 modules that generates an index.js file like so: \n\nit should search through the directory located at \n```js\nglobal.root_directory + '/plugins'\n```\n\nit should search through each folder looking for an index.js file. \n\nIf this file exists, it should import that file like: \n\n```js\nimport \"/plugins/{plugin-name}/index.js\"\n\n```\n\nit should import all available index.js files in the directory this way. \n\n## ChatGPT Response: \n\n```js\nimport fs from 'fs';\nimport path from 'path';\n\nexport default function (app) {\n  app.get('/index.js', async function(req, res) {\n    const pluginsDirectory = path.join(global.root_directory, 'plugins');\n    let indexJsContent = '';\n\n    // Read the contents of the plugins directory\n    const pluginFolders = fs.readdirSync(pluginsDirectory, { withFileTypes: true });\n\n    // Iterate through each folder in the plugins directory\n    for (const folder of pluginFolders) {\n      if (folder.isDirectory()) {\n        const pluginPath = path.join(pluginsDirectory, folder.name);\n        const indexPath = path.join(pluginPath, 'index.js');\n\n        try {\n          // Check if the folder contains an \"index.js\" file\n          if (fs.existsSync(indexPath)) {\n            // Import the \"index.js\" file and add it to the content\n            indexJsContent += `import \"/plugins/${folder.name}/index.js\";\\n`;\n          }\n        } catch (error) {\n          console.error(`Error checking for index.js in ${indexPath}: ${error.message}`);\n        }\n      }\n    }\n\n    // Send the generated index.js content as the response\n    res.type('text/javascript').send(indexJsContent);\n  });\n}\n```\n\n> Great, take this code and write one that does the same thing for a file called index.css. Instead of js endpoints use css endpoints.\n\n\n## ChatGPT Responds:\n\n```js\nimport fs from 'fs';\nimport path from 'path';\n\nexport default function (app) {\n  app.get('/index.css', async function(req, res) {\n    const pluginsDirectory = path.join(global.root_directory, 'plugins');\n    let indexCssContent = '';\n\n    // Read the contents of the plugins directory\n    const pluginFolders = fs.readdirSync(pluginsDirectory, { withFileTypes: true });\n\n    // Iterate through each folder in the plugins directory\n    for (const folder of pluginFolders) {\n      if (folder.isDirectory()) {\n        const pluginPath = path.join(pluginsDirectory, folder.name);\n        const indexPath = path.join(pluginPath, 'index.css');\n\n        try {\n          // Check if the folder contains an \"index.css\" file\n          if (fs.existsSync(indexPath)) {\n            // Read the content of the \"index.css\" file and add it to the response\n            const cssContent = fs.readFileSync(indexPath, 'utf-8');\n            indexCssContent += `@import ${cssContent}\\n`;\n          }\n        } catch (error) {\n          console.error(`Error checking for index.css in ${indexPath}: ${error.message}`);\n        }\n      }\n    }\n\n    // Send the generated index.css content as the response with the appropriate content type\n    res.type('text/css').send(indexCssContent);\n  });\n}\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-20T21:23:59.050Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "set-last-url",
      "content": "talks to [[wss]]\n\n\n"
    },
    {
      "file-id": "dataroom-setup",
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:45:12.746Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "setup",
      "content": "\n\n\n```sh\n#!/bin/sh\nsudo apt install curl\nsudo apt install npm\ncurl -fsSL https://bun.sh/install | bash \ncurl -fsSL https://bun.sh/install | bash -s \"bun-v1.0.0\"\nnpm install\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-01-11T20:57:37.054Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "sort.js",
      "content": "https://www.youtube.com/watch?v=leNaS9eJWqo\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:52:10.310Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "speak-text",
      "content": "```js\n\n// https://stackoverflow.com/questions/21947730/chrome-speech-synthesis-with-longer-texts\n\nvar speechUtteranceChunker = function (utt, settings, voice, callback) {\n  settings = settings || {};\n  var newUtt;\n  var txt = (settings && settings.offset !== undefined ? utt.text.substring(settings.offset) : utt.text);\n  if (utt.voice && utt.voice.voiceURI === 'native') { // Not part of the spec\n    newUtt = utt;\n    newUtt.text = txt;\n    newUtt.addEventListener('end', function () {\n      if (speechUtteranceChunker.cancel) {\n          speechUtteranceChunker.cancel = false;\n      }\n      if (callback !== undefined) {\n          callback();\n      }\n    });\n  }\n  else {\n    var chunkLength = (settings && settings.chunkLength) || 160;\n    var pattRegex = new RegExp('^[\\\\s\\\\S]{' + Math.floor(chunkLength / 2) + ',' + chunkLength + '}[.!?,]{1}|^[\\\\s\\\\S]{1,' + chunkLength + '}$|^[\\\\s\\\\S]{1,' + chunkLength + '} ');\n    var chunkArr = txt.match(pattRegex);\n\n    if (chunkArr[0] === undefined || chunkArr[0].length <= 2) {\n      //call once all text has been spoken...\n      if (callback !== undefined) {\n          callback();\n      }\n      return;\n    }\n    var chunk = chunkArr[0];\n    newUtt = new SpeechSynthesisUtterance(chunk);\n    var x;\n    for (x in utt) {\n      if (utt.hasOwnProperty(x) && x !== 'text') {\n        newUtt[x] = utt[x];\n      }\n    }\n    newUtt.addEventListener('end', function () {\n      if (speechUtteranceChunker.cancel) {\n        speechUtteranceChunker.cancel = false;\n        return;\n      }\n      settings.offset = settings.offset || 0;\n      settings.offset += chunk.length - 1;\n      speechUtteranceChunker(utt, settings, callback);\n    });\n  }\n\n  if (settings.modifier) {\n    settings.modifier(newUtt);\n  }\n\n  newUtt.pitch = settings.pitch\n  newUtt.rate = settings.rate\n  newUtt.voice = voice\n  console.log(newUtt); //IMPORTANT!! Do not remove: Logging the object out fixes some onend firing issues.\n  //placing the speak invocation inside a callback fixes ordering and onend issues.\n  setTimeout(function () {\n    speechSynthesis.speak(newUtt);\n  }, 0);\n};\n\n//\n// class HansDetail extends HTMLElement {\n//   connectedCallback(){\n//\n//     this.onclick = () => {\n//       this.speakText(this.innerText)\n//     }\n//   }\n//\n//   speakText(text){\n//     speechSynthesis.cancel()\n//     const speech = new SpeechSynthesisUtterance(text)\n//\n//     const voices = speechSynthesis.getVoices()\n//     speech.voice = voices.filter(function(voice){\n//       console.log(voice.voiceURI)\n//       if(voice.voiceURI === 'Google UK English Male'\n//         || voice.voiceURI === 'urn:moz-tts:speechd:English%20(America)+Iven3?en-US-IVEN3')\n//         { return voice }\n//     })[0]\n//     console.log(speech)\n//     speech.rate = 0.8\n//     speech.pitch = 0.8\n//     speechUtteranceChunker(speech)\n//   }\n//\n// }\n//\n// customElements.define('hans-detail', HansDetail)\n\n\nexport function speakText(text){\n    if(window.no_speech){\n      return\n    }\n\n    speechSynthesis.cancel()\n    const speech = new SpeechSynthesisUtterance(text)\n\n    const voices = speechSynthesis.getVoices()\n    const voice = voices.filter(function(voice){\n      console.log(voice.voiceURI)\n      if(voice.voiceURI === 'Google UK English Female'\n        || voice.voiceURI === 'urn:moz-tts:speechd:English%20(America)+Iven3?en-US-IVEN3')\n        { return voice }\n    })[0]\n\n    speechUtteranceChunker(speech, {rate: 0.5 + Math.random(), pitch: 1 + Math.random()}, voice)\n}\n\nwindow.speakText = speakText\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-07-06T18:43:43.588Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "sqlite",
      "content": "\n```js\n// Import required modules\nconst express = require('express');\nconst sqlite3 = require('sqlite3').verbose();\n\n// Create an Express.js application\nconst app = express();\n\n// Create a new SQLite database instance\nconst db = new sqlite3.Database(':memory:');\n\n// Create a books table in the database\ndb.serialize(() => {\n  db.run('CREATE TABLE IF NOT EXISTS books (id INTEGER PRIMARY KEY AUTOINCREMENT, title TEXT, author TEXT)');\n});\n\n// Middleware to parse JSON request bodies\napp.use(express.json());\n\n// API endpoint to get all books\napp.get('/books', (req, res) => {\n  db.all('SELECT * FROM books', (err, rows) => {\n    if (err) {\n      console.error(err);\n      res.status(500).json({ error: 'Internal server error' });\n    } else {\n      res.json(rows);\n    }\n  });\n});\n\n// API endpoint to get a specific book by ID\napp.get('/books/:id', (req, res) => {\n  const id = req.params.id;\n  db.get('SELECT * FROM books WHERE id = ?', id, (err, row) => {\n    if (err) {\n      console.error(err);\n      res.status(500).json({ error: 'Internal server error' });\n    } else if (!row) {\n      res.status(404).json({ error: 'Book not found' });\n    } else {\n      res.json(row);\n    }\n  });\n});\n\n// API endpoint to create a new book\napp.post('/books', (req, res) => {\n  const { title, author } = req.body;\n  db.run('INSERT INTO books (title, author) VALUES (?, ?)', title, author, function (err) {\n    if (err) {\n      console.error(err);\n      res.status(500).json({ error: 'Internal server error' });\n    } else {\n      res.json({ id: this.lastID });\n    }\n  });\n});\n\n// API endpoint to update an existing book\napp.put('/books/:id', (req, res) => {\n  const id = req.params.id;\n  const { title, author } = req.body;\n  db.run('UPDATE books SET title = ?, author = ? WHERE id = ?', title, author, id, function (err) {\n    if (err) {\n      console.error(err);\n      res.status(500).json({ error: 'Internal server error' });\n    } else if (this.changes === 0) {\n      res.status(404).json({ error: 'Book not found' });\n    } else {\n      res.json({ message: 'Book updated successfully' });\n    }\n  });\n});\n\n// API endpoint to delete a book\napp.delete('/books/:id', (req, res) => {\n  const id = req.params.id;\n  db.run('DELETE FROM books WHERE id = ?', id, function (err) {\n    if (err) {\n      console.error(err);\n      res.status(500).json({ error: 'Internal server error' });\n    } else if (this.changes === 0) {\n      res.status(404).json({ error: 'Book not found' });\n    } else {\n      res.json({ message: 'Book deleted successfully' });\n    }\n  });\n});\n\n// Start the server\nconst port = 3000;\napp.listen(port, () => {\n  console.log(`Server is running on port ${port}`);\n});\n\n```\n\n```js\nconst sqlite3 = require('sqlite3').verbose();\n\n// Create a new database connection\nconst db = new sqlite3.Database(':memory:');\n\n// Create a table if it doesn't exist\ndb.run(`\n  CREATE TABLE IF NOT EXISTS records (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    name TEXT,\n    email TEXT\n  )\n`);\n\n// Create a record\nfunction createRecord(name, email) {\n  db.run('INSERT INTO records (name, email) VALUES (?, ?)', [name, email], function(err) {\n    if (err) {\n      console.error('Error creating record:', err.message);\n      return;\n    }\n    console.log(`Record created with ID: ${this.lastID}`);\n  });\n}\n\n// Update a record\nfunction updateRecord(id, name, email) {\n  db.run('UPDATE records SET name = ?, email = ? WHERE id = ?', [name, email, id], function(err) {\n    if (err) {\n      console.error('Error updating record:', err.message);\n      return;\n    }\n    if (this.changes > 0) {\n      console.log('Record updated successfully');\n    } else {\n      console.log('No record found with the specified ID');\n    }\n  });\n}\n\n// Delete a record\nfunction deleteRecord(id) {\n  db.run('DELETE FROM records WHERE id = ?', id, function(err) {\n    if (err) {\n      console.error('Error deleting record:', err.message);\n      return;\n    }\n    if (this.changes > 0) {\n      console.log('Record deleted successfully');\n    } else {\n      console.log('No record found with the specified ID');\n    }\n  });\n}\n\n// Usage examples\ncreateRecord('John Doe', 'john@example.com');\nupdateRecord(1, 'Jane Smith', 'jane@example.com');\ndeleteRecord(1);\n\n// Close the database connection\ndb.close();\n\n```\n\n\n---\n\nSure! Here's an example of a basic graph database implemented using Node.js and the `sqlite3` package. This database stores triples (subject, predicate, object) and allows you to perform basic graph operations.\n\nFirst, make sure you have Node.js and the `sqlite3` package installed. You can install the `sqlite3` package by running `npm install sqlite3`.\n\n```javascript\nconst sqlite3 = require('sqlite3').verbose();\n\n// Open the SQLite database\nconst db = new sqlite3.Database(':memory:');\n\n// Create a table to store the triples\ndb.run(`\n  CREATE TABLE triples (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    subject TEXT,\n    predicate TEXT,\n    object TEXT\n  )\n`);\n\n// Function to insert a triple into the database\nfunction insertTriple(subject, predicate, object) {\n  db.run(`\n    INSERT INTO triples (subject, predicate, object)\n    VALUES (?, ?, ?)\n  `, [subject, predicate, object], function(err) {\n    if (err) {\n      console.error('Error inserting triple:', err);\n    } else {\n      console.log('Triple inserted successfully');\n    }\n  });\n}\n\n// Function to query triples based on a given subject\nfunction queryTriplesBySubject(subject) {\n  db.all(`\n    SELECT * FROM triples WHERE subject = ?\n  `, [subject], function(err, rows) {\n    if (err) {\n      console.error('Error querying triples:', err);\n    } else {\n      console.log('Triples with subject', subject + ':');\n      rows.forEach(row => {\n        console.log(row.subject, row.predicate, row.object);\n      });\n    }\n  });\n}\n\n// Example usage\ninsertTriple('Alice', 'likes', 'Chocolate');\ninsertTriple('Bob', 'likes', 'Ice cream');\ninsertTriple('Charlie', 'likes', 'Pizza');\n\nqueryTriplesBySubject('Alice');\n```\n\nIn this example, we first create a table called `triples` with columns for the subject, predicate, and object. The `insertTriple` function is used to insert a triple into the database. The `queryTriplesBySubject` function retrieves all triples with a given subject.\n\nIn the example usage, we insert three triples into the database and then query for all triples with the subject \"Alice\".\n\nPlease note that this is a basic implementation and lacks error handling, complex querying, and other features typically found in a fully-fledged graph database. It serves as a starting point and can be expanded upon based on your requirements.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-12T16:32:50.832Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "symbolic link",
      "content": "```bash\nln -s [Source_File_Path] [Symbolic_Link_Path]\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-02-17T19:49:53.217Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "test-obsidian.js",
      "content": "```javascript\n\n\n/*\n\n    If I had my druthers,\n    this would be pure javascript\n\n\n*/\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2022-10-23T20:47:44.331Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "tippecanoe",
      "content": "https://github.com/mapbox/tippecanoe\n\n```sh\nbrew install tippecanoe\n```\n\n```sh\ntippecanoe -zg -o out.mbtiles --drop-densest-as-needed in.geojson\n```\n\ntakes [[GeoJSON]] files, converts them to [[MapBox]] ready tilesets for a [[Tile Server]]\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-24T19:29:24.741Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "vanilla-js-structure",
      "content": "# vanilla-js-structure\n\n## File: custom-html-element.js\n\n```javascript\n/*\n\n  Custom HTML Elements\n\n  For More information go to: https://lnsy.dev/blog/custom-html-components.html\n\n */\n\nconst web_worker = new Worker('./src/web-worker.js');\n\nclass ElementName extends HTMLElement {\n  connectedCallback(){\n\n    this.innerHTML = `\n      <h3>Custom HTML Element</h3>\n      <p><a href=\"https://lnsy.dev/blog/custom-html-components.html\" target=\"_blank\">About Custom HTML Elements</a></p> \n    `\n\n    web_worker.postMessage('Hello, worker!');\n\n    // Listening for messages from the worker\n    web_worker.onmessage = function(e) {\n      console.log('Message received from worker:', e.data);\n    };\n\n    // Optional: Listening for errors from the worker\n    web_worker.onerror = function(e) {\n      console.error('Worker error:', e);\n    };\n  }\n\n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n    switch(name){\n      default:\n    }\n  }\n}\n\ncustomElements.define('custom-html-element', ElementName)\n```\n\n## File: index.js\n\n```javascript\nimport  \"./custom-html-element.js\";\n\n```\n\n## File: web-worker.js\n\n```javascript\n/*\n  Web Worker\n\n  For more information go to:\n  https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers\n\n */\n\n// Use web workers to handle heavy processese\nself.addEventListener('message', function(e) {\n  // Receive message from the main thread\n  const data = e.data;\n  // Process the data (this is where your background task goes)\n  // For demonstration, let's just send back the received message\n  self.postMessage('Received: ' + data);\n}, false);\n\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-15T17:13:39.781Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "visidata",
      "content": "I cloned this directory and put it into documents:\n\nhttps://jsvine.github.io/intro-to-visidata/\n\nload with npx http-server\n\n\n\n---\n\n\nvd(1)\t\t\t\t\t Quick Reference Guide\t\t\t\t\t vd(1)\n\nNAME\n     VisiData — a terminal utility for exploring and arranging tabular data\n\nSYNOPSIS\n     vd [options] [input ...]\n     vd [options] --play cmdlog [-w waitsecs] [--batch] [-o output] [field=value]\n     vd [options] [input ...] +toplevel:subsheet:col:row\n\nDESCRIPTION\n     VisiData is an easy-to-use multipurpose tool to explore, clean, edit, and restructure data. Rows\n     can be selected, filtered, and grouped; columns can be rearranged, transformed, and derived via\n     regex or Python expressions; and workflows can be saved, documented, and replayed.\n\n   REPLAY MODE\n     -p, --play=cmdlog\t     replay a saved cmdlog within the interface\n     -w, --replay-wait=seconds\n\t\t\t     wait seconds between commands\n     -b, --batch\t     replay in batch mode (with no interface)\n     -o, --output=file\t     save final visible sheet to file as .tsv\n     --replay-movement\t     toggle --play to move cursor cell-by-cell\n     field=value\t     replace \"{field}\" in cmdlog contents with value\n\n   Commands During Replay\n\t^U\t\t     pause/resume replay\n\t^N\t\t     execute next row in replaying sheet\n\t^K\t\t     cancel current replay\n\n   GLOBAL COMMANDS\n     All keystrokes are case sensitive. The ^ prefix is shorthand for Ctrl.\n\n   Keystrokes to start off with\n      ^Q\t      abort program immediately\n      ^C\t      cancel user input or abort all async threads on current sheet\n     g^C\t      abort all secondary threads\n       q\t      quit current sheet\n      gq\t      quit all sheets (clean exit)\n\n      ^H\t      view this man page\n     z^H\t      view sheet of command longnames and keybindings\n     Space longname   execute command by its longname\n\n       U\t      undo the most recent modification (requires enabled options.undo)\n       R\t      redo the most recent undo (requires enabled options.undo)\n\n   Cursor Movement\n     Arrow PgUp Home  go as expected\n      h\t  j   k\t  l   go left/down/up/right\n     gh\t gj  gk\t gl   go all the way to the left/bottom/top/right of sheet\n\t  G  gg\t      go all the way to the bottom/top of sheet\n     ^B\t ^F\t      scroll one page back/forward\n     zz\t\t      scroll current row to center of screen\n\n     ^^ (Ctrl+^)      jump to previous sheet (swaps with current sheet)\n\n      /\t  ? regex     search for regex forward/backward in current column\n     g/\t g? regex     search for regex forward/backward over all visible columns\n     z/\t z? expr      search by Python expr forward/backward in current column (with column names as\n\t\t      variables)\n      n\t  N\t      go to next/previous match from last regex search\n\n      <\t  >\t      go up/down current column to next value\n     z<\t z>\t      go up/down current column to next null value\n      {\t  }\t      go up/down current column to next selected row\n\n      c regex\t      go to next column with name matching regex\n      r regex\t      go to next row with key matching regex\n     zc\t zr number    go to column/row number (0-based)\n\n      H\t  J   K\t  L   slide current row/column left/down/up/right\n     gH\t gJ  gK\t gL   slide current row/column all the way to the left/bottom/top/right of sheet\n     zH\t zJ  zK\t zK number\n\t\t      slide current row/column number positions to the left/down/up/right\n\n     zh\t zj  zk\t zl   scroll one left/down/up/right\n\n   Column Manipulation\n       _ (underscore)\n\t\t      toggle width of current column between full and default width\n      g_\t      toggle widths of all visible columns between full and default width\n      z_ number\t      adjust width of current column to number\n     gz_ number\t      adjust widths of all visible columns to Ar number\n\n      - (hyphen)      hide current column\n     z-\t\t      reduce width of current column by half\n     gv\t\t      unhide all columns\n\n     ! z!\t      toggle/unset current column as a key column\n     ~\t#  %  $\t @  z#\n\t\t      set type of current column to str/int/float/currency/date/len\n       ^\t      edit name of current column\n      g^\t      set names of all unnamed visible columns to contents of selected rows (or cur‐\n\t\t      rent row)\n      z^\t      set name of current column to combined contents of current cell in selected rows\n\t\t      (or current row)\n     gz^\t      set name of all visible columns to combined contents of current column for se‐\n\t\t      lected rows (or current row)\n\n       = expr\t      create new column from Python expr, with column names, and attributes, as\n\t\t      variables\n      g= expr\t      set current column for selected rows to result of Python expr\n     gz= expr\t      set current column for selected rows to the items in result of Python sequence\n\t\t      expr\n      z= expr\t      evaluate Python expression on current row and set current cell with result of\n\t\t      Python expr\n\n       i (iota)\t      add column with incremental values\n      gi\t      set current column for selected rows to incremental values\n      zi step\t      add column with values at increment step\n     gzi step\t      set current column for selected rows at increment step\n\n      ' (tick)\t      add a frozen copy of current column with all cells evaluated\n     g'\t\t      open a frozen copy of current sheet with all visible columns evaluated\n     z'\t gz'\t      add/reset cache for current/all visible column(s)\n\n      : regex\t      add new columns from regex split; number of columns determined by example row at\n\t\t      cursor\n      ; regex\t      add new columns from capture groups of regex (also requires example row)\n     z; expr\t      create new column from bash expr, with $columnNames as variables\n      * regex/subst   add column derived from current column, replacing regex with subst (may include\n\t\t      \\1 backrefs)\n     g*\t gz* regex/subst\n\t\t      modify selected rows in current/all visible column(s), replacing regex with\n\t\t      subst (may include \\1 backrefs)\n\n      (\t  g(\t      expand current/all visible column(s) of lists (e.g. [3]) or dicts (e.g. {3})\n\t\t      fully\n     z(\t gz( depth    expand current/all visible column(s) of lists (e.g. [3]) or dicts (e.g. {3}) to\n\t\t      given depth (0= fully)\n      )\t\t      unexpand current column; restore original column and remove other columns at\n\t\t      this level\n     zM\t\t      row-wise expand current column of lists (e.g. [3]) or dicts (e.g. {3}) within\n\t\t      that column\n\n   Row Selection\n       s   t   u      select/toggle/unselect current row\n      gs  gt  gu      select/toggle/unselect all rows\n      zs  zt  zu      select/toggle/unselect all rows from top to cursor\n     gzs gzt gzu      select/toggle/unselect all rows from cursor to bottom\n      |\t  \\ regex     select/unselect rows matching regex in current column\n     g|\t g\\ regex     select/unselect rows matching regex in any visible column\n     z|\t z\\ expr      select/unselect rows matching Python expr in any visible column\n      , (comma)\t      select rows matching display value of current cell in current column\n     g,\t\t      select rows matching display value of current row in all visible columns\n     z, gz,\t      select rows matching typed value of current cell/row in current column/all visi‐\n\t\t      ble columns\n\n   Row Sorting/Filtering\n       [    ]\t      sort ascending/descending by current column; replace any existing sort criteria\n      g[   g]\t      sort ascending/descending by all key columns; replace any existing sort criteria\n      z[   z]\t      sort ascending/descending by current column; add to existing sort criteria\n     gz[  gz]\t      sort ascending/descending by all key columns; add to existing sort criteria\n      \"\t\t      open duplicate sheet with only selected rows\n     g\"\t\t      open duplicate sheet with all rows\n     gz\"\t      open duplicate sheet with deepcopy of selected rows\n\n   Editing Rows and Cells\n       a   za\t      append a blank row/column; appended columns cannot be copied to clipboard\n      ga  gza number  append number blank rows/columns\n       d   gd\t      delete (cut) current/selected row(s) and move to clipboard\n       y   gy\t      yank (copy) current/all selected row(s) to clipboard\n      zy  gzy\t      yank (copy) contents of current column for current/selected row(s) to clipboard\n      zd  gzd\t      delete (cut) contents of current column for current/selected row(s) and move to\n\t\t      clipboard\n       p    P\t      paste clipboard rows after/before current row\n      zp  gzp\t      set cells of current column for current/selected row(s) to last clipboard value\n       Y   gY\t      yank (copy) current/all selected row(s) to system clipboard (using\n\t\t      options.clipboard_copy_cmd)\n      zY  gzY\t      yank (copy) contents of current column for current/selected row(s) to system\n\t\t      clipboard (using options.clipboard_copy_cmd)\n       f\t      fill null cells in current column with contents of non-null cells up the current\n\t\t      column\n       e text\t      edit contents of current cell\n      ge text\t      set contents of current column for selected rows to text\n\n     Commands While Editing Input\n\tEnter  ^C\t accept/abort input\n\t^O\t\t open external $EDITOR to edit contents\n\t^R\t\t reload initial value\n\t^A  ^E\t\t go to beginning/end of line\n\t^B  ^F\t\t go back/forward one character\n\t^←  ^→ (arrow)\t go back/forward one word\n\t^H  ^D\t\t delete previous/current character\n\t^T\t\t transpose previous and current characters\n\t^U  ^K\t\t clear from cursor to beginning/end of line\n\t^Y\t\t paste from cell clipboard\n\tBackspace  Del\t delete previous/current character\n\tInsert\t\t toggle insert mode\n\tUp  Down\t set contents to previous/next in history\n\tTab  Shift+Tab\t autocomplete input (when available)\n\tShift+Arrow\t move cursor in direction of Arrow and re-enter edit mode\n\n   Data Toolkit\n      o input\t      open input in VisiData\n     ^S g^S filename  save current/all sheet(s) to filename in format determined by extension (default\n\t\t      .tsv)\n\t\t      Note: if the format does not support multisave, or the filename ends in a /, a\n\t\t      directory will be created.\n     z^S filename     save current column only to filename in format determined by extension (default\n\t\t      .tsv)\n     ^D filename.vd   save CommandLog to filename.vd file\n     A\t\t      open new blank sheet with one column\n     T\t\t      open new sheet that has rows and columns of current sheet transposed\n\n      + aggregator    add aggregator to current column (see Frequency Table)\n     z+ aggregator    display result of aggregator over values in selected rows for current column\n      &\t\t      concatenate top two sheets in Sheets Stack\n     g&\t\t      concatenate all sheets in Sheets Stack\n\n   Data Visualization\n      . (dot)\t    plot current numeric column vs key columns. The numeric key column is used for the\n\t\t    x-axis; categorical key column values determine color.\n     g.\t\t    plot a graph of all visible numeric columns vs key columns.\n\n     If rows on the current sheet represent plottable coordinates (as in .shp or vector .mbtiles\n     sources),\t. plots the current row, and g. plots all selected rows (or all rows if none\n     selected).\n\n     Canvas-specific Commands\n\t +   -\t\t    increase/decrease zoom level, centered on cursor\n\t _ (underscore)\t    zoom to fit full extent\n\tz_ (underscore)\t    set aspect ratio\n\t x xmin xmax\t    set xmin/xmax on graph\n\t y ymin ymax\t    set ymin/ymax on graph\n\t s   t\t u\t    select/toggle/unselect rows on source sheet contained within canvas cursor\n\tgs  gt\tgu\t    select/toggle/unselect rows on source sheet visible on screen\n\t d\t\t    delete rows on source sheet contained within canvas cursor\n\tgd\t\t    delete rows on source sheet visible on screen\n\t Enter\t\t    open sheet of source rows contained within canvas cursor\n\tgEnter\t\t    open sheet of source rows visible on screen\n\t 1 - 9\t\t    toggle display of layers\n\t^L\t\t    redraw all pixels on canvas\n\t v\t\t    toggle show_graph_labels option\n\tmouse scrollwheel   zoom in/out of canvas\n\tleft click-drag\t    set canvas cursor\n\tright click-drag    scroll canvas\n\n   Split Screen\n      Z\t\t    split screen in half, so that second sheet on the stack is visible in a second\n\t\t    pane\n     zZ\t\t    split screen, and queries for height of second pane\n\n     Split Window specific Commands\n\tgZ\t\t    close an already split screen, current pane full screens\n\tTab\t\t    jump to other pane\n\t^^ (Ctrl+^)\t    swap which sheet is in current pane\n\n   Other Commands\n     Q\t\t      quit current sheet and remove it from the CommandLog\n     v\t\t      toggle sheet-specific visibility (multi-line rows on Sheet, legends/axes on\n\t\t      Graph)\n\n      ^E  g^E\t      view traceback for most recent error(s)\n     z^E\t      view traceback for error in current cell\n\n      ^L\t      refresh screen\n      ^R\t      reload current sheet\n     z^R\t      clear cache for current column\n      ^Z\t      suspend VisiData process\n      ^G\t      show cursor position and bounds of current sheet on status line\n      ^V\t      show version and copyright information on status line\n      ^P\t      open Status History\n     m keystroke      first, begin recording macro; second, prompt for keystroke No, and complete\n\t\t      recording. Macro can then be executed everytime provided keystroke is used. Will\n\t\t      override existing keybinding. Macros will run on current row, column, sheet.\n     gm\t\t      open an index of all existing macros. Can be directly viewed with Enter, and\n\t\t      then modified with ^S.\n\n      ^Y  z^Y  g^Y    open current row/cell/sheet as Python object\n      ^X expr\t      evaluate Python expr and opens result as Python object\n     z^X expr\t      evaluate Python expr, in context of current row, and open result as Python\n\t\t      object\n     g^X stmt\t      execute Python stmt in the global scope\n\n   Internal Sheets List\n      .\t VisiDataMenu (Shift+V)\t     browse list of core sheets\n      .\t Directory Sheet\t     browse properties of files in a directory\n      .\t Plugins Sheet\t\t     browse, install, and (de)activate plugins\n\n     Metasheets\n      .\t Columns Sheet (Shift+C)     edit column properties\n      .\t Sheets Sheet (Shift+S)\t     jump between sheets or join them together\n      .\t Options Sheet (Shift+O)     edit configuration options\n      .\t Commandlog (Shift+D)\t     modify and save commands for replay\n      .\t Error Sheet (Ctrl+E)\t\t view last error\n      .\t Status History (Ctrl+P)\t view history of status messages\n      .\t Threads Sheet (Ctrl+T)\t\t view, cancel, and profile asynchronous threads\n\n     Derived Sheets\n      .\t Frequency Table (Shift+F)   group rows by column value, with aggregations of other columns\n      .\t Describe Sheet (Shift+I)    view summary statistics for each column\n      .\t Pivot Table (Shift+W)\t     group rows by key and summarize current column\n      .\t Melted Sheet (Shift+M)\t     unpivot non-key columns into variable/value columns\n      .\t Transposed Sheet (Shift+T)   open new sheet with rows and columns transposed\n\n   INTERNAL SHEETS\n   VisiDataMenu (Shift+V)\n     (sheet-specific commands)\n\tEnter\t\t load sheet in current row\n\n   Directory Sheet\n     (global commands)\n\tSpace open-dir-current\n\t\t\t open the Directory Sheet for the current directory\n     (sheet-specific commands)\n\tEnter  gEnter\t open current/selected file(s) as new sheet(s)\n\t ^O  g^O\t open current/selected file(s) in external $EDITOR\n\t ^R  z^R  gz^R\t reload information for all/current/selected file(s)\n\n   Plugins Sheet\n     Browse through a list of available plugins. VisiData needs to be restarted before plugin\n     activation takes effect. Installation may require internet access.\n     (global commands)\n\tSpace open-plugins\n\t\t\t open the Plugins Sheet\n     (sheet-specific commands)\n\ta\t\t install and activate current plugin\n\td\t\t deactivate current plugin\n\n   METASHEETS\n   Columns Sheet (Shift+C)\n     Properties of columns on the source sheet can be changed with standard editing commands (e ge g=\n     Del) on the Columns Sheet. Multiple aggregators can be set by listing them (separated by spaces)\n     in the aggregators column. The 'g' commands affect the selected rows, which are the literal\n     columns on the source sheet.\n     (global commands)\n\tgC\t\t open Columns Sheet with all visible columns from all sheets\n     (sheet-specific commands)\n\t &\t\t add column from concatenating selected source columns\n\tg! gz!\t\t toggle/unset selected columns as key columns on source sheet\n\tg+ aggregator\t add Ar aggregator No to selected source columns\n\tg- (hyphen)\t hide selected columns on source sheet\n\tg~ g# g% g$ g@ gz# z%\n\t\t\t set type of selected columns on source sheet to str/int/float/cur‐\n\t\t\t rency/date/len/floatsi\n\t Enter\t\t open a Frequency Table sheet grouped by column referenced in current row\n\n   Sheets Sheet (Shift+S)\n     open Sheets Stack, which contains only the active sheets on the current stack\n     (global commands)\n\tgS\t\t open Sheets Sheet, which contains all sheets from current session, active and\n\t\t\t inactive\n\tAlt number\t jump to sheet number\n     (sheet-specific commands)\n\t Enter\t\t jump to sheet referenced in current row\n\tgEnter\t\t push selected sheets to top of sheet stack\n\t a\t\t add row to reference a new blank sheet\n\tgC  gI\t\t open Columns Sheet/Describe Sheet with all visible columns from selected\n\t\t\t sheets\n\tg^R\t\t reload all selected sheets\n\tz^C  gz^C\t abort async threads for current/selected sheets(s)\n\tg^S\t\t save selected or all sheets\n\t & jointype\t merge selected sheets with visible columns from all, keeping rows according\n\t\t\t to jointype:\n\t\t\t .  inner  keep only rows which match keys on all sheets\n\t\t\t .  outer  keep all rows from first selected sheet\n\t\t\t .  full   keep all rows from all sheets (union)\n\t\t\t .  diff   keep only rows NOT in all sheets\n\t\t\t .  append keep all rows from all sheets (concatenation)\n\t\t\t .  extend copy first selected sheet, keeping all rows and sheet type, and\n\t\t\t    extend with columns from other sheets\n\t\t\t .  merge  mostly keep all rows from first selected sheet, except prioritise\n\t\t\t    cells with non-null/non-error values\n\n   Options Sheet (Shift+O)\n     (global commands)\n\tShift+O\t\t edit global options (apply to all sheets)\n\tzO\t\t edit sheet options (apply to current sheet only)\n\tgO\t\t open options.config as TextSheet\n     (sheet-specific commands)\n\tEnter  e\t edit option at current row\n\td\t\t remove option override for this context\n\n   CommandLog (Shift+D)\n     (global commands)\n\tD\t\t open current sheet's CommandLog with all other loose ends removed; includes\n\t\t\t commands from parent sheets\n\tgD\t\t open global CommandLog for all commands executed in the current session\n\tzD\t\t open current sheet's CommandLog with the parent sheets commands' removed\n     (sheet-specific commands)\n\t  x\t\t replay command in current row\n\t gx\t\t replay contents of entire CommandLog\n\t ^C\t\t abort replay\n\n   DERIVED SHEETS\n   Frequency Table (Shift+F)\n     A Frequency Table groups rows by one or more columns, and includes summary columns for those with\n     aggregators.\n     (global commands)\n\tgF\t\t open Frequency Table, grouped by all key columns on source sheet\n\tzF\t\t open one-line summary for all rows and selected rows\n     (sheet-specific commands)\n\t s   t\t u\t select/toggle/unselect these entries in source sheet\n\t Enter\tgEnter\t open copy of source sheet with rows that are grouped in current cell / se‐\n\t\t\t lected rows\n\n   Describe Sheet (Shift+I)\n     A Describe Sheet contains descriptive statistics for all visible columns.\n     (global commands)\n\tgI\t\t open Describe Sheet for all visible columns on all sheets\n     (sheet-specific commands)\n\tzs  zu\t\t select/unselect rows on source sheet that are being described in current cell\n\t !\t\t toggle/unset current column as a key column on source sheet\n\t Enter\t\t open a Frequency Table sheet grouped on column referenced in current row\n\tzEnter\t\t open copy of source sheet with rows described in current cell\n\n   Pivot Table (Shift+W)\n     Set key column(s) and aggregators on column(s) before pressing Shift+W on the column to pivot.\n     (sheet-specific commands)\n\t Enter\t\t open sheet of source rows aggregated in current pivot row\n\tzEnter\t\t open sheet of source rows aggregated in current pivot cell\n\n   Melted Sheet (Shift+M)\n     Open Melted Sheet (unpivot), with key columns retained and all non-key columns reduced to\n     Variable-Value rows.\n     (global commands)\n\tgM regex\t open Melted Sheet (unpivot), with key columns retained and regex capture\n\t\t\t groups determining how the non-key columns will be reduced to Variable-Value\n\t\t\t rows.\n\n   Python Object Sheet (^X ^Y g^Y z^Y)\n     (sheet-specific commands)\n\t Enter\t\t dive further into Python object\n\t v\t\t toggle show/hide for methods and hidden properties\n\tgv  zv\t\t show/hide methods and hidden properties\n\nCOMMANDLINE OPTIONS\n     Add -n/--nonglobal to make subsequent CLI options sheet-specific (applying only to paths\n     specified directly on the CLI). By default, CLI options apply to all sheets.\n\n     Options can also be set via the Options Sheet or a .visidatarc (see FILES).\n\n     -P=longname\t\t  preplay longname before replay or regular launch; limited to Base\n\t\t\t\t  Sheet bound commands\n     +toplevel:subsheet:col:row\t  launch vd with subsheet of toplevel at top-of-stack, and cursor at\n\t\t\t\t  col and row; all arguments are optional\n\n     -f, --filetype=filetype\t  tsv\t\t     set loader to use for filetype instead of file\n\t\t\t\t  extension\n     -y, --confirm-overwrite=F\t  True\t\t     overwrite existing files without confirmation\n     --mouse-interval=int\t  1\t\t     max time between press/release for click (ms)\n     --null-value=NoneType\t  None\t\t     a value to be counted as null\n     --undo=bool\t\t  True\t\t     enable undo/redo\n     --col-cache-size=int\t  0\t\t     max number of cache entries in each cached column\n     --clean-names\t\t  False\t\t     clean column/sheet names to be valid Python iden‐\n\t\t\t\t\t\t     tifiers\n     --default-width=int\t  20\t\t     default column width\n     --default-height=int\t  10\t\t     default column height\n     --textwrap-cells=bool\t  True\t\t     wordwrap text for multiline rows\n     --quitguard\t\t  False\t\t     confirm before quitting last sheet\n     --debug\t\t\t  False\t\t     exit on error and display stacktrace\n     --skip=int\t\t\t  0\t\t     skip N rows before header\n     --header=int\t\t  1\t\t     parse first N rows as column names\n     --load-lazy\t\t  False\t\t     load subsheets always (False) or lazily (True)\n     --force-256-colors\t\t  False\t\t     use 256 colors even if curses reports fewer\n     --use-default-colors\t  False\t\t     curses use default terminal colors\n     --note-pending=str\t\t  ⌛\t\t     note to display for pending cells\n     --note-format-exc=str\t  ?\t\t     cell note for an exception during formatting\n     --note-getter-exc=str\t  !\t\t     cell note for an exception during computation\n     --note-type-exc=str\t  !\t\t     cell note for an exception during type conversion\n     --scroll-incr=int\t\t  3\t\t     amount to scroll with scrollwheel\n     --name-joiner=str\t\t  _\t\t     string to join sheet or column names\n     --value-joiner=str\t\t\t\t     string to join display values\n     --wrap\t\t\t  False\t\t     wrap text to fit window width on TextSheet\n     --save-filetype=str\t  tsv\t\t     specify default file type to save as\n     --profile=str\t\t\t\t     filename to save binary profiling data\n     --min-memory-mb=int\t  0\t\t     minimum memory to continue loading and async pro‐\n\t\t\t\t\t\t     cessing\n     --input-history=str\t\t\t     basename of file to store persistent input his‐\n\t\t\t\t\t\t     tory\n     --encoding=str\t\t  utf-8\t\t     encoding passed to codecs.open\n     --encoding-errors=str\t  surrogateescape    encoding_errors passed to codecs.open\n     --bulk-select-clear\t  False\t\t     clear selected rows before new bulk selections\n     --some-selected-rows\t  False\t\t     if no rows selected, if True, someSelectedRows\n\t\t\t\t\t\t     returns all rows; if False, fails\n     --delimiter=str\t\t\t\t     field delimiter to use for tsv/usv filetype\n     --row-delimiter=str\t\t\t     \" row delimiter to use for tsv/usv filetype\n     --tsv-safe-newline=str\t\t\t     replacement for newline character when saving to\n\t\t\t\t\t\t     tsv\n     --tsv-safe-tab=str\t\t\t\t     replacement for tab character when saving to tsv\n     --visibility=int\t\t  0\t\t     visibility level (0=low, 1=high)\n     --expand-col-scanrows=int\t  1000\t\t     number of rows to check when expanding columns (0\n\t\t\t\t\t\t     = all)\n     --json-indent=NoneType\t  None\t\t     indent to use when saving json\n     --json-sort-keys\t\t  False\t\t     sort object keys when saving to json\n     --default-colname=str\t\t\t     column name to use for non-dict rows\n     --filetype=str\t\t\t\t     specify file type\n     --confirm-overwrite=bool\t  True\t\t     whether to prompt for overwrite confirmation on\n\t\t\t\t\t\t     save\n     --safe-error=str\t\t  #ERR\t\t     error string to use while saving\n     --clipboard-copy-cmd=str\t\t\t     command to copy stdin to system clipboard\n     --clipboard-paste-cmd=str\t\t\t     command to get contents of system clipboard\n     --fancy-chooser\t\t  False\t\t     a nicer selection interface for aggregators and\n\t\t\t\t\t\t     jointype\n     --describe-aggrs=str\t  mean stdev\t     numeric aggregators to calculate on Describe\n\t\t\t\t\t\t     sheet\n     --histogram-bins=int\t  0\t\t     number of bins for histogram of numeric columns\n     --numeric-binning\t\t  False\t\t     bin numeric columns into ranges\n     --replay-wait=float\t  0.0\t\t     time to wait between replayed commands, in sec‐\n\t\t\t\t\t\t     onds\n     --replay-movement\t\t  False\t\t     insert movements during replay\n     --visidata-dir=str\t\t  ~/.visidata/\t     directory to load and store additional files\n     --rowkey-prefix=str\t  キ\t\t     string prefix for rowkey in the cmdlog\n     --cmdlog-histfile=str\t\t\t     file to autorecord each cmdlog action to\n     --regex-flags=str\t\t  I\t\t     flags to pass to re.compile() [AILMSUX]\n     --regex-maxsplit=int\t  0\t\t     maxsplit to pass to regex.split\n     --default-sample-size=int\t  100\t\t     number of rows to sample for regex.split\n     --show-graph-labels=bool\t  True\t\t     show axes and legend on graph\n     --plot-colors=str\t\t\t\t     list of distinct colors to use for plotting dis‐\n\t\t\t\t\t\t     tinct objects\n     --zoom-incr=float\t\t  2.0\t\t     amount to multiply current zoomlevel when zooming\n     --motd-url=str\t\t\t\t     source of randomized startup messages\n     --dir-recurse\t\t  False\t\t     walk source path recursively on DirSheet\n     --dir-hidden\t\t  False\t\t     load hidden files on DirSheet\n     --config=str\t\t  ~/.visidatarc\t     config file to exec in Python\n     --play=str\t\t\t\t\t     file.vd to replay\n     --batch\t\t\t  False\t\t     replay in batch mode (with no interface and all\n\t\t\t\t\t\t     status sent to stdout)\n     --output=NoneType\t\t  None\t\t     save the final visible sheet to output at the end\n\t\t\t\t\t\t     of replay\n     --preplay=str\t\t\t\t     longnames to preplay before replay\n     --imports=str\t\t  plugins\t     imports to preload before .visidatarc (command-\n\t\t\t\t\t\t     line only)\n     --incr-base=float\t\t  1.0\t\t     start value for column increments\n     --csv-dialect=str\t\t  excel\t\t     dialect passed to csv.reader\n     --csv-delimiter=str\t  ,\t\t     delimiter passed to csv.reader\n     --csv-quotechar=str\t  \"\t\t     quotechar passed to csv.reader\n     --csv-skipinitialspace=bool  True\t\t     skipinitialspace passed to csv.reader\n     --csv-escapechar=NoneType\t  None\t\t     escapechar passed to csv.reader\n     --csv-lineterminator=str\t\t\t     \" lineterminator passed to csv.writer\n     --safety-first\t\t  False\t\t     sanitize input/output to handle edge cases, with\n\t\t\t\t\t\t     a performance cost\n     --fixed-rows=int\t\t  1000\t\t     number of rows to check for fixed width columns\n     --fixed-maxcols=int\t  0\t\t     max number of fixed-width columns to create (0 is\n\t\t\t\t\t\t     no max)\n     --postgres-schema=str\t  public\t     The desired schema for the Postgres database\n     --http-max-next=int\t  0\t\t     max next.url pages to follow in http response\n     --html-title=str\t\t  <h2>{sheet.name}</h2>\n\t\t\t\t\t\t     table header when saving to html\n     --pcap-internet=str\t  n\t\t     (y/s/n) if save_dot includes all internet hosts\n\t\t\t\t\t\t     separately (y), combined (s), or does not include\n\t\t\t\t\t\t     the internet (n)\n     --graphviz-edge-labels=bool  True\t\t     whether to include edge labels on graphviz dia‐\n\t\t\t\t\t\t     grams\n     --pdf-tables\t\t  False\t\t     parse PDF for tables instead of pages of text\n     --plugins-url=str\t\t  https://visidata.org/plugins/plugins.jsonl\n\t\t\t\t\t\t     source of plugins sheet\n\n   DISPLAY OPTIONS\n     Display options can only be set via the Options Sheet or a .visidatarc (see FILES).\n\n     disp_splitwin_pct\t 0\t\t     height of second sheet on screen\n     disp_currency_fmt\t %.02f\t\t     default fmtstr to format for currency values\n     disp_float_fmt\t {:.02f}\t     default fmtstr to format for float values\n     disp_int_fmt\t {:.0f}\t\t     default fmtstr to format for int values\n     disp_date_fmt\t %Y-%m-%d\t     default fmtstr to strftime for date values\n     disp_note_none\t ⌀\t\t     visible contents of a cell whose value is None\n     disp_truncator\t …\t\t     indicator that the contents are only partially visible\n     disp_oddspace\t ·\t\t     displayable character for odd whitespace\n     disp_more_left\t <\t\t     header note indicating more columns to the left\n     disp_more_right\t >\t\t     header note indicating more columns to the right\n     disp_error_val\t\t\t     displayed contents for computation exception\n     disp_ambig_width\t 1\t\t     width to use for unicode chars marked ambiguous\n     disp_pending\t\t\t     string to display in pending cells\n     color_note_pending\t bold magenta\t     color of note in pending cells\n     color_note_type\t 226 yellow\t     color of cell note for non-str types in anytype columns\n     color_note_row\t 220 yellow\t     color of row note on left edge\n     disp_column_sep\t |\t\t     separator between columns\n     disp_keycol_sep\t ║\t\t     separator between key columns and rest of columns\n     disp_rowtop_sep\t |\n     disp_rowmid_sep\t ⁝\n     disp_rowbot_sep\t ⁝\n     disp_rowend_sep\t ║\n     disp_keytop_sep\t ║\n     disp_keymid_sep\t ║\n     disp_keybot_sep\t ║\n     disp_endtop_sep\t ║\n     disp_endmid_sep\t ║\n     disp_endbot_sep\t ║\n     disp_selected_note\t •\n     disp_sort_asc\t ↑↟⇞⇡⇧⇑\t\t     characters for ascending sort\n     disp_sort_desc\t ↓↡⇟⇣⇩⇓\t\t     characters for descending sort\n     color_default\t normal\t\t     the default color\n     color_default_hdr\t bold\t\t     color of the column headers\n     color_bottom_hdr\t underline\t     color of the bottom header row\n     color_current_row\t reverse\t     color of the cursor row\n     color_current_col\t bold\t\t     color of the cursor column\n     color_current_hdr\t bold reverse\t     color of the header for the cursor column\n     color_column_sep\t 246 blue\t     color of column separators\n     color_key_col\t 81 cyan\t     color of key columns\n     color_hidden_col\t 8\t\t     color of hidden columns on metasheets\n     color_selected_row\t 215 yellow\t     color of selected rows\n     disp_rstatus_fmt\t  {sheet.longname} {sheet.nRows:9d} {sheet.rowtype}\n\t\t\t\t\t     right-side status format string\n     disp_status_fmt\t {sheet.shortcut}› {sheet.name}|\n\t\t\t\t\t     status line prefix\n     disp_lstatus_max\t 0\t\t     maximum length of left status line\n     disp_status_sep\t  |\t\t     separator between statuses\n     color_keystrokes\t white\t\t     color of input keystrokes on status line\n     color_status\t bold\t\t     status line color\n     color_error\t red\t\t     error message color\n     color_warning\t yellow\t\t     warning message color\n     color_top_status\t underline\t     top window status bar color\n     color_active_status bold\t\t      active window status bar color\n     color_inactive_status 8\t\t     inactive window status bar color\n     color_working\t green\t\t     color of system running smoothly\n     color_edit_cell\t normal\t\t     cell color to use when editing cell\n     disp_edit_fill\t _\t\t     edit field fill character\n     disp_unprintable\t ·\t\t     substitute character for unprintables\n     disp_histogram\t *\t\t     histogram element character\n     disp_histolen\t 50\t\t     width of histogram column\n     disp_replay_play\t ▶\t\t     status indicator for active replay\n     disp_replay_pause\t ‖\t\t     status indicator for paused replay\n     color_status_replay green\t\t     color of replay status indicator\n     disp_pixel_random\t False\t\t     randomly choose attr from set of pixels instead of most\n\t\t\t\t\t     common\n     color_graph_hidden\t 238 blue\t     color of legend for hidden attribute\n     color_graph_selected bold\t\t     color of selected graph points\n     color_graph_axis\t bold\t\t     color for graph axis labels\n     color_add_pending\t green\t\t     color for rows pending add\n     color_change_pending reverse yellow     color for cells pending modification\n     color_delete_pending red\t\t     color for rows pending delete\n     color_xword_active\t green\t\t     color of active clue\n\nEXAMPLES\n\t   vd foo.tsv\n     open the file foo.tsv in the current directory\n\n\t   vd -f sqlite bar.db\n     open the file bar.db as a sqlite database\n\n\t   vd foo.tsv -n -f sqlite bar.db\n     open foo.tsv as tsv and bar.db as a sqlite database\n\n\t   vd -f sqlite foo.tsv bar.db\n     open both foo.tsv and bar.db as a sqlite database\n\n\t   vd -b countries.fixed -o countries.tsv\n     convert countries.fixed (in fixed width format) to countries.tsv (in tsv format)\n\n\t   vd postgres://username:password@hostname:port/database\n     open a connection to the given postgres database\n\n\t   vd --play tests/pivot.vd --replay-wait 1 --output tests/pivot.tsv\n     replay tests/pivot.vd, waiting 1 second between commands, and output the final sheet to\n     test/pivot.tsv\n\n\t   ls -l | vd -f fixed --skip 1 --header 0\n     parse the output of ls -l into usable data\n\n\t   ls | vd | lpr\n     interactively select a list of filenames to send to the printer\n\n\t   vd newfile.tsv\n     open a blank sheet named newfile if file does not exist\n\n\t   vd sample.xlsx +:sheet1:2:3\n     launch with sheet1 at top-of-stack, and cursor at column 2 and row 3\n\n\t   vd -P open-plugins\n     preplay longname open-plugins before starting the session\n\nFILES\n     At the start of every session, VisiData looks for $HOME/.visidatarc, and calls Python exec() on\n     its contents if it exists. For example:\n\n\toptions.min_memory_mb=100  # stop processing without 100MB free\n\n\tbindkey('0', 'go-leftmost')   # alias '0' to go to first column, like vim\n\n\tdef median(values):\n\t    L = sorted(values)\n\t    return L[len(L)//2]\n\n\taggregator('median', median)\n\n     Functions defined in .visidatarc are available in python expressions (e.g. in derived columns).\n\nSUPPORTED SOURCES\n     Core VisiData includes these sources:\n\n\ttsv (tab-separated value)\n\t   Plain and simple. VisiData writes tsv format by default. See the --tsv-delimiter option.\n\n\tcsv (comma-separated value)\n\t   .csv files are a scourge upon the earth, and still regrettably common.\n\t   See the --csv-dialect, --csv-delimiter, --csv-quotechar, and --csv-skipinitialspace\n\t   options.\n\t   Accepted dialects are excel-tab, unix, and excel.\n\n\tfixed (fixed width text)\n\t   Columns are autodetected from the first 1000 rows (adjustable with --fixed-rows).\n\n\tjson (single object) and jsonl/ndjson/ldjson (one object per line).\n\t   Cells containing lists (e.g. [3]) or dicts ({3}) can be expanded into new columns with (\n\t   and unexpanded with ).\n\n\tsqlite\n\t   May include multiple tables. The initial sheet is the table directory; Enter loads the\n\t   entire table into memory. z^S saves modifications to source.\n\n     URL schemes are also supported:\n\thttp (requires requests); can be used as transport for with another filetype\n\n     For a list of all remaining formats supported by VisiData, see https://visidata.org/formats.\n\n     In addition, .zip, .gz, .bz2, and .xz files are decompressed on the fly.\n\nSUPPORTED OUTPUT FORMATS\n     These are the supported savers:\n\n\ttsv (tab-separated value)\n\tcsv (comma-separated value)\n\tjson (one object with all rows)\n\tjsonl/ndjson/ldjson (one object per line/row)\n\t   All expanded subcolumns must be closed (with )) to retain the same structure.\n\tsqlite (save to source with z^S)\n\tmd (markdown table)\n\nAUTHOR\n     VisiData was made by Saul Pwanson <vd@saul.pw>.\n\nLinux/MacOS\t\t\t\t     Feb 07, 2021\t\t\t\t   Linux/MacOS\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-17T20:37:43.179Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "voice-commands",
      "content": "best open source voice commands?\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T21:13:53.732Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "voice-control.js",
      "content": "```js\nimport notify from './notifications.js'\nimport { getNewID, fetchPlugin, getReflectedCoordinates } from './helpers.js'\nimport { parseVariables } from './variables.js'\n\nexport function openVoiceCommandWindow(){\n\n  const hans_tag = document.createElement('hans-tag')\n  hans_tag.setAttribute('hans-id', 'voice-commands')\n  document.body.appendChild(hans_tag)\n\n  const microphone = document.createElement('h1')\n  const microphone_icon = document.createElement('span')\n  microphone_icon.classList.add('fa','fa-microphone')\n  microphone.appendChild(microphone_icon)\n  hans_tag.querySelector('main').appendChild(microphone)\n\n  const code = document.createElement('code')\n  hans_tag.querySelector('main').appendChild(code)\n\n  try {\n    let SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition\n    \n    let recognition = new SpeechRecognition()\n    recognition.lang = 'en-US'\n    recognition.interimResults = false\n    recognition.maxAlternatives = 5\n    recognition.continuous = true\n\n    recognition.onstart = function(e){\n      if(document.body.querySelector('[hans-id=\"voice-commands\"]') === null){\n        const hans_tag = document.createElement('hans-tag')\n        hans_tag.setAttribute('hans-id', 'voice-commands')\n        document.body.appendChild(hans_tag)\n        const code = document.createElement('code')\n        hans_tag.querySelector('main').appendChild(code)\n      }\n    }\n\n    recognition.onspeechend = function(e){\n      hans_tag.remove()\n    }\n\n    recognition.onerror = function(e){\n    }\n\n    recognition.onsoundend = function(e){\n      code.innerHTML += '\\n'\n    }\n\n    recognition.onresult = function(e){\n      let current = e.resultIndex\n      code.innerHTML += [...e.results[current]].map(d => {\n        return `<p><span>${d.transcript}</span><span>${d.confidence}</span></p>`\n      })\n      let transcript = e.results[current][0].transcript.toLowerCase().trim()\n      handleTranscriptAvailable(e.results[current])\n    }\n\n    recognition.start()\n\n  } catch(e) {\n    console.log(e)\n  }\n\n\n  const download_anchor_node = document.createElement('a')\n  download_anchor_node.setAttribute(\"download\", \"voice-commands.hans\")\n  hans_tag.querySelector('footer').appendChild( download_anchor_node )\n\n\n  let parsed_data = {}\n\n\n  function handleTranscriptAvailable(transcripts){\n    const new_data_id = getNewID()\n    parsed_data[new_data_id] = [];\n\n    [...transcripts].forEach(el => {\n      const new_transcript = el.transcript.toLowerCase()\n\n      parsed_data[new_data_id].push({\n        hans_id: getNewID(),\n        type: 'transcription',\n        parent_id: new_data_id,\n        created: Date.now(),\n        transcript: new_transcript,\n        confidence: el.confidence\n      })\n\n    })\n\n    const dataStr = \"data:text/hans;charset=utf-8,\" +\n      encodeURIComponent(JSON.stringify(parsed_data))\n    download_anchor_node.innerText = 'download'\n    download_anchor_node.setAttribute(\"href\", dataStr)\n    download_anchor_node.setAttribute(\"download\", \"create-object.hans\")\n  }\n\n\n  async function handleSaveTranscript(){\n    let new_transcript_object = await fetchPlugin('transcript')\n    let coordinates = getReflectedCoordinates()\n\n    const new_vars = parseVariables(new_transcript_object.variables)\n    const new_metadata = {\n      hans_id: getNewID(),\n      notes:JSON.stringify(parsed_data),\n      created: Date.now()\n    }\n\n    const new_object = Object.assign(new_transcript_object, new_vars, coordinates, new_metadata)\n    dispatch('UPDATE OBJECT', new_object)\n\n  }\n\n  const save_button = document.createElement('button')\n  save_button.classList.add('footer-button')\n  save_button.innerHTML = '<span class=\"fa fa-floppy-o\"></span> '\n  hans_tag.querySelector('footer').appendChild(save_button)  \n  save_button.onclick = handleSaveTranscript\n\n\n}\n\n```\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.518Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "webcomponent-boilerplate",
      "content": "\n## Default HTML Element\n\n```js\n\nclass DataroomElement extends HTMLElement {\n  connectedCallback(){\n  }\n  \n  static get observedAttributes() {\n    return [];\n  }\n\n  attributeChangedCallback(name, old_value, new_value){\n    switch(name){\n      default:\n    }\n  }\n\n}\n\ncustomElements.define('dataroom-element', DataroomElement)\n\n```\n\n\nnota bena: elements defined named must have a dash in them. \n\nFor instance:\n\n```HTML\n<hans-element></hans-element>\n<e-y-e></e-y-e>\n<object-list></object-list>\n```\n\nbut not\n```HTML\n<hans_element></hans_element>\n<EYE></EYE>\n```\n\nTags cannot be self closing.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-08-09T19:34:38.428Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "webpack",
      "content": "# Webpack\nhttps://webpack.js.org/\n\nAt its core, **webpack** is a _static module bundler_ for modern JavaScript applications. When webpack processes your application, it internally builds a [dependency graph](https://webpack.js.org/concepts/dependency-graph/) from one or more _entry points_ and then combines every module your project needs into one or more _bundles_, which are static assets to serve your content from.\n\n\n\n> **webpack** is an free and open-source module bundler for JavaScript. It is made primarily for JavaScript, but it can transform front-end assets such as HTML, CSS, and images if the corresponding loaders are included. Webpack takes modules with dependencies and generates static assets representing those modules.Webpack takes the dependencies and generates a dependency graph allowing web developers to use a modular approach for their web application development purposes. It can be used from the command line or can be configured using a configuration file which is named webpack.config.js. This file defines rules, plugins, etc., for a project. (webpack is highly extensible via rules which allow developers to write custom tasks that they want to perform when bundling files together.) \n>\n> Node.js is required for using webpack.\n>\n> Webpack provides code on demand using the moniker code splitting. The Technical Committee 39 for ECMAScript is working on standardization of a function that loads additional code: \"proposal-dynamic-import\".\n>\n> [Wikipedia](https://en.wikipedia.org/wiki/Webpack)\n\n\nhttps://medium.com/@danharris_io/setup-a-webpack-built-vanilla-js-css-simple-static-site-b4e92003e634\n\nhttps://hackernoon.com/a-dead-simple-webpack-4-example-with-vanilla-javascript-no-libraries-and-frameworks-8b9d0a7684be\n\nhttps://www.freecodecamp.org/news/how-to-write-simple-modern-javascript-apps-with-webpack-and-progressive-web-techniques-a30354eab214/\n\nhttps://dev.to/robotspacefish/how-i-set-up-webpack-and-babel-with-vanilla-js-2k5e\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2024-02-15T20:37:17.518Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "webrtc-notes",
      "content": "https://www.mobilefish.com/download/webrtc/webrtc_noserver.html\n\nhttps://github.com/lesmana/webrtc-without-signaling-server\n\nhttps://mac-blog.org.ua/webrtc-one-to-one-without-signaling-server/\n\nhttps://github.com/muaz-khan/WebRTC-Experiment\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-17T22:27:46.236Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "window-switcher",
      "content": "assuming javascript, write code that listens for the user to press ctrl-1 to ctrl-0, and when they do clear the window and open the assigned html file.\n\n// First, define the key codes for each Ctrl-1 to Ctrl-0 combination\n\nconst keyCodes = {\n\n  '49': 'file1.html', // Ctrl-1\n\n  '50': 'file2.html', // Ctrl-2\n\n  '51': 'file3.html', // Ctrl-3\n\n  '52': 'file4.html', // Ctrl-4\n\n  '53': 'file5.html', // Ctrl-5\n\n  '54': 'file6.html', // Ctrl-6\n\n  '55': 'file7.html', // Ctrl-7\n\n  '56': 'file8.html', // Ctrl-8\n\n  '57': 'file9.html', // Ctrl-9\n\n  '48': 'file10.html' // Ctrl-0\n\n}\n\n\n// Define a function to handle the key event\n\nfunction handleKeyEvent(e) {\n\n  // Check if the Ctrl key is being held down\n\n  if (e.ctrlKey) {\n\n    // Check if the key pressed is one of the specified keys\n\n    if (keyCodes[e.keyCode]) {\n\n      // Clear the window\n\n      document.body.innerHTML = '';\n\n      \n\n      // Open the assigned HTML file\n\n      window.location.href = keyCodes[e.keyCode];\n\n    }\n\n  }\n\n}\n\n\n// Add the event listener to the document\n\ndocument.addEventListener('keydown', handleKeyEvent);\n\n\n// To assign a specific HTML file to a key combination, simply add it to the keyCodes object using the appropriate key code. For example:\n\nkeyCodes['81'] = 'file11.html'; // Ctrl-Q\n\n\n// Save the file and open it in a browser window. When you press a Ctrl-1 to Ctrl-0 combination, the window should be cleared and the assigned HTML file opened. You can modify the keyCodes object to assign different HTML files to different keys.\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-13T19:58:08.917Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "write a script that",
      "content": "```js\n#!/usr/bin/env node\n\nconst fs = require('fs');\nconst dotenv = require(\"dotenv\");\ndotenv.config();\nconst { logContent } = require('./log-content.js');\nconst { sanitizeString } = require('./sanitize-strings.js');\nconst path_name = process.env.OBSIDIAN_PATH_NAME\nconst { queryLLMForCode } = require(\"./query-llm.js\");\n\nconst PROMPT = `Write a node.js script that ${process.argv[3]}. Export the function using module.exports.`;\n\nasync function main() {\n\n  logContent(`*Prompted*:${PROMPT}\\n`); \n  const responseText = await queryLLMForCode(PROMPT);\n  const title = process.argv[2]\n  const markdown = `---\ntarget_filename:${title}.js\ntype: script\n---\n# Prompt\n${PROMPT}\n\n# Script\n\\`\\`\\`js\n\\n${responseText}\\n\n\\`\\`\\``;\n\n  const FILE_PATH = path_name + title + '.md';\n\n  fs.writeFileSync(__dirname + FILE_PATH, markdown);\n  fs.writeFileSync(__dirname + '/' + title + '.js', responseText);\n  logContent(`*CREATED FILE:*[[${title}]]\\n`);\n  logContent('\\n---\\n');\n\n}\n\nmain();\n```\n\n"
    },
    {
      "lastIndexed": "never",
      "lastUpdated": "2023-06-20T21:32:02.092Z",
      "latitude": 33.736061,
      "longitude": 118.2922,
      "id": "wss",
      "content": "Web sockets\n\nhas a component\n\n```html\n\t<wss-server></wss-sever>\n\n```\n\n\n```html\n<wss-server server=\"${target-server}\"></wss-server>\n```\n\n\n\n\n"
    }
  ],
  "links": [
    {
      "source": "2023-08-06",
      "target": "Context Switcher"
    },
    {
      "source": "2023-08-06",
      "target": "Sync, Save and Export"
    },
    {
      "source": "2023-08-06",
      "target": "Notebooks"
    },
    {
      "source": "2023-08-06",
      "target": "Manual"
    },
    {
      "source": "2023-08-06",
      "target": "Settings"
    },
    {
      "source": "2023-08-06",
      "target": "Notebooks"
    },
    {
      "source": "2023-08-06",
      "target": "Router"
    },
    {
      "source": "2023-08-06",
      "target": "3d view"
    },
    {
      "source": "2023-08-06",
      "target": "Editor"
    },
    {
      "source": "2023-08-06",
      "target": "Rendered View"
    },
    {
      "source": "3d view",
      "target": "Construct Graph"
    },
    {
      "source": "A Controversial Tutorial about Javascript, HTML and CSS",
      "target": "Cobol and HTML"
    },
    {
      "source": "Async Generator",
      "target": "WebWorkers"
    },
    {
      "source": "Brain.js",
      "target": "Neural Network"
    },
    {
      "source": "Build System",
      "target": "Obsidian"
    },
    {
      "source": "Build System",
      "target": "Mermaid.js"
    },
    {
      "source": "Build System",
      "target": "Gatsby.js"
    },
    {
      "source": "Build System",
      "target": "lasso.js"
    },
    {
      "source": "Build System",
      "target": "parcel.js"
    },
    {
      "source": "Build System",
      "target": "11ty"
    },
    {
      "source": "Build System",
      "target": "webpack"
    },
    {
      "source": "Build System",
      "target": "yarn"
    },
    {
      "source": "Build System",
      "target": "babel.js"
    },
    {
      "source": "Build System",
      "target": "rollup.js"
    },
    {
      "source": "Build System",
      "target": "snowpack.js"
    },
    {
      "source": "Build System",
      "target": "esbuild"
    },
    {
      "source": "Build System",
      "target": "broccoli"
    },
    {
      "source": "Build System",
      "target": "browserify"
    },
    {
      "source": "Build System",
      "target": "brunch.io"
    },
    {
      "source": "Build System",
      "target": "grunt"
    },
    {
      "source": "Build System",
      "target": "gulp"
    },
    {
      "source": "Build System",
      "target": "system.js"
    },
    {
      "source": "Build System",
      "target": "bazel build"
    },
    {
      "source": "Build System",
      "target": "buck"
    },
    {
      "source": "Build System",
      "target": "pants"
    },
    {
      "source": "Build System",
      "target": "nomnoml"
    },
    {
      "source": "C",
      "target": "WebASM"
    },
    {
      "source": "C",
      "target": "WebAsm"
    },
    {
      "source": "C",
      "target": "C"
    },
    {
      "source": "C",
      "target": "Business Physics"
    },
    {
      "source": "CSS",
      "target": "CSS Rotation Snippet"
    },
    {
      "source": "Command Line arguments in node.js",
      "target": "Node.js"
    },
    {
      "source": "D3 Map Boilerplate",
      "target": "Screen Shot 2022-03-21 at 14.26.32 1.png"
    },
    {
      "source": "D3 Map Boilerplate",
      "target": "x - 0.455 * k, y - 0.238 * k], [x + 0.455 * k, y + 0.238 * k"
    },
    {
      "source": "D3 Map Boilerplate",
      "target": "x - 0.425 * k + epsilon, y + 0.120 * k + epsilon], [x - 0.214 * k - epsilon, y + 0.234 * k - epsilon"
    },
    {
      "source": "D3 Map Boilerplate",
      "target": "x - 0.214 * k + epsilon, y + 0.166 * k + epsilon], [x - 0.115 * k - epsilon, y + 0.234 * k - epsilon"
    },
    {
      "source": "D3 Map Boilerplate",
      "target": "x + 0.320 * k, y + 0.204 * k], [x + 0.380 * k, y + 0.234 * k"
    },
    {
      "source": "D3 Map Boilerplate",
      "target": "Screen Shot 2022-03-21 at 14.26.32.png"
    },
    {
      "source": "D3.js Centroid",
      "target": "D3.js"
    },
    {
      "source": "D3.js",
      "target": "Mapping"
    },
    {
      "source": "D3.js",
      "target": "D3.js Centroid"
    },
    {
      "source": "DATAROOM",
      "target": "firefox-plugin"
    },
    {
      "source": "DATAROOM",
      "target": "Obsidian Plugins"
    },
    {
      "source": "DATAROOM",
      "target": "QR Code Element"
    },
    {
      "source": "DATAROOM",
      "target": "programming/Routes"
    },
    {
      "source": "DATAROOM",
      "target": "CrashDeck/README"
    },
    {
      "source": "Databases",
      "target": "saisquoi.ai/MongoDB|MongoDB"
    },
    {
      "source": "Databases",
      "target": "SQL"
    },
    {
      "source": "Drawing AI",
      "target": "aa0ae14c9a1e05d3b105799060b7e326_MD5.png|Open: Pasted image 20231107200044.png"
    },
    {
      "source": "Drawing AI",
      "target": "aa0ae14c9a1e05d3b105799060b7e326_MD5.png"
    },
    {
      "source": "Editor",
      "target": "Hashtags"
    },
    {
      "source": "Editor",
      "target": "Embeddings"
    },
    {
      "source": "File Handling in Node.js",
      "target": "Watch a folder in node.js"
    },
    {
      "source": "File Handling in Node.js",
      "target": "Node.js"
    },
    {
      "source": "File handling in Browser",
      "target": "Browser"
    },
    {
      "source": "Flipper Runes",
      "target": "Runes"
    },
    {
      "source": "Fretted MIDI keyboard in Javascript",
      "target": "DevTerm"
    },
    {
      "source": "GeoJSON",
      "target": "tippecanoe"
    },
    {
      "source": "Git",
      "target": "Git Submodules"
    },
    {
      "source": "Git",
      "target": "Github SFTP Instructions"
    },
    {
      "source": "Git",
      "target": "Oh Shit, Git!.pdf"
    },
    {
      "source": "Git",
      "target": "Oh Shit, Git!.pdf"
    },
    {
      "source": "Google",
      "target": "Reflective Earth"
    },
    {
      "source": "Google",
      "target": "Google Earth Engine"
    },
    {
      "source": "Graduated Symbol Map Plot",
      "target": "Pasted image 20220224092931.png"
    },
    {
      "source": "Graduated Symbol Map Plot",
      "target": "Vega Lite"
    },
    {
      "source": "Graduated Symbol Map Plot",
      "target": "Albers USA Projection"
    },
    {
      "source": "HTML Accessibility",
      "target": "WAI-ARIA"
    },
    {
      "source": "HTML Accessibility",
      "target": "WCAG"
    },
    {
      "source": "HTML Partial",
      "target": "HTML"
    },
    {
      "source": "HTML to IMG expiriment",
      "target": "Puppeteer"
    },
    {
      "source": "HTMLCad",
      "target": "Aframe.js"
    },
    {
      "source": "Headless Browser",
      "target": "Chrome Commands"
    },
    {
      "source": "Intersphere.earth",
      "target": "Ben Toms"
    },
    {
      "source": "JavaScript Proxy",
      "target": "MapData"
    },
    {
      "source": "Javascript Arrays",
      "target": "Screenshot 2023-07-26 at 10.10.46 AM.png"
    },
    {
      "source": "Javascript Arrays",
      "target": "Screenshot 2023-07-26 at 10.10.42 AM.png"
    },
    {
      "source": "Javascript Arrays",
      "target": "Screenshot 2023-07-26 at 10.10.37 AM.png"
    },
    {
      "source": "Javascript Libraries",
      "target": "Javascript Spreadsheets"
    },
    {
      "source": "Jetson Nano",
      "target": "AI BOX"
    },
    {
      "source": "Legends in D3.js",
      "target": "D3.js"
    },
    {
      "source": "Legends in D3.js",
      "target": "Pasted image 20220518141648.png"
    },
    {
      "source": "Lie Economy",
      "target": "Lie Economy"
    },
    {
      "source": "Lie Economy",
      "target": "News Dive August 15 2022"
    },
    {
      "source": "Machine Learning",
      "target": "attention-is-all-you-need.pdf"
    },
    {
      "source": "Manual",
      "target": "programming/README"
    },
    {
      "source": "MapBox",
      "target": "MapBox Filters"
    },
    {
      "source": "MapBox",
      "target": "Albers USA Projection"
    },
    {
      "source": "Mapping",
      "target": "HMDA Map"
    },
    {
      "source": "Mapping",
      "target": "Pasted image 20220224093625.png"
    },
    {
      "source": "Mapping",
      "target": "Fairplay Mapping Product Design Brief"
    },
    {
      "source": "MuckRaker",
      "target": "Tesla P40"
    },
    {
      "source": "Neural Network",
      "target": "Pasted image 20220314112517.png"
    },
    {
      "source": "Neural Network",
      "target": "Google Notebooks"
    },
    {
      "source": "Neural Network",
      "target": "Jupiter Notebooks"
    },
    {
      "source": "Neural Network",
      "target": "Brain.js"
    },
    {
      "source": "Neural Network",
      "target": "Feedforward neural network"
    },
    {
      "source": "Node.js",
      "target": "Debian"
    },
    {
      "source": "Node.js",
      "target": "rollup.js"
    },
    {
      "source": "Notebook Page",
      "target": "3d view"
    },
    {
      "source": "Notebook Page",
      "target": "Editor"
    },
    {
      "source": "Notebook Page",
      "target": "Map View"
    },
    {
      "source": "Notebooks",
      "target": "Notebook Page"
    },
    {
      "source": "Notebooks",
      "target": "Create New Notebook"
    },
    {
      "source": "Obsidian Setup",
      "target": "Obsidian"
    },
    {
      "source": "One Time Code",
      "target": "OTC"
    },
    {
      "source": "One Time Code",
      "target": "AWS"
    },
    {
      "source": "One Time Code",
      "target": "Signed URL"
    },
    {
      "source": "One Time Code",
      "target": "DATAROOM"
    },
    {
      "source": "OpenSCAD",
      "target": "Gear"
    },
    {
      "source": "OpenSCAD",
      "target": "Music Gear"
    },
    {
      "source": "OpenSCAD",
      "target": "stl-file component"
    },
    {
      "source": "PDF Handling in Linux",
      "target": "PDFS"
    },
    {
      "source": "PDF Handling in Linux",
      "target": "pdfunity"
    },
    {
      "source": "PDF Handling in Linux",
      "target": "poppler-utils"
    },
    {
      "source": "PDF Handling in Linux",
      "target": "ghostscript"
    },
    {
      "source": "PPP Loans",
      "target": "LCMS"
    },
    {
      "source": "Pico-8",
      "target": "Pasted image 20220310124013.png"
    },
    {
      "source": "Pico-8",
      "target": "Voxatron"
    },
    {
      "source": "Puppeteer",
      "target": "Command Line arguments in node.js"
    },
    {
      "source": "Python",
      "target": "MongoDB"
    },
    {
      "source": "Python",
      "target": "Neo4j"
    },
    {
      "source": "Python",
      "target": "SQL"
    },
    {
      "source": "QR Code Element",
      "target": "],[6,18],[6,22],[6,26],[6,30],[6,34],[6,22,38],[6,24,42],[6,26,46],[6,28,50],[6,30,54],[6,32,58],[6,34,62],[6,26,46,66],[6,26,48,70],[6,26,50,74],[6,30,54,78],[6,30,56,82],[6,30,58,86],[6,34,62,90],[6,28,50,72,94],[6,26,50,74,98],[6,30,54,78,102],[6,28,54,80,106],[6,32,58,84,110],[6,30,58,86,114],[6,34,62,90,118],[6,26,50,74,98,122],[6,30,54,78,102,126],[6,26,52,78,104,130],[6,30,56,82,108,134],[6,34,60,86,112,138],[6,30,58,86,114,142],[6,34,62,90,118,146],[6,30,54,78,102,126,150],[6,24,50,76,102,128,154],[6,28,54,80,106,132,158],[6,32,58,84,110,136,162],[6,26,54,82,110,138,166],[6,30,58,86,114,142,170"
    },
    {
      "source": "QR Code Element",
      "target": "1,26,19],[1,26,16],[1,26,13],[1,26,9],[1,44,34],[1,44,28],[1,44,22],[1,44,16],[1,70,55],[1,70,44],[2,35,17],[2,35,13],[1,100,80],[2,50,32],[2,50,24],[4,25,9],[1,134,108],[2,67,43],[2,33,15,2,34,16],[2,33,11,2,34,12],[2,86,68],[4,43,27],[4,43,19],[4,43,15],[2,98,78],[4,49,31],[2,32,14,4,33,15],[4,39,13,1,40,14],[2,121,97],[2,60,38,2,61,39],[4,40,18,2,41,19],[4,40,14,2,41,15],[2,146,116],[3,58,36,2,59,37],[4,36,16,4,37,17],[4,36,12,4,37,13],[2,86,68,2,87,69],[4,69,43,1,70,44],[6,43,19,2,44,20],[6,43,15,2,44,16],[4,101,81],[1,80,50,4,81,51],[4,50,22,4,51,23],[3,36,12,8,37,13],[2,116,92,2,117,93],[6,58,36,2,59,37],[4,46,20,6,47,21],[7,42,14,4,43,15],[4,133,107],[8,59,37,1,60,38],[8,44,20,4,45,21],[12,33,11,4,34,12],[3,145,115,1,146,116],[4,64,40,5,65,41],[11,36,16,5,37,17],[11,36,12,5,37,13],[5,109,87,1,110,88],[5,65,41,5,66,42],[5,54,24,7,55,25],[11,36,12],[5,122,98,1,123,99],[7,73,45,3,74,46],[15,43,19,2,44,20],[3,45,15,13,46,16],[1,135,107,5,136,108],[10,74,46,1,75,47],[1,50,22,15,51,23],[2,42,14,17,43,15],[5,150,120,1,151,121],[9,69,43,4,70,44],[17,50,22,1,51,23],[2,42,14,19,43,15],[3,141,113,4,142,114],[3,70,44,11,71,45],[17,47,21,4,48,22],[9,39,13,16,40,14],[3,135,107,5,136,108],[3,67,41,13,68,42],[15,54,24,5,55,25],[15,43,15,10,44,16],[4,144,116,4,145,117],[17,68,42],[17,50,22,6,51,23],[19,46,16,6,47,17],[2,139,111,7,140,112],[17,74,46],[7,54,24,16,55,25],[34,37,13],[4,151,121,5,152,122],[4,75,47,14,76,48],[11,54,24,14,55,25],[16,45,15,14,46,16],[6,147,117,4,148,118],[6,73,45,14,74,46],[11,54,24,16,55,25],[30,46,16,2,47,17],[8,132,106,4,133,107],[8,75,47,13,76,48],[7,54,24,22,55,25],[22,45,15,13,46,16],[10,142,114,2,143,115],[19,74,46,4,75,47],[28,50,22,6,51,23],[33,46,16,4,47,17],[8,152,122,4,153,123],[22,73,45,3,74,46],[8,53,23,26,54,24],[12,45,15,28,46,16],[3,147,117,10,148,118],[3,73,45,23,74,46],[4,54,24,31,55,25],[11,45,15,31,46,16],[7,146,116,7,147,117],[21,73,45,7,74,46],[1,53,23,37,54,24],[19,45,15,26,46,16],[5,145,115,10,146,116],[19,75,47,10,76,48],[15,54,24,25,55,25],[23,45,15,25,46,16],[13,145,115,3,146,116],[2,74,46,29,75,47],[42,54,24,1,55,25],[23,45,15,28,46,16],[17,145,115],[10,74,46,23,75,47],[10,54,24,35,55,25],[19,45,15,35,46,16],[17,145,115,1,146,116],[14,74,46,21,75,47],[29,54,24,19,55,25],[11,45,15,46,46,16],[13,145,115,6,146,116],[14,74,46,23,75,47],[44,54,24,7,55,25],[59,46,16,1,47,17],[12,151,121,7,152,122],[12,75,47,26,76,48],[39,54,24,14,55,25],[22,45,15,41,46,16],[6,151,121,14,152,122],[6,75,47,34,76,48],[46,54,24,10,55,25],[2,45,15,64,46,16],[17,152,122,4,153,123],[29,74,46,14,75,47],[49,54,24,10,55,25],[24,45,15,46,46,16],[4,152,122,18,153,123],[13,74,46,32,75,47],[48,54,24,14,55,25],[42,45,15,32,46,16],[20,147,117,4,148,118],[40,75,47,7,76,48],[43,54,24,22,55,25],[10,45,15,67,46,16],[19,148,118,6,149,119],[18,75,47,31,76,48],[34,54,24,34,55,25],[20,45,15,61,46,16"
    },
    {
      "source": "QR Code Element",
      "target": "17,14,11,7],[32,26,20,14],[53,42,32,24],[78,62,46,34],[106,84,60,44],[134,106,74,58],[154,122,86,64],[192,152,108,84],[230,180,130,98],[271,213,151,119],[321,251,177,137],[367,287,203,155],[425,331,241,177],[458,362,258,194],[520,412,292,220],[586,450,322,250],[644,504,364,280],[718,560,394,310],[792,624,442,338],[858,666,482,382],[929,711,509,403],[1003,779,565,439],[1091,857,611,461],[1171,911,661,511],[1273,997,715,535],[1367,1059,751,593],[1465,1125,805,625],[1528,1190,868,658],[1628,1264,908,698],[1732,1370,982,742],[1840,1452,1030,790],[1952,1538,1112,842],[2068,1628,1168,898],[2188,1722,1228,958],[2303,1809,1283,983],[2431,1911,1351,1051],[2563,1989,1423,1093],[2699,2099,1499,1139],[2809,2213,1579,1219],[2953,2331,1663,1273"
    },
    {
      "source": "QR Code Element",
      "target": "],[6,18],[6,22],[6,26],[6,30],[6,34],[6,22,38],[6,24,42],[6,26,46],[6,28,50],[6,30,54],[6,32,58],[6,34,62],[6,26,46,66],[6,26,48,70],[6,26,50,74],[6,30,54,78],[6,30,56,82],[6,30,58,86],[6,34,62,90],[6,28,50,72,94],[6,26,50,74,98],[6,30,54,78,102],[6,28,54,80,106],[6,32,58,84,110],[6,30,58,86,114],[6,34,62,90,118],[6,26,50,74,98,122],[6,30,54,78,102,126],[6,26,52,78,104,130],[6,30,56,82,108,134],[6,34,60,86,112,138],[6,30,58,86,114,142],[6,34,62,90,118,146],[6,30,54,78,102,126,150],[6,24,50,76,102,128,154],[6,28,54,80,106,132,158],[6,32,58,84,110,136,162],[6,26,54,82,110,138,166],[6,30,58,86,114,142,170"
    },
    {
      "source": "QR Code Element",
      "target": "1,26,19],[1,26,16],[1,26,13],[1,26,9],[1,44,34],[1,44,28],[1,44,22],[1,44,16],[1,70,55],[1,70,44],[2,35,17],[2,35,13],[1,100,80],[2,50,32],[2,50,24],[4,25,9],[1,134,108],[2,67,43],[2,33,15,2,34,16],[2,33,11,2,34,12],[2,86,68],[4,43,27],[4,43,19],[4,43,15],[2,98,78],[4,49,31],[2,32,14,4,33,15],[4,39,13,1,40,14],[2,121,97],[2,60,38,2,61,39],[4,40,18,2,41,19],[4,40,14,2,41,15],[2,146,116],[3,58,36,2,59,37],[4,36,16,4,37,17],[4,36,12,4,37,13],[2,86,68,2,87,69],[4,69,43,1,70,44],[6,43,19,2,44,20],[6,43,15,2,44,16],[4,101,81],[1,80,50,4,81,51],[4,50,22,4,51,23],[3,36,12,8,37,13],[2,116,92,2,117,93],[6,58,36,2,59,37],[4,46,20,6,47,21],[7,42,14,4,43,15],[4,133,107],[8,59,37,1,60,38],[8,44,20,4,45,21],[12,33,11,4,34,12],[3,145,115,1,146,116],[4,64,40,5,65,41],[11,36,16,5,37,17],[11,36,12,5,37,13],[5,109,87,1,110,88],[5,65,41,5,66,42],[5,54,24,7,55,25],[11,36,12],[5,122,98,1,123,99],[7,73,45,3,74,46],[15,43,19,2,44,20],[3,45,15,13,46,16],[1,135,107,5,136,108],[10,74,46,1,75,47],[1,50,22,15,51,23],[2,42,14,17,43,15],[5,150,120,1,151,121],[9,69,43,4,70,44],[17,50,22,1,51,23],[2,42,14,19,43,15],[3,141,113,4,142,114],[3,70,44,11,71,45],[17,47,21,4,48,22],[9,39,13,16,40,14],[3,135,107,5,136,108],[3,67,41,13,68,42],[15,54,24,5,55,25],[15,43,15,10,44,16],[4,144,116,4,145,117],[17,68,42],[17,50,22,6,51,23],[19,46,16,6,47,17],[2,139,111,7,140,112],[17,74,46],[7,54,24,16,55,25],[34,37,13],[4,151,121,5,152,122],[4,75,47,14,76,48],[11,54,24,14,55,25],[16,45,15,14,46,16],[6,147,117,4,148,118],[6,73,45,14,74,46],[11,54,24,16,55,25],[30,46,16,2,47,17],[8,132,106,4,133,107],[8,75,47,13,76,48],[7,54,24,22,55,25],[22,45,15,13,46,16],[10,142,114,2,143,115],[19,74,46,4,75,47],[28,50,22,6,51,23],[33,46,16,4,47,17],[8,152,122,4,153,123],[22,73,45,3,74,46],[8,53,23,26,54,24],[12,45,15,28,46,16],[3,147,117,10,148,118],[3,73,45,23,74,46],[4,54,24,31,55,25],[11,45,15,31,46,16],[7,146,116,7,147,117],[21,73,45,7,74,46],[1,53,23,37,54,24],[19,45,15,26,46,16],[5,145,115,10,146,116],[19,75,47,10,76,48],[15,54,24,25,55,25],[23,45,15,25,46,16],[13,145,115,3,146,116],[2,74,46,29,75,47],[42,54,24,1,55,25],[23,45,15,28,46,16],[17,145,115],[10,74,46,23,75,47],[10,54,24,35,55,25],[19,45,15,35,46,16],[17,145,115,1,146,116],[14,74,46,21,75,47],[29,54,24,19,55,25],[11,45,15,46,46,16],[13,145,115,6,146,116],[14,74,46,23,75,47],[44,54,24,7,55,25],[59,46,16,1,47,17],[12,151,121,7,152,122],[12,75,47,26,76,48],[39,54,24,14,55,25],[22,45,15,41,46,16],[6,151,121,14,152,122],[6,75,47,34,76,48],[46,54,24,10,55,25],[2,45,15,64,46,16],[17,152,122,4,153,123],[29,74,46,14,75,47],[49,54,24,10,55,25],[24,45,15,46,46,16],[4,152,122,18,153,123],[13,74,46,32,75,47],[48,54,24,14,55,25],[42,45,15,32,46,16],[20,147,117,4,148,118],[40,75,47,7,76,48],[43,54,24,22,55,25],[10,45,15,67,46,16],[19,148,118,6,149,119],[18,75,47,31,76,48],[34,54,24,34,55,25],[20,45,15,61,46,16"
    },
    {
      "source": "QR Code Element",
      "target": "17,14,11,7],[32,26,20,14],[53,42,32,24],[78,62,46,34],[106,84,60,44],[134,106,74,58],[154,122,86,64],[192,152,108,84],[230,180,130,98],[271,213,151,119],[321,251,177,137],[367,287,203,155],[425,331,241,177],[458,362,258,194],[520,412,292,220],[586,450,322,250],[644,504,364,280],[718,560,394,310],[792,624,442,338],[858,666,482,382],[929,711,509,403],[1003,779,565,439],[1091,857,611,461],[1171,911,661,511],[1273,997,715,535],[1367,1059,751,593],[1465,1125,805,625],[1528,1190,868,658],[1628,1264,908,698],[1732,1370,982,742],[1840,1452,1030,790],[1952,1538,1112,842],[2068,1628,1168,898],[2188,1722,1228,958],[2303,1809,1283,983],[2431,1911,1351,1051],[2563,1989,1423,1093],[2699,2099,1499,1139],[2809,2213,1579,1219],[2953,2331,1663,1273"
    },
    {
      "source": "QR Code Element",
      "target": "],[6,18],[6,22],[6,26],[6,30],[6,34],[6,22,38],[6,24,42],[6,26,46],[6,28,50],[6,30,54],[6,32,58],[6,34,62],[6,26,46,66],[6,26,48,70],[6,26,50,74],[6,30,54,78],[6,30,56,82],[6,30,58,86],[6,34,62,90],[6,28,50,72,94],[6,26,50,74,98],[6,30,54,78,102],[6,28,54,80,106],[6,32,58,84,110],[6,30,58,86,114],[6,34,62,90,118],[6,26,50,74,98,122],[6,30,54,78,102,126],[6,26,52,78,104,130],[6,30,56,82,108,134],[6,34,60,86,112,138],[6,30,58,86,114,142],[6,34,62,90,118,146],[6,30,54,78,102,126,150],[6,24,50,76,102,128,154],[6,28,54,80,106,132,158],[6,32,58,84,110,136,162],[6,26,54,82,110,138,166],[6,30,58,86,114,142,170"
    },
    {
      "source": "QR Code Element",
      "target": "1,26,19],[1,26,16],[1,26,13],[1,26,9],[1,44,34],[1,44,28],[1,44,22],[1,44,16],[1,70,55],[1,70,44],[2,35,17],[2,35,13],[1,100,80],[2,50,32],[2,50,24],[4,25,9],[1,134,108],[2,67,43],[2,33,15,2,34,16],[2,33,11,2,34,12],[2,86,68],[4,43,27],[4,43,19],[4,43,15],[2,98,78],[4,49,31],[2,32,14,4,33,15],[4,39,13,1,40,14],[2,121,97],[2,60,38,2,61,39],[4,40,18,2,41,19],[4,40,14,2,41,15],[2,146,116],[3,58,36,2,59,37],[4,36,16,4,37,17],[4,36,12,4,37,13],[2,86,68,2,87,69],[4,69,43,1,70,44],[6,43,19,2,44,20],[6,43,15,2,44,16],[4,101,81],[1,80,50,4,81,51],[4,50,22,4,51,23],[3,36,12,8,37,13],[2,116,92,2,117,93],[6,58,36,2,59,37],[4,46,20,6,47,21],[7,42,14,4,43,15],[4,133,107],[8,59,37,1,60,38],[8,44,20,4,45,21],[12,33,11,4,34,12],[3,145,115,1,146,116],[4,64,40,5,65,41],[11,36,16,5,37,17],[11,36,12,5,37,13],[5,109,87,1,110,88],[5,65,41,5,66,42],[5,54,24,7,55,25],[11,36,12],[5,122,98,1,123,99],[7,73,45,3,74,46],[15,43,19,2,44,20],[3,45,15,13,46,16],[1,135,107,5,136,108],[10,74,46,1,75,47],[1,50,22,15,51,23],[2,42,14,17,43,15],[5,150,120,1,151,121],[9,69,43,4,70,44],[17,50,22,1,51,23],[2,42,14,19,43,15],[3,141,113,4,142,114],[3,70,44,11,71,45],[17,47,21,4,48,22],[9,39,13,16,40,14],[3,135,107,5,136,108],[3,67,41,13,68,42],[15,54,24,5,55,25],[15,43,15,10,44,16],[4,144,116,4,145,117],[17,68,42],[17,50,22,6,51,23],[19,46,16,6,47,17],[2,139,111,7,140,112],[17,74,46],[7,54,24,16,55,25],[34,37,13],[4,151,121,5,152,122],[4,75,47,14,76,48],[11,54,24,14,55,25],[16,45,15,14,46,16],[6,147,117,4,148,118],[6,73,45,14,74,46],[11,54,24,16,55,25],[30,46,16,2,47,17],[8,132,106,4,133,107],[8,75,47,13,76,48],[7,54,24,22,55,25],[22,45,15,13,46,16],[10,142,114,2,143,115],[19,74,46,4,75,47],[28,50,22,6,51,23],[33,46,16,4,47,17],[8,152,122,4,153,123],[22,73,45,3,74,46],[8,53,23,26,54,24],[12,45,15,28,46,16],[3,147,117,10,148,118],[3,73,45,23,74,46],[4,54,24,31,55,25],[11,45,15,31,46,16],[7,146,116,7,147,117],[21,73,45,7,74,46],[1,53,23,37,54,24],[19,45,15,26,46,16],[5,145,115,10,146,116],[19,75,47,10,76,48],[15,54,24,25,55,25],[23,45,15,25,46,16],[13,145,115,3,146,116],[2,74,46,29,75,47],[42,54,24,1,55,25],[23,45,15,28,46,16],[17,145,115],[10,74,46,23,75,47],[10,54,24,35,55,25],[19,45,15,35,46,16],[17,145,115,1,146,116],[14,74,46,21,75,47],[29,54,24,19,55,25],[11,45,15,46,46,16],[13,145,115,6,146,116],[14,74,46,23,75,47],[44,54,24,7,55,25],[59,46,16,1,47,17],[12,151,121,7,152,122],[12,75,47,26,76,48],[39,54,24,14,55,25],[22,45,15,41,46,16],[6,151,121,14,152,122],[6,75,47,34,76,48],[46,54,24,10,55,25],[2,45,15,64,46,16],[17,152,122,4,153,123],[29,74,46,14,75,47],[49,54,24,10,55,25],[24,45,15,46,46,16],[4,152,122,18,153,123],[13,74,46,32,75,47],[48,54,24,14,55,25],[42,45,15,32,46,16],[20,147,117,4,148,118],[40,75,47,7,76,48],[43,54,24,22,55,25],[10,45,15,67,46,16],[19,148,118,6,149,119],[18,75,47,31,76,48],[34,54,24,34,55,25],[20,45,15,61,46,16"
    },
    {
      "source": "QR Code Element",
      "target": "17,14,11,7],[32,26,20,14],[53,42,32,24],[78,62,46,34],[106,84,60,44],[134,106,74,58],[154,122,86,64],[192,152,108,84],[230,180,130,98],[271,213,151,119],[321,251,177,137],[367,287,203,155],[425,331,241,177],[458,362,258,194],[520,412,292,220],[586,450,322,250],[644,504,364,280],[718,560,394,310],[792,624,442,338],[858,666,482,382],[929,711,509,403],[1003,779,565,439],[1091,857,611,461],[1171,911,661,511],[1273,997,715,535],[1367,1059,751,593],[1465,1125,805,625],[1528,1190,868,658],[1628,1264,908,698],[1732,1370,982,742],[1840,1452,1030,790],[1952,1538,1112,842],[2068,1628,1168,898],[2188,1722,1228,958],[2303,1809,1283,983],[2431,1911,1351,1051],[2563,1989,1423,1093],[2699,2099,1499,1139],[2809,2213,1579,1219],[2953,2331,1663,1273"
    },
    {
      "source": "Redis",
      "target": "Redis Streams"
    },
    {
      "source": "Render PDF in Node.js",
      "target": "PDFS"
    },
    {
      "source": "Render PDF in Node.js",
      "target": "Node.js"
    },
    {
      "source": "SQL",
      "target": "Become a SELECT Star.pdf"
    },
    {
      "source": "SQL",
      "target": "2022-04-22"
    },
    {
      "source": "SQL",
      "target": "0,'hello'],[1,'world'"
    },
    {
      "source": "SQL",
      "target": "Graph Theory"
    },
    {
      "source": "Shapley_value",
      "target": "Pasted image 20221003102311.png"
    },
    {
      "source": "Simple Modal Component",
      "target": "Embed CSS with Javascript"
    },
    {
      "source": "Small World Networks",
      "target": "small-world-networks.pdf"
    },
    {
      "source": "Sublime Snippet for Custom HTML Element",
      "target": "Custom HTML Element"
    },
    {
      "source": "Sublime Snippet for Custom HTML Element",
      "target": "Sublime Text"
    },
    {
      "source": "Sublime Text Settings",
      "target": "Sublime Text"
    },
    {
      "source": "Swagger",
      "target": "OpenAPI"
    },
    {
      "source": "Swagger",
      "target": "Nest.js"
    },
    {
      "source": "Three JS",
      "target": "3d Graphics"
    },
    {
      "source": "Three JS",
      "target": "OpenGL"
    },
    {
      "source": "Three JS",
      "target": "OpenGL ES"
    },
    {
      "source": "WebWorkers",
      "target": "ServiceWorker"
    },
    {
      "source": "WebWorkers",
      "target": "SharedWorker"
    },
    {
      "source": "XLST",
      "target": "XML"
    },
    {
      "source": "XML to JSON",
      "target": "Node.js"
    },
    {
      "source": "custom-obsidian-plugins",
      "target": "typescript"
    },
    {
      "source": "Debian Overview",
      "target": "Debian"
    },
    {
      "source": "Installing Debian",
      "target": "Debian"
    },
    {
      "source": "installing docker",
      "target": "Debian"
    },
    {
      "source": "kubernetes",
      "target": "Debian"
    },
    {
      "source": "deck.gl",
      "target": "pydeck"
    },
    {
      "source": "deck.gl",
      "target": "Pasted image 20220224090047.png"
    },
    {
      "source": "engineers-log-2024-02-08",
      "target": "LLM"
    },
    {
      "source": "engineers-log-2024-02-10",
      "target": "askmendel.ai"
    },
    {
      "source": "engineers-log-2024-02-10",
      "target": "askmendel-spec-work-sprint"
    },
    {
      "source": "engineers-log-2024-02-13",
      "target": "programming/file-clerk"
    },
    {
      "source": "engineers-log-2024-02-13",
      "target": "geo-map"
    },
    {
      "source": "engineers-log-2024-02-13",
      "target": "dataroom-editor"
    },
    {
      "source": "engineers-log-2024-02-13",
      "target": "md-renderer"
    },
    {
      "source": "engineers-log-2024-02-13",
      "target": "plugin-wizard"
    },
    {
      "source": "engineers-log-2024-02-20",
      "target": "webasm-component"
    },
    {
      "source": "engineers-log-2024-02-22",
      "target": "Catalogue Raisonné Generator"
    },
    {
      "source": "engineers-log-2024-02-22",
      "target": "Extract Text by Page from PDF"
    },
    {
      "source": "engineers-log-2024-02-24",
      "target": "consolidate-scripts"
    },
    {
      "source": "engineers-log-2024-02-24",
      "target": "vanilla-js-structure"
    },
    {
      "source": "engineers-log-2024-02-24",
      "target": "video-security-system"
    },
    {
      "source": "engineers-log-2024-02-24",
      "target": "index-images"
    },
    {
      "source": "ffmpeg",
      "target": "VR AI Videos"
    },
    {
      "source": "geo-map",
      "target": "gardening-index"
    },
    {
      "source": "hans-js-project-switcher",
      "target": "Atom text editor"
    },
    {
      "source": "hans-js-project-workflow",
      "target": "create-new-project"
    },
    {
      "source": "hans-js-project-workflow",
      "target": "delete-project"
    },
    {
      "source": "hans-js-project-workflow",
      "target": "save-project"
    },
    {
      "source": "hans-js-project-workflow",
      "target": "auto-reload"
    },
    {
      "source": "hans-js-project-workflow",
      "target": "programming/file-clerk"
    },
    {
      "source": "hans-js-project-workflow",
      "target": "notification-workflow wss"
    },
    {
      "source": "hans-js",
      "target": "hans-js-secret-password-copy"
    },
    {
      "source": "hans-js",
      "target": "device-0-overview"
    },
    {
      "source": "hans-js",
      "target": "johnny-decimal"
    },
    {
      "source": "index",
      "target": "search-pdf"
    },
    {
      "source": "index",
      "target": "fuse.js"
    },
    {
      "source": "kepler.gl",
      "target": "deck.gl"
    },
    {
      "source": "pochade-web-framework",
      "target": "952abb65f7b7cbc3451536cbfa78e05e_MD5.png|Open: Pasted image 20231107112224.png"
    },
    {
      "source": "pochade-web-framework",
      "target": "952abb65f7b7cbc3451536cbfa78e05e_MD5.png"
    },
    {
      "source": "pochade-web-framework",
      "target": "Stable Diffusion Component"
    },
    {
      "source": "printed-books",
      "target": "annurev-polisci-051120-013649.pdf"
    },
    {
      "source": "server",
      "target": "server.js"
    },
    {
      "source": "set-last-url",
      "target": "wss"
    },
    {
      "source": "tippecanoe",
      "target": "GeoJSON"
    },
    {
      "source": "tippecanoe",
      "target": "MapBox"
    },
    {
      "source": "tippecanoe",
      "target": "Tile Server"
    },
    {
      "source": "write a script that",
      "target": "${title}"
    }
  ]
}